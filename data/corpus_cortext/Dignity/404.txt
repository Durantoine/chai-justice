human rights council session october agenda items annual report united nations high commissioner human rights reports office high commissioner promotion protection human rights civil political economic social cultural rights including right development right privacy digital age report united nations high commissioner human rights edited versiondistr general september original english summary present report mandated human rights council resolution high commissioner analyses widespread use states businesses artificial intelligence including profiling automated technologies affects enjoyment right privacy associated rights following overview international legal framework high commissioner highlights aspects artificial intelligence facilitate interference privacy provides examples impacts right privacy associated rights four key sectors high commissioner discusses approaches addressing challenges providing set recommendations states businesses regarding design implementation safeguards prevent minimize harmful outcomes facilitate full enjoyment benefits artificial intelligence provide present report submitted deadline include recent information introduction present report submitted pursuant human rights council resolution council requested united nations high commissioner human rights organize expert seminar discuss artificial intelligence including profiling automated technologies may without proper safeguards affect enjoyment right privacy prepare thematic report issue submit council session technological development recent years captured public imagination artificial intelligence particular technologies indeed technologies tremendous force good helping overcome great challenges current time however technologies also negative even catastrophic effects deployed without sufficient regard impact human rights present report focus coronavirus disease pandemic ongoing global health crisis provides powerful highly visible example speed scale impact diverse spheres life across globe systems using multiple types data geolocation credit card transport system health demographic information personal networks used track spread disease systems used flag individuals potentially infected infectious requiring isolate quarantine systems used predictive allocation grades resulted outcomes discriminated students public schools poorer neighbourhoods developments demonstrated broad range impacts systems people daily lives right privacy affected cases using personal information often making decisions tangible effects people lives nevertheless deeply intertwined question privacy various impacts enjoyment rights rights health education freedom movement freedom peaceful assembly freedom association freedom expression highest aspiration call action human rights united nations recognized digital age opened new frontiers human welfare knowledge exploration underscored digital technologies provide new means advocate defend exercise human rights nevertheless new technologies often used violate rights especially people already vulnerable left behind instance surveillance repression censorship online harassment including human rights defenders digitization welfare systems despite potential improve efficiency risks excluding people need emphasized advances new technologies must used erode human rights deepen inequality exacerbate existing discrimination stressed governance needs ensure fairness accountability explainability transparency security sphere reiterated call global prohibition lethal autonomous weapon systems present report builds upon two previous reports high commissioner issue right privacy digital age also incorporates insights virtual expert seminar organized pursuant council resolution preparation report postponed see generally accepted definition term artificial intelligence present report employed refer constellation processes technologies enabling computers complement replace specific tasks otherwise performed humans making decisions solving problems para includes limited machine learning deep learning held may well responses high commissioner call input present report legal framework article universal declaration human rights article international covenant civil political rights several international regional human rights instruments recognize right privacy fundamental human right right privacy plays pivotal role balance power state individual foundational right democratic society importance enjoyment exercise human rights online offline increasingly world growing right privacy expression human dignity linked protection human autonomy personal identity aspects privacy particular context use include informational privacy covering information exists derived person life decisions based information freedom make decisions one identity interference right privacy must arbitrary unlawful unlawful means states may interfere right privacy basis law accordance law law must comply provisions aims objectives international covenant civil political rights must specify detail precise circumstances interference permissible concept arbitrariness intended guarantee even interference provided law accordance provisions aims objectives covenant event reasonable particular circumstances interference right privacy must serve legitimate purpose necessary achieving legitimate purpose proportionate restriction must see call input received see article convention rights child article international convention protection rights migrant workers members families article convention rights persons disabilities article african charter rights welfare child article american convention human rights article convention protection human rights fundamental freedoms european convention human rights para committee rights child general comment paras para committee rights child general comment para european court human rights goodwin united kingdom application judgment july para para detailed analysis terms arbitrary unlawful see paras human rights committee general comment paras para toonen australia para van hulst netherlands paras madhewoo mauritius para para see also committee rights child general comment para least intrusive option available must impair essence right privacy right privacy applies everyone differences protection basis race colour sex language religion political opinion national social origin property birth status inconsistent principle laid articles international covenant civil political rights discrimination grounds also violates right equality law contained article covenant article international covenant civil political rights requires states respect ensure rights recognized covenant individuals within territory subject jurisdiction without discrimination words states must refrain violating rights recognized covenant obligation take positive steps protect enjoyment rights implies duty adopt adequate legislative measures safeguard individuals interference privacy whether emanates state authorities natural legal persons duty also reflected pillar guiding principles human rights outlines duty states protect adverse human rights impacts involving companies business enterprises responsibility respect internationally recognized human rights means avoid infringing human rights others address adverse human rights impacts involved pillar guiding principles business human rights provides authoritative blueprint enterprises regarding meet responsibility responsibility respect throughout enterprise activities business relationships iii impacts artificial intelligence right privacy human rights relevant features artificial intelligence systems operation systems facilitate deepen privacy intrusions interference rights variety ways include entirely new applications well features systems expand intensify incentivize interference right privacy notably increased collection use personal data systems typically rely large data sets often including personal data incentivizes widespread data collection storage processing many businesses optimize services collect much data possible example online businesses like social companies rely collection monetization massive amounts data internet users internet things rapidly growing source data businesses states alike data collection happens intimate private human rights committee general comment para para para human rights committee general comment para para see also human rights committee general comments paras para committee rights child general comment paras resolution human rights council unanimously endorsed guiding principles human rights wolflie christl corporate surveillance everyday life vienna cracked lab institute critical culture submission ranking digital spaces data brokers acquire merge analyse share personal data recipients data transactions largely shielded public scrutiny marginally inhibited existing legal frameworks resulting data sets large information collected unprecedented proportions apart exposing people private lives companies states data sets make individuals vulnerable number ways data breaches repeatedly exposed sensitive information millions people large data sets enable countless analysis sharing data third parties often amounting privacy intrusions incurring adverse human rights impacts arrangements enabling government agencies direct access data sets held businesses example increase likelihood arbitrary unlawful interference right privacy individuals concerned one particular concern possibility facilitated fusing data various sources time design data sets implications individuals identity example data set records gender binary misgenders identify male female storage personal data also carries particular risks data open future forms exploitation envisaged time data collection time data inaccurate irrelevant carry historic misidentification thereby causing biased erroneous outcomes future data processing noted systems exclusively rely processing personal data however even personal data involved human rights including right privacy may still adversely affected use shown tools widely used seek insights patterns human behaviour access right data sets possible draw conclusions many people particular neighbourhood likely attend certain place worship television shows may prefer even roughly time tend wake sleep tools make inferences individuals including mental physical condition enable identification groups people political personal leanings also used assess likelihood future behaviour events inferences predictions despite probabilistic nature basis decisions affecting people rights times fully automated way many inferences predictions deeply affect enjoyment right privacy including people autonomy right establish details identity also raise many questions concerning rights rights freedom thought opinion right freedom expression right fair trial related rights submissions centre communication governance national law university delhi derechos digital rights watch global partners digital international center law universidade federal uberl√¢ndia aaron rieke others data brokers open society london open society foundation see submission global network submissions centre communication governance national law university delhi derechos privacy international submission committee elimination racial discrimination general recommendation council europe guidelines addressing human rights impacts algorithmic systems appendix recommendation committee ministers member states human rights impacts algorithmic systems sect para submissions derechos digitales privacy decisions free error fact scalability solutions dramatically increase negative effects seemingly small error rates faulty outputs various sources start outputs algorithms probabilistic elements means uncertainty attached outputs moreover accuracy data used often questionable furthermore unrealistic expectations lead deployment tools equipped achieve desired goals example analysis hundreds medical tools diagnosing predicting risks developed high hopes revealed none fit clinical use outputs systems relying faulty data contribute human rights violations multitude ways example erroneously flagging individual likely terrorist committed welfare fraud biased data sets lead discriminatory decisions based systems particularly concerning processes many systems opaque complexity data environment algorithms models underlying development operation systems well intentional secrecy government private actors factors undermine meaningful ways public understand effects systems human rights society systems add important element opacity capable identifying patterns developing prescriptions difficult impossible explain often referred black box problem opacity challenging meaningfully scrutinize system obstacle effective accountability cases systems cause harm nevertheless worth systems entirely inscrutable concerns artificial intelligence systems key sectors present section illustrates concerns experienced practice considering four key areas application tools given rise concern submission european union agency fundamental rights bigdata discrimination vienna see committee elimination racial discrimination general recommendation panel digital cooperation age digital interdependence june submission see see see inioluwa deborah raji others closing accountability gap defining framework internal algorithmic auditing january artificial intelligence law enforcement national security criminal justice border management states increasingly integrating systems law enforcement national security criminal justice border management systems many may indeed cause concern present section focus select examples represent diverse emerging human rights issues systems often used forecasting tools use algorithms analyse large quantities data including historic data assess risks predict future trends depending purpose training data data analysed include example criminal records arrest records crime statistics records police interventions specific neighbourhoods social media posts communications data travel records may used create profiles people identify places likely sites increased criminal terrorist activity even flag individuals likely suspects future reoffenders privacy broader human rights implications activities vast first data sets used include information large numbers individuals thus implicating right privacy second trigger interventions state searches questioning arrest prosecution even though assessments seen basis reasonable suspicion due probabilistic nature predictions rights affected include rights privacy fair trial freedom arbitrary arrest detention right life third inherent opacity decisions raises particularly pressing questions concerning state accountability informs coercive measures even areas typically suffer general lack transparency activities forces fourth predictive tools carry inherent perpetuating even enhancing discrimination reflecting embedded historic racial ethnic bias data sets used disproportionate focus policing certain minorities developments field biometric recognition technology led increasing use law enforcement national security agencies biometric recognition relies comparison digital representation certain features individual face fingerprint iris voice gait representations database comparison higher lower probability deduced person person identified processes increasingly carried real time distance particular remote facial recognition increasingly deployed authorities across globe remote biometric recognition raises serious concerns international human rights law high commissioner highlighted previously analysis human rights implications digital technologies management see submission privacy international see also para see paras submission tech hive advisory limited see also committee elimination racial general recommendation para conference room paper united nations high commissioner human rights promotion protection human rights fundamental freedoms africans people african descent excessive use force human rights violations law enforcement officers available paras para submissions derechos digitales international center concerns reflect problems associated predictive tools including possibility erroneous identification individuals disproportionate impacts members certain groups moreover facial recognition technology used profile basis ethnicity race national origin gender characteristics remote biometric recognition linked deep interference right privacy person biometric information constitutes one key attributes personality reveals unique characteristics distinguishing persons moreover remote biometric recognition dramatically increases ability authorities systematically identity track individuals public spaces undermining ability people lives unobserved resulting direct negative effect exercise rights freedom expression peaceful assembly association well freedom movement background high commissioner therefore welcomes recent efforts limit ban use biometric recognition technologies tools also developed allegedly deduce people emotional mental state facial expressions predictive biometrics decide whether security threat facial emotional recognition systems operate possible automatically systematically infer emotional state human beings facial expressions lacks solid scientific basis found weak association emotions facial expressions facial expressions vary across cultures contexts making emotion susceptible bias misinterpretations given concerns use emotion recognition systems public authorities instance singling individuals police stops arrests assess veracity statements interrogations risks undermining human rights rights privacy liberty fair trial artificial intelligence systems public services systems increasingly used help deliver public services often stated goal developing efficient systems timely accurate delivery services also increasingly seen humanitarian contexts delivery humanitarian goods services may linked systems although legitimate even laudable goals deployment tools delivery public submission privacy paras para see also european court human rights reklos davourlis greece judgment april para see european data protection board european data protection supervisor joint opinion submissions international center law privacy international see also para submission european union see also european commission proposal regulation european parliament council laying harmonized rules artificial intelligence artificial intelligence act amending certain union legislative acts com final april art see see see see services may adverse impact human rights proper safeguards place used diverse public services ranging welfare entitlements flagging families visits childcare services decisions made large data sets include data also include information obtained private entities social media companies data brokers often gathered outside protective legal frameworks furthermore since computational power systems tends held private companies arrangements often mean private companies gain access data sets containing information large parts population raises privacy concerns well concerns historic bias embedded data affect public authorities major concern regarding use public services discriminatory particularly regard marginalized groups special rapporteur extreme poverty human rights warned digital welfare dystopia unfettered used expose survey punish welfare beneficiaries conditions imposed beneficiaries undermine individual autonomy choice concerns illustrated recently netherlands widely reported court ruling banned digital welfare fraud detection system found infringe right privacy system question provided central local authorities broad powers share analyse data previously kept separately including employment housing education benefits health insurance well forms identifiable data moreover tool targeted minority neighbourhoods leading facto discrimination based socioeconomic background use artificial intelligence employment context range employers across types sizes business demonstrate growing demand monitoring managing workers using technologies including systems people analytics claims provide efficient objective information employees include automated hiring promotion schemes dismissal focus technologies lies monitoring behaviour performance range applications systems also extends behaviour data pandemic accelerated trend two first companies provide workers preventive health schemes increasingly collect data second processes executed digitally people work home workplace monitoring systems taken people homes trends increase risk merging data workplace monitoring data inputs monitoring practices constitute vast privacy risks throughout full data life cycle adding data used purposes initially communicated employees result function see submission privacy submission digital rights watch analysis disparate impacts automation welfare systems see virginia eubanks automating inequality new york martin press see see also special rapporteur letter irl noted similar regarding digital services card reply thereto several references made present report communications sent special procedure mandate holders human rights council communications replies thereto available see see time quantitative social science basis many systems used management solid prone biases example company uses hiring algorithm trained historic data sets favour male white men resulting algorithm disfavour women people colour younger older people would equally qualified fill vacancy time structures transparency protect workers often lacking workers increasingly confronted little explanation monitoring practices situations companies genuine interest preventing workplace measures uphold interest often justify extensively invasive practices quantifying social modes interaction connected performance goals work workplace setting light power relationship employer employee one also envisage potential scenarios workers compelled waive away privacy rights exchange work artificial intelligence managing information online social media platforms use systems support content management decisions use systems rank content decide amplify downgrade including personalizing decisions different individual users based profiles automation also used implementing restrictions content including response different legal requirements within across jurisdictions filter obligations intermediaries relating perceived online harms risk expanding widespread reliance without consideration severe impact systems rights privacy freedom expression local global levels vast data sets curation amplification moderation systems rely created continuously expanded extensive online monitoring profiling platform users personal networks perpetual process collecting making inferences combined extreme market concentration led situation handful companies globally hold control profiles billions individuals networked public sphere large content curation done companies enormous market power raises concerns impact capacity individual form develop opinions two successive holders mandate special rapporteur promotion protection right freedom opinion expression pointed platform recommender systems tend focus maximizing user engagement relying insights people preferences demographic behavioural patterns shown often promote sensationalist content potentially reinforcing trends towards polarization moreover targeting information may unwelcome even lead dangerous privacy intrusions recommender systems example christl corporate surveillance everyday submission poland see also see see see see oth oth analysis automated content filtering see also para para para see survivors violence finding perpetrator offered potential friend social media platforms vice versa putting survivor risk addition bias majority dominant groups reflected data search results shown affect information shared minority vulnerable groups example research demonstrated disturbing degree gender racial bias search results addressing challenges need human approach new technologies general artificial intelligence particular recognized growing number experts stakeholders international community human approach offers help societies identify ways prevent limit harm maximizing benefits technological progress fundamental principles human approach requires application number core principles including equality participation accountability principles also heart sustainable development goals guiding principles business human rights addition requirements legality legitimacy necessity proportionality must consistently applied technologies deployed way facilitates realization economic social cultural rights ensuring key elements availability affordability accessibility quality achieved suffer human rights violations relating use access effective judicial remedies pointed restrictions right privacy must provided law necessary achieve legitimate goal proportionate goal practice means states required carefully determine measure able achieve set objective important objective impacts measure states also determine less invasive approaches could achieve results effectiveness measures need taken high commissioner already outlined necessary limitations safeguards context surveillance intelligence agencies law enforcement noted proportionality tests also lead conclusion certain measures must taken example requirements blanket indiscriminate retention communications data imposed telecommunications companies would fail submissions austria safiya umoja noble algorithms oppression new york new york university press general assembly resolution para human rights council resolutions para sixteenth preambular para paras para submissions austria privacy commissioner canada digital rights watch global network initiative privacy international para see detailed analysis role new technologies realization economic social rights international covenant civil political rights art guiding principles business human rights principle pillar iii paras test similarly imposing biometric identification requirements welfare benefits disproportionate alternative provided moreover crucial measures assessed isolation cumulative effects distinct interacting measures properly taken account example deciding deploy new surveillance tools state must take stock existing capacities effects enjoyment right privacy rights legislation regulation effective protection right privacy interlinked rights depends legal regulatory institutional frameworks established states importance effective legal protections data privacy laws grown emergence systems protections meet minimum standards identified previous report high commissioner right privacy data privacy frameworks account new threats linked use example laws could impose limitations type data may legally used shared legislators also consider strengthening individuals rights including granting rights meaningful explanation object fully automated decisions affect rights technologies continue necessary continue develop safeguards within data privacy frameworks one key element counter growing complexity opacity global data environment including vast information asymmetries independent data privacy oversight bodies bodies need effective enforcement powers adequately resourced civil society organizations empowered support enforcement data privacy laws including establishment robust complaint mechanisms beyond data privacy legislation broader range laws need reviewed potentially adopted address challenges way taking account diversity applications systems uses regulation specific enough address issues tailor responses risks involved higher risk human rights stricter legal requirements use technology accordingly sectors stakes individuals para court justice european union digital rights ireland others para see also court justice european union maximilan schrems data protection commissioner para finding legislation permitting public authorities access generalised basis content electronic communications must regarded compromising essence fundamental right respect private life para paras council europe protocol amending convention protection individuals automatic processing personal data adopted example response emergence new practices see general data protection regulation european union contains rights california privacy rights act authorizes regulator adopt rules effect see council europe recommendation committee ministers member human rights impacts algorithmic systems proposed act european union takes approach submissions online coalition global network initiative global partners digital contain support particularly high law enforcement national security criminal justice social employment health care education financial sector priority approach legislation regulation require prohibition certain technologies applications use cases would create potential actual impacts justified international human rights law including fail necessity proportionality tests moreover uses inherently conflict prohibition discrimination allowed example social scoring individuals governments systems categorize clusters prohibited discriminatory grounds banned line principles systems whose use presents risks human rights deployed certain contexts states need regulate use sale prevent mitigate adverse human rights impacts within outside state territory involvement human supervision prescribed adverse human rights impacts likely occur given take time assessed addressed states also impose moratoriums use potentially technology remote facial recognition ensured use violate human rights states also adopt robust export control regimes trade surveillance technologies order prevent sale technologies risk could used violating human rights including targeting human rights defenders journalists spectrum risks arising systems suggests need adequate independent impartial oversight development deployment use systems oversight carried combination administrative judicial parliamentary oversight bodies example addition data privacy consumer protection agencies sectoral regulators bodies national human rights institutions form part oversight system moreover regulators dedicated overseeing use help set fundamental standards ensure policy enforcement coherence high commissioner clarified requirements measures taken context criminal investigations purposes protection national security guide legislation area submission european union catelijne muller impact artificial intelligence human democracy rule law report council europe hoc committee artificial intelligence cahai june para united nations educational scientific cultural organization unesco draft text recommendation ethics artificial intelligence june para see european data protection board european data protection supervisor joint opinion submission derechos see para para reports special rapporteur protection right freedom opinion expression high commissioner also called moratorium granting export licences surveillance technologies see human rights due diligence states businesses ensure comprehensive human rights due diligence conducted systems acquired developed deployed operated well big data held individuals shared used well resourcing processes states may also require otherwise incentivize companies conduct comprehensive human rights due diligence aim human rights due diligence processes identify assess prevent mitigate adverse impacts human rights entity may cause may contribute directly linked due diligence processes reveal use human rights due lack meaningful avenues mitigate harms form use pursued assessing human rights impacts essential element human rights due diligence processes due diligence throughout entire life cycle system particular attention disproportionate impacts women girls lesbian gay bisexual transgender queer individuals persons disabilities persons belonging minorities older persons persons poverty persons vulnerable situation meaningful consultations carried potentially affected rights holders civil society experts interdisciplinary skills involved impact assessments including development evaluation mitigations states businesses continuously monitor impacts systems use verify whether adverse human rights impacts results human rights impact assessments action taken address human rights risks public consultations made public nexus situations close nexus state technology company require dedicated attention state important economic actor shape developed used beyond states role legal policy measures states work developers service providers private sector states take additional steps ensure used towards ends incompatible human rights steps applied across management companies research development funding financial support provided states technology companies privatization efforts public procurement practices states operate economic actors remain primary duty bearer international human rights law must proactively meet obligations time businesses remain responsible respecting human rights collaborating states seek ways honour human rights faced state requirements project office united nations high commissioner human rights ohchr developing guidance implementation guiding principles business human rights technology industry including responses human rights impact use technologies see overview human rights due diligence context see concise summary human rights impact assessment methodologies see para paras para see conflict human rights law example faced demands access data fail meet human rights standards use leverage resist mitigate harm could caused states enhance human rights protections consistently requiring responsible business conduct example export credit agencies offer support technology companies ensure companies robust track record conduct demonstrate robust due diligence processes states rely businesses deliver public goods services states must ensure oversee development deployment systems done demanding assessing information accuracy risks application risks effectively mitigated states use deliver public goods services transparency developers marketers operators users systems drastically increase efforts regarding transparency around use first step states businesses users make information available kind systems use purposes identity developer operator systems individuals systematically informed decisions made automatically help automation tools individuals also personal data provide become part data set used system moreover human applications states introduce containing key information tools use effective enforcement transparency obligations data access erasure rectification rights contained data privacy frameworks ensured particular attention given enabling individuals better understand control profiles compiled promoting transparency including sustained efforts overcome black box problem described development systematic deployment methodologies make systems explainable often referred algorithmic transparency utmost importance ensuring adequate rights protections essential used determine critical issues within processes relating social services essential realization economic social cultural rights researchers already developed range approaches goal increased investments area essential also take steps ensure intellectual property protections prevent guiding principles business human rights principle para see also para para council europe guidelines addressing human rights impacts algorithmic systems appendix recommendation committee ministers member states human rights impacts algorithmic systems sect para para para european union proposal act contains provisions register systems see overview elements algorithmic transparency see see scrutiny systems human rights impacts procurement rules updated reflect need transparency including auditability systems particular states avoid using systems material human rights impacts subject meaningful auditing conclusions recommendations conclusions present report highlighted undeniable steadily growing impacts technologies exercise right privacy human rights better worse pointed worrying developments including sprawling ecosystem largely personal data collection exchanges underlies parts systems widely used systems affect government approaches policing administration justice determine accessibility public services decide chance recruited job affect information people see share online moreover risk discrimination linked decisions real report outlines range ways address fundamental problems associated underscoring comprehensive human approach ensure sustainable solutions benefit nevertheless given diversity new questions arising context present report snapshot constantly evolving landscape areas deserve analysis include health education housing financial services biometric technologies becoming increasingly solution states international organizations technology companies area human rights guidance urgently needed furthermore one focus future work human rights perspective finding ways fill immense accountability gap global data environment lastly solutions overcoming discrimination urgently identified implemented recommendations high commissioner recommends states fully recognize need protect reinforce human rights development use governance central objective ensure equal respect enforcement human rights online offline ensure use compliance human rights interference right privacy human rights use provided law pursues legitimate aim complies principles necessity proportionality impair essence rights question expressly ban applications operated compliance international human rights law impose moratoriums sale use systems carry high risk enjoyment human rights unless adequate safeguards protect human rights place council europe guidelines addressing human rights impacts algorithmic systems appendix recommendation committee ministers member states human rights impacts algorithmic systems sect para see submissions germany derechos digitales freedom online coalition global partners para para impose moratorium use remote biometric recognition technologies public spaces least authorities responsible demonstrate compliance privacy data protection standards absence significant accuracy issues discriminatory impacts recommendations set paragraph implemented adopt effectively enforce independent impartial authorities data privacy legislation public private sectors essential prerequisite protection right privacy context adopt legislative regulatory frameworks adequately prevent mitigate multifaceted adverse human rights impacts linked use public private sectors ensure victims human rights violations abuses linked use systems access effective remedies require adequate explainability decisions significantly affect human rights particularly public sector enhance efforts combat discrimination linked use systems states business enterprises including conducting requiring supporting systematic assessments monitoring outputs systems impacts deployment ensure partnerships provision use technologies transparent subject independent human rights oversight result abdication government accountability human rights high commissioner recommends states business enterprises systematically conduct human rights due diligence throughout life cycle systems design develop deploy sell obtain operate key element human rights due diligence regular comprehensive human rights impact assessments dramatically increase transparency use including adequately informing public affected individuals enabling independent external auditing automated systems likely serious potential actual human rights impacts linked use transparency needed ensure participation relevant stakeholders decisions development deployment use particular affected individuals groups advance explainability decisions including funding conducting research towards goal high commissioner recommends business enterprises make efforts meet responsibility respect human rights including full operationalization guiding principles business human rights enhance efforts combat discrimination linked development sale operation systems including conducting systematic assessments monitoring outputs systems impacts deployment take decisive steps order ensure diversity workforce responsible development provide cooperate remediation legitimate processes caused contributed adverse human rights impacts including effective grievance mechanisms
