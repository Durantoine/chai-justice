house commons science technology committee algorithms decisionmaking fourth report session report together formal minutes relating report ordered house commons printed may published may authority house commons science technology committee science technology committee appointed house commons examine expenditure administration policy government office science associated public bodies current membership norman lamb liberal democrat north norfolk chair vicky ford conservative chelmsford bill grant conservative ayr carrick cumnock darren jones labour bristol north west liz kendall labour leicester west stephen metcalfe conservative south basildon east thurrock carol monaghan scottish national party glasgow north west damien moore conservative southport neil brien conservative harborough graham stringer labour blackley broughton martin whitfield labour east lothian powers committee one departmental select committees powers set house commons standing orders principally available internet via publication committee reports published committee website print order house evidence relating report published relevant inquiry page committee website committee staff current staff committee simon fiander clerk yohanna sallberg second clerk harry beeson committee specialist martin smith committee specialist seb motala committee specialist sonia draper senior committee assistant julie storey committee assistant sean kinsey media officer contacts correspondence addressed clerk science technology committee house commons london telephone number general inquiries committee address scitechcom algorithms contents summary introduction inquiry applications bias data sharing health sector criminal justice system web social media sector government data sharing getting value data bias training data insufficient data correlation without causation lack representation algorithm development community accountability transparency accountability principles codes audit certification ethics boards transparency right explanation centre data ethics innovation research regulatory environment automated decisions consent data protection impact assessments information commissioner powers sector regulation algorithms conclusions recommendations formal minutes witnesses published written evidence list reports committee current parliament algorithms summary algorithms long used aid last years growth big data machine learning driven increase algorithmic finance legal sector criminal justice system education healthcare well recruitment decisions giving loans targeting adverts social media plans autonomous vehicles public roads case inquiry made stephanie mathisen sense science raised question extent algorithms exacerbate reduce biases well need decisions made algorithms challenged understood regulated issues echo predecessor committee concerns inquiries big data artificial intelligence two years elapsed since committee called oversight body monitor address issues report identifies themes challenges newly established centre data ethics innovation address begins work report comes general data protection regulation gdpr becomes effective wake recent controversy centred around algorithm used cambridge analytica target political campaign test case reinforces need effective data protection regulation algorithms need data effectiveness value tends increase data used datasets brought together government play part algorithms revolution continuing make public sector datasets available big data developers also algorithm developers new data trusts government also produce maintain publish list algorithms significant impacts used within central government along projects underway planned public service algorithms aid private sector involvement also transparency government identify ministerial champion provide oversight algorithms used public sector departments approaches development deployment algorithms partnerships private sector government could realise great value tied databases including nhs negotiate improved public service delivery seeks arrangements transparency simply accept developers offer return data access crown commercial service commission review alan turing institute expert bodies set procurement model algorithms developed private sector partners fully realises value public sector government explore proposed data trusts could fully developed forum striking algorithm partnering deals urgent requirements partnership deals already struck without benefit comprehensive national guidance evolving field algorithms looking exploiting data patterns sometimes produce flawed biased decisions human often inexact endeavour result algorithmic decision may disproportionately affect certain groups algorithms centre data ethics innovation examine algorithm identify improve training data use unjustified correlations avoided meaningful causal relationships discernible algorithm developer teams established include sufficiently wide society groups might affected algorithm new body also evaluate accountability codes audits algorithms certification algorithm developers charging ethics boards oversight algorithmic advise embedded private sector well government bodies share data private sector developers given international nature digital innovation centre also engage organisations comparable jurisdictions order develop share best practice transparency must key underpinning algorithm accountability debate whether transparency involve sharing workings algorithm black box affected algorithm individuals whose data used whether alternatively explanation provided acknowledge practical difficulties sharing data understandable form default algorithms transparent algorithms question affect public centre data ethics innovation ico examine scope individuals able challenge results significant algorithm decisions affect appropriate seek redress impacts decisions algorithms might significantly adversely affect public rights believe answer combination explanation much transparency possible overall gdpr provide helpful protections affected algorithms whose data subsumed algorithm development including explicit consent requirements although remains uncertainty provisions interpreted challenge secure framework facilitates encourages innovation also maintains vital public trust confidence centre data ethics innovation information commissioner office ico keep operation gdpr review far governs algorithms report government may areas data protection legislation might need refinement start immediately review lessons cambridge analytica case welcome amendments made data protection bill give ico powers sought relation information notices avoiding delays experienced investigating cambridge analytica case government also ensure ico adequately funded carry new powers government along ico centre data ethics innovation continue monitor terms conditions rules gdpr applied ensure personal data protected consumers effectively informed acknowledging predominantly algorithms use data data protection impact assessments required gdpr essential safeguard ico centre data ethics innovation encourage publication also consider whether legislation provides sufficient powers compel data controllers prepare adequate impact assessments algorithms also important tasks centre data ethics innovation address around regulatory environment algorithms review extent algorithm oversight main regulators use results guide regulators extend work area needed information commissioner also make assessment back work whether needs greater powers perform regulatory oversight role sector regulators see priority government plans put centre data ethics innovation statutory footing set requirement report annually parliament results work allow others scrutinise effectiveness algorithms introduction algorithms used aid centuries computers core algorithm set instructions usually applied solve problem last years however witnessed exponential growth use automation power decisions impact lives societies increase digital data businesses access large datasets advent new family algorithms utilising machine learning artificial intelligence driven increase algorithmic see box spurred huge investment area recently announced sector deal worth almost billion including million newly allocated funding box machine learning artificial intelligence algorithms although single agreed definition similarities many used broadly set statistical tools algorithms combine form part intelligent software enabling computers simulate elements human behaviour learning reasoning classification often confused machine learning algorithms narrower subset technology describe family techniques allow computers learn directly examples data experience finding rules patterns human programmer explicitly specify contrast conventional algorithms fully coded instructions given machine learning algorithms objectives completes left learning use term machine learning algorithms report although recognise many use interchangeably algorithms availability big data increased computational power allowing algorithms identify patterns data royal society explained machine learning offers possibility extending automated processes allowing greater range depth without human input potential uses vast continues grow unprecedented rate thanks cheaper computing power google put benefits algorithmic decisionmaking become ever broadly distributed new use cases continue professor nick jennings upturn omidyar network public scrutiny automated decisions early lessons emerging methods government tech sector backs british industry multi million pound investment april industrial strategy artificial intelligence sector deal april science technology committee fifth report session robotics artificial intelligence para see also shane legg marcus hutter collection definitions intelligence frontiers artificial intelligence applications transpolitica para upturn omidyar network public scrutiny automated decisions early lessons emerging methods prof louise amoore royal society see also malicious use artificial intelligence forecasting prevention mitigation february google para algorithms range different industries machine learning already put use includes finance including access loans insurance legal sector criminal justice system education healthcare well recruitment decisions targeting adverts social media plans driverless vehicles public roads near future hetan shah royal statistical society believed best understand ubiquitous technology think almost public infrastructure royal academy engineering believes data generated increase use machine learning algorithms allow organisations consider much broader range datasets inputs previously possible providing opportunity better combining human machine intelligence smart way algorithms driven machine learning bring certain risks well benefits first fatal collision involving autonomous car march placed technologies heightened scrutiny led suspension selfdriving car tests uber recent controversy currently examined digital culture media sport committee inquiry fake news use algorithms cambridge analytica identify characteristics facebook users help target political campaign messaging test case reinforces need effective data protection regulation see chapter predecessor committee undertook work relevant algorithms reported big data examining opportunities proliferation big data associated risks recommended creation called council data ethics committee envisaged body responsible addressing growing legal ethical challenges associated balancing privacy anonymisation security public benefit response government agreed establish body would address key ethical challenges data science provide technical research thought leadership implications data science across sectors committee examined implications recently approved general data protection regulation gdpr become operational may transposed law data protection bill predecessor committee subsequent report robotics also reiterated call data ethics council recommended standing commission established alan turing institute focused establishing principles govern development application techniques well advising government regulation required limits progression alan turing institute wrote committee later welcoming committee recommendation royal academy engineering guardian news media autumn budget november para royal academy engineering para cars scrutiny uber pedestrian death financial times march uber halts car tests death bbc march digital culture media sport committee fake news accessed april facebook bans political data company cambridge analytica financial times march science technology committee fourth report session big data dilemma big data dilemma para ibid science technology committee fifth special report session big data dilemma government response committee fourth report session para science technology committee fifth report session robotics artificial intelligence para letter alan turing institute commission artificial intelligence october algorithms government response work front conducted royal society british academy however subsequent report institutions data management use governance century rehearsed important principles around data protection tackle algorithms generally nuffield foundation announced intention establish partnership bodies convention data ethics artificial intelligence promote support data practices trustworthy understandable challengeable accountable last year industrial strategy white paper government announced establishment council supported new government office champion research innovation take advantage advanced data analytics promote greater diversity workforce white paper also announced would take international leadership role investing new centre data ethics innovation advisory body review existing governance landscape advise government enable ensure ethical safe innovative uses data including margot james minister digital creative industries told house proposed new centre advise government regulators strengthen improve way data governed well supporting innovative ethical use data april government launched sector deal announced interim centre data ethics innovation start work key issues straightaway findings used inform final design work programme permanent centre established statutory footing due course public consultation permanent centre launched government proposed centre data ethics innovation welcome initiative occupy critically important position alongside information commissioner office overseeing future development algorithms decisions make challenge secure framework facilitates encourages innovation also maintains vital public trust confidence many issues raised report require close monitoring ensure oversight machine algorithms continues strike appropriate safe balance recognising benefits healthcare public services example innovation private sector risks science technology committee fifth special report session robotics artificial intelligence government response committee fifth report session also see royal society data management use governance century british academy royal society project accessed march joint report british academy royal society data management use governance century june nuffield foundation data ethics artificial intelligence accessed march industrial strategy november ibid data protection bill committee march col government tech sector backs british industry multi million pound investment april algorithms privacy consent data security unacceptable impacts individuals discuss report government ensure issues top new body remit agenda government plans put centre data ethics innovation statutory footing set requirement report annually parliament results work allow others scrutinise effectiveness although terms government proposed consultation centre data ethics innovation yet announced anticipate report feeding exercise inquiry background earlier inquiries big data predecessor committee also launched inquiry algorithms case inquiry made stephanie mathisen sense science part evidence committee science inquiry initiative sought scrutiny suggestions public inquiry launched february ceased general election called decided subsequently continue inquiry received submissions including previous inquiry took oral evidence witnesses including academics field industry public sector organisations using algorithms information commissioner minister digital creative industries margot james addition held private introductory seminar algorithms october speakers alan turing institute facebook sap software developer would like thank everyone contributed inquiry april house lords committee published report taken conclusions board relevant inquiry stephanie mathisen call algorithms inquiry raised question extent algorithms exacerbate reduce biases well need decisions made algorithms challenged understood regulated issues echo predecessor committee concerns albeit expressed context big data two years since committee called oversight body monitor address issues report intended identify themes challenges proposed centre data ethics innovation address begins work specifically chapter look algorithms rely data sharing potential bias discrimination chapter explore ways achieving accountability transparency algorithms chapter consider regulatory environment light cambridge analytica case imminent implementation general data protection regulation science technology committee ninth report session future programme science inquiry para sap company information accessed april house lords select committee report session ready willing able science technology committee ninth report session future programme science inquiry para algorithms applications bias data sharing foundation machine learning algorithms data initial training data paragraph continuing feedback data allow algorithms interpret adjust changing scenarios big data drawing disparate datasets together provide new data flow across organisational boundaries predecessor committee report big data expounded enormous benefits prospect economy people lives making public data open current inquiry examined way data sharing affecting three sectors healthcare criminal justice social media health sector context healthcare academy medical sciences highlighted machine learning algorithms precise sensitive learning large set training according dame fiona caldicott national data guardian new technologies ways sharing data mean gain huge benefit sharing health care data algorithms assisting earlier accurate diagnosis supporting preventative medicine guiding complex treatment decisions recent report genomics saw potential genomic data linked data find patterns diagnosing rare diseases personalising medicine microsoft seeing application told enables people visually impaired use mobile app allows see hear description around used risk assessment tool field cancer pharmacology assisting clinical trial interpretations simulations epidemiology applied public health data detect track infectious disease outbreak enhance medical monitoring optimise demand management resource allocation healthcare systems recent controversy computer algorithm failure nhs breast screening programme shows benefits risks system allowed enormous number women automatically invited screening appropriate time coding error also meant women aged missed digitalisation key part nhs strategy use data algorithms improve patient care present reform noted healthcare system still heavily reliant paper files systems based science technology committee fourth report session big data dilemma para academy medical sciences para national data guardian national data guardian report published december phg foundation para research councils para academy medical sciences para science technology committee third report session genomics genome editing nhs carolyn nguyen reflect research team university manchester para academy medical sciences polygeia deb may col algorithms standards nuance communications technology firm calculated nhs trusts investing form artificial intelligence polygeia worried variability nhs digitisation mean trusts lag behind others terms improved healthcare access reform believed without digitalisation adoption machine learning nhs sparse pace digitisation nhs slipping behind schedule national information board envisaged patient care records digital real time interoperable wachter review concluded however journey integrated paperless records unrealistic pushed back national advisory group health information technology concerned aggressive push digitalise entire secondary care sector likely fail succeed recent annual survey digital health intelligence found falling confidence nhs leaders able achieve target integrated digital health care records national data guardian dame fiona caldicott highlighted report genomics urgency needed developing consensus legitimacy data sharing order deliver safe effective diagnostic services professor harry hemingway farr institute health informatics research emphasised costs sharing data could severe revised caldicott principles published emphasised duty share information important duty protect patient confidentiality reform pointed however people generally reticent share data always understand happens data following termination care data patient initiative low acceptance patients doctors national data guardian stipulated stringent consent agreements patients observed recently praiseworthy attempts innovation falter lose public trust explore issues around consent chapter current lack digital nhs data slowing development algorithms dominic king research scientist deepmind health company owned google reform thinking nhs january new data reveals nearly half nhs trusts investing patient services nuance communications january polygeia para reform thinking nhs january national information board delivering five year forward view june paperless likely fail says wachter review nhs computer weekly september national advisory group health information technology england making work harnessing power health information technology improve care england september confidence achieving nhs digitisation targets falls digital health intelligence july national data guardian developing consensus data sharing support nhs clinical genetics genomics services august original caldicott principles developed following review patient information handled across nhs source information governance toolkit department health caldicott guardian council manual caldicott guardians january information share share information governance review march reform thinking nhs january national data guardian health care review data security consent june national data guardian national data guardian report published december deepmind founded acquired google algorithms told uncleaned unrepresentative disconnected nhs datasets took many months produce data machine readable format research deepmind work able start algorithm diagnose kidney disease king wanted see better education investment takes get datasets ready made available wide group people differing data codes used across nhs trusts seen one hindrance rapid processing data eleonora harwich reform thought standardisation clinical codes going replaced standard system would positive step forward criminal justice system criminal justice system algorithms used police forces facial image recognition big brother watch raised concerns including reliability technology potential racial bias paragraph home office told separate inquiry biometrics algorithm systems matched video images watch list wanted people also police operators confirm match indicated algorithm people arrested solely basis matches made facial recognition software algorithms also used detect crime hotspots find areas susceptible crime kent constabulary using commercial predpol algorithm since predictive policing tool identify areas offences likely take place using data past crime patterns rusi highlighted similar algorithm developed greater manchester police shown effective reducing burglary ucl jill dando institute security crime science emphasised knowing problem likely one part another heard inquiry durham constabulary also using algorithms assist decision making relating whether suspect could eligible deferred prosecution box well wider controversial use decisions bail parole sentencing paragraph durham constabulary believed ability assess risk past behaviours used get consistency decision making targeted interventions offenders inspectorate constabulary concluded wider use technology used durham could improve effectiveness release officer capacity likely cost effective big brother watch big brother watch briefing short debate use facial recognition technology security policing house lords march letter baroness williams trafford committee march oxford internet institute ucl jill dando institute security crime science para marion oswald sheena urwin submission see also software recruited track gang thieves new scientist march rusi big data policing september ucl jill dando institute security crime science sheena urwin head criminal justice durham constabulary institute mathematics applications para durham constabulary inspectorate constabulary peel police effectiveness march algorithms box durham constabulary use algorithms harm assessment risk tool hart designed result collaboration durham constabulary barnes university cambridge decision support system used assist officers deciding whether suspect eligible deferred prosecution based future risk offending taking different past criminal behaviour age gender model trained custody events fiveyear period algorithm uses data make predictions level risk reoffending source sheena urwin durham constabulary hart algorithm piloted evaluated durham constabulary utilise data police force areas indeed national systems royal united services institute big data policing review concluded system using durham police data offences committed areas would considered dangerous criminals might identified inspectorate constabulary found forces yet explored fully use new emerging techniques analysis direct operational activity local level marion oswald director centre information rights sheena urwin durham constabulary noted police forces using algorithmic data analysis intelligence work professor louise amoore questioned whether place inference correlation criminal justice system since unlike normal evidence questioned jamie grace sheffield hallam university accepted use wanted single independent oversight body regulator use police databases algorithmic analysis criminal justice web social media sector web social media platforms algorithms allow faster searches adverts news effectively targeted recent controversy use algorithms cambridge analytica use facebook users data help target political campaigning shows risks associated applications exacerbated particular case absence consent use personal data paragraph report upturn omidyar network found people also adversely affected uncompetitive practices distorted filtering search engines algorithmic collusion automatic price fixing built algorithms european commission fined google manipulating algorithms demote rival comparison shopping services search results giving prominent placement durham constabulary rusi big data policing september see also big brother watch para inspectorate constabulary peel police effectiveness march marion oswald sheena urwin para jamie grace sheffield hallam university para upturn omidyar network public scrutiny automated decisions early lessons emerging methods algorithms comparison shopping service royal statistical society called competition markets authority consider potential effects arising independent use pricing algorithms major social media platforms cemented strong market positions providing services founded vast datasets control professor ashiq anjum university derby explained smaller organisations get benefit access wealth data lack resources invest technology also concern house lords committee consolidation platforms flows part acquisition social media businesses acquire customers also combine datasets different complementary search engine messaging opening new opportunities sophisticated algorithms targeting adverts news following facebook acquisition whatsapp european commission established facebook able match facebook users accounts whatsapp users accounts synergies merging datasets two companies key motivation acquisitions government data sharing getting value data predecessor committee report big data welcomed progress making government datasets open data analytics businesses acknowledged vital role played government digital catapult facilitating private sector data sharing committee recommended government produce framework identifying data sharing opportunities break department silos map set catapult work plans open share government data could dovetailed review concluded government industry deliver programme develop data trusts share data fair safe equitable way autumn budget subsequently announced investment take forward key recommendations independent review including exploratory work facilitate data access data trusts industrial strategy white paper suggested remit european commission antitrust commission fines google billion abusing dominance search engine giving illegal advantage comparison shopping service june royal statistical society para professor ashiq anjum professor distributed systems university derby para house lords select committee report session ready willing able para shared space space sharing project para see also ico information commissioner updates whatsapp facebook investigation accessed november nick srnicek platform capitalism cambridge need nationalise google facebook amazon guardian august european commission mergers commission fines facebook million providing misleading information whatsapp takeover may informatica role data mergers acquisitions december science technology committee fourth report session big data dilemma para big data dilemma para big data dilemma para professor dame wendy hall jérôme pesenti growing artificial intelligence industry october autumn budget november para algorithms planned centre data ethics innovation include engaging industry explore establishing data trusts facilitate easy secure sharing data current inquiry government explained idea behind data trusts facilitate sharing multiple organisations way ensures proper privacy protections relevant protections place governance data ensures voices interested parties represented governance fair sharing value derived data recommendation autumn beginning work develop aim piloting data trusts future central government use growing government written evidence lords committee highlights use machine learning within hmrc part goal automate million processes end government submission reveals used opaque specific ways deployed deliver public services opportunities also explored within royal navy mod cabinet office although less clear government transformation strategy making better use data improve building expanding data science analytical capability across government set priority government witnesses told holistic oversight public sector algorithms including human rights issues fall single department last year autumn budget pledged government create govtech catalyst small central unit based government digital service give businesses innovators clear access point government april sector deal allocates million govtech fund provide innovative solutions efficient public services stimulate growing govtech sector hetan shah royal statistical society told however public sector taking full advantage extraordinary value vast amount data already shares private sector algorithm developers data algorithms inextricably linked algorithms valueless without data recent genomics inquiry genomics england genomics scientists explained value patients genomic data could linked medical data provide valuable insights diagnosing rare diseases shaping personalised medicine nhs unique scale patient coverage benefits algorithm developers data generally particularly digitised paragraph enormous industrial strategy november oliver buckley written evidence received house lords committee government written evidence received house lords committee government cabinet office government digital service government transformation strategy september oliver buckley autumn budget november para industrial strategy artificial intelligence sector deal april professor harry hemingway dominic king science technology committee third report session genomics genome editing nhs see also oral evidence taken november sir john bell algorithms hetan shah told however public sector currently lack confidence area thinks magic lies private sector royal free nhs foundation trust signed agreement deepmind health giving company access million personal identifiable records paragraph received monetary gain return hetan shah thought nhs seduced magic algorithm company future least seek control data transparency nhs realise ones really important thing dataset time going see private sector providers springing provide algorithms public sector magic dataset monopoly transacting private sector confidence get tied exclusivity contracts ask greater transparency private sector providers say open show people going evidence reform recent report thinking nhs argue planned data trusts could provide means striking agreements industry nhs commercial value generated data reform recommended government explore mutually beneficial arrangements profit agreements specifically department health social care centre data ethics innovation build national framework conditions upon commercial value generated patient data way beneficial nhs department health social care encourage nhs digital work sustainability transformation plans trusts use framework ensure industry acts locally useful partner nhs algorithms used number areas ways bringing big changes wake better medical diagnoses driverless cars within central government opportunities make public services effective achieve cost savings also moving areas benefits applying may matched benefits subject decisions aspects criminal justice system example algorithms using social media datasets algorithms like big data analytics need data shared across previously unconnected areas find new patterns new insights government play part algorithms revolution two ways continue make public sector datasets available big data developers also algorithm developers welcome government proposals data google deepmind giving nhs free access patient monitoring app business insider june sustainability transformation plans stps announced nhs planning guidance published december nhs organisations local authorities different parts england developed common plans future health care services area reform thinking nhs january algorithms trusts approach mirror existing open data initiatives secondly government produce publish maintain list algorithms significant impacts used within central government along projects underway planned public service algorithms aid private sector involvement also transparency government identify ministerial champion provide oversight algorithms used public sector departments approaches development deployment algorithms partnerships private sector algorithms need data effectiveness value tends increase data used datasets brought together government could realise great value tied databases including nhs negotiate improved public service delivery seeks arrangements transparency simply accept developers offer return data access crown commercial service commission review alan turing institute expert bodies set procurement model algorithms developed private sector partners fully realises value public sector government explore proposed data trusts could fully developed forum striking algorithm partnering deals urgent requirements partnership deals already struck without benefit comprehensive national guidance evolving field bias sharing data widely likely improve quality algorithms support underpinning systems also need produce reliable fair without bias machine learning application agnostic algorithms designed tell example people images documents professor louise amoore durham university explained order algorithm operate give weight pieces information others bias intrinsic algorithm durham constabulary warned demanding hypothetical perfection instead suggested considering conditions would persist models available pavel klimov chair law society technology law group highlighted importance turning technology weapon referring need checks balances forms bias nevertheless extend beyond acceptable although algorithms potential promote efficiency consistency fairness also reinforce historical discrimination obscure undesirable behaviour alan turing institute told automated applied current legislation little protect individuals discriminated algorithms used criminal justice system imperative algorithms unfairly discriminatory always case told information commissioner algorithmic risk scores used states professor nick jennings durham constabulary upturn omidyar network public scrutiny automated decisions early lessons emerging methods alan turing institute algorithms determine sentencing inaccurately classified black defendants future criminals almost twice rate white defendants perpetuating bias already existed training even relatively benign uses algorithms advertisements displayed online result users service profiled way perpetuates discrimination example basis race oxford nottingham universities warned complexity algorithmic applications increases inherent risks bias greater number stages process errors occur accumulate discrimination undesirable type introduced subsequent deployment amplify discriminatory effects discrimination enter process variety use inappropriate training data lack data correlation disguised causation unrepresentativeness algorithm development present stage algorithm lifecycle including conception design testing deployment sale repurpose training data perhaps biggest source unfair bias inappropriate training data data algorithm learns identifies patterns statistical rules algorithm applies way training data selected algorithm developers susceptible subconscious cultural biases especially population diversity omitted data royal society noted biases arising social structures embedded datasets point collection meaning data reflect biases society example risk algorithms used recruitment mark gardiner put historical recruitment data fed company algorithm company continue hiring manner assume male candidates better equipped bias built reinforced equivalent hetan shah royal statistical society noted telling algorithm best people right get microsoft told part fairness accountability transparency machine learning initiative computer scientists examining recruitment algorithms learned biases based skewed input data inquiry professor louise amoore durham university informed case black researcher mit working algorithms found information commissioner office ico big data artificial intelligence machine learning data protection september horizon digital economy research institute university nottingham human centred computing group university oxford para human rights big data technology project para human rights big data technology project para ibm para science technology committee fifth report session robotics artificial intelligence para ibm para royal society para mark gardiner para microsoft para algorithms widely used algorithms recognise black face professor amoore explained trained identify patterns facial geometry using predominantly white faces professor nick jennings royal academy engineering believed algorithms always well trained people always understand exactly work involved training research area still relatively undeveloped explained end poorly trained algorithms giving biased results vulnerability difficult tackle increasingly case process compiling training data process separate endeavours machine learning algorithm developers procure training data third parties data brokers access original basis data collected unavailable horizon digital economy research institute explained algorithms become embedded software packages cloud services algorithm reused various contexts trained different data one point code data viewed together insufficient data well unrepresentative data insufficient data also cause discrimination prediction accuracy generally linked amount data available algorithm training incorrect assessments could common algorithms applied groups training data recognised issue personal financial credit sector google told lack good data poor quality incomplete biased datasets potentially produce inequitable results algorithmic systems adrian weller alan turing institute explained one result thin data problem banks may withhold credit simply individual match pattern larger bank customer groups train algorithm based looking people least probability repaying loans happen looking particular person comes demographic much data perhaps many people particular racial background certain area able get sufficient certainty person might excellent credit risk assess data artificial intelligence avoid racist algorithms bbc april human rights big data technology project para horizon digital economy research institute university nottingham human centred computing group university oxford para google research blog equality opportunity machine learning october google para algorithms correlation without causation bias unfairness arise royal society told machine learning algorithm correctly finds attributes individuals predict outcomes contexts society may deem use attribute inappropriate institute mathematics applications gave example algorithm used courts broward county florida asks one parents ever sent jail prison even predictive institute emphasised unfairness inference defendant deserves harsher sentence father went prison sophistication means even setting restrictions algorithms produced example ignore protected characteristics like race may easily solve problem machine learning systems may instead identify proxies characteristics professor amoore explained algorithms used predict outcome criminal trials even race category removed input data algorithm still learned characteristics attributes might say breach equality act use could call proxies race learn patterns past patterns crime learn patterns postcodes following review durham constabulary hart algorithm used aid custody decisions paragraph postcode field removed amid concerns could discriminate people poorer areas concerns expressed characteristics used hart policing algorithms potential sources bias especially serve proxies race gender paragraph opaque nature algorithm black box makes use controversial areas professor amoore warned may exist areas social political economic lives might want say place algorithmic decisionmaking also questioned use inference correlation criminal justice system suggested use sentencing constitutes violation due process overt discrimination durham constabulary using algorithm help determine whether offender suitable deferred prosecution risk compounded professor amoore explained algorithm results allow challenge whereas conventional tools like dna photograph cctv image evidence given eye witness always possibility questioning arrive judgment machine learning algorithms method obviated royal society para institute mathematics applications para wired police using inform custodial decisions could discriminating poor march kehl danielle priscilla guo samuel kessler algorithms criminal justice system assessing use risk assessments sentencing accessed april sheena urwin head criminal justice durham constabulary algorithms evidence desire algorithms within criminal justice system restricted advisory roles elizabeth denham information commissioner noted may red lines scope use around sensitive areas human intervention decisions around sentencing determining big brother watch raised concern durham hart algorithm assessing reoffending risks part basis wider experian algorithm characterises people using metrics postcode family composition occupation could discriminatory silkie carlo liberty told algorithms used areas would engage human rights best advisory heart source bias propensity confuse correlation algorithms detect causality information commissioner office explained algorithmic decisions made based patterns data risk may biased inaccurate actually causality discovered difficulties fully understanding machine learning algorithm discuss chapter make hard even identify whether correlation without causation applied lack representation algorithm development community adrian weller alan turing institute told algorithm bias also result employees within algorithm software industries representative wider population greater diversity algorithm development teams could help avoid minority perspectives simply overlooked taking advantage broader spectrum experience backgrounds opinions national science technology council committee technology concluded importance including individuals diverse backgrounds experiences identities one critical challenges computer science weller also made case representation techuk told must done government increase diversity entering computer science profession particularly machine learning system design issue techuk would like see government review exploring make recommendations action taken address diversity research community industry big brother watch police use experian marketing data custody decisions april also known national council civil liberties institute mathematics applications para information commissioner office national science technology council committee technology preparing future artificial intelligence october preparing future artificial intelligence october techuk para algorithms algorithms looking exploiting data patterns sometimes produce flawed biased decisions human often inexact endeavour result algorithmic decision may disproportionately discriminate certain groups unacceptable existing human discrimination algorithms like humans produce bias results even unintentional algorithms involve machine learning learn patterns training data may incomplete unrepresentative may subsequently affected resulting algorithm result example race gender discrimination recruitment processes patterns algorithms rely may good correlations may fact show reliable causal relationship important consequences people discriminated result offender rehabilitation decisions algorithms may incomplete data example get favourable financial credit decisions algorithm developer teams may include sufficiently wide society groups might affected algorithm ensure wide range perspectives subsumed work biases need tackled industries involved discuss chapter regulatory environment introduced gdpr safeguards bias critical element remit centre data ethics innovation algorithms accountability transparency extent algorithms affect people use personal data must accountability application affected entitled transparency results arrived accountability information commissioner explained accountability requires someone responsible responsibility algorithms lie uncertain nesta highlighted need identifying responsible anything goes wrong decisions made algorithms people problem european commission acknowledged developer algorithmic tools may know precise future use implementation individuals implementing algorithmic tools applications may turn fully understand algorithmic tools operate pavel klimov law society technology law group wary placing full responsibility user algorithm strict liability may put innocent users risk answer losses normal application legal principles liable adrian weller alan turing institute believed already existing legal framework dealing situations need assign accountability considered may want assign strict liability certain settings going require careful thought make sure right incentives place lead best outcome hand professor alan winfield professor robot ethics university west england told house lords select committee artificial intelligence need treat engineered system held high standards provable safety designers manufacturers owners operators held responsible exactly way attribute responsibility failure motor car instance turns serious problem generally speaking responsibility manufacturers royal academy engineering told issues governance accountability need considered design development algorithmic systems incorrect assumptions behaviour avoided submissions inquiry agreed accountability necessary preferred means achieving varied upturn omidyar network nesta council europe human rights dimensions automated data processing techniques particular algorithms possible regulatory implications october oral evidence taken house lords artificial intelligence committee october professor alan winfield royal academy engineering algorithms reported many ways achieving accountability fairer interpretable auditable explored remain largely theoretical today examine scope potential accountability mechanisms principles codes sandra wachter oxford internet institute emphasised standards prerequisite developing system accountability information commissioner suggested codes conduct may drawn trade associations bodies representing specific sectors order assist proper application gdpr approved ico monitored body nesta favoured establishment general principles guide behaviours understanding norms rules examples standards principles field already cabinet office published data science ethics framework civil servants using data private sector amazon facebook ibm microsoft developed partnership address opportunities challenges benefit people society eight tenets include working protect privacy security individuals striving understand respect interests parties may impacted advances asilomar principles include ones addressing research funding ethics transparency privacy shared prosperity association advancement artificial intelligence association computing machinery developed professional codes ethics development computer science institute electrical electronics engineers body begun work define ethical concerns technical standards related autonomous systems mit technology review developed five principles algorithm developers house lords committee also suggests code comprising five overarching principles calling intelligibility fairness use common good well principle used diminish data rights privacy individuals families communities upturn omidyar network public scrutiny automated decisions early lessons emerging methods information commissioner office nesta cabinet office data science ethical framework may see also operational research society para microsoft para techuk para future life institute principled discussion asilomar january techuk para ieee ieee standards association introduces global initiative ethical considerations design autonomous systems april upturn omidyar network public scrutiny automated decisions early lessons emerging methods techuk para principles artificial intelligence developed common good benefit humanity artificial intelligence operate principles intelligibility fairness artificial intelligence used diminish data rights privacy individuals families communities citizens right educated enable flourish mentally emotionally economically alongside artificial intelligence autonomous power hurt destroy deceive human beings never vested artificial intelligence house lords select committee report session ready willing able para algorithms despite efforts however upturn omidyar network worried use automated decisions far outpacing evolution frameworks understand govern government witnesses told giving consideration asilomar principles currently unified framework private sector hoped centre data ethics innovation would able help issues coalesce around one set standards audit certification audit also key building trust algorithms oxford internet institute explained audit create procedural record help data controllers meet accountability requirements detecting decisions harm individuals groups explaining occurred conditions may occur centre intelligent sensing told audits could probe system fictitious data generated sampling demographic data company anonymised customer data counterfactually vary effects auditors could evaluate outputs google explained provide indicator whether might producing negative unfair effects challenge machine learning algorithms highlighted institute mathematics applications guarantee online algorithm remain unbiased relevant google flu trends launched use search queries predict spread flu outbreaks closely matched surveillance data centres disease control reported ran difficulties media coverage prompted searches people institute mathematics believed wholly online algorithms would need data updated fully revalidated information commissioner called data scientists find innovative ways building auditability allow internal review algorithmic behaviour professor daniel neyland goldsmiths university believed certificates seals algorithms audited could help address contemporary limitations accountability transparency algorithmic systems particularly seals publicised alan turing institute told certification seals could used signify algorithms whose design development deployment produced fair reasonable outcomes gdpr provides certification algorithms terms privacy protections information upturn omidyar network public scrutiny automated decisions early lessons emerging methods oliver buckley techuk para oxford internet institute centre intelligent sensing google para institute mathematics applications para google got flu wrong nature news february institute mathematics applications para information commissioner office professor daniel neyland goldsmiths alan turing institute algorithms commissioner believed seals help inform people data protection compliance particular product service ico currently looking certification schemes set managed practice ethics boards ethics boards used apply ethical principles assess difficult issues arise creation use algorithms information commissioner office told aid transparency publishing deliberations development algorithm openly documented techuk cautioned however ethics boards could seen burden smes stand benefit automated technologies setting principles codes establishing audits algorithms introducing certification algorithms charging ethics boards oversight algorithmic decisions play part identifying tackling bias algorithms growing proliferation algorithms initiatives urgently needed government immediately task centre data ethics innovation evaluate various tools advise prioritise embedded private sector well government bodies share data private sector developers given international nature digital innovation centre also engage organisations comparable jurisdictions order develop share best practice transparency algorithm accountability often framed terms openness transparency ability challenge scrutinise decisions reached using algorithms although details yet available recent nhs breast screening programme failure women aged sent screening appointments possible flaw relatively straightforward coding error health secretary put making algorithm coding widely available might allowed error spotted much sooner transparency would challenge however algorithm driven machine learning rather fixed computer coding pavel klimov law society technology law group explained machine learning environment problem algorithms humans may longer control decision taken may even know understand wrong decision taken losing sight transparency process beginning end rebecca mackinnon new america warned algorithms driven machine learning quickly become opaque even creators longer understand logic followed transparency important particularly critical consequences information commissioner office information commissioner office techuk para neyland bearing accountable witness ethical algorithmic system science technology human values deb may col mark gardiner referencing quote made rebecca mackinnon director ranking digital rights project new america algorithms stake upturn omidyar network put governments use algorithms screen immigrants allocate social services vital know interrogate hold systems accountable liberty stressed importance transparency algorithmic decisions engage rights liberties individuals transparency nesta told could lead greater acceptability algorithmic decisions transparency take different algorithmic decision arrived visibility workings inside black box human rights big data technology project suggested transparency needs considered stage algorithmic process process whole several submissions indicated users algorithms able explain decisions terms users understand transparency inside black box may practical use carolyn nguyen microsoft put takes lot data scientists understand exactly going even janet bastiman told given complex nature algorithms even full structure weighting training data published unlikely would able understand challenge output algorithm algorithms based machine learning professor louise amoore durham university wondered whether full transparency possible even designed written even difficulties could overcome university college london warned central tension making algorithms completely open many trained personal data private data might discoverable release algorithmic models hetan shah royal statistical society nevertheless highlighted recent attempts new york city council require code city agencies algorithms published professor nick jennings royal academy engineering however drew attention issue adversarial machine learning individuals know way algorithm works try dupe believe something come particular set conclusions exploit fact know google originally published pagerank algorithm nearly years ago example spammers gamed search algorithm paying links undermined algorithm effectiveness alan turing institute told two biggest hurdles right explanation paragraph trade secrets copyright concerns patents upturn omidyar network public scrutiny automated decisions early lessons emerging methods liberty nesta human rights big data technology project para projects janet bastiman professor louise amoore durham university para university college london subsequently amended creation task force provide recommendations automated decision systems may shared public peter hamilton manipulating pagerank algorithm alan turing institute algorithms traditionally used balance interests society inventors academics oxford nottingham universities questioned balance might struck age machine learning microsoft told wanted government broaden copyright exception text data mining bringing line usa japan canada ensuring well placed forefront data analytics janet bastiman worried since intellectual property machine learned systems encapsulated structure weighting input data comprise final algorithm legislation requiring clear transparency algorithm could negative impact commercial viability private sector institutions using future advocacy recently explained may result less accurate algorithms designers opt less accurate easier explain concern affects healthcare algorithms others cautioned letting commercial interests supersede rights people obtain information upturn omidyar network pointed france country explicitly required disclosure source code governmentdeveloped algorithms open record laws right explanation many submissions advocated right explanation royal statistical society think wider standards algorithmic transparency legislatively set specifics technology algorithms application vary much projects emphasised transparency useful context comparing industries royal statistical society found important differences level pressure explain data science statistical approaches projects concluded service explains workings users different explains workings heard various ways use others development facilitating right explanation hetan shah saw scope counterfactual explanations approach wachter told avoids open black box gave example loan application rejected algorithm would tell would needed different order get loan give grounds contest horizon digital economy research institute university nottingham human centred computing group university oxford para microsoft para current copyright exception permits researchers legal access copyrighted work make copies purpose computational analysis allowing use automated analytical techniques analyse text data patterns trends useful information however exists research restricting companies like microsoft commercialising algorithm intellectual property office guidance exceptions copyright november janet bastiman future advocacy wellcome trust ethical social political challenges artificial intelligence health april horizon digital economy research institute university nottingham human centred computing group university oxford para upturn omidyar network public scrutiny automated decisions early lessons emerging methods aire university college london para alan turing institute royal statistical society para royal statistical society projects royal statistical society projects algorithms might income higher would google thought better data visualisation tools could also help showing key metrics relating algorithm functioning without going full complexity akin way car dashboards gauges speed oil pressure techuk similarly highlighted interactive visualisation systems department defence announced funding thirteen projects examining different approaches making algorithms transparent including visualisation tools machine learning might future also used explain algorithms whatever form transparency takes projects emphasised services based outcome algorithm need empower users raise complaint decision dispute oxford internet institute believed rapid spread automated sensitive areas life health insurance credit scoring recruiting demands better allowing people understand lives shaped algorithms ibm thought important explanations uncover algorithms interpreted input well recommended particular output oxford internet institute highlighted right explanation omitted gdpr article paragraph included binding recital serves guidance university college london wanted meaningful right explanation strengthened include well automated decisions covered gdpr right information data protection bill gives data subject right obtain data controller request knowledge reasoning underlying processing decision connection intelligence services data processing bill wider right explanation one could applied decisions rather intelligence field france minister mounir mahjoubi recently said government use algorithm whose decisions explained transparency must key underpinning algorithm accountability debate whether transparency involve sharing workings algorithm black box affected algorithm individuals whose data used whether information widely understood explanation provided disclosure inner workings algorithms would present developers commercial confidentiality issues government centre google para techuk para techuk military wants autonomous machines explain mit technology review march recent experiment aimed explaining system involved running another system parallel monitored patterns people narrating experiences playing computer game patterns human explanations learnt parallel system applied provide explanations see osbert bastani carolyn kim hamsa bastani interpretability via model extraction unexamined mind economist february projects para oxford internet institute ibm para oxford internet institute university college london para humans may always grasp ais act panic economist february algorithms data ethics innovation explore industries involved scope using proposed data trust model make data available suitably desensitised format acknowledge practical difficulties sharing explanation understandable form government default position explanations way algorithms work published algorithms question affect rights liberties individuals make easier decisions produced algorithms also explained centre data ethics innovation examine explanations algorithms work required sufficient quality allow reasonable person able challenge decision issue explore chapter algorithms might significantly adversely affect public rights believe answer combination explanation much transparency possible right explanation key part achieving accountability note government gone beyond gdpr provisions individuals currently able formally challenge results algorithm decisions appropriate seek redress impacts decisions scope safeguards considered centre data ethics innovation ico review operation gdpr advocate chapter algorithms centre data ethics innovation research regulatory environment government false starts made commitment establish oversight ethics planned centre data ethics innovation paragraph many submissions inquiry identified need continuing research might focus work new body royal society like predecessor committee argued progress areas machine learning research impact directly social acceptability machine learning applications recommended research funding bodies encourage studies algorithm interpretability robustness privacy fairness inference causality interactions security university college london advised government invest interdisciplinary research around achieve meaningful algorithmic transparency accountability social technical perspectives think tank future advocacy wanted government research transparency accountability supported open data initiatives paragraph techuk suggested called algorithmic transparency challenge created encourage businesses academia come innovative ways increase transparency algorithms april government announced plans spend million research projects better understand ethical security implications data sharing privacy breaches welcome announcement made sector deal invest research tackling ethical implications around government liaise centre data ethics innovation research innovation encourage sufficient research undertaken algorithms realise potential benefits also mitigate risks well tools necessary make widely accepted including tools address bias potential accountability transparency measures discussed chapters inquiry also identified key areas believe prominent centre early work described chapter examine biases built identify example better training data used unjustified correlations avoided meaningful causal relationships discernible algorithm developer teams established include sufficiently wide society groups might affected algorithm new body also recommend evaluate accountability principles codes audits algorithms certification algorithm developers charging ethics boards oversight algorithmic advise embedded private sector well government bodies share data private sector developers chapter royal society university college london future advocacy techuk government tech sector backs british industry multi million pound investment april algorithms also important urgent tasks centre data ethics innovation address around regulatory environment algorithms work requires priority cambridge analytica case uncertainty general data protection regulation gdpr address issues around use algorithms widespread rapidly growing application algorithms across economy cambridge analytica allegedly harvested personal data facebook accounts without consent personality quiz app set academic university cambridge facebook users purportedly gave consent data used however app also took personal data users friends total least individuals reported firms linked cambridge analytica used data target campaign messages sought influence voters referendum well elections elsewhere information commissioner electoral commission investigating cambridge analytica case automated decisions gdpr bearing way algorithms developed used involve processing data article gdpr prohibits many uses data processing including algorithms processing automated data subject objects stipulates data subject shall right subject decision based solely automated processing including profiling produces legal effects concerning similarly significantly affects ico explained unless trivial decision necessary contract iii authorised law organisations need obtain explicit consent able use algorithms believed gdpr provides powerful right gives people greater control automated decisions made minister saw positive step explaining people must informed decisions going made algorithms rather human management companies must make aware data protection bill provides right informed requiring data controllers notify data subject writing significant decision taken based solely automated processing done soon reasonably practicable data subject exercises right bill also allows individual request ftc question facebook cambridge analytica data scandal march new york times facebook surveillance machine march great british brexit robbery democracy hijacked guardian may ico information commissioner opens formal investigation use data analytics political purposes may ico update ico investigation data analytics political purposes dec electoral commission foi release may article information commissioner office algorithms either decision reconsidered new decision based solely automated processing considered however limited decisions required authorised law would unavailable vast majority sandra wachter oxford internet institute told constituted term significant affect gdpr complicated unanswered question guidance relevant gdpr working party independent european advisory body data protection privacy explained decision must potential significantly influence circumstances behaviour choices individuals concerned extreme decision may lead exclusion discrimination individuals ultimately wachter told depend individual circumstances individual silkie carlo liberty concerns derogations believed apply decisions affecting human rights gdpr allows member states draw exemption exemptions applied broad way law enforcement processing intelligence service processing particular others criticised fact data subject discern assess potential negative outcomes automated decision algorithms underlying decisions often complex operate level restriction article gdpr decisions based solely automated processing concerned institute mathematics applications highlighted many algorithms may principle advisory therefore automated human beings using may practice advice practice determinative university college london similarly concerned decisions may effectively automated human machines perception objective neutral protections article would fall away professor kate bowers ucl jill dando institute worried similarly people could pay lip service fact human decision involved algorithmic processes gdpr working party article recommended unless meaningful human input decision still considered solely automated requires individuals regularly change decisions authority competence organisationally without durham constabulary told hart algorithm paragraph supports article data protection working party guidelines automated individual profiling purposes regulation october university leuven centre right subject automated role explicit consent august institute mathematics applications para university college london para university college london para algorithms making custody officer human always remains loop running test algorithm reliability comparing results police officers making unaided decisions parallel sort algorithm used cambridge analytica case would effectively prohibited gdpr automated processing provisions become effective may reported algorithm used target political campaign messages without human intervention consent even future use cambridge analytica algorithm would regarded automated therefore potentially allowable use data would satisfy requirements gdpr consent gdpr seeks embed privacy design addressing data protection designing new systems ico told data protection terms transparency means people given basic information use personal data purpose use identity organisation using gdpr addresses online terms conditions clauses often used get consent predecessor committee explained way used significant shortcomings current inquiry sandra wachter oxford internet institute pointed people would hundreds pages terms conditions instead preferred see understandable overview going happen data visiting service minister margot james also acknowledged importance active consent emphasised introduction gdpr mechanism achieving predecessor committee highlighted potential simple layered privacy notices empower consumer decide exactly far willing trust dataholder engage inquiry pavel klimov suggested layered notices could helpful giving certain critical information allowing user click want learn including policies sharing data algorithm technology might future used provide transparency consent notifying data subjects data used algorithms deepmind told working verifiable data audit project using digital ledgers blockchains give people cryptographic proof data used particular ways sheena urwin head criminal justice durham constabulary gdpr gdpr key changes accessed march information commissioner office science technology committee fourth report session big data dilemma science technology committee fourth report session big data dilemma para dominic king algorithms meantime privacy consent remain critical issues predecessor committee found compiling profiles people diverse big data personal data always sufficiently anonymised previous committee highlighted risk big data analytics data anonymisation undone datasets brought together risks apply equally algorithms look patterns across datasets although carolyn nguyen microsoft argued anonymisation could still play part deterring privacy abuse provided backed privacy laws cambridge analytica use personal data used alleged would met requirements consent even existing regime harvested personal data least million users individuals participants initial personality survey asked consent provisions gdpr applied data processor data processing countries data protection bill individuals data subjects situations consent obtained problem power imbalance individual organisation seeking consent according information commissioner invested digital services become dependent service always extricate especially true acquisitions companies restrict alternative services information commissioner goes say million research announced sector deal paragraph intended better understand ethical implications data sharing data protection impact assessments help identify bias decisions examined chapter gdpr requires data protection impact assessments article gdpr reflected data protection bill states type data processing likely result high risk rights freedoms natural persons data controller shall prior processing carry assessment impact envisaged processing operations protection personal data elizabeth denham information commissioner expected impact assessments produced building technological systems could impact individuals according gdpr working party impact assessments offer process building demonstrating compliance information commissioner hoped would force organisation think big data dilemma royal society ftc question facebook cambridge analytica data scandal financial times march worry whatsapp accessing personal information guardian november government tech sector backs british industry multi million pound investment april article article data protection working party processing likely result high risk purposes regulation april algorithms carefully data going system decisions going made output commercial sensitives however would promoting need publish assessments arguable whether facebook users completed personality questionnaire cambridge analytica subsequently used target campaigning material gave full informed consent clear however millions people receiving material data included algorithm friends contacts completing questionnaire give consent recently dealing cambridge analytica controversy facebook begun provide customers explicit opportunity allow disallow apps use data every days users prompted facebook login process users specify data permissions whether facebook cambridge analytica would undertaken data protection impact assessment meet requirements gdpr impossible know appears however completed assessment would concluded algorithm would likely result high risk rights freedoms individuals affected information commissioner powers enforcement key features gdpr fall shoulders information commissioner professor louise amoore durham university expressed misgivings ico able ask questions data used form analysis taking place december speech however information commissioner said ico duties wide comprehensive merely regulator office ensure fairness transparency accountability use personal data behalf people gdpr provide information commissioner greater powers including article undertake data protection audits well right obtain personal data necessary ico investigations secure access premises required gdpr also give ico power ban data processing operations issue much significant financial penalties existing regulations gdpr however ico compel companies make data available march information commissioner issued demand access records data hands cambridge analytica secure high court warrant gain access data company oblige delay ico access led question powers information commissioner quickly obtain digital search warrants submission data protection bill committee march information commissioner wrote facebook developer news user access token changes april information commissioner office speech information commissioner techuk data ethics summit december article article information commissioner office ico statement investigation data analytics political purposes march financial times data watchdog still seeking cambridge analytica warrant march algorithms current data protection act dpa information notice criminal offence punishable fine magistrate court however court compel compliance information notice issue disclosure order means although data controller receive criminal sanction commissioner still unable obtain information needs investigation complained inability compel compliance information notice meant investigations guarantee success may affect outcomes proves impossible follow essential lines enquiry contrasted previous role information privacy commissioner british columbia power compel disclosure documents records testimony data controllers individuals failure contempt court result called data protection bill provide mechanism require disclosure requested information information notice powers opinion failure adverse effect investigatory enforcement addressing challenges government subsequently amended bill increase information commissioner powers enabling courts compel compliance information orders making offence block otherwise withhold required information developments within algorithms way data used changed since information commissioner office set accommodate new landscape hetan shah called government sort funding model government since announced new charging structure requiring large organisation pay higher fee representative higher risk provisions general data protection regulation provide helpful protections affected algorithms whose data subsumed algorithm development although effective safeguards practice tested become operational later spring example uncertainty provisions interpreted appear offer important tools regulators insist meaningful privacy protections explicit consent regulation provides automated algorithm decisions grey area may leave individuals decisions might indicated algorithm superficially reviewed adjusted human loop particularly human intervention little algorithms decision welcome inclusion data protection bill requirement data controllers inform individuals automated algorithm produces decision unfortunate restricted decisions required authorised law information commissioner office data protection bill public bill committee march information commissioner office data protection bill public bill committee march bill commons amendments may information commissioner office new model announced funding data protection work information commissioner office february algorithms also difficulty individuals exercising right decisions unaware subject entirely automated process first place centre data ethics innovation ico keep operation gdpr review far governs algorithms report government may areas data protection legislation might need refinement start immediate review lessons cambridge analytica case welcome amendments made data protection bill give ico powers sought relation information notices avoiding delays experienced investigating cambridge analytica case government also ensure ico adequately funded carry new powers government along ico centre data ethics innovation continue monitor terms conditions rules gdpr applied ensure personal data protected consumers effectively informed acknowledging predominantly algorithms use data data protection impact assessments required gdpr essential safeguard ico centre data ethics innovation encourage publication assessments summary form needed avoid commercial confidentiality issues also consider whether legislation provides sufficient powers compel data controllers prepare impact assessments improve ico centre believe assessments inadequate sector regulation wider issue centre data ethics innovation consider early work believe role might providing regulatory oversight complement ico remit nesta advocated establishment general principles around accountability visibility control applied plenty flexibility believed time start designing new institutions financial services consumer panel also wanted framework place supervision enforcement algorithmic decision making continues play increasing role financial services sector royal society concluded volumes portability nature new uses data digital world raise many challenges existing data access frameworks seem well equipped timely consider best address novel questions via new framework data nesta financial services consumer panel royal society algorithms range views inquiry relative benefits general overarching oversight framework framework nesta doubted effectiveness well intentioned private initiatives would unlikely clout credibility deal serious potential problems royal society favoured sectoral regulation may specific questions use machine learning specific circumstances handled way rather via overarching framework uses machine learning noted impact algorithms affect buying listening recommendations matter less filtering appears news affect evaluated others similarly professor kate bowers ucl jill dando institute believed algorithms context specific different set risks issues point view degree expose individuals arguments suggest sectoral regulation opposed single view supported elizabeth denham information commissioner think need regulator nevertheless bringing sector regulators together talk systems role could taken newly created centre data ethics innovation view also shared minister margot james contrast sectoral approach oxford internet institute proposed watchdog trusted independent regulatory body would equipped proper expertise spanning ideally law ethics computer science resources auditing authority make inspections ensure algorithmic decision making fair unbiased transparent similar vein microsoft favoured aspects society including government academia business coming together create set shared principles guide use algorithms although necessary leading overarching regulation nesta wanted advisory body guide behaviours understanding norms rules without formal regulatory powers approval certification instead strong powers investigation recommendation centre data ethics innovation information commissioner review extent algorithm oversight main regulators use results guide regulators extend work area appropriate information commissioner also make assessment back work whether needs greater powers perform regulatory oversight role sector regulators see priority nesta royal society mark gardiner see also algorithms regulated pro december oxford internet institute microsoft para nesta algorithms conclusions recommendations introduction government proposed centre data ethics innovation welcome initiative occupy critically important position alongside information commissioner office overseeing future development algorithms decisions make challenge secure framework facilitates encourages innovation also maintains vital public trust confidence paragraph many issues raised report require close monitoring ensure oversight machine algorithms continues strike appropriate safe balance recognising benefits healthcare public services example innovation private sector risks privacy consent data security unacceptable impacts individuals discuss report government ensure issues top new body remit agenda paragraph government plans put centre data ethics innovation statutory footing set requirement report annually parliament results work allow others scrutinise effectiveness although terms government proposed consultation centre data ethics innovation yet announced anticipate report feeding exercise paragraph applications bias algorithms used number areas ways bringing big changes wake better medical diagnoses driverless cars within central government opportunities make public services effective achieve cost savings also moving areas benefits applying may matched benefits subject decisions aspects criminal justice system example algorithms using social media datasets algorithms like big data analytics need data shared across previously unconnected areas find new patterns new insights paragraph government play part algorithms revolution two ways continue make public sector datasets available big data developers also algorithm developers welcome government proposals data trusts approach mirror existing open data initiatives secondly government produce publish maintain list algorithms significant impacts used within central government along projects underway planned public service algorithms aid private sector involvement also transparency government identify ministerial champion provide oversight algorithms used public sector departments approaches development deployment algorithms partnerships private sector paragraph algorithms algorithms need data effectiveness value tends increase data used datasets brought together government could realise great value tied databases including nhs negotiate improved public service delivery seeks arrangements transparency simply accept developers offer return data access crown commercial service commission review alan turing institute expert bodies set procurement model algorithms developed private sector partners fully realises value public sector government explore proposed data trusts could fully developed forum striking algorithm partnering deals urgent requirements partnership deals already struck without benefit comprehensive national guidance evolving field paragraph algorithms looking exploiting data patterns sometimes produce flawed biased decisions human often inexact endeavour result algorithmic decision may disproportionately discriminate certain groups unacceptable existing human discrimination algorithms like humans produce bias results even unintentional algorithms involve machine learning learn patterns training data may incomplete unrepresentative may subsequently affected resulting algorithm result example race gender discrimination recruitment processes patterns algorithms rely may good correlations may fact show reliable causal relationship important consequences people discriminated result offender rehabilitation decisions algorithms may incomplete data example get favourable financial credit decisions algorithm developer teams may include sufficiently wide society groups might affected algorithm ensure wide range perspectives subsumed work biases need tackled industries involved regulatory environment introduced gdpr safeguards bias critical element remit centre data ethics innovation paragraph accountability transparency setting principles codes establishing audits algorithms introducing certification algorithms charging ethics boards oversight algorithmic decisions play part identifying tackling bias algorithms growing proliferation algorithms initiatives urgently needed government immediately task centre data ethics innovation evaluate various tools advise prioritise embedded private sector well government bodies share data private sector developers given international nature digital innovation centre also engage organisations comparable jurisdictions order develop share best practice paragraph transparency must key underpinning algorithm accountability debate whether transparency involve sharing workings algorithm black box affected algorithm individuals algorithms whose data used whether information widely understood explanation provided disclosure inner workings algorithms would present developers commercial confidentiality issues government centre data ethics innovation explore industries involved scope using proposed data trust model make data available suitably desensitised format acknowledge practical difficulties sharing explanation understandable form government default position explanations way algorithms work published algorithms question affect rights liberties individuals make easier decisions produced algorithms also explained centre data ethics innovation examine explanations algorithms work required sufficient quality allow reasonable person able challenge decision algorithm algorithms might significantly adversely affect public rights believe answer combination explanation much transparency possible paragraph right explanation key part achieving accountability note government gone beyond gdpr provisions individuals currently able formally challenge results algorithm decisions appropriate seek redress impacts decisions scope safeguards considered centre data ethics innovation ico review operation gdpr advocate paragraph centre data ethics innovation research regulatory environment welcome announcement made sector deal invest research tackling ethical implications around government liaise centre data ethics innovation research innovation encourage sufficient research undertaken algorithms realise potential benefits also mitigate risks well tools necessary make widely accepted including tools address bias potential accountability transparency measures paragraph provisions general data protection regulation provide helpful protections affected algorithms whose data subsumed algorithm development although effective safeguards practice tested become operational later spring example uncertainty provisions interpreted appear offer important tools regulators insist meaningful privacy protections explicit consent regulation provides automated algorithm decisions grey area may leave individuals decisions might indicated algorithm superficially reviewed adjusted human loop particularly human intervention little algorithms decision welcome inclusion data protection bill requirement data controllers inform individuals automated algorithm produces algorithms decision unfortunate restricted decisions required authorised law also difficulty individuals exercising right decisions unaware subject entirely automated process first place paragraph centre data ethics innovation ico keep operation gdpr review far governs algorithms report government may areas data protection legislation might need refinement start immediate review lessons cambridge analytica case welcome amendments made data protection bill give ico powers sought relation information notices avoiding delays experienced investigating cambridge analytica case government also ensure ico adequately funded carry new powers government along ico centre data ethics innovation continue monitor terms conditions rules gdpr applied ensure personal data protected consumers effectively informed acknowledging predominantly algorithms use data paragraph data protection impact assessments required gdpr essential safeguard ico centre data ethics innovation encourage publication assessments summary form needed avoid commercial confidentiality issues also consider whether legislation provides sufficient powers compel data controllers prepare impact assessments improve ico centre believe assessments inadequate paragraph centre data ethics innovation information commissioner review extent algorithm oversight main regulators use results guide regulators extend work area appropriate information commissioner also make assessment back work whether needs greater powers perform regulatory oversight role sector regulators see priority paragraph algorithms formal minutes tuesday may members present norman lamb chair vicky ford bill grant darren jones liz kendallstephen metcalfe carol monaghan damien moore neil brien draft report algorithms proposed chair brought read ordered draft report read second time paragraph paragraph paragraphs read agreed summary agreed resolved report fourth report committee house ordered chair make report house ordered embargoed copies report made available accordance provisions standing order adjourned till tuesday may algorithms witnesses following witnesses gave evidence transcripts viewed inquiry publications page committee website tuesday november question numbers hetan shah executive director royal statistical society professor nick jennings royal academy engineering adrian weller turing fellow alan turing institute professor louise amoore durham university silkie carlo senior advocacy officer liberty sandra wachter lawyer researcher data ethics robotics oxford internet institute pavel klimov chair law society technology law group tuesday december martin wattenberg senior staff research scientist google team charles butterworth managing director europe middle east africa experian carolyn nguyen director technology policy microsoft nick pickles head public policy israel twitter sheena urwin head criminal justice durham constabulary professor kate bowers academic director ucl jill dando institute tuesday january dominic king senior staff research scientist clinical lead deepmind health ian hudson chief executive medicines healthcare products regulatory agency mhra professor harry hemingway farr institute health informatics research eleonora harwich head digital tech innovation reform tuesday january elizabeth denham information commissioner margot james minister digital creative industries department digital culture media sport oliver buckley deputy director digital charter data ethics department digital culture media sport andrew elliot data protection bill manager department digital culture media sport algorithms published written evidence following written evidence received viewed inquiry publications page committee website adm numbers generated evidence processing system may complete bcs chartered institute big brother watch comptia datanut sciences consultancy department digital culture media sport durham constabulary filament financial conduct authority google guardian news media ibm information commissioner office institute mathematics applications ethics applied idea centre university leeds marion oswald medconfidential medicines healthcare products regulatory agency mhra mozilla john phillips mrs katherine garzonis ofcom ofgem ofsted phg foundation professor ashiq anjum react reflect research team university manchester techuk operational research society royal society university college london university nottingham algorithms following written evidence received last parliament previous committee inquiry viewed inquiry publications page committee website alg numbers generated evidence processing system may complete academy medical sciences aire bcs chartered institute centre intelligent sensing council professors heads computing datakind department culture media sport alex griffiths henry rothstein prof david demeritt alison powell galina andreeva hab anna matuszyk janet bastiman stephen castell durham constabulary financial services consumer panel future advocacy imosphere information commissioner office institute mathematics applications liberty marion oswald sheena urwin microsoft david strudwick jamie grace mark gardiner tom macfarlane nesta office national statistics oxford internet institute university oxford paul pedley polygeia professor daniel neyland professor louise amoore professor nigel harvey projects algorithms research councils rcuk royal academy engineering sensible code company simul systems ltd space sharing project alan turing institute human rights big data technology project operational research society royal society royal statistical society ucl jill dando institute security crime science university college london university nottingham university oxford algorithms list reports committee current parliament publications committee available publications page committee website reference number government response report printed brackets printing number session first report hearing chair research innovation executive chair medical research councilhc second report brexit science innovation third report genomics genome editing nhs first special report science communication engagement government response committee eleventh report session second special report managing intellectual property technology transfer government response committee tenth report session third special report industrial strategy science stem skills government response committee thirteenth report session fourth special report science emergencies chemical biological radiological nuclear incidents government response committee twelfth report session fifth special report brexit science innovation government response committee second reporthc
