doc_id,sentence
0,"Four of them are core principles commonly used in bioethics: beneficence, non-maleficence, autonomy, and justice."
0,"In the ensuing discussion, we note the limitations and assess the implications of this ethical framework for future efforts to create laws, rules, technical standards, and best practices for ethical AI in a wide range of contexts.Keywords: accountability, autonomy, artificial intelligence, beneficence, ethics, explicability, fairness, intelligibility, justice, non-maleficence.1."
0,"This convergence can most clearly be shown by comparing the sets of principles with the four core principles commonly used in bioethics: beneficence, non-maleficence, autonomy, and justice (Beauchamp & Childress, 2012)."
0,"Justice: Promoting Prosperity, Preserving Solidarity, Avoiding UnfairnessThe decision to make or delegate decisions does not take place in a vacuum."
0,The consequences of this disparity in autonomy are addressed in the principle of justice.
0,"The importance of ‘justice’ is explicitly cited in the Montreal Declaration, which argues that “the development of AI should promote justice and seek to eliminate all types of discrimination,” while the Asilomar Principles include the need for both “shared benefit” and “shared prosperity” from AI."
0,"Under its principle named “Justice, equity and solidarity,” the EGE argues that AI should “contribute to global justice and equal access to the benefits” of AI technologies."
0,"It also warns against the risk of bias in datasets used to train AI systems, and – unique among the documents – argues for the need to defend against threats to “solidarity,” including “systems of mutual assistance such as in social insurance and healthcare.” Elsewhere ‘justice’ has still other meanings (especially in the sense of fairness), variously relating to the use of AI to correct past wrongs such as eliminating unfair discrimination, promoting diversity, and preventing the rise of new threats to justice."
0,"The diverse ways in which justice is characterised hints at a broader lack of clarity over AI as a human-made reservoir of ‘smart agency.’ Put simply, are we (humans) the patient, receiving the ‘treatment’ of AI, the doctor prescribing it?"
0,"This list was designed by consensus of a large diverse interdisciplinary committee to give the public something better than Asimov’s Laws (which covered beneficence & justice), but extended to five in order to bring in transparency and accountability."
102,22 Regulation in the Canadian Federal State vs the EU and its Member States ................................................................22 Bias ............................................................................................................................................................................................................22 Risk Management and Impact Assessment ..............................................................................................................................23 Data Governance .................................................................................................................................................................................23 Policing and Criminal Justice .........................................................................................................................................................24 Enforcement ..........................................................................................................................................................................................26 Due Process and Procedural Fairness ..........................................................................................................................................27 Consumer Protection .......................................................................................................................................................................28 COMPARING MODELS: STRENGTHS AND WEAKNESSES ...................................................................................................
102,"Through this work, the LCO promotes access to justice, evidence-based law reform and public debate."
102,"This report is part of the LCO’s ongoing AI, ADM and the Justice System project."
102,"The first phase of this project brings together policymakers, legal professionals, technologists, NGOs and community members to discuss the development, deployment, regulation and impact of AI and algorithms on access to justice, human rights, and due process."
102,The LCO’s project considers this technology in both the criminal and civil/administrative law justice systems.
102,"COMPARING EUROPEAN AND CANADIAN AI REGULATION 3• The Rise and Fall of Algorithms in the American Justice System: Lessons for Canada. • LCO Forum on AI and ADM in the Civil and Administrative Justice System. • LCO Forum on AI in Ontario’s Criminal Justice System (with The Citizen Lab, Criminal Lawyers Association and the International Human Rights Program, Faculty of Law, University of Toronto). • AI, Automated Decision-Making: Impact on Access to Justice and Legal Aid. • AI for Lawyers: A Primer on Artificial Intelligence in Ontario’s Justice System with Element AI and Osgoode Hall Law School. • Roundtable on Digital Rights and Digital Society with the Mozilla Foundation."
102,"For example, the Canada ADM Directive does not govern: • Systems that support government non-administrative decisions and/or decisions that are not “about a client. ” • Systems could be deployed in the criminal justice system or criminal proceedings. • National security applications are explicitly exempt from the Directive,26 as are the Offices of the Auditor General, the Chief Electoral Officer, the Information Commissioner of Canada and the Privacy Commissioner of Canada and others.27 • Several agencies, crown corporations, and Agents of P arliament that outside the core federal public service may enter into agreements with the Treasury Board to adopt the Directive’s requirements but are not required to do so.28 • Systems that do not “provide external services.”29 • Systems that were in “production” prior to the time the Directive came into effect.30 THE CANADA ADM DIRECTIVE 8Form of Regulation The Canada ADM Directive does not have the legal status of a statute or a regulation."
102,"CV-sorting software for recruitment procedures); • Essential private and public services (e.g. credit scoring denying citizens opportunity to obtain a loan); • Law enforcement that may interfere with people ’s fundamental rights (e.g. evaluation of the reliability of evidence); • Migration, asylum and border control management (e.g. veriﬁcation of authenticity of travel documents); • Administration of justice and democratic processes (e.g. applying the law to a concrete set of facts)."
102,Policing and Criminal Justice AI and automated decision-making systems are used extensively by governments and police services in criminal justice systems around the world.
102,A DEEPER LOOK: COMPARING AND CONTRASTING THE CANADA ADM DIRECTIVE AND EC PROPOSAL 25The LCO’s The Rise and Fall of Algorithms in the American Justice System: Lessons for Canada report discusses the risks of AI and automated decision-making systems in the criminal justice system at length.
102,"These risks include, but are not limited to: Charter violations, biased data, the “metrics of fairness” , data transparency and opacity, “data scoring” , algorithmic bias, lack of due process, and a lack of access to justice.67 In the United States, there has been an extraordinary backlash to the use of AI and related tools in American criminal justice."
102,"Importantly, American systems were invariably introduced before comprehensive regulation.68 Articles 6 and 7 and Annex III of the European Commission’s proposed AI rules crystalize an emerging international standard of prohibited and high-risk AI systems, including facial recognition systems and systems used by law enforcement and sy st ems used in the administration of justice and democratic processes."
102,Administration of justice and democratic processes: a) AI systems intended to assist a judicial authority in researching and interpreting facts and the law and in applying the law to a concrete set of facts.
102,"A DEEPER LOOK: COMPARING AND CONTRASTING THE CANADA ADM DIRECTIVE AND EC PROPOSAL 26In contrast to the EC proposed rules, there is a major gap in regulation of AI and automated decisionmaking technologies in policing and the criminal justice system: • The Directive’s focus on “administrative decisions” suggests that the Directive may not apply to ADM systems that could be deployed in the criminal justice system or criminal proceedings."
102,"As a result, it appears the federal government could adopt predictive policing algorithms, facial recognition technology, and/or automated risk assessments in bail and sentencing proceedings without having to comply with the Directive.69 • The Canada ADM Directive does not pre-emptively identify or prohibit the use of facial recognition technologies, nor it include detailed provisions identifying AI systems in “law enforcement” and the “administration of justice” as being pre-emptively high-risk, and thus subject to more detailed and expansive regulatory requirements. • Most importantly, the Canada ADM Directive does not govern the use of AI or automated decision-making technologies in policing or the administration of justice that may be deployed by governments and public institutions far beyond the reach of the Canada ADM Directive, including provincial governments and police services."
102,"This means that whole areas of government and private sector AI and ADM development are outside the scope of AI governance and thus largely unregulated, including AI and ADM systems used by provincial governments, municipalities, (most) police services, public agencies and the private sector. • Criminal justice."
102,The Canada ADM Directive does not include AI or automated decisionmaking systems in the federal criminal justice system.
102,"In contrast, the European Commission Proposal include detailed provisions identifying AI systems in “law enforcement” and the “administration of justice” as being pre-emptively high-risk, and thus subject to more detailed and expansive regulatory requirements."
102,"The Court of Justice of the EU (CJEU) may rely on the recitals and may wish to give greater prominence to the Charter, as it has often done in digital matters and in the protection of personal data."
102,"“High-risk” systems include many systems used in law enforcement and the administration of justice, among others."
102,Nor does the Canada ADM Directive regulate law enforcement or criminal justice AI applications.
102,"The LCO can be contacted at: Law Commission of Ontario Osgoode Hall Law School, York University 2032 Ignat Kaneff Building 4700 Keele Street Toronto, Ontario, Canada M3J 1P3 Telephone: (416) 650-8406 Toll-free: (866) 950-8406 Email: LawCommission@lco-cdo.org Web: www.lco-cdo.org Twitter: @LCO_CDO ENDNOTES 381 Law Commission of Ontario, Regulating AI: Critical Issues and Choices, (2021) [Regulating AI], online: https://www.lco-cdo.org/en/our-currentprojects/ai-adm-and-the-justice-system/regula ting-ai-critical-issues-and-choices/ ."
102,"While the GDPR concerns civil and commercial matters, the directive deals with criminal matters and concerns the protection of personal data in the field of police and justice."
104,"In particular, the European Union Agency for Fundamental Rights (FRA) and the Ad Hoc Committee on Artificial Intelligence (CAHAI), a Council of Europe body responsible for examining the possibilities of establishing a legal framework on AI, have drawn up an inventory of fundamental rights likely to be threatened by AI: in particular respect for human dignity, respect for privacy and data protection, equality and non-discrimination, access to justice, access to social rights, etc."
104,"However, in addition to the observations on use cases prohibited by the proposal for an EU regulation on AI, the CNCDH would like to highlight two types of use of particular concern for the respect of human rights: predictive justice and the recognition of emotions in support of a selection process."
104,"The CNCDH also notes that the Ministry of Justice prematurely terminated, in January, its experimentation with such software, by establishing the multiplicity of criteria to be taken into account to characterise the extent of bodily injury and the excessive importance of the means to be mobilised to study and prevent algorithmic biases in order to achieve a satisfactory level of performance36."
104,"33 According to appearance theory, enshrined by the European Court of Human Rights, “ justice must not only be done, it must also be seen to be done”."
104,"See the response of the Minister of Justice published in the OJ Senate of 01/10/2020, page 4462, available online: https://www.senat.fr/questions/base/2020/qSEQ200616942.html ."
104,"Marzolf, “ Le ministère de la Justice renonce à son algorithme DataJust ”, Acteurs publics , 14 January 2022."
104,"These adverse effects are most often mentioned on the basis of a reference to the “sensitive” sectors in which the system is deployed, such as police, justice or health, or an inventory of fundamental rights and freedoms that may be challenged by AI technology43."
104,"These are AI systems that operate in “sensitive” areas: biometric identification, management and operation of critical infrastructure, education and training, employment, access to essential private services, public services and social benefits, police, justice, migration management."
104,"A - 2022 - 6 • EN • Opinion on the impact of artificial intelligence on fundamental rights28 as the preservation of the rule of law and democracy, not forgetting the environment, the National Consultative Commission on Human Rights intends to continue its work on artificial intelligence in the future, especially to examine its impacts, particularly in the areas of health, education, employment and justice."
106,"And it was in this mindset that the CNIL set a collective approach in motion, for several months overseeing a public debate with the help of partners from various sectorial fields (health, justice...)."
106,"Among them, we could mention the “Ligue de l’Enseignement” (associa tion that focused on education concerns), French Insu rance Federation (FFA), French Ministry of Culture (DG-MIC), Open Law (association that reflects on the justice system) as well as trade unions such as CFE-CFC and FO Cadres (for recruitment and HR), etc.An innovative approach to crafting a collective and pluralist ethical thought process Ethical thinking concerns decisive societal choices."
106,"The views of the diverse stakeholders (trade unions, associations, businesses, researchers, citizens, etc.) across a wide range of sectors (from insurance to education, justice and healthcare) thus informed the writing of this report, which provides an overview of the ethical matters raised by algorithms and artificial intel ligence in their current applications and their potential uses in the relatively short term."
106,"THE ETHICAL MATTERS RAISED BY ALGORITHMS AND ARTIFICIAL INTELLIGENCE ALGORITHMS AND ARTIFICIAL INTELLIGENCE TODAY 22 Education Justice Health Security Work, HR Culture Other Generating knowledgeBetter identify learners’ abilitiesReveal the different ways judgments are handed down between regionsTap into the vast amount of scientific publicationsIdentify unsuspected links for solving gendarmerie-led investigations Understand social phenomena in the workplaceCreate cultural showpieces (painting, music)Fine-tune an insurance company customer’s risk profile MatchingAllocate higher education places to candidates (APB)Allocate patients for participation in a clinical trialMatch a list of applicants to a job vacancyMatch “compatible” profiles on dating apps, etc."
106,"The next step of what some refer to as “predictive justice” would involve entrusting systems with the task of making decisions based on a cross-analysis of the data pertaining to a certain case, with case-law data.Delegating tasks to algorithms: contrasting situations What immediately becomes clear is that concern over the potential ethical and social implications of automated systems varies depending on the tasks being delegated to the latter and the very conditions shaping this delegation."
106,"In the report it submitted to the CNIL, the Conseil National des Barreaux, the national institution that represents all practising lawyers in France, highlighted that “care must be taken to ensure that the obsession for effectiveness and predictability behind the use of algorithms does not lead to us designing legal rules and categories no longer on the grounds of our ideal of justice, but so that they are more readily ‘codable’”."
106,"A question of scale: the massive delegation of non-critical decisions Should ethical thinking on algorithms and artificial intel-ligence be limited to crucial decisions, sectors where the impact on humans is undeniable, such as medicine, justice, educational guidance, and even the automotive sector with its implications in terms of safety?"
106,"Practical examples of algorithms being used by the authorities as well as the example of predictive justice give a clearer idea of this ambivalence, between the optimising and diminishing of processes stripped of their spatial dimension."
106,"Similarly, at the symposium on predictive justice orga nised on 19 May 2017 by the Lille Bar, Law Department of Université catholique de Lille and the Douai Court of Appeal, certain participants stressed that “knowledge of judgments given by the other neighbouring jurisdictions or by the other magistrates would contribute towards a certain consistency and prevent that the outcome of a dispute depends on knowing whether it is heard in a city or another”."
106,The same line of thinking could be applied to the idea of a predictive justice.
106,Predictive justice applications are being subjected to particularly close public scrutiny as regards their Management Profile for Alternative Sanction) tool designed to come up with a recidivism risk score for prisoners or defendants on trial.
106,Medicine and justice are other sectors where this question might be asked.
106,"IIt is crucial to guard against excessive trust by raising awar eness of the ethical dimensions of a decision-making process that must not exclude human intervention and by honing critical thinking in some particularly sensitive sec tors, such as medicine, recruitment, justice and perhaps now marketing above all, where the antisemitic categories recently generated by Facebook’s machine learning algorithms are a stark wakeup call to the sharpness of the risks."
106,"The partners in the public debate • Allistene’s research committee on ethics (CERNA) • Bordeaux’s Cognitique Institute (ENSC) • Bordeaux University • Caisse des dépôts et consignations (CDC) • Club des Juristes (thinktank) • Collège des Bernardins • Complex Systems Institute of Paris Ile-de-France (ISC-PIF) • Confédération française de l’encadrement – Confédération générale des cadres (CFE-CGC, trade union) • Communication Publique • Conseil National des Barreaux (national institution that represents all practising lawyers in France/CNB) • Conseil Supérieur de l’Audiovisuel (independent authority to protect audiovisual communication freedom/CSA) • Conservatoire National des Arts et Métiers (leading higher education and research institution dedicated to adult continuing education/CNAM) • Douai court of appeal • ESCP Europe, IoT Chair • Etalab(body that works in France on data sharing in the public sector) • “Familles rurales” association • Federal University of Toulouse • French Association for Artificial intelligence (AFIA) • French Association for Employment Law (AFDT) • French Development Agency(AFD) • French governmental advisory council on bioethics issues (CCNE) • French Insurance Federation (FFA) • French National Center for Scientific Research (CNRS)’s ethics committee (COMETS) • FO-Cadres (trade union) • Fondation Internet Nouvelle Génération (FING) • Fotonower • Génotoul societal (bioscience and ethics platform) • Groupe VYV (MGEN – ISTYA – Harmonie) • Imagine Institute on genetic diseases • INNOvation Ouverte par Ordinateur (INNOOO)• Institut Mines-Télécom (IMT), Research Chair “Values and Politics of Personal Information” • Laboratory for Collective and Artificial Intelligence (LICA) • Law Department of Université Catholique de Lille, Centre of research on relations between risk and law • Law Department of Université Catholique de Lyon • Ligue des Droits de l’Homme (Human Rights League/LDH) • Ligue de l’Enseignement (Education League) • Lille 2 University • Lille Association of Lawyers • Lyon’s administrative court of appeal • Microsoft • Ministry of Culture, via the General Directorate of Media and Cultural Industries (DGMIC) • Ministry of National Education, via the Directorate of Digital Technology for Education (DNE) and its Numéri’lab • National Academy of Technologies of France • National Institute of Higher Studies on Defence (IHEDN) • National Institute of Higher Studies on Security and Justice (INHESJ) • National Institute of Applied Sciences (INSA) • Necker Hospital • OpenLaw (association) • Paris II University • Randstad • Research Centre of the National Gendarmerie School of Officers (CREOGN) • Rhône Département -level Council of the Medical Association • Renaissance Numérique (thinktank) • School of Advanced Studies in the Social Sciences (EHESS) • Sciences Po Lille • Sciences Po Paris • Société informatique de France (association devoted to computer science/SIF) • The Future Society at Harvard Kennedy School, AI Initiative • Universcience • Visions d’Europe (association) The other contributors • Arbre des connaissances (association) • Autorité de contrôle prudentiel et de résolution (French authority responsible for the supervision of the banking and insurance sectors/ACPR) • Autorité des marchés financiers (authority which regulates participants and products in France’s financial markets/AMF) • Montpellier Méditerranée Métropole and its President, Philippe Saurel • City of MontpellierThe 37 citizens who took part in the public consultation organised in Montpellier on 14 October 2017."
106,"LAUNCH EVENT ROUNDTABLE SESSIONS “Algorithms and humans” and “Fairness, transparency and plurality of algorithms” > CNIL SYMPOSIUM “Towards new forms of humanity?” > Universcience CONFERENCE “Algorithms and law” > Lille II University CONFERENCE “The choice in the age of Big Data” > Sciences Po Lille and Visions d’Europe DEBATE “The governance of emerging technosciences” > German American Conference at Harvard University DEBATE “Transatlantic perspectives on: AI in the age of social media; privacy, security and the future of political campaigning” > The Future Society at Harvard Kennedy School ROUNDTABLE SESSIONS “Big Data, human resources: algorithms on the agenda” > FO-Cadres CONFERENCE “Fairness of algorithmic decision-making” > Toulouse III – Paul Sabatier University DEBATE “Will digital technology spell the end of the rule of law?” > Collège des Bernadins SYMPOSIUM “Predictive justice” > Douai Court of Appeal, Lille Association of Lawyers and Law Department of Université Catholique de Lille WORKSHOPS “Fairness of algorithmic decision-making and processing” > LabEx International Centre for Mathematics and Computer Science in Toulouse23/01/2017 23/03/2017 25/03/2017 31/03/2017 06/04/201708/04/201718/04/2017 18/04/2017 04/05/201716/05/201719/05/201702/06/2017 DEBATE “Algorithms in healthcare: what ethics?” > Groupe VYV (MGEN – ISTYA – Harmonie) ROUNDTABLE SESSION “Artificial intelligence: ethics, at the intersection of HR and Big Data” > Confédération française de l’encadrement – Confédération générale des cadres (CFE-CGC) DEBATE “Algorithms, employment and ethics” > French Association for Employment Law (AFDT) DAY “Ethical algorithms, a moral requirement and competitive advantage” > Allistene’s CERNA and Société Informatique de France (SIF) SYMPOSIUM “Human, non-human in the age of artificial intelligence” > Paris II University SYMPOSIUM “Artificial intelligence: autonomy, delegation and accountability” > Bordeaux’s Cognitique Institute (ENSC) WORKSHOP “Ethics of algorithms: implications for healthcare” > Genotoul (bioscience and ethics platform) CROWDSOURCING WORKSHOP “Artificial intelligence and law” > OpenLaw SYMPOSIUM “ The many dimensions of data ” > Institut Mines-Télécom, Values and Politics of Personal Information Research Chair SYMPOSIUM “Security and justice, the challenge of the algorithm” > National Institute of Higher Studies of Security and Justice (INHESJ) MOCK TRIAL AND ROUNDTABLE SESSION “ Ethique, algorithmes and justice ” > Law Department of Université Catholique de Lyon and Lyon’s Administrative Court of Appeal STUDY DAY “Admission Post-bac, textbook case of public algorithms” > Fondation Internet Nouvelle Génération (FING) and Etalab DAY “Algorithms and digital sovereignty” > Allistene’s CERNA DAY “Ethics and artificial intelligence” > French National Center for Scientific Research (CNRS)’s ethics committee (COMETS) and French Association for AI (AFIA) DEBATES on algorithms in education. > Ligue de l’Enseignement (Education League) DEBATE MORNING “Work in the algorithm era: what ethics for employment?” > Renaissance Numérique and Randstad SYMPOSIUM ““Convergences of law and digital technology” > Bordeaux University DAY “Algorithms and Politics."
110,"A titre d’exemples non hiérarchisés, des SIA sont d’ores et déjà opérationnels dans les domaines les plus divers : - La gestion des territoires : circulation automobile, entretien de la voirie, gestion des déchets, de l’eau, de l’éclairage public, du nettoyage urbain, transport public par véhicule dit « autonome »… ; - La défense et la sécurité : détection de forces militaires sur des images aériennes et satellite, prévention des attaques informatiques, détection de la désinformation d’origine étrangère avec Viginum, lecture automatisée de plaque d’immatriculation, anticipation des catastrophes naturelles par les services de secours, reconnaissance faciale de suspects ou de victimes par la police judiciaire… ; - Les activités de contrôle et de lutte contre la fraude : ciblage des contrôles fiscaux et douaniers, contrôle aux frontières, détection de constructions non autorisées sur des images satellite… ; - La justice : pseudonymisation des jugements, recherche documentaire, évaluation des préjudices en cas de dommage corporel… ; - La politique de l’emploi : appariement entre offre et demande d’emplois, personnalisation de l’accompagnement… ; Page 7 - L’éducation : prévention du décrochage scolaire, affectation en première année de l’enseignement supérieur… ; - La protection sociale : liquidation des prestations, identification du non-recours aux droits… ; - La santé : aide au diagnostic et à la prescription médicale, alertes sanitaires, robotique médicale… En deuxième lieu, à l’instar de ses voisins européens, la France ne vit pas une révolution de l’IA publique , mais connaît un déploiement très progressif des SIA dans les services publics, très inégal selon les administrations et souvent expérimental."
110,"Page 18 L’utilisation de ces systèmes pour une politique publique donnée (sécurité, justice, aménagement du territoire, santé, éducation…) mériterait à elle seule la rédaction de plusieurs études."
110,"A titre d’exemple (fictif), pour construire un système d’IA d’aide à l’examen de la recevabilité d’un recours contentieux, on peut soit transcrire en instructions informatiques les dispositions pertinentes du code de justice administrative et la jurisprudence pour que le programme les applique à un dossier donné (approche symbolique), soit construire un modèle qui va déduire ces règles à partir de l’exploitation d’un très grand nombre de jugements – il constatera, « à l’expérience », que ce délai est de deux mois la plupart du temps, sauf dans certaines matières ; qu’il n’est pas déclenché en l’absence de mention des voies et délais de recours dans la décision attaquée, etc."
110,"A titre d’exemple, un outil de traitement du langage naturel entraîné sur des articles de l’encyclopédie en ligne Wikipédia devra être ré-entraîné sur des décisions de justice si on souhaite l’utiliser pour rechercher automatiquement une décision dans une base de jurisprudence à partir d’une requête formulée en langage courant)."
110,"Page 35 Plusieurs méthodes d’apprentissage peuvent être distinguées. a/ On parle d’ apprentissage supervisé lorsque le modèle est alimenté par des données dites labellisées, étiquetées, annotées ou qualifiées, c’est-à-dire auxquelles on a assigné une valeur ou qu’on a rangé dans une catégorie, de manière à permettre à la machine de différencier ce qui est une bonne et une mauvaise réponse : telle photo représente une chaise, tel caractère (présenté à l’endroit, à l’envers, en police Times New Roman ou écrit d’une main ferme ou tremblante…) est le chiffre 1, tel terme est un nom propre qui doit être pseudonymisé dans une décision de justice… Les paramètres « manuels » (non entraînables46) du modèle sont ajustés de telle sorte que la prévision qu’effectue la machine (inférence) à partir de données d’entrée (n’importe quelle photo, n’importe quel caractère ou n’importe quelle décision de justice) soit conforme ou la plus proche possible de la valeur attendue (l’outil devra indiquer qu’une chaise se trouve sur la photo si tel est bien le cas et donner le résultat inverse dans le cas contraire ; il devra reconnaître correctement le chiffre 1 sur un papier, une enveloppe ou dans une image ; il devra proposer ou procéder à la pseudonymisation d’un nom propre dans une décision s’il s’agit bien d’un nom propre)."
110,"Il permet l’ analyse sémantique de textes et l’identification de leur contenu (ex. les entités nommées à anonymiser dans une décision de justice ; le traitement du courrier pour l’orienter automatiquement vers le service chargé d’y répondre), le sens (repérage des fausses informations par exemple), de les résumer ou de les reformuler, et même d’en identifier la tonalité émotionnelle."
110,"Le droit conventionnel européen Le Conseil de l’Europe s’est très tôt préoccupé des incidences du développement des systèmes d’IA sur les droits fondamentaux, l’État de droit, la démocratie et la justice (avec l’adoption en 2018 de la charte éthique européenne sur l’utilisation de l’IA dans les systèmes judiciaires, dans le cadre des travaux de la Commission européenne pour l’efficacité de la justice - CEPEJ)."
110,"Dans le champ de la justice, où les SIA publics sont encore rares, les outils de pseudonymisation des décisions juridictionnelles , développés à partir d’algorithmes de traitement du langage naturel, visent à automatiser la suppression des éléments permettant l’identification des personnes mentionnées dans les décisions et, ainsi, à faciliter leur mise à disposition du public, prévue par l’ article 24 de la loi pour une République numérique en 2016, puis précisé par l’ article 33 de la loi du 23 mars 2019 de programmation 2018-2022 et de réforme de la justice89."
110,"A l’heure actuelle, aucun mécanisme ne garantit de façon systématique et complète l’égalité devant la loi ou devant la justice à l’échelle nationale."
110,"Ensuite, les ressources humaines libérées des tâches automatisées peuvent être redéployées, non seulement pour assurer l’entraînement (la complémentarité entre le travail humain d’annotation des données et le SIA est manifeste, par exemple, dans le déploiement de l’outil de pseudonymisation des décisions de justice de la Cour de cassation), la supervision et la maintenance des systèmes, mais aussi et surtout pour assurer des prestations qui ne le sont pas actuellement, ou qui le sont mal, faute de moyens humains suffisants."
110,"Les normes constitutionnelles touchant à la qualité et à la performance de l’action publique sont, pour la plupart, des objectifs de valeur constitutionnelle insusceptibles d’être directement invoqués par le justiciable, quoiqu’ils s’imposent au législateur (objectif de bon usage des deniers publics, objectif de bonne administration de la justice, lutte contre la fraude…)."
110,"Or, ces systèmes sont des outils au service des politiques publiques, des auxiliaires d’administration et de justice, et ne sont que cela."
110,"Page 89 DataJust Le décret n° 2020-356 du 27 mars 2020 a autorisé le ministère de la justice, à titre expérimental, à développer un outil permettant d’extraire et d’exploiter de façon automatisée les données relatives aux montants des demandes indemnitaires en réparation des préjudices résultant de dommages corporels, par poste de préjudice, des offres indemnitaires des personnes mises en cause, des évaluations effectuées dans le cadre de procédures de règlement amiable et des condamnations prononcées à ce titre, qui figurent dans les décisions rendues par les juridictions d’appel, de l’ordre administratif et de l’ordre judiciaire."
110,"A terme, le ministère de la justice envisageait de mettre en ligne un « référentiel indicatif d’indemnisation » à destination du grand public."
110,"Une telle possibilité est en outre exclue pour les décisions entrant dans le champ de la directive « police-justice », les décisions de justice impliquant une appréciation sur le comportement d’une personne, ou encore les services de conciliation, de médiation judiciaire ou d’arbitrage."
110,"Ex. : dans 98% des cas où la machine a proposé de pseudonymiser un mot dans une décision de justice, il s’agissait bien d’un mot à pseudonymiser (nom propre…)."
110,"C’est précisément en raison de ce risque que la Cour de justice de l’Union européenne a, à deux reprises, annulé les instruments qui entendaient encadrer les échanges de données à caractère personnel traitées avec les Etats-Unis174."
110,"Contrairement à d’autres actes de droit dérivé connexes, comme la directive dite e-privacy178 ou le RGPD et la directive dite « police-justice », la proposition de la Commission n’exclut pas de son champ d’application l’ensemble des matières classiquement exclues du champ du droit de l’Union , à savoir la sécurité nationale (y compris le renseignement), la défense et la politique étrangère."
110,"En effet, les domaines énumérés par l’annexe III du projet de règlement recouvrent l’essentiel des activités régaliennes (police, justice, immigration), l’accès et le droit aux services publics et aux prestations sociales, l’enseignement et la formation professionnelle, la gestion et l’exploitation de réseaux publics (eau, électricité…) ou encore le recrutement, l’évaluation, la promotion et la sortie de service des agents."
110,"En tant que simples utilisatrices de systèmes fournis par des tiers, leurs obligations seraient moindres et le texte leur offrirait au contraire des garanties, au prix toutefois d’un renchérissement des prestations dès lors que les fournisseurs répercuteront sur les clients publics les coûts liés à la conformité des systèmes ; - d’autre part, la simple inclusion du système dans le champ d’application du règlement, fût-ce au titre de la soumission à un code de conduite, emporte l’inclusion dans le champ du droit de l’Union, ce qui entraîne l’application du droit primaire, notamment de la Charte des droits fondamentaux de l’Union européenne , dont on sait à quel point, telle que l’interprète la Cour de justice de l’Union européenne, elle peut être exigeante à l’égard des autorités publiques, en particulier pour celles qui sont en charge de missions touchant à la sécurité."
110,"S’il est vrai que les principes de fonctionnement des SIA ne diffèrent pas selon la finalité poursuivie, de sorte que les obligations prévues par la proposition peuvent, dans leur principe, s’appliquer indifféremment aux SIA répressifs comme à la généralité des systèmes, on ne peut nier la spécificité des finalités de puissance publique et, singulièrement, celles qui touchent aux activités de police et de justice, qui pourraient appeler un encadrement européen plus souple. d/ En quatrième et dernier lieu, le droit de l’Union ne préjuge pas du niveau de norme – loi ou règlement – nécessaire pour asseoir le recours à telle ou telle catégorie de SIA publics."
110,On ne peut se satisfaire de la relative précipitation et du retard dans lesquels le droit national a été adapté au RGPD et la directive « police-justice » transposée en droit interne.
110,201 A l’instar de ce qui existe pour la prohibition du profilage des professionnels de justice ( art.
110,10 du code de justice administrative et art.
110,"Ainsi, l’outil d’anonymisation des décisions de justice développé par la Cour de cassation mobilise une vingtaine d’agents annotateurs, encadrés par une directrice des services de greffe."
110,Certains SIA publics relèveront de cette exception (ex : identification des variables explicatives 230 Le paragraphe 2 de l’article 4 et l’article 9 de la directive « police-justice » fixent des conditions distinctes pour le traitement ultérieur.
110,"Page 178 Il y a place pour la construction, par les pouvoirs publics, en lien avec la CNIL, d’une grille d’analyse de la compatibilité permettant de situer le projet entre deux extrêmes : - Un SIA développé dans le même champ d’activité que celui pour lequel les données à caractère personnel ont été collectées (ex. : système d’aide à l’évaluation du préjudice corporel sur la base des données personnelles contenues dans les décisions de justice), répondant à des motifs d’intérêt général éminents, dont la destination est susceptible de bénéficier aux personnes concernées et, en tous les cas, qui n’est pas susceptible de prendre, de recommander ou de participer à des décisions qui leur seraient défavorables (ex. : améliorer le diagnostic d’une maladie), utilisant des données fournies spontanément à l’administration et non de façon contrainte, ne relevant pas des « données sensibles » et préalablement pseudonymisées dans les règles de l’art, devrait bénéficier d’une présomption de compatibilité ; - à l’inverse, un SIA développé dans un champ totalement étranger à celui qui avait justifié la collecte, pour des motifs d’intérêt général de second ordre, recourant à des données sensibles non pseudonymisées obtenues de manière coercitive ou contrainte, et susceptibles de prendre des décisions défavorables à l’égard des personnes concernées, serait présumé poursuivre une finalité incompatible."
110,"Cette proposition prévoit la possibilité, en-dehors du champ police-justice, d’une mise à disposition contrainte des données du secteur privé au profit des administrations publiques en cas de « besoin exceptionnel » , c’est-à-dire soit pour répondre à ou prévenir une situation d’urgence publique, soit lorsque l’absence de données disponibles fait obstacle à ce qu’une administration s’acquitte d’une tâche d’intérêt général spécifique qui lui est confiée par la loi."
110,"Les contentieux éventuels sur ces actes de droit souple, portés directement devant le Conseil d’Etat, permettent d’en obtenir rapidement – en un an environ, sous réserve d’éventuelles questions préjudicielles à la Cour de justice de l’Union européenne – la confirmation ou l’infirmation."
110,"Or, un SIA pouvant décider du sort de questions cruciales peut parfaitement ne traiter aucune donnée personnelle, et ainsi se prêter assez mal, pour le cœur de son contrôle, à une approche individuelle : la justice ou l’équité du système sont des questions globales, reposant autant sur la nature des données traitées que sur les choix faits pour orienter le fonctionnement du système, ou les variables qui vont déterminer son évolution."
110,"L'étude s'attachera ensuite, au regard de l'évolution du droit européen, à évaluer l'impact potentiel, en termes de qualité de l'action publique, de l'introduction ou du développement de l'intelligence artificielle pour certaines missions telles que, Page 212 notamment, la santé, la justice, l'éducation, l'emploi, la sécurité intérieure ainsi qu'au sein de services disposant de pouvoirs d'enquête (fiscalité, concurrence, douanes)."
110,"Antoine Michon, conseiller chargé de la transformation numérique de l’État, des affaires européennes et internationales Stéphane Barritault, secrétaire général de l’Institut de cardiométabolisme et nutrition (IHU ICAN) Adrien Basdevant , avocat et membre du Conseil national du numérique (CNNUM) Laure Bédier, directrice des affaires juridiques au ministère de l’économie, des finances et de la relance, accompagnée de Serge Doumain, chef du bureau « Economie, statistiques et techniques de l’achat public » (Observatoire économique de la commande publique) Alexandra Bensamoun , professeure de droit privé à l’université Paris-Saclay Alain Bensoussan , avocat, accompagné de M. Éric Bonnet, directeur de la communication juridique du cabinet Lexing Alain Bensoussan Avocats Benoît Bergeret , directeur exécutif du Metalab, accompagné de Julia Fenart, Head of European Affairs, France Digitale et de Louis Fleuret, directeur adjoint de La French Tech Page 215 Patrick Bezombes, président de la commission de normalisation Intelligence artificielle de l’Association française de normalisation (Afnor), accompagné de Isabelle Blanc , Chief Data Officer, ministère de l'enseignement supérieur et de la recherche Gérard Biau , professeur, Sorbonne Université, directeur du Sorbonne Center for Artificial Intelligence (SCAI) accompagné de Raja Chatila, professeur émérite en robotique et en intelligence artificielle Isabelle Blanc , Chief Data Officer, ministère de l'enseignement supérieur et de la recherche, AMDAC Annabelle Bouchet , représentante du syndicat Snepap-FSU Hélène Brisset , directrice du numérique aux ministères chargés des affaires sociales, AMDAC Michel Cadot , Délégué interministériel aux Jeux olympiques et paralympiques, accompagné de Christophe Delaye, conseiller en charge de la sécurité Anne-Florence Canton, cheffe du service du numérique au ministère de la justice (AMDAC), accompagnée de Fabien Antoine, directeur de projet Stratégie data, de Marine Kettani, chargée de mission près de la cheffe du service de l'expertise et de la modernisation et de Camille le Douaron, chargée de mission data au service de l'expertise et de la modernisation Jean-Yves Capul , administrateur des données, ministère de l'éducation nationale, de la jeunesse et des sports (AMDAC) Emmanuel Chiva , directeur de l’Agence de l’innovation de défense, ministère des armées, accompagné de Michaël Krajecki, directeur de projet IA Julien Chiaroni, directeur du Grand Défi en Intelligence Artificielle au Secrétariat général pour l'investissement Olivier Colliot , directeur de recherche, Centre national de la recherche scientifique (CNRS) Stéphanie Combes, directrice du Health Data Hub (plateforme nationale des données de santé) Stéphane Commans , responsable Portfolio Projets scientifiques et alliances à l’Institut de cardiométabolisme et nutrition (IHU ICAN) Michel Cottura , directeur général adjoint chargé du pilotage des programmes et de la maîtrise d'ouvrage, Pôle Emploi Bertrand Decaix, directeur de cabinet de l’Agence centrale des organismes de sécurité sociale (ACOSS), accompagné de Jean-Baptiste Courouble, directeur des systèmes d'information, de Carole Leclerc, directrice de l'innovation et de Xavier Bonnet, directeur de l'audit du pilotage de la performance et de la stratégie Page 216 Amaury Decludt , chef de la délégation à la stratégie de la direction générale des douanes et droits indirects Maud Decraene , responsable du pôle Juridique & Valorisation à l’Institut de cardiométabolisme et nutrition (IHU ICAN), déléguée à la protection des données (DPO) ICAN Nicolas Deffieux , directeur du pôle d’expertise de la régulation numérique (PEReN), ministère de l’économie, des finances et de la relance, accompagné de Florent Laboy, directeur adjoint, et de Lucas Verney, expert technique Romain Delassus , chef du service du numérique au ministère de la culture, accompagné de Christine Debray, cheffe du département stratégie et pilotage du numérique, ainsi que de Romain Joron et Aurélien Cornaux Marie-Laure Denis , présidente de la Commission nationale de l’informatique et des libertés (CNIL), accompagnée de Louis Dutheillet de Lamothe, secrétaire général, Bertrand Pailhes, directeur des technologies et de l’innovation et Thomas Dautieu, directeur de la conformité Stéphane Donne , directeur du département statistiques, système d’information et big data de la Caisse nationale des allocations familiales (CNAF), accompagné de Agnès-Laurence Nal, attachée de direction à la direction du réseau au ministère du budget, des comptes publics, de la fonction publique et de la réforme de l’État Stéphane Duhieu , délégué de recherche à l’Institut de la vision (IHU Foresight) Nathalie Demont , secrétaire fédérale de la Fédération générale des fonctionnaires force ouvrière (FGFFO) Thomas Dumortier, conseiller juridique à la Commission nationale consultative des droits de l’homme (CNCDH), accompagné de Célia Zolynski, personnalité qualifiée et de Lucien Castex, membre Olivier Esper, gestionnaire principal des politiques publiques chez Google, accompagné de Ludovic Peran, chef de produit pour la recherche IA, Inès Kouraïchi, responsable commercial secteur public France, Italie, Espagne et Portugal, et Léa Manenti, responsable collectivités territoriales Luc Farré , secrétaire général de l’Union nationale des syndicats autonomes (UNSA) Fonction publique Gabriel Ferriol, directeur du service de vigilance et de protection contre les ingérences numériques étrangères (Viginum) au Secrétariat général de la défense et de la sécurité nationale (SGDSN) Fabien Fieschi , directeur du numérique au ministère de l'Europe et des affaires étrangères (AMDAC) Xavier Fischer , Chief Executive Officer, DatakaLab Corinne Fortin, secrétaire générale de l’Institut du cerveau Page 217 Nicolas Goniak , conseiller pour les affaires intérieures à la représentation permanente de la France auprès de l’Union européenne, Benoît Blary, conseiller en charge des télécommunications, du numérique et des postes, Pauline Dubarry, conseillère Justice, Jonathan Cole, conseiller en charge des relations avec le Parlement européen Etienne Grass , Directeur général « secteur public », Capgemini Invent Emmanuel Grégoire, premier adjoint de la maire de Paris, accompagné de Pierre Musseau, conseiller ville intelligente et durable David Gruson , directeur du programme Santé, Jouve Stéphane Hatem , directeur de l’unité mixte de recherche 1166 (maladies cardiovasculaires et métaboliques, faculté de médecine Sorbonne Université Samuel Heuzé, chef de la mission d'organisation des services du Premier ministre (AMDAC) Sylvain Humbert , secrétaire général adjoint du Conseil d’État, chargé des juridictions administratives Mylène Jacquot , secrétaire générale de l’Union des fédérations de fonctionnaires et assimilés (Uffa-CFDT) Dominique Jamme , directeur général des services de la Commission de régulation de l’énergie, accompagné de Didier Lafaille, chef du service de la prospective et de l’innovation Edward Jossa , président de l'Union des groupements d’achats publics (UGAP), accompagné de Frédéric Trinquecoste, directeur des achats informatiques, de Lionel Ferraris, directeur en charge des politiques publiques et d’Emilia Soeiro-Terme, cheffe de département Prestations intellectuelles informatiques Nicolas Kanhonou , directeur de la promotion de l’égalité et de l’accès aux droits, Défenseur des droits accompagné de Sarah Benichou, adjointe au directeur et de Gaëtan Goldberg, chargé de mission numérique, droits et libertés Pascal Kessler , président de la Fédération autonome de la fonction publique (FA-FP) Thierry Kirat , directeur de recherche au Centre national de la recherche scientifique (CNRS), directeur de l’école doctorale « Sciences de la décision, des organisations, de la société et de l'échange » (SDOSE), université Paris Dauphine-PSL Claude Kirchner , directeur de recherche émérite de l’Institut national français de recherche en sciences et technologies du numérique (INRIA) Jérôme Lang , directeur de recherche au Centre national de la recherche scientifique (CNRS), Senior Researcher, Lamsade, université Paris Dauphine-PSL Ivan Laptev , directeur de recherche à l’Institut national français de recherche en sciences et technologies du numérique (INRIA) Page 218 Benoit Le Blanc , directeur de l’École nationale supérieure de cognitique, ENSC Bordeaux, président de l'Association française pour l'intelligence artificielle (AFIA) Marc Le Floch, directeur adjoint du réseau de la Caisse nationale des allocations familiales (CNAF), accompagné de Yasmine Leroueil, adjointe au directeur collaboratif et système d’information des fonctions supports Pascal Le Luong , secrétaire général de la Cour de cassation, accompagné d’Estelle Jond-Necand, conseillère référendaire et directrice du projet open data et de l’équipe-projet « pseudonymisation des décisions de justice » Georges-François Leclerc, préfet de la région Hauts-de-France, accompagné d’Amélie Puccinelli, secrétaire générale adjointe de la préfecture du Nord, d’Olivier Rovère, directeur territorial adjoint Nord de l’Agence régionale de santé des Hautsde-France, Jean-Yves Bessol, inspecteur d’académie, directeur académique des services de l’éducation nationale du Nord, et Jean-François Papineau, directeur zonal Nord de la sécurité publique."
110,"Philippine Lefèvre-Rottmann , déléguée aux affaires publiques de Numeum, Jawaher Allala, CEO de Systnaps et Katya Lainé, CEO de Kwalys, administratrices, Valentin Hueber, délégué Industrie du futur, innovation et technologies, Lucile Lecomte, déléguée aux usages numériques Fabrice Lenglart , directeur de la recherche, des études, de l’évaluation et des statistiques au ministère des solidarités et de la santé (AMDAC) Thomas Lesueur , commissaire général au développement durable, ministère de la transition écologique (AMDAC), accompagné de Thomas Cottinet, directeur d’Ecolab et Marc Léobet, directeur de projet IA & Transition écologique auprès du directeur d'Ecolab Jérôme Letier , directeur du numérique (DNUM) du ministère de l’intérieur (AMDAC), Jean-Martin Jaspers, délégué ministériel à l'intelligence artificielle et Christophe Marquaille, chef du bureau Laboratoire valorisation des données à la DNUM, datalab Gaëlle Martinez, déléguée générale fonction publique de l’Union syndicale Solidaires Nicolas Mayer-Rossignol , président de la métropole Rouen-Normandie Françoise Mercadal-Delasalles, co-présidente du Conseil national du numérique (CNNum), accompagnée de Jean Cattan, secrétaire général, de Justine Cassell, directrice de recherche INRIA, Gilles Dowek, chercheur INRIA et de Philippine Régniez, rapporteure Rémi Meunier , Directeur « secteur public » de Dataiku etRomain Doutriaux, viceprésident marketing et communication Europe Louise Meyfroit , chargée d’opérations scientifiques à l’Institut de cardiométabolisme et nutrition (IHU ICAN) Page 219 Sarah Michot, Junior Advocacy & Campaign Manager et Anne Mollen, Policy & Advocacy Managerin, AlgorithmWatch Nicolas Monsarrat, directeur général Accenture Health, accompagné de Gabriel Bellenger, Health & Public Service Consulting lead Laurent Nunez, coordonnateur national du renseignement et de la lutte contre le terrorisme Cédric O, secrétaire d’État chargé de la transition numérique et des communications électroniques Akim Oural , adjoint au maire et délégué ville numérique, Ville de Lille Benoît Parizet, directeur de la transformation numérique de la Caisse des dépôts et consignations et de la stratégie digitale de la Banque des territoires, accompagné de Matthieu Blanc, responsable du Pôle Data Lior Perez , responsable du département des développements à la direction des systèmes d’information Météo France et Christophe Morel, directeur de la stratégie de Météo-France Manon Perrière , directrice adjointe de Tracfin, accompagnée de Mélanie Gourié, cheffe du département des systèmes d'information Edouard Philippe , maire de la Ville du Havre Lionel Ploquin , administrateur général des données de la DGFIP, ministère de l'économie, des finances et de la relance, accompagné de Su Yang, responsable du pôle donné de la délégation à la transformation numérique et de François Terrier, directeur de recherches au CEA, directeur du programme Intelligence Artificielle de CEA Tech et de l’inflexion IA de confiance du CEA List Fabrice Popineau , professeur à l’Ecole supérieure d’électricité (Supélec) Guillaume Poupard , directeur général de l’Agence nationale de la sécurité des systèmes d'information (ANSSI) Annie Prévot , directrice de l'Agence du numérique en santé, accompagnée de Marc Loutrel, directeur expertise Laurence Prevost , directrice de la division Consulting Secteur public de Sopra Steria, accompagnée de Nicolas Conso, directeur conseil Secteur public Simon Raout , directeur de la performance au centre hospitalier de Valenciennes Pierre-Louis Rolle , directeur des programmes Société Numérique et Nouveaux Lieux Nouveaux Liens & Mission incubateur de services numériques et AMDAC de l'Agence nationale de la cohésion des territoires (ANCT) Isabelle Ryl, directrice du centre de recherche de Paris de l’Institut national de recherche en sciences et technologies du numérique (INRIA) Page 220 Benoît Sagot , directeur de recherche à l’Institut national français de recherche en sciences et technologies du numérique (INRIA) Philippe Schall , chef du bureau Programmation des contrôles et analyse des données à la direction générale des finances publiques (DGFIP) Mehdi Siaghy , directeur de la recherche et de l’innovation, CHRU de Nancy Sébastien Soriano , directeur général de l’Institut national de l’information géographique et forestière (IGN) Bruno Sportisse , directeur général de l’Institut national de recherche en sciences et technologies du numérique (INRIA) accompagné d’Isabelle Herlin, coordinatrice de l’équipe recherche IA de l’INRIA Périca Sucevic, chef du pôle Droit et société d’Etalab (DINUM) et Paul-Antoine Chevalier, responsable du Lab IA et du pôle exploitation de données d’Etalab Jérôme Teillard , chef de projet Réforme de l'accès à l'enseignement supérieur du ministère de l'enseignement supérieur, de la recherche et de l’innovation (MESRI) Stéphane Trainel , AMDAC des ministères économiques et financiers Francky Trichet , vice-président de Nantes Métropole en charge de l'innovation, du numérique et de l'international et Claire Sacheaud, administratrice générale de la donnée, en charge de la stratégie data de la collectivité Mohammed-Adnène Trojette , conseiller action publique et numérique du Président de la République et conseiller technique numérique du Premier ministre Olivier Vallet , Président directeur général de Docaposte, accompagné de PierreEtienne Bardin, chief data officer du groupe La Poste Renaud Vedel , Coordinateur national pour l’intelligence artificielle Henri Verdier, ambassadeur pour le numérique Julien Vignon , directeur de projets IA, service de l'économie numérique à la direction générale des entreprises, ministère de l'économie, des finances et de la relance Cédric Villani , député, président de l’office parlementaire d’évaluation des choix scientifiques et technologiques Renaud Villard, directeur général de la Caisse nationale d'assurance vieillesse (CNAV), accompagné de Véronique Puche, directrice des systèmes d’Information de la CNAV Vincent Vuiblet , néphrologue au CHU de Reims, maître de conférences des universités, directeur de l’Institut d’intelligence artificielle en santé université de Reims Champagnes-Ardenne * Page 221 Conseil de l’Europe Muriel Décot, secrétaire de la Commission européenne pour l'efficacité de la justice (CEPEJ) Yannick Meneceur , conseiller spécial auprès du secrétariat de la Commission européenne pour l’efficacité de la justice (CEPEJ) Parlement européen Iban Garcia Del Banco , député européen Axel Voss, député européen Dragos Tudorache , député européen Commission européenne Cabinets Lucrezia Busa , membre du cabinet du commissaire européen en charge de la justice (Didier Reynders) Werner Stengg , membre du cabinet de la vice-présidente de la commission européenne Margrethe Vestager Nuria Subirats-Rebull , assistance chargée des politiques au cabinet du commissaire européen pour le marché intérieur (Thierry Breton) DG CONNECT Kilian Gross, chef de l’unité A2 développement et coordination des politiques en matière d’intelligence artificielle DG JUST Eike Gräf, gestionnaire des politiques pour les droits fondamentaux DG HOME Zsuzsana Felkai Janssen , coordinatrice IA Dan Rotenberg , adjoint au chef d’unité D4 Sécurité dans un monde numérique Gilles Robine , END DG JRC Carlos Torrecilla Salinas , chef de l’unité B6 (Economie numérique), Ignacio Sanchez, Luca Tangi et Emilia Gomez Agence Frontex Darek Saunders , directeur de l'Observatoire de la sécurité des frontières et chercheur dans l’unité Recherche et Innovation de Frontex Page 222 Annexe 4 : Glossaire Schéma synthétique du vocabulaire de base de l’intelligence artificielle261 261 J."
110,"Données - Donnée structurée : donnée formatée selon un référentiel prédéfini, à laquelle sont associées des métadonnées, et qui peut être aisément trouvée et traitée (organisée dans un entrepôt de données, avec des champs normés) : Exemple : numéros de téléphones et adresses dans un fichier de personnel ; références de produits dans une base de données d’un fabricant ; montant des transactions sur un compte bancaire ; référence du dossier contentieux sur une décision de justice..."
110,"Exemple : lac de données, contenu d’un courrier électronique, motifs d’une décision de justice, image satellite, film… - Données d’entrée : données fournies à un système d’IA ou obtenues directement par lui et sur la base desquelles il produit un résultat (projet de règlement IA) - Données de sortie (résultats) : données produites par un système d’IA en appliquant un traitement algorithmique à des données d’entrée. - Données d’entraînement : données d’apprentissage qui permettent au système d’IA d’apprendre à effectuer la tâche qui lui est assignée. - Données de validation : données utilisées pour fournir une évaluation d’un système d’IA entraîné et ajuster ses paramètres non entraînables et son processus d’apprentissage, notamment pour éviter le surajustement (projet de règlement IA)."
110,"Infrastructures critiques et protection de l’environnement Composants de sécurité dans la gestion et l’exploitation du trafic routier et dans la fourniture d’eau, de gaz, de chauffage et d’électricité Composants de sécurité ou de contrôle d’infrastructures digitales Systèmes de contrôle des émissions et de la pollution Education et formation professionnelle Accès, admission et affectation dans les établissements d’enseignement ou de formation à tous niveaux Evaluation des résultats des personnes physiques et pilotage des programmes d’enseignement et de formation dans les établissements à tous niveaux Emploi, gestion de la main d’œuvre et accès à l’emploi indépendant Recrutement et sélection de personnes physiques (diffusion des offres d’emploi, pré-sélection, filtrage) Promotion, licenciement, attribution de tâches basée sur le comportements ou les caractéristiques personnelles de chacun, suivi et évaluation des performances et comportement des travailleurs sous contrat Accès et droit aux services privés, aux services publics et aux prestations sociales Gestion des prestations et services d’aide sociale (éligibilité, octroi, retrait, récupération…) Evaluation de la solvabilité des personnes physiques ou établissement d’une note de crédit (hors « petits fournisseurs » pour leurs besoins propres) Gestion des appels d’urgence (priorisation des interventions des services de secours, pompiers…) Fixation des primes d’assurance, gestion des souscriptions et réclamations Page 245 Systèmes d’aide aux autorités répressives, ou à une autre autorité agissant en leur nom Evaluation de la probabilité de commission d’une infraction ou de récidive Prédiction de la survenance ou de la réitération d’infraction sur la base du profilage individuel ou de l’évaluation des traits de personnalité, des caractéristiques et des antécédents judiciaires Evaluation du risque encouru par les victimes potentielles d’infractions pénales Détection des mensonges, des émotions et des hypertrucages (deepfakes) Evaluation de la fiabilité des preuves Gestion de la migration, de l’asile et des contrôles aux frontières, par les autorités compétentes ou en leur nom Détection de mensonges et d’émotions ; vérification de l’authenticité des documents de voyage et pièces justificatives Evaluation du risque sécuritaire, sanitaire ou migratoire que représente un étranger Vérification d’éligibilité des demandeurs (d’asile, de visa, de titre de séjour) à un statut Administration de la justice et processus démocratiques Utilisation par le juge (ou pour son compte) pour l’interprétation des faits et de la loi, application de la loi à un ensemble concret de faits Au terme d’un réexamen annuel, la Commission serait autorisée à compléter cette liste, dans les domaines limitativement énumérés par cette annexe, pour des usages présentant des risques équivalents ou supérieurs pour la santé, la sécurité, ou l’atteinte aux droits fondamentaux."
110,"Page 248 En outre, les codes de conduite ont vocation à prendre en compte d’autres exigences : la viabilité environnementale, l’accessibilité aux personnes handicapées, la participation des parties prenantes à la conception et au développement des SIA, la diversité des équipes de développement… VII - Articulation avec les règles relatives au traitement des données à caractère personnel Le principe de base, explicité dans l’exposé des motifs, est que le règlement IA s’appliquerait sans préjudice du RGPD et de la directive police-justice, c’est-à-dire que les deux corps de règles s’appliqueraient cumulativement aux fournisseurs et utilisateurs dès lors que les SIA peuvent être qualifiés de traitements de données à caractère personnel."
110,"Par exemple, la délégation à l’intelligence artificielle (DMIA) du ministère de l'Intérieur met en commun le développement de certains projets expérimentaux avec le ministère des Armées et celui de la Justice."
110,"Page 260 Administrations répondantes Ministères - Ministère de l’Agriculture et de l’alimentation - Ministère de la Culture - Ministère de l'Intérieur - Ministère de l'Éducation nationale, de la jeunesse et des sports - Ministère de l'Économie, des Finances et de la Relance - Ministère des solidarités et de la santé - Ministère du Travail, de l’emploi et de l’insertion - Ministère de la justice - Ministère des Armées Autorités indépendantes - Commission nationale de l'informatique et des libertés (CNIL) - Haut Conseil du Commissariat aux Comptes (H3C) - Autorité de régulation des communications électroniques, des postes et de la distribution de la presse (ARCEP) - Autorité de contrôle des nuisances aéroportuaires (ACNUSA) - Commission nationale de contrôle des techniques de renseignement (CNCTR) - Conseil supérieur de l’audiovisuel (CSA) - Haut Conseil de l’évaluation de la recherche et de l’enseignement supérieur (HCERES) - Autorité de régulation des transports (ART) - Agence française de lutte contre le dopage (AFLD) - Haute Autorité pour la transparence de la vie publique (HATVP) - Autorité des marchés financiers (AMF) - Autorité de sûreté nucléaire (ASN) - Médiateur national de l’énergie - Haute Autorité pour la diffusion des œuvres et la protection des droits sur internet (HADOPI) Collectivités territoriales - Ville de Nîmes - Ville de Lyon - Ville de Marseille - Métropole Rouen Normandie - Métropole Nice Côte d’Azur - Métropole de Lyon - Bordeaux Métropole - Aix Marseille Provence Métropole - Montpellier Méditerranée Métropole - Strasbourg Métropole Page 261 - Grenoble-Alpes Métropole - Orléans Métropole - Toulouse Métropole - Région Hauts de France - Région Occitanie - Conseil Régional de Guadeloupe - Région Grand Est - Régions de France - Nantes Métropole et Ville de Nantes Secteur sanitaire et social - Caisse nationale des allocations familiales (Cnaf) - Caisse nationale de solidarité pour l'autonomie (Cnsa) - Hospices civils de Lyon - CHU de Nice - Pôle Emploi - Caisse des dépôts et consignations Page 262 Annexe 8 : Présentation des acteurs de l’écosystème de l’IA publique Les administrations centrales dédiées Bien que son décret d’attribution n’en fasse pas expressément mention, le secrétaire d’État chargé de la transition numérique et des communications électroniques joue un rôle de sponsor et d’impulsion dans la mise en œuvre de la stratégie nationale pour l’IA."
110,"Page 267 Annexe 9 : Cartographie des cas d’usage des systèmes d’IA dans l’action publique Fiche n° 1 : Gestion des territoires Fiche n° 2 : Défense Fiche n° 3 : Sécurité, activités d’enquête, de contrôle et de sanction Fiche n° 4 : Justice Fiche n° 5 : Travail et emploi Fiche n° 6 : Education Fiche n° 7 : Protection sociale Fiche n° 8 : Santé * Page 268 Fiche n° 1 : Gestion des territoires La gestion et l’aménagement du territoire et de l'espace (voiries et réseaux, urbanisme…) constituent un terrain d’application privilégié pour le déploiement des SIA."
110,"Cette distorsion vient notamment de l’utilisation du lieu de résidence, qui, compte tenu de la composition ethnique des quartiers, fournit une probabilité d’appartenance à telle 288 V. notamment le rapport – critique – du ministère de la justice américain de novembre 2014, Predictive analytics in law enforcement : a report by the Department of Justice ."
110,"Le systèm LSI-R ( Level of Service Inventory-Revised ), également en service aux EtatsUnis, calcule de la même façon un score de risque de récidive sur la base de 54 données d’entrée, porté à la connaissance de l’administration pénitentiaire et de la justice afin d’examiner les demandes de libération conditionnelle et, plus particulièrement, d’allouer davantage de ressources d’accompagnement et de suivi aux détenus à haut risque."
110,"Au Royaume-Uni, le ministère de la justice a entraîné un réseau de neurones en matière de traitement de langage naturel, à partir de 500 rapports d’inspection des prisons (représentant 250 000 phrases) et l’a ré-entraîné grâce aux nouveaux rapports rédigés, afin d’identifier les situations à risque et les facteurs explicatifs d’incidents et d’orienter les décisions et les inspections en conséquence."
110,"Il y a lieu de relever que, quand bien même les images font-elles l’objet, dès leur captation et avant leur transmission à un agent, d’un traitement destiné à empêcher toute identification par un humain (floutage…), elles constituent des données à caractère personnel soumises aux règles applicables en fonction de la finalité du traitement – en particulier le titre III de la loi du 6 janvier 1978, pris pour la transposition de la directive « police-justice » pour ce qui concerne les caméras utilisées à des fins de police administrative ou judiciaire (V. sur ce point : CE, 22 décembre 2020, Association La Quadrature du Net , n° 446155 , T.)."
110,Page 297 Fiche n° 4 : Justice L’activité juridictionnelle est habituellement identifiée comme l’un des secteurs prometteurs de l’action publique pour le déploiement de l’intelligence artificielle.
110,"Elle est aussi l’un de ceux dans lesquels, sur les plans médiatique et marketing, le fantasme a d’emblée pris le pas sur la raison, à travers la notion de « justice prédictive », présentée abusivement comme la capacité d’un système d’IA à deviner par avance le sens des décisions de justice."
110,"Sur le plan terminologique, elle repose sur une traduction littérale erronée de l’expression anglo-saxonne « predictive justice » qui signifie en réalité « justice prévisible »."
110,"La prévisibilité du droit est un enjeu majeur, pleinement intégrée à la construction jurisprudentielle à travers, notamment, l’importance du précédent ; la prédictibilité des décisions de justice est quant à elle une illusion présomptueuse et dangereuse, surtout lorsqu’elle vise à anticiper sur la position personnelle de tel ou tel juge, pris individuellement."
110,"La seconde méprise tient à ce que les outils de « justice prédictive » n’ont évidemment pas la capacité de lire l’avenir, pas plus que l’humain."
110,"Le scepticisme croissant qu’a produit le discours marketing, en l’absence de concrétisations significatives dans le quotidien des tribunaux et des avocats, a d’ailleurs conduit à un recul progressif de cette notion de « justice prédictive » au profit de celle de « jurimétrie », portée par des acteurs institutionnels comme le Conseil national des barreaux (et inspirée de l’anglais « jurimetrics » qui recouvre les méthodes d’analyse quantitative et statistique du droit), ou encore de « justice algorithmisée »310."
110,10 du code de justice administrative et le 3° alinéa de l’art.
110,"Storchan, Mécanisme d’une justice algorithmisée , Ed."
110,"Page 298 L’effervescence irrationnelle autour du phénomène de la « justice prédictive » ne saurait toutefois justifier une réaction de rejet, de dénigrement ou de défiance."
110,"D’une part, elle ne doit pas occulter l’absolue nécessité pour le monde de la justice de développer une réflexion prospective sur l’impact de ces innovations technologiques sur l’avenir du juge et de son office."
110,"En outre, les algorithmes d’apprentissage-machine – essentiellement dans le domaine du traitement du langage naturel, puisqu’il s’agit en règle générale de traiter des données de textes – peuvent être développés en mettant à profit la structuration naturelle de certaines données, à commencer par les décisions de justice elles-mêmes, qui suivent en général un format relativement standardisé."
110,"Dans ce champ de l’action publique également, la réflexion sur l’IA doit impérativement s’inscrire dans une réflexion plus vaste sur la numérisation de l’activité juridictionnelle , ce qui suppose à la fois : - de doter les magistrats, les agents de greffe et l’ensemble des collaborateurs y participant des équipements informatiques adaptés à leurs missions, alors que l’informatisation de la justice est parfois incomplète ou en trop fort décalage avec l’état de l’art ; - de privilégier les processus dématérialisés et, plus encore, nativement numériques (c’est-à-dire avec des documents et données produites dès le départ en format numérique et qui n’ont jamais eu de matérialité physique, par 311 V."
110,"312 V. sur cette typologie et des statistiques sur les projets européens en cours ou réalisés : Study on the use of innovative technologies in the justice field – Final Report [Etude sur l’utilisation des technologies innovantes dans le domaine de la justice – Rapport final, commandée par la Commission européenne, septembre 2020."
110,"Le développement optimal de systèmes d’IA publics et privés dans le domaine du droit suppose en outre d’achever, dans les délais prescrits par l’arrêté du 28 avril 2021, la mise en ligne des décisions de justice dans les conditions prévues par la législation issue de la loi pour une République numérique, en sus de la mise à disposition, dans un format exploitable, des données afférentes aux autres sources du droit, nationales, européennes et internationales."
110,"La fonction de juger S’agissant de la fonction de juger, au sens strict, la mise en œuvre de systèmes d’IA est théoriquement concevable dans les deux volets classiques que sont la prise de décision automatisée (« juge robot ») et l’aide à la décision de justice (l’IA comme « assistant de justice », intervenant pour aider à identifier, analyser et résoudre des questions posées dans un litige, notamment à travers une fonctionnalité de recommandation de solutions)."
110,"Elle peut en outre emprunter aux deux branches classiques de l’IA : les systèmesexperts, consistant à programmer tout ou partie des raisonnements juridiques sous la forme d’un arbre de causalité (« si délai de recours de deux mois à compter de la notification + décision notifiée avec voies et délais de recours le 2 mars 2021 + requête introduite le 10 mai 2021, alors requête tardive et rejet pour irrecevabilité ») ; et l’apprentissage-machine, consistant à nourrir l’algorithme des décisions de justice rendues par le passé afin de dégager des raisonnements et des appréciations qui pourront ensuite être utilisés pour la résolution de litiges futurs."
110,"Il pourra s’agir, par exemple, de l’identification et de la pondération des critères ou indices mobilisés par le juge pour fixer le montant d’une prestation ou d’une indemnité, le quantum d’une sanction, le droit d’obtenir telle ou telle décision favorable… L’automatisation de la fonction de juger ne saurait être celle de la décision de justice elle-même ."
110,"En l’état de la loi, la garantie humaine dans la fonction de juger est expressément prévue au premier alinéa de l’ article 47 de la loi du 6 janvier 1978, qui exclut qu’une décision de justice impliquant une appréciation sur le comportement d’une personne puisse avoir pour fondement (exclusif ou non) un traitement automatisé de données à caractère personnel destiné à évaluer certains aspects de la personnalité de la personne."
110,"Toutefois, il est certain que l’ensemble des dispositions régissant le fonctionnement des juridictions, voire la Constitution elle-même, font obstacle à ce qu’une décision de justice soit rendue Page 300 sur le fondement exclusif d’un traitement algorithmique – autrement dit, que le SIA prenne lui-même la décision de justice."
110,"Le robot-juge est en général considéré comme présentant les atouts suivants313 : - L’uniformité territoriale de la jurisprudence (pour autant que les textes applicables soient identiques sur le territoire considéré) et l’égalité des citoyens devant la justice, quelle que soit la juridiction à laquelle ils s’adressent."
110,"Le résultat est censé être identique à situation identique (ou ne différant que sur des aspects non pertinents pour la résolution de la question) ; - Une plus grande sécurité juridique en raison d’une prévisibilité accrue du droit et la suppression (ou la réduction) de « l’aléa judiciaire », par la neutralisation de paramètres susceptibles d’influencer le sens de la décision ou sa motivation314 ; - La prise en compte d’un nombre accru de paramètres pertinents et la capacité, à première vue paradoxale pour des outils reposant sur la catégorisation, à produire des jugements « sur-mesure », épousant plus finement les contours particuliers de chaque litige ; - La célérité de la justice : l’IA calcule plus vite que l’humain, et ne souffre pas de la fatigue ; - La réduction du coût de la justice (baisse d’effectifs, économie des coûts inhérents à des formations longues, possibilité de traiter des litiges de masse à coût quasi constant…) ; - Une baisse du volume du contentieux lui-même, les parties étant davantage susceptibles de régler leurs litiges à l’amiable si elles disposent d’une évaluation de leurs chances de succès."
110,"Elles tiennent : - à l’acceptabilité sociale d’une justice, civile et plus encore pénale, qui ne serait plus rendue directement par l’homme, tout en l’étant juridiquement et symboliquement au nom du peuple français ; - à la disparition de la fonction « cathartique » de l’oralité dans le procès, qui permet de s’exprimer et d’être écouté par la partie adverse et par des juges : cette fonction, qu’elle se déploie lors de l’instruction ou de l’audience, et a 313 V. sur cette question J.-P."
110,"Van den Branden, La robotisation de la justice , in L’intelligence artificielle et le droit, sous la coordination de H."
110,"Van den Branden, Les robots à l’assaut de la justice."
110,"Robin, Justice et intelligence artificielle, préparer demain – épisode I, Dalloz Actualité, 14 avril 2020 : « Nombreuses sont les études qui démontrent que des données fort variées et parfois étonnantes − le peƟt-déjeuner du juge, sa fatigue, l'influence médiatique, son égocentrisme à ses préjugés divers − peuvent inﬂuer sur la décision prise » (et les renvois aux études mentionnés)."
110,"Lassègue, Justice digitale."
110,"Certes, la rédaction des décisions de justice est relativement normalisée ; mais elles sont loin d’être parfaitement homogènes et des subtilités rédactionnelles peuvent aisément échapper à la machine."
110,Il ne semble pas que la voie de la robotisation de la justice ait été empruntée avec succès par d’autres pays occidentaux à ce jour.
110,"La proposition de règlement de la Commission européenne identifie à cet égard le domaine de « l’administration de la justice » comme susceptible de donner lieu à la mise en service de systèmes d’IA à hauts risques, et prévoit elle-même que les systèmes d’aide à la décision de justice (consistant à rechercher et interpréter les faits et la loi, et à appliquer la loi à un ensemble concret de faits) relèvent de cette catégorie."
110,"317 V. notamment l’expérimentation d’un outil de « justice prédictive » dans les cours d’appel de Douai et de Rennes, qui ne s’est pas avéré plus performant que les moteurs de recherche classiques."
110,318 Cette initiative n’est d’ailleurs pas recensée dans l’étude sur l’utilisation des technologies innovantes dans le domaine de la justice réalisée à la demande de la Commission européenne en septembre 2020.
110,"Mal conçus ou mal utilisés, ils peuvent induire en erreur le juge et aboutir à des résultats exactement inverses à ceux qui étaient recherchés et, partant, au déni de justice."
110,La rédaction des décisions de justice constitue également un champ intéressant pour le déploiement des SIA.
110,"821 du code de justice administrative, énonciation qu’aucun des moyens soulevés n’est de nature à permettre l’admission…)."
110,"Il repose sur un apprentissage supervisé à partir de la labellisation des conclusions et des moyens dans un grand nombre de requêtes contentieuses, de manière à entraîner la machine à distinguer les unes et les autres et à mettre en relation des conclusions connexes ou identiques 323 V. par ex. le projet « Avvocatura 2020 » en Italie ou encore l’outil, basé sur un réseau de neurones de traitement du langage naturel, développé par le ministère de la justice britannique afin de détecter rapidement des récurrences dans les centaines de rapports d’inspection des établissements pénitentiaires (rédigés par l’administration pénitentiaire, les commissions de surveillance indépendantes et l’Ombudsman des prisons et de la probation, équivalent du Contrôleur général des lieux de privation de liberté), notamment pour l’analyse des incidents, l’identification de facteurs géographiques ayant une incidence sur les établissements, orienter les inspections et mieux allouer les moyens."
110,"En revanche, il serait opportun de confier à des SIA opérés par les juridictions, et (ré-)entraînés à partir de données issues de textes et d’actes juridiques, le soin d’assurer la traduction des décisions de justice (notamment en anglais), à des fins de rayonnement institutionnel mais aussi de convergence dans l’application du droit européen (en améliorant l’accessibilité des décisions juridictionnelles françaises pour des juridictions étrangères)."
110,"Page 308 Enfin, la tâche qui donne lieu au plus grand nombre de projets de SIA dans le monde judiciaire européen est celle qui consiste à pseudonymiser voire anonymiser les décisions de justice afin de réduire ou supprimer l’atteinte à la protection de la vie privée des protagonistes du dossier au moment de leur publication."
110,"Pseudonymisation automatisée des décisions judiciaires en France Afin d’assurer la mise en œuvre de l’« open data des décisions de justice » décidée par la loi pour une République numérique, la Cour de cassation a lancé en 2019 la conception d’un SIA reposant sur l’apprentissage machine supervisé, permettant d’automatiser la pseudonymisation des décisions de justice rendues publiques, c’està-dire la suppression des éléments permettant l’identification directe des parties et des tiers qui y sont mentionnés."
110,L’exécution des décisions de justice Les SIA pourraient être mobilisés pour dynamiser l’exécution des décisions de justice.
110,"Le ministère de la justice finlandais a développé un outil (« Robot Process Page 309 Automation ») permettant de relier plus facilement les paiements aux sanctions auxquelles ils correspondent, et de traiter les défauts de paiement comme les surpaiements et les remboursements (en cas d’annulation de la sanction par exemple)."
110,"La relation avec les usagers du service public de la justice et l’accès au juge La numérisation de l’activité juridictionnelle, en particulier le développement des téléprocédures, a considérablement accru les possibilités de suivi, par les parties, de l’avancement du traitement de leur dossier."
110,Le ministère de la justice autrichien conçoit également un chatbot qui assiste les parties dans le suivi de leur dossier sur téléphone portable.
110,"Il pourrait éclairer les justiciables sur la juridiction qu’ils doivent saisir pour contester une décision donnée, les modalités de cette saisine, l’état d’avancement du dossier, les échéances à venir, les modalités de contestation de la décision rendue… Les juridictions, les ordres d’avocats et le Conseil national des barreaux permettraient de fédérer les acteurs de la justice autour de la construction d’une interface."
110,"Ce n’est pas plus dans l’esprit de ses créateurs que de remplacer les professionnels du droit (ou les syndicats) dans le conseil aux justiciables333, mais de faire en sorte de faire du numérique « le vecteur d’une plus grande justice » dès lors que « la compétence reconnue au professionnel ne saurait justifier une inaction dont pâtirait la partie la plus faible dans la relation de travail »334."
110,"Robin, « Justice et intelligence artificielle, préparer demain – épisode III2 », Dalloz actualité, 17 avril 2020."
110,"Il y a lieu d’observer à titre liminaire que l’expression même d’intelligence artificielle ne figure dans aucun de ces textes, et que ni le RGPD, ni la directive police-justice n’évoque expressément les algorithmes."
110,"Le considérant 15 du RGPD et le considérant 18 de la directive police-justice rappellent le principe de neutralité technologique de la protection des données, c’est-à-dire son application à tout traitement de données à caractère personnel, quelle que soit la technique utilisée."
110,"Ainsi : - s’agissant des traitements de données à caractère personnel régis par la directive « police-justice », l’article 95 de la loi du 6 janvier 1978, transposant l’article 11 de cette directive dans le sens le plus strict et en cohérence avec la jurisprudence du Conseil constitutionnel ( n° 2003-467 DC du 13 mars 2003), interdit par principe qu’une décision qui produit des effets juridiques ou affecte de manière significative une personne dans ce domaine soit prise sur le seul fondement d’un traitement automatisé destiné à prévoir ou évaluer certains aspects personnels de la personne."
110,Il proscrit en outre le profilage entraînant une discrimination sur la base des catégories particulières de données (« données sensibles ») ; - le premier alinéa de l’article 47 de la loi de 1978 interdit l’édiction d’une décision de justice impliquant une appréciation sur le comportement d'une personne sur le fondement d’un traitement automatisé de données à caractère personnel destiné à évaluer certains aspects de la personnalité de cette personne.
110,"A la lettre, cette prohibition s’étend ainsi à la simple prise de décision assistée ; - l’article 4-3 de la loi n° 2016-1547 du 18 novembre 2016 de modernisation de la justice du XXIème siècle fait obstacle à ce qu’un service en ligne de conciliation, de médiation judiciaire ou d’arbitrage ait « pour seul fondement un traitement algorithmique ou automatisé de données à caractère personnel »."
110,"Au plan européen, la CEPEJ (commission européenne pour l’efficacité de la justice auprès du Conseil de l’Europe) a adopté, les 3 et 4 décembre 2018, une charte des principes éthiques relatifs à l’utilisation de l’IA dans les systèmes judiciaires, adoptée par les 47 Etats membres du Conseil de l’Europe."
111,"Connectez-vous pour accéder à des contenus exclusifs et à l'ensemble des services en ligne S'identifier avec e-dentitas Voir les Conditions générales d'utilisation (nouvelle fenêtre) Vous êtes dans Accueil Actualités Préconisations d’actions pour les legaltechs du domaine de la jurimétrie 13 octobre 2020 Préconisations d’actions pour les legaltechs du domaine de la jurimétrie Numérique Partager par email.' ' .(ouvre votre boîte de messagerie) Le Conseil national des barreaux a toujours manifesté son intention de prendre un rôle actif sur le sujet de la réutilisation de la donnée judiciaire, en demandant notamment la création d’une instance publique chargée de la régulation et du contrôle des algorithmes utilisés pour l’exploitation de la base de données des décisions de justice ainsi que de leur réutilisation, dont doivent, notamment, être membres la Cour de cassation, le Conseil d’Etat et le Conseil national des barreaux."
111,"Après avoir constaté la nécessité de déterminer le fonctionnement technique et éthique de chacune des technologies portées par les Legaltechs du domaine de la « Justice prédictive » ainsi que leur utilité pratique pour les professionnels du droit, l’assemblée générale du Conseil national des barreaux (CNB), réunie les 5 et 6 juillet 2019, a donné mandat au groupe de travail Legaltech de piloter une étude comparative."
111,Elaborer une stratégie de large intégration du numérique dans les activités des professionnels du droit et de la justice ; 13.
111,Les travaux réalisés ont ainsi permis de rappeler l’importance de réguler les nouveaux outils de jurimétrie et d’assurer le respect de principes éthiques dans le cadre de la réutilisation de la donnée de justice.
111,"En conséquence, une Charte sur la transparence et l’éthique de l’utilisation des données judiciaires annexée au rapport a été adoptée pour garantir l’autorégulation des acteurs tant s’agissant des algorithmes utilisés pour l’exploitation de la base de données des décisions de justice que de la réutilisation des informations qu’elle contient."
114,"The process of focusing on quantitative data buried deep in case law brought about the introduction of a new class of tools called “analytical justice tools”, where the search is no longer focused on retrieving relevant textual information, but on amounts of money (in claims or damages calculations), lengths of prison sentence and the extent of other penalties."
114,"The Council of the European Union adopted in 2019 the 2019-2023 Action Plan on European e-Justice, which sets out a list of projects and initiatives (‘actions’) to be implemented as part of the 2019-2023 European e-Justice Strategy."
114,The drafting of a guide on the use of AI by lawyers in the EU was mentioned in the Action Plan under the possible actions to be implemented under ‘Artificial Intelligence for Justice’.
114,"Predicting Judicial Decisions from Legal Briefs, and What That Means for Access to Justice ’ [2021] Texas Law Review.The advantage of the integration approach is in its ease of use and the short learning curve."
114,"36 European Commission for the Efficiency of Justice (CEPEJ), ‘ Guidelines on Electronic Court Filing (e-Filing) and Digitalisation of Courts ’ (9 December 2021) 13 accessed 27 December 2021."
114,A report of the Conseil National des Barreaux calls this the level of “informative justice”.50 But it is not only the name of the court and the date of the decision that can be extracted from a legal text.
114,"Through the use of such analytical tools, case law becomes more transparent in terms of quantifiable information, and this is what the Conseil National des Barreaux calls “analytical justice”."
114,Analytical justice focuses on making past cases visible to users through queries based on figures.
114,"In English speaking countries, these tools are often called “predictive justice” tools."
114,"In that sense, even ranking of legal texts retrieved from a database in terms of relevancy is a prediction in itself (prediction of relevancy), in contrast to which predictive justice in this context usually means an output on the expected terms of the judgement or the outcome of a court process based on historical data."
114,We do not label these three levels as levels just because level “two” or “three” (analytical or predictive justice) would be more advanced in many ways than level “one” (informative justice).
114,"52 We avoid using the term „simulative justice” as the third level, as suggested in the report from the Conseil National des Barreaux already mentioned ( ibid 63. ), because that term is based on how the working of a specific tool was explained to drafters of that report, and it would be misleading to use the same term for other tools."
114,"Guide on the use of AI-based tools by lawyers and law firms in the EU30because it highlights the historical process of how solutions in informative justice are a prerequisite for analytical justice, and access to quantifiable figures in case law is in turn a prerequisite for any machine learning based divination or dispute resolution algorithms of a predictive nature."
114,"However, one has to be mindful that a predictive justice AI tool comes with its own considerable risks and special dangers compared to the other two levels."
114,"In informative and analytical justice, interpretation is undertaken by the user (the lawyer), and there is no risk of introducing further bias into the service provided (other than the bias already included in past cases, but that is rarely the responsibility of the lawyer)."
114,"56 Like explanations on how “virtual judges” make decisions in a simulation where virtual judges are actually just decision trees trained on dozens of features in hundreds of cases.A predictive justice AI tool comes with its own considerable risks and special dangers compared to the other two levels [informative and analytic justice]. … The lack of explainability and introduction of new bias could cause a problem, and therefore lawyers using such tools should be aware of the increase in such risks and take appropriate steps."
114,"Advanced searching techniques beyond the text: semantic search and argument mining Even what is called “informative justice” in the previous section has a great deal of potential for improvement, and advances in this area may fundamentally change how lawyers work in the future."
114,"If we are able to create a reliable representation of argumentation in case law, that could enhance not only informative justice, but also other levels of legal analytics.59 5.3.4."
114,60 ‘Article 33 - LOI N° 2019-222 Du 23 Mars 2019 de Programmation 2018-2022 et de Réforme Pour La Justice (1) - Légifrance ’ accessed 28 December 2021.
114,66 See Fashion ID judgement of the European Court of Justice (ECLI EU:C:2019:629) on a platform provider and the group administrator both considered as a joint controllers.
114,"Bibliography ‘Article 33 - LOI N° 2019-222 Du 23 Mars 2019 de Programmation 2018-2022 et de Réforme Pour La Justice - Légifrance ’ accessed 28 December 2021 Ashley KD, Artificial Intelligence and Legal Analytics (First, Cambridge University Press 2017) Bommasani R and others, ‘ On the Opportunities and Risks of Foundation Models ’ [2021] arXiv:2108.07258 [cs] accessed 19 December 2021 Bourne CP and Hahn TB, A History of Online Information Services, 1963-1976 (Cambridge, Mass : MIT Press 2003) accessed 27 December 2021 Chalkidis I and others, ‘ Neural Contract Element Extraction Revisited ’ (2021) abs/2101.04355 CoRR Choi CQ, ‘ 7 Revealing Ways AIs Fail ’ (IEEE Spectrum, 21 September 2021) accessed 14 December 2021 Debra Cassens Weiss, ‘ “Treated like a Robot,” Contract Lawyers Chafe under Fickle Facial Recognition Surveillance ’ (ABA Journal, 15 November 2021) accessed 19 December 2021."
114,"European Banking Authority, ‘ Guidelines on Outsourcing Arrangements ’ (5 June 2019) accessed 12 December 2021 European Commission, ‘ Communication from the Commission: Artificial Intelligence for Europe ’ (2018) accessed 19 November 2021 European Data Protection Board, ‘ Guidelines 02/2021 on Virtual Voice Assistants ’ (7 July 2021) accessed 14 January 2022 High-Level Expert Group on Artificial Intelligence, ‘ Ethics Guidelines for Trustworthy AI ’ accessed 12 December 2021 European Commission for the Efficiency of Justice (CEPEJ), ‘ Guidelines on Electronic Court Filing (e-Filing) and Digitalisation of Courts ’ (9 December 2021) accessed 27 December 2021 Ferrer X and others, ‘ Bias and Discrimination in AI: A Cross-Disciplinary Perspective ’ (2021) 40 IEEE Technology and Society Magazine 72 accessed 25 February 2022 Gohel P , Singh P and Mohanty M, ‘ Explainable AI: Current Status and Future Directions ’ [2021] arXiv:2107.07045 [cs] accessed 12 December 2021 Heaven D, ‘ Why Deep-Learning AIs Are so Easy to Fool ’ (2019) 574 Nature 163 accessed 25 February 2022 Homoki P , ‘ Overview on Average State of the Art IT Capabilities and Comparison with Best Practices United Kingdom, USA and Canada ’ (Council of European Bars and Law Societies (CCBE), European Lawyers Foundation) Lippi M and others, ‘ CLAUDETTE: An Automated Detector of Potentially Unfair Clauses in Online Terms of Service ’ (2019) 27 Artificial Intelligence and Law 117 accessed 25 February 2022 Lippi M and Torroni P , ‘ Argumentation Mining: State of the Art and Emerging Trends ’ (2016) 16 ACM Transactions on Internet Technology 1 accessed 25 February 2022 Lohn AJ, ‘ Estimating the Brittleness of AI: Safety Integrity Levels and the Need for Testing Out-OfDistribution Performance ’ [2020] arXiv:2009.00802 [cs, stat] accessed 14 December 2021 ‘Managed by Bots: Surveillance of Gig Economy Workers ’ (Privacy International) accessed 19 December 2021 Medvedeva M and others, ‘ Automatic Judgement Forecasting for Pending Applications of the European Court of Human Rights ’ (2021) accessed 25 February 2022 Mell P and Grance T, ‘ The NIST Definition of Cloud Computing ’ (National Institute of Standards and Technology 2011) NIST Special Publication (SP) 800-145 accessed 5 December 2021 Pasquale F, New Laws of Robotics: Defending Human Expertise in the Age of AI (The Belknap Press of Harvard University Press 2020) Poudyal P and others, ‘ ECHR: Legal Corpus for Argument Mining ’, ARGMINING (2020) accessed 25 February 2022 Guide on the use of AI-based tools by lawyers and law firms in the EU56‘Proposal for a Regulation of the European Parliament and of the Council Amending Regulation (EU) No 910/2014 as Regards Establishing a Framework for a European Digital Identity ’ accessed 21 November 2021 ‘Proposal for a Regulation of the European Parliament and of the Council Laying Down Harmonised Rules on Artificial Intelligence (Artificial Intelligence Act) and Amending Certain Union Legislative Acts ’ accessed 12 December 2021 ‘Proposal for a Regulation of the European Parliament and of the Council on Digital Operational Resilience for the Financial Sector and Amending Regulations (EC) No 1060/2009, (EU) No 648/2012, (EU) No 600/2014 and (EU) No 909/2014 ’ accessed 12 December 2021 ‘Proposal for a Regulation of the European Parliament and of the Council on European Production and Preservation Orders for Electronic Evidence in Criminal Matters ’ accessed 5 December 2021 ‘Survivorship Bias ’, Wikipedia (2021) accessed 18 December 2021 Themis Solutions Inc., ‘ 2021 Legal Trends Report Published by Clio ’ (August 2021) accessed 30 December 2021 Themis Solutions Inc., ‘ Legal Trends Report 2017 Powered By Clio ’ (2017) accessed 30 December 2021 Themis Solutions Inc., ‘ Legal Trends Report 2018 Powered By Clio ’ (2018) accessed 30 December 2021 Tippett EC and others, ‘ Does Lawyering Matter?"
114,"Predicting Judicial Decisions from Legal Briefs, and What That Means for Access to Justice ’ [2021] Texas Law Review Tuggener D and others, ‘ LEDGAR: A Large-Scale Multi-Label Corpus for Text Classification of Legal Provisions in Contracts ’, Proceedings of the 12th Language Resources and Evaluation Conference (European Language Resources Association 2020) accessed 10 October 2021 Vadász P and others, ‘ A Report on the Barriers and Opportunities in the Use of Natural Language Processing Tools in Small Legal Offices ’ (Council of European Bars and Law Societies, European Lawyers Foundation) accessed 25 February 2022 Vilone G and Longo L, ‘ Explainable Artificial Intelligence: A Systematic Review ’ [2020] arXiv:2006.00093 [cs] accessed 12 December 2021 Xudong Pan and others, ‘ Privacy Risks of General-Purpose Language Models ’, 2020 IEEE Symposium on Security and Privacy (SP) (2020) accessed 18 December 2021."
116,"The Commissioner for Human Rights11, the Consultative Commit tee of the Convention for the Protection of Individuals with regard to Automatic Processing of Personal Data (T -PD12) and the European Commission for the Efficiency of Justice (CEPEJ13) use a relatively similar generic definition referring to a set of scienc es, theories and techniques."
116,"16 See e.g. the reports of the Parliamentary Assembly of the Council of Europe, in particu lar on the need for democratic governance of AI ; the role of AI in policing and criminal justice systems ; preventing discrimination caused by AI ; ethical and legal frameworks for the research and development of neurotechnology ; AI and health care ; consequences of AI on labour markets ; and legal aspects of ‘autonomous vehicles’ ."
116,"5, 6, 7 ECHR) when these systems are used in situations where physical freedom or personal security is at stake (such as justice and law enforcement)."
116,"If applied responsibly and with prudence, however, certain AI applications can also make the work of justice and law enforcement professionals more efficient and hence have a positive impact on these rights."
116,4.4 Work in the field of justice 50.
116,"The European Commission for the Efficiency of Justice (CEPEJ) adopted in December 2018 the European Ethical Charter for the use of artificial intelligence in judicial systems75 which sets five key principles (respect of fundamental rights, non -discriminatio n, quality and security, transparency, impartiality and fairness, ""under the control"" of the user) for the use of AI systems in this field."
116,"On 22 October 2020, the PACE adopted 7 reports, focusing on: the need for democratic governance of AI; the role of AI in policing and criminal justice systems; discrimination caused by AI; threats to fundamental freedoms; medical, legal and ethical challenges in the fie ld of health care; consequences on labour markets; and legal aspects of ‘autonomous vehicles’."
116,"19 non-binding instruments in four core areas (data protection, health, de mocracy and justice) and was complemented by an overview of the Council of Europe’s instruments in other fields."
116,"The principles of privacy, justice and fairness showed the least variation across Council of Europe’s member States, observers and the rest of the world, and hence the highest degree of cross -geographical and cross -cultural stability."
116,"The development and use of AI systems has also been considered in sectorial strategies on agriculture, e -justice, public services, health, environment, education, security and defence, mobility and data."
116,"156 ▪ This right must be ensured in relation to the entire lifecycle of an AI system (design, development, implementation and use), as wel l as to the human choices around the AI system’s use, whether used in the public or private sector. ❖ Key obligations: o Member States are obliged to ensure that the AI systems they deploy do not result in unlawful discrimination, harmful stereotypes (including but not limited to gender stereotypes) and wider social inequality, and should therefore apply the highest level of scrutiny when using or promoting the use of AI systems in sensitive public policy areas, including but not limited to law enforcement, justice, asylum and migration, health, social security and employment. o Member States should include non -discrimination and promotion of equality requirements in public procurement processes for AI systems, and ensure that the systems are independently audited for discriminatory effects prior to deployment."
116,"This should also include the possibility to get insight into and challenge a n AI-informed decision in the context of law enforcement or justice, including the right to review of such decision by a human. o The right to judicial independence and impartiality, and the right to legal assistance. o The right to an effective remedy (Art."
116,"1 3 ECHR), also in case of unlawful harm or breach an individual’s human rights in the context of AI systems. ❖ Key obligations o Member States must ensure that AI systems used in the field of justice and law enforcement are in line with the essential requirements of the right to a fair trial."
116,"Moreover, this would secure access to justice should they fail to meet these obligations.173 125."
118,Justice ................................ ................................ ................................ ..................
118,"The Council of Europe has committed to framing their scope and implications in most of its specialised areas of activity, such as justice, data protection, equality and non -discrimination 3."
118,"3 European Commission for the Efficiency of Justice (CEPEJ), European Ethical Charter for the Use of Judicial Intelligence in Judicial Systems and their Environment ; Consultative Committee of the Convention for the Protection of Individuals with regard to the Processing of Personal Data (Convention 108), Gui delines on Artificial Intelligence and Data Protection ; European Commission against Racism and Intolerance (ECRI), Study, Discrimination, Artificial Intelligence and Algorithmic Decisions ."
118,"These applications have found their way into sectors such as law enforcement, justice, human resource management, financial services, transport, healthcare, public services, etc."
118,The European Commission f or the Efficiency of Justice already in 2018 outlined 5 principles for the use of AI in the judiciary in the “European Ethical Charter on the use of AI in the judicial systems and their environment”.
118,Redress in l ight of AI impact on human rights entails access to justice and effective remedy.
118,"As far as access to justice goes, it might be too soon to determine whether this is sufficiently guaranteed when it comes to AI and human rights impact."
118,"More importantly however, access to justice is challenged when many AI -applications are deve loped and deployed by only a handful of large private actors."
118,"In this respect, AI might serve as a good opportunity and think of a structure that would legally oblige private actors to comply with human rights and to grant access to justice if they fail to do so.58 The basic question is whether to a) accept the private power of AI companies and to make sure they use it responsibly, or to b) challenge it and try to reassert the power of the state."
118,"Furtherm ore, no single ethical principle is common to all of the 116 documents on ethical AI we reviewed. ➢ We found growing agreement around the following ethical principles: transparency, justice, non-maleficence, responsibility, and privacy."
118,"In contrast, they appear to refer more sporadically to the principles of beneficence and dignity. ➢ The principles of privacy, justice and fairness showed the least variation across CoE- member countries, CoE -observer countries and the rest of the world, hence the highest degree of cross - geographical and cross -cultural stability."
118,"Due to conflict of interest, self-regulation efforts by private AI actors are at particular risk of being promoted to bypass or obviate mandatory governance by governmental and intergovernmental authorities. ➢ In order to ensure inclusiveness, cultural pluralism and fair participation t o collective decision making on AI, the development of soft law documents by organisations located in currently underrepresented global regions, especially Africa and South America, should be promoted. ➢ The convergence of current soft law instruments around five generic ethical principles such as transparency, justice, non-maleficence, responsibility, and privacy reveals five priority areas of oversight and possible intervention by mandatory governance authorities at both the governmental and intergovernmental level. ➢ In order to be translated into effective governance, these ethical principles should be conceptually clarified."
118,"These are, by decreasing order of frequency of the sources in which they were featured: transparency, justice and fairness, non -maleficence, responsibility, privacy, beneficence, freedom and autonomy, trust, dignity, sustainability, and solidarity."
118,"49 Ethical principle Number of documents Included codes Transparency, explainability, explicability, understandability, Transparency 101/116 interpretability, communication, disclosure, showing Justice, fairness, consistency, inclusion, equality, equity, (non -)bias, (non-)discrimination, diversity, Justice and fairness 97/116 plurality, accessibility, reversibility, remedy, redress, challenge, access and distribution, impartiality Non-maleficence, security, safety, harm, protection, precaution, Non-maleficence 84/116 prevention, integrity (bodily or mental), non - subversion Responsibility, accountability, Responsibility 79/116 liability, acting with integrity Privacy, personal or private Privacy 74/116 information, confidentiality Benefits, beneficence, well - Beneficence 58/116 being, peace, social good, common good Freedom, autonomy, consent, Freedom and autonomy 48/116 choice, self -determination, liberty, empowerment Trustworthiness 41/116 Trust, trustworthiness Sustainability, environment (nature), Sustainability 20/116 energy, resources (energy) Dignity 20/116 Dignity Solidarity 10/116 Solidarity, social security, cohesion Table 2 - Frequency of ethical themes and associated codes 50 No single ethical principle appears to be common to the entire corpus of documents, although there is an emerging convergence around the following principles: transparency, justice and fairness, non - maleficence, responsibility and privacy."
118,"In contrast, they appear to refer more sporadically to the principles of justice, beneficence, and dignity."
118,"The principles of privacy, justice and fairness showed the least variation, hence the highest degree of cross -geographical and cross -cultural stability."
118,"Justice, fairness, and equity : Justice is mainly expressed in terms of fairness and prevention (or mitigation) of algorithmic biases that can lead to discrimination."
118,Documents disagree on how to achieve justice and fairne ss in AI.
118,We identified five main non - mutually - exclusive implementation strategies for preserving and promoting justice and fairness in AI: i.
118,"Our analysis shows the emergence of an apparent cross -stakeholder convergence on promoting the ethical principles of transparency, justice, non -maleficence, responsibility, and privacy."
118,"Although no single ethical principle is explicitly endorsed by all existing guidelines, transparency, justice and fairness, non -maleficence, responsibility and privacy are each referenced in more than half of all guidelines."
118,"In particular, the prevalence of calls for tr ansparency, justice and fairness points to an emerging moral priority to require transparent processes throughout the entire AI continuum (from transparency in the development and design of algorithms to transparent practices for AI use), and to caution the global community against the risk that AI might increase inequality if justice and fairness considerations are not adequately addressed."
118,"Both these themes appear to be strongly intertwined with the theme of responsibility, as the promotion of b oth transparency and justice seems to postulate increased responsibility and accountability on the side of AI makers and deployers."
118,"The convergence of current soft law instruments around five generic ethical principles such as transparency, justice, non-maleficence, responsibility, and privacy reveals five priority areas of oversight and possible intervention by mandatory governance authorities at both the governmental and intergovernmental level."
118,"After an init ial sector -specific analysis to map and identify key guiding principles in four core areas (data protection, health, democracy and justice), these principles are contextualised in the light of the changes to society produced by AI."
118,The fourth and the fifth sections are centred on democracy and justice .
118,69 European Commission for the Efficiency of Justice (CEPEJ).
118,"In this regard four key areas have been selected: data, health, democracy and justice. iii."
118,The following two tables provide a first example of this mapping exercise based on a preliminary overview of the data protection and justice realms to identify the guiding principles for future regulation of AI.
118,2018 Guiding principles and legal values Accountability Risk-based approach Precautionary principle Data quality & security Transparency Fairness Contextual approach Role of experts Participation/Inclusiveness Freedom of choice/Autonomy Human control/oversight Awareness Literacy Responsible innovation Cooperation between supervisory authorities 66 Figure 2: Justice Binding instruments Universal Declaration of Human Rights International Covenant on Civil and Political Rights International Convention on the Elimination of All Forms of Racial Discrimination Convention on the Elimination of All Forms of Discrimination against Women Convention for the Protection of Human Rights and Fundamental Freedoms Charter of Fundamental Rights of the European Union Impacted areas Processing of judicial decisions and data Predictive policing Related non - binding instruments CEPEJ.
118,Figure 4: Common guiding values in the field of data protection and justice 68 III.
118,The fourth and the fifth sections are centred on democracy and justice.
118,"The result of this analysis made it possible to group the guiding principles and values around a number of key elements which emerged in terms of distribution (frequency): Non-discrimination (15) Diversity, inclusion and pluralism (13) Privacy and Data Protection (11) Transparency (9) Equality (8) Access to justice, fair trial (7) Human control (7) Impartiality (6) Access to information (5) Security (5) 74 See Council of Europe -Committee of experts on internet intermediaries (MSI -NET), 2018."
118,"Such committees may play an especially important role in areas where transparency and stakeholder engagement can be more difficult due to competing interests and rights, such as in the fields of predictive justice, crime prevention and detection.94 Appropriate mechanisms should be put in place to ensure the independence of these committees of experts.95 88 See GAI, para."
118,124 See e.g. above Fig ure 4: Common guiding values in the field of data protection and justice.
118,"Justice As in the previous section, the field of justice is a broad domain and analysing the whole spectru m of the consequences of AI on justice and its related effects on democracy would be too ambitious."
118,"Justice differs from data protection and health in the absence of specific and dedicated binding instruments, such as Convention 108+ and the Oviedo Convention."
118,"This exercise is facilitated by the European Ethical Charter on the use of artificial intelligence (AI) in judicial systems and th eir environment, adopted by the CEPEJ in 2019, which directly addresses the relationship between justice and AI."
118,"Guiding principles for the development of AI in the field of justice can be derived from the following binding instruments: the Universal Declaration of Human Rights, the International Covenant on Civil and Political Rights, the Convention for the Protection of Human Rights and Fundamental Freedoms, the International Convention on the Elimination of All Forms of Racial Discrimination, the Convention on the Elimination of All Forms of Discrimination against Women, and the Conventio n for the Protection of Human Rights and Fundamental Freedoms.188 Given the range of types and purposes of operations in this field and the various professional figures and procedures involved, this section makes a functional distinction between two areas: (i) judicial decisions and alternative dispute resolutions (ADRs) and (ii) crime prevention/prediction."
118,"Given the textual nature of legal documents, natural language processing (NLP) plays an important role in AI applications for the justice sphere."
118,"All these constraints suggest a careful and more critical adoption of AI in the field of justice than in other do mains and, with regard to court decisions and ARDs, suggest following a distinction between cases characterised by routinely and fact -based evaluations and cases characterised by a significant margin for legal reasoning and discretion.192 Court decisions an d ADRs Several so-called Legal Tech AI products do not have a direct impact on the decision - making processes in courts or alternative dispute resolutions (ADRs), but rather facilitate content and knowledge management, organisational management, and performance measurement.193 These applications include, for example, tools for contracts categorisation, detection of divergent or incompatible contractual clauses, e -discovery, drafting assistance, law provision retrieval, assisted compliance review."
118,192 See the following Section on the dist inction between codified justice and equitable justice.
118,193 See European Commission for the Efficiency of Justice (CEPEJ).
118,"Here, the distinction between codified justice and equitable justice196 suggests that AI should be circumscribed for decision -making purposes to cases characterised by routine and fact -based evaluations."
118,"This entails the importance to carry out further research on the classification of the different kind of decisional processes to identify those routinised applications of legal reasoning that can be demanded to AI, preserving in any case human overview that also guarantees legal creativity of decision makers.197 Regarding equitable justice, as the literature points out,198 its logic is more complicated than the simple outcome of individual cases."
118,"The Universal Declaration of Human Rights (Articles 7 and 10), the ICCPR 195 See also European Commission for the Efficiency of Justice (CEPEJ)."
118,"196 See Re and Solow -Niederman, 2019, 252 -254 (“Equitable just ice entails both reflection on the values set in place by the legal system and the reasoned application of those values, in context […] Codified justice refers to the routinized applicati on of standardized procedures to a set of facts […] In short, codifie d justice sees the vices of discretion, whereas equitable justice sees its virtues”)."
118,199 See European Commission for the Efficiency of Justice (C EPEJ).
118,"As stated by the European Commission for the Efficiency of Justice, “the neutrality of algorithms is a myth, as their creators consciously or unintentionally transfer their own value systems into them”."
118,"Many cases of biases regarding AI applications confirm that these systems too often – albeit in many cases unintentionally – provide a partial representation of society and individual cases, whic h is not compatible with the principles of equal treatment before the law and non-discrimination .200 Data quality and other forms of quality assessment (impact assessment, audits, etc.) can reduce this risk201but, given the degree of potentially affected interests in the event of biased decisions, the risks remain high in the case of equitable justice and seem disproportionate to the benefits largely in terms of efficiency for the justice system.202 Further concerns affect the principles of fair tr ial and of equality of arms ,203 when court decisions are based on the results of proprietary algorithms whose training data and structure are not publicly available.204 A broad notion of transparency might address these issues in relation to the use of AI in judicial decisions, but the transparency of AI – a challenging goal in itself – cannot address the other structural and functional objections cited above."
118,"This is the case, for instance, of the independence of the judges or the principles of fair trial and of equality of arms, which concern justice alone.220 Second, some guiding principles are the same in different areas, but with different nuances in each context."
118,"Then again, in the context of justice, transparency has a more complex significance being vital to safeguard fundame ntal rights and freedoms (e.g. use of AI in the courts), but also requiring limitations to avoid prejudicing competing interests (e.g. crime detection and prevention in predictive policing)."
118,"For instance, in the field of data protection there are several provisions implementing these principles with a significant degree of detail, whereas in the case of democracy and justice these principles are less developed with regard to data intensive applications such as AI."
118,"These mainly concern broad areas, such as democracy and justice, where different options and interpretations are available, depending on the political and societal vision of the future relationship between humans and machines."
118,Artificial Intelligence in the Context of Crime and Criminal Justice.
118,"Korean Institute of Criminology 2018. https://www.cyberjustice.ca/publications/lintelligence -artificielle -dans -le-contexte -de- lacriminalite -et-de-la-justice -penale/ , accessed 30.05.2020."
118,European Commission for the Efficiency of Justice (CEPEJ).
118,Developing Artificially Intelligent Justice.
118,Algorithmic Justice: Algorithms and Big Data in Criminal Justice Settings.
118,Justice - Universal Declaration of Human Rights - International Covenant on Civil and Political Rights CEPEJ.
118,"In addition, there are many social rights (and Charter) aspects related to subjects covered by a wide range of other areas of CoE work: Some examples: - CM Rec(93)1 on effective access to the law and to justice to the very poor; - social rights aspects of the prison rules (health care, living conditions, employment, education, family rights,…); - etc."
118,"Impacted areas Impacted areas (applications) Biomedicine • AI-based surveillance, prevention, diagnosis and intervention in healthcare settings • Prediction -based surveillance, diagnosis, monitoring, financing (insurance) treatments (e.g. user facing apps and online services beyond healthcare settings) Antidiscrimination • Automated Decision -making covering different areas in both public and private sectors (e.g. job applications, welfare/social benefits, access to goods and services, such as bank loans, insurance) • Predictive policing (which holds high ris k of racial profiling) • Predictive justice • Facial recognition • Behavioural prediction technologies such as emotional recognition and AI -based lie detection • Personal assistance tools (e.g."
118,"Siri) • Content moderation • Data protection Cybercrime and electronic evidence • Automated cybercrime and cyberattacks, such as: - Distributed denial of service (DDOS) attacks - Criticial information infrastructure attacks - Man-in-the-middle attacks - Phishing and similar social engineering techniques - Scanning for vulnerabilities - Etc. • Cybercrime investigations and computer forensics: - Collection and analysis of electronic evidence (in relation to any crime). - Attribution - Reverse engineering • Cybersecurity and prevention of cybercrime: - Detection of malware, intrusions, etc. - Automated patching of vulnerabilities Justice sector • Processing of judicial decisions and data: - to support judicial decision -making or judicial research) - On-line dispute resolution - Provision of legal advice to litigants • Predictive policing Congress of Local and Regional Authorities • Provision of local public services. • Instruments to promote citizen participation. • Wide variety of digital and electronic applications in cities and local communities. • Application of information and communication technologies (ICT) to improve the quality of life and working environments in cities. • Smart city -governance."
118,"General issues related to AI as an employment sector: • The lack of participation /under -representation of women exacerbates the potential gender biases and excludes them from a powerful sector • Exploitation of “click workers” in Europe and worldwide (low salaries, no social protection, no labour rights , long term exposition to damaging content for content moderators etc.) Specific challenges • Discriminatory job screening • Automated decision -making for public and private services • Facial & speech recognition (performing worse for women, especially some groups) • Surveillance /stalking facilitated by AI tools ex in the context of domestic violence • Automated decision -making exacerbating the possibility for multiple discrimination based on sex/gender, race and social origin by combining secondary data like level of education, address, level of income. • Predictive justice (ex VAW) • Predictive health based on gender -biased data (ex some diseases characterised as “female” or “male”) • Inherited biases in machine -led content moderation (high tolerance for sexism, sexist hate speech & VAW) • Gendered virtual assistants / robots perpetuating gender stereotypes • Gendered marketing perpetuating gender stereotypes • Differential pricing ba sed on sex/gender Positive impacts • Use of GPS tracking devices to ensure respect of protection orders in cases of VAW • Use of AI by law enforcement agencies to conduct risk assessment in DV cases • Use of AI to identify and track gender bias and being able to quarantine or eliminate the spreading of (sexist) hate speech on platforms • Developments of Apps to support and inform victims of VAW • Use of AI -based tools to analyse content and track gender bias / analyse representation (ex in movies or other media) Culture, Creativity and Heritage • Access and participation in public / cultural life; • FoE (incl. freedom of artistic expression) • Access to impartial information? • Automated decision making, targeting, profiling • Automated decision making, targeting, profiling; • But also learning of endangered languages to preserve/ protect them • Automated assistance in administration, health etc. for speakers from minority groups/ languages • Geolocalisation, Predictive policing, criminal analytics (re destruction, looting, trafficking of cultural property; targeting; learning re endangered heritage can help with its protection • Automated creation of content, targeting, profiling (re cultural creation, exchange, consumption) • Audiovisual content developmen t & production: - Predictive audience analysis - Automated script analysis - Assisted or automated script writing - Computer Generated Images (SFX, Animation...) - Automated location scouting, scheduling and budgeting (impact yet to be assessed) • Content distribution 107 - Recommendation algorithms - Targeted advertising - Automated control of content (compliance with regulations) / Censorship (ref."
118,"Including, but not limited to: many aspects of employment (including but not limited to monitoring and surveillance, job screening and work in the platform economy, etc); ditto different aspects of health (the right to enjoy the highest standard of health attainable); ditto education; equally for social protection, integration and participation; let alone non-discrimination; housing and protection from social exclusion; For example: justice (both as regards the administration of justice, and criminal justice and prisons; trafficking in human beings (forced labour and exploitation, …); migration and refugees; gender equality, plus violence against women; children and youth, plus education; bioethics; non-discrimination, Roma and Travellers, SOGI ; drug policy; participation and culture; sport; 108 Annex 3 ."
118,Problem of evidence in the cloud versus territorial enforcement jurisdiction for criminal justice (to be addressed in the 2nd Additional Protocol to the Budapest Convention).
118,"Justice sector Non-discrimination Data quality & security Transparency Impartiality Fairness Freedom of choice/ Independence of judges (decision -making process) Human control/oversight Guarantees of the right of access to the judge Guarantees of the right to a fair trial Precautionary principle for applications missing fundamental transparency requirements Congress Transparency Human control (oversight) Impartiality Right to privacy Data security Cyber security Non-discrimination Inclusive cities Financial sustainability Monitoring safety Service efficiency Digital literacy Democracy and participation – Deep fakes, Microtargeting and propaganda in the framework of electoral processes 109 Democracy and participation Right to free elections Freedom of expression Right of individuals to access the internet Right to private life; Data protection Equality of opportunity for parties and candidates Requirement of a neutral attitude by state authorities with regard to the election campaign, to coverage by the media, and to public funding of parties and campaigns Requirement of a minimum access to privately owned audio -visual media, with regard to the election campaign and to advertising, for all participants in elections Transparency in campaign funding Prevention of improper influence on political decisions through financial donations Responsible, accurate and f air media coverage of electoral campaigns; right of reply, modalities of disseminating opinion polls, transparency requirements on paid advertising content; media pluralism Network neutrality Protection of individuals with regard to the collection and proc essing of personal data on information highways Non-discrimination Data quality & security Transparency Impartiality Fairness Freedom of choice/ Independence of judges (decision -making process) Human control/oversight Guarantees of the right of access to the judge Guarantees of the right to a fair trial Balance between sometimes conflicting rights such as e.g. - right to free elections / freedom of expression - right of access to information including on the internet / right to private life, data pro tection Standards which would be applicable and adequate for digital advertising/campaigns, e.g. with respect to - equality of opportunity for parties and candidates - election campaign and campaign funding, transparency and enforcement - fair media coverage, media pluralism - accountability of internet intermediaries in terms of transparency and access to data enhancing transparency of spending, specifically for political advertising - net neutrality - data protection Freedom of expression Individual autonomy Equality Democratic security Transparency and accountability Independence of the media Diversity and pluralism Precautionary principle for applications missing fundamental transparency requirements 110 Elections - Free and fair elections - Freedom of choice/opinion/speech - Universal suffrage - Equal suffrage - Free suffrage - Secret suffrage - Direct suffrage - Frequency of elections - Transparency of electoral process - Inclusiveness of electoral process - Gender balanced - participation/representation in public decision -making - Principle of use of AI systems in electoral processes (especially e -voting systems, etc.) - Opportunities offered by AI to have more inclusive electoral processes (AI as tool for the Electoral Management Bodies and election commissions, AI as an assistant for the voters)."
118,"Democracy (excluding issues relating to elections and electoral cycle) Transparency Impartiality Fairness Freedom of choice Freedom of expression Freedom of assembly and association Access to information Human control/oversight Diversity Equality Non-discrimination Data quality & security Data protection Independence - Role of intermediaries - Tech & digital literacy - Question of who owns the data - Democratic oversight - Open data and open government - Risk assessment Good Governance - Non-discrimination - Data quality & security - Impartiality - Fairness - Participation, Representation Fair Conduct of Elections - Responsiveness - Efficiency and Effectiveness - Openness and Transparency - Rule of Law - Ethical Conduct - Competence and Capacity - Innovation and Openness to Change - Sustainability and Long -term Orientation - Sound Financial Management - Human rights, Cultural Diversity and Social Cohesion - Accountability - Redress mechanisms - Access to remedy - Independence - Democratic oversight - Access to remedy and redress mechanisms in case of automated and algorithmic decisions making by public officials - Role of intermediaries - Tech literacy & competences - Questions of who actually owns the data - Open data and open government - Civil and criminal liability - Risk assessments and risk management 111 Gender equality including violence against women Equality and non -discrimination Integrity / Elimination of violence (against women) Equal access to justice Guarantees of the right to a fair trial and to redress Un-biased data (Gender) inclusiveness of AI as a sector AI as an employment sector respecting labour and social rights Data quality & security Transparency & explainability Accountability Impartiality Fairness Human control/oversight Digital literacy and closing existing digital (gender) gaps, essential with regards to right to redress – if citizens & consumers do not understand AI, they will not be able to claim their rights Precautionary principle for applications missing fundamental transparency requirements Ethical principles such as “do no harm” are not respected because some of the spyware apps are developed and advertised for the sole purpose of “knowing what your wife is up to”."
118,"Such committees may play an especially important role in areas where transparency and stakeholder engagement can be more difficult due to competing interests and rights, such as in the fields of predictive justice, crime prevention and detection."
118,"Acknowledgments The authors would like to thank Cedric Sabbah, Director of International Cybersecurity & IT Law at the Office of the Deputy Attorney General (International Law), within Israel's Ministry of Justice, Prof."
118,"In the development of each of those projects, Digital Israel has worked with in -house counsel and Ministry of Justice constitutional counsel, to ensure that the development an d deployment of each project complies with applicable constitutional and administrative law limitations Digital health The project has ambitious goals, including:242 • Customized treatment: promoting research, development and implementation of tools that allow the patient to receive the best and most personalized treatment; • Promoting health and patient prevention through use of digital tools in a way that shifts the focu s from patient care to preventive medicine; • Sustainable health: promoting the development and implementation of systems that increase the operational and managerial effectiveness of the health system, in a way that frees up existing resources; • Development and implementation of digital tools that streamline communication between the Ministry of Health and those it serves; • Delivery of emergency treatment services through an appointment management system and an application informing the patient on the progress of the treatment."
119,"36 Anjanette Raymond, The Dilemma of Private Justice Systems: Big Data Sources, the Cloud and Predictive Analytics , NORTHWESTERN JOURNAL OF INTERNATIONAL LAW & BUSINE SS, FORTHCOMING (2014), http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2469291 (last visited Jul 22, 2015); Kate Crawford, Can an Algorithm be Agonistic?"
119,"56 Jeroen van den Hoven & Emma Rooksby, Distributive justice and the value of information: A (broadly) Rawlsian approach , 376 INFORMATION TECHNOLOGY AND MORAL PHILOSOPHY (2008)."
119,"Models of the (ideal) doctor patient relationship have adapted over time in recognition of the growing importance of patient autonomy and its appropriate balance with other ethical obligations of the doctor towards beneficence, non -maleficence, and justice.124 An influential paper from Emanuel and Emanuel (1992) proposed four models for the doct or-patient relationship: ► Paternalistic Model – This model vests the vast majority of decision -making power in the doctor."
119,"For example, approaches to care ethics and feminist ethics focus on related goods such as the caring role of t he health professional , relationships and care responsibilities (in contrast to a focus on justice and rights) ,135 tacit knowledge and context -sensitive care that respond s to the interests and needs of patients as unique, socially embedded individuals , and power imbalances and coercion owing to the vulnerable position of the patient."
119,"NUSSBAUM , FRONTIERS OF JUSTICE DISABILITY , NATIONALITY , SPECIES MEMBERSHIP (OIP): DISABILITY , NATIONALITY , SPECIES MEMBERSHIP (TANNER LECTURES ON HUMAN VALUES ) (New Ed ed."
119,"As with all practices, phronesis or prudence is a central virtue in medicine, without which other virtues cannot be incorporated into behaviour through virtuous act s.246 Justice, truthfulness and courage are also necessary to protect medicine from the corrupting power of medical institutions, including hospitals, paying organisations and government departments.247 These three core virtues are necessary for continuous revision of standards of excellence and internal goods by practitioners, which requires critical self -reflection on the relationship between one’s actions and the norms of the practice, or the institutional influence on the definition and realisation of nor ms.248 Justice is defined broadly as “the strict habit of rendering what is due to others,”249 or “the virtue of rewarding desert and of repairing failures in rewarding desert within an already constituted community.”250 To be just, standards for treating people in a community must be “uniform and impersonal,” meaning it is unjust to favour personal acquaintances."
119,"In social or national healthcare systems, justice can be applied to the distribution of medical resources ( e.g., pharmaceuticals, treatments, clinical encounters) in a manner fair to all stakeholders."
119,"Justice is not merely a quantitative notion, by which all stakeholders receive an equal share, but instead requires matching resources to the needs of the patient a nd making judgments between the relative importance of different needs."
12,"Making government services more efficient and accessible: Despite often being slow to adopt new technologies, governments around the world are using AI, from the local to the national levels, to make public services more efficient and accessible, with an emphasis on developing “smart cities.” AI is also being used to allocate government resources and optimize budgets.37 HARMFUL AI Perpetuating bias in criminal justice: There are many documented cases of AI gone wrong in the criminal justice system."
12,"38 A 2016 ProPublica investigation revealed that not only was COMPAS, an ML-powered software widely used in the U.S. criminal justice system, was inaccurate at forecasting future crime and heavily biased against black defendants."
12,"Considering ethical concepts such as justice, fairness, transparency, and accountability allows for valuable debate about the societal impacts of AI, and the role of AI in our lives.52 There is also an academic research community devoted to addressing ethical issues.53 Ethics have helped those researching and developing AI to define boundaries for themselves."
12,"In countries which have not abolished the death penalty, sentence of death may be imposed only for the most serious crimes in accordance with the law in force at the time of the commission of the crime and not contrary to the provisions of the present Covenant. ” - Article 6 of the ICCPR The growing use of AI in the criminal justice system risks interfering with rights to be free from interferences with personal liberty."
12,"One example is in recidivism risk-scoring software used across the U.S. criminal justice system to inform detainment decisions at nearly every stage, from assigning bail to criminal sentencing.62 The software has led to more black defendants falsely labeled as high risk and given higher bail conditions, kept in pre-trial detention, and sentenced to longer prison terms."
12,"In criminal justice, this discrimination is often the result of forms of bias."
12,"Article 35 of the EU’s General Data Protection Regulation (GDPR) sets out a requirement to carry out a Data Protection Impact Assessment (DPIA); in addition, Article 25 of the GDPR requires data protection principles to be applied by design and by default from the conception phase of a product, service or service and through its lifecycle. accessnow.org33 HUMAN RIGHTS IN THE AGE OF ARTIFICIAL INTELLIGENCEthe uses of AI for these purposes.118 Any assessment process should include: • Testing and audits by independent experts • Identifying measures to mitigate identified risks and prevent any rights violations from occurring, and measuring compliance and efficacy • A failsafe to terminate acquisition, deployment, or any continued use if at any point an identified human rights violation is too high or unable to be mitigated • Identification of any new legal safeguards needed to protect human rights in specific applications of AI tools • Special determinations of bias, particularly in the criminal justice sector due to the risks to fair trial, right to liberty, and non-discrimination • If a third party is used to develop and/or implement the system, a requirement for the third party to participate in the human rights assessment process 3."
12,"There should always be a human in the loop, and for high-risk areas, including criminal justice, significant human oversight is necessary."
12,This is particularly important in areas such as in law enforcement and the justice system.
120,46 ODR and access to justice (article 6 and 13) ................................ ................................ ................
120,(5) The use of online courts has the ability revolutionise access to justice for litigants.
120,The development of new procedures to resolve disputes online can revolutionise access to justice to persons who would usually be unable to understand court procedures without hiring a lawyer.
120,"It could improve the justice system to make it more accessible for those who live far from legal centres or who struggle to afford the costs of seeking justice, by providing cheaper, alternative means to resolving disputes."
120,This is a massive improvement of access to justice for litigants.
120,(7) An issue with ODR and access to justice is that those who are computer illiterate or have no access to technology might be side -lined in the process.
120,Requiring parties to use technology to resolve disputes could inhibit access to justice if there is a great discrepancy between the parties and their access to technology.
120,"The move to online and virtual justice also threatens to significantly increase the number of unrepresented defendants, to further discriminate against vulnerable defendants, to CDCJ(2018) 5 7 inhibit the relationship between defence lawyers and their clients, and, as some argue, make justice less open."
120,"(8) If some litigants do not have access to, or the ability to use, technology and the internet, these litigants will be excluded from the administration of justice."
120,"Traditionally members of the public have been granted physical access to the court building, but many countries in Europe do not allow public broadcasting of trials on TV for the reason that this may influence advocates and judges who then ” play” to populist sentiments of crowd watching which may not lead to better justice."
120,"This would correspond to the pyramid model of dispute resolution which integrates legal advic e (the parties informing themselves about their legal rights and their legal position through the use of expert systems/artificial intelligence), negotiation and conflict resolution techniques (restorative justice), facilitated negotiation and mediation, a nd adjudication (potentially several stages, including the possibility of review and appeal)."
120,"(17) Generally speaking, like in other areas of digiti zation, ODR may have a negative impact on data protection and privacy in that online justice is likely to generate a much greater wealth of data (including metadata, for example who accessed a particular court record when and from where), increases the pos sibilities of data processing, searching, data mining and the use of artificial intelligence (which is the other side of the coin of increased access to justice) and online data (including court data) may be more mobile (easy online transfer), sticky (in t he sense that data remains on storage devices until erased) and vulnerable to unauthorised, remote access (computer hacking from anywhere in the world)."
120,"If ODR is to be implemented into public justice systems, these systems mu st be designed in such a way that there is equality of arms between the litigants."
120,"(25) Given the pressure of high caseloads and insufficient resources from which most justice systems suffer, there is a danger that support systems based on artificial intelligence are inappropriately us ed by judges to “delegate” decisions to technological systems that were not developed for that purpose and are perceived as being more ‘objective' even when this is not the case."
120,"A second expert was also appointed, Petra Jurina who is Head of Service for Civil Procedure Law, Commercial Law and Alternative Dispute Resolution at the Ministry of Justice in Croatia who helped to produce the Dra ft Questionnaire ."
120,To analyse the compatibility of Online Dispute Resolution with the right to a fair trial both in terms of the challenges to the right of a fair trial as well as opportunities afforded by Online Dispute Resolution to provide greater access to justice and enha nced due process.
120,"3 J Hornle Cross -border Internet Dispute Resolution (Cambridge University Press 2009) 4 Dory Reiling, ‘E -justice: experiences with court IT in Europe’ at pg."
120,However such processes are only part of the Study to the extent that they are part of the civil or administrative procedure of the country concerned ( ie mandatory or ordered by a judge or someho w annexed or integrated into the official civil /administrative justice system).
120,Q.A.3: under Belgian Law family disputes are dealt with by the Family Tribunal and the Justice of the Peace deals with neighbourhood disputes and other minor disputes - but there are no specific ODR processes/techniques for these special tribunals other than those used in the ordinary civil courts.
120,"If any criminal or civil proceedings, the Court may – if it considers that justice requires so – to allow a witness who is abroad, to give his/her testimony via videoconference."
120,The “ePodatelna“ system can be used (https://epodatelna.justice.cz/ePodatelna/epo1200new/form.do ).
120,"This is regulated in the Administration of Justice Act, chapter 26 and 27."
120,"France Q.A.1 and Q.A.2 A 2016 Act (La loi n° 2016 -1547 du 18 novembre 2016 de modernisation de la justice du XXIème siècle) has introduced into French Law an obligation to attempt mediation/conciliatio n led by a judicial mediator, when the submission of the case to the trial court is envisaged by statement to the court registry."
120,Q.A.4 In 2013 the Ministry of Security and Justice in cooperation with the Council for the Judiciary started a modernization program for the judiciary.
120,"The Portugues e Ministry of Justice has developed an online platform – named ‘Citius’, accessible at www.citius.mj.pt – to dematerialise proceedings by treating electronically all information belonging to the proceedings (such as claims, counterclaims, responses and rel ated documents), thus reducing their physical form to a minimum."
120,"While ‘Citius’ is managed by the Ministry of Justice, enforcement officers use an application managed by their professional association (‘Ordem dos Solicitadores e dos Agentes de Execução’) which interconnects with ‘Citius’."
120,"As for civil courts, the Portuguese Ministry of Justice has developed an online platform designed for administrative courts – named ‘SITAF and accessible at www.taf.mj.pt – to dematerialise proceedings by treating electronically all information belonging to the proceedings (such as claims, counterclaims, responses and related documents), thus reducing their physical form to a mi nimum."
120,The last report drawn up by the mediator at the end of the mediation negotiations is submitted to the Department of Mediation of the M inistry of Justice Directorate General for Civil Affairs.
120,"This is a challenge which this report must attemp t to tackle: how to ensure that, if ODR mechanisms are developed and implemented into the court systems of EU Member States, these ODR systems are compliant with the right to a fair tri al: a right that imposes procedural safeguards onto the justice system, and which would impose procedural safeguards onto the ODR systems."
120,This must be done in a way that does not destroy the efficiency savings and access to justice gained through ODR.
120,"The fair trial standards to be developed foc us on the following challenges i ) due process in a narrow sense (equality of arms, impartiality, transparency etc), ii) access to justice and the digital divide, iii) issues inherent in the technology itself, for example prejudice issues embedded in artificial intelligence and iv) cybersecurity (authenticity, identification and integrity) and data protection."
120,"The Civil Justice Council formed an Online Dispute Resolution Advisory Group reporting in February 2015 and recommending that there should be a new, Int ernet based , court service, known as the HM Online Court."
120,Lord Justice Briggs has been tasked in July 2015 to review the structure of the civil courts in England & Wales with a view to their modernisation and is currently consulting on the possibility of online courts for lower value disputes.
120,"In 2012, the British Columbia government passed the Civil Resolution Tribunal Act, “with the goal of using technology and ADR to increase access to justice for British Columbians with small claims and condominium property disputes.”17 36."
120,"The Civil Resolution Tribunal (CRT) is Canada’s first online tribunal, and currently the only ODR system in the world that is fully integrated into the justice system."
120,"A key design feature of the CRT is that wherever possible, a user should only have to enter information once, and the system should carry this information forward to other stages of the CRT 17 Shan non Salter, ‘ODR and Justice System Integration: B.C.’s Civil Resolution Tribunal’ (2017) at pg."
120,"18 Shannon Salter, ‘ODR and Justice System Integration: B.C.’s Civil Resolution Tribunal’ (2017) at pg."
120,"(2017) 34 Windsor Y B Access Just 19 Taken from Shannon Salter, ‘ODR and Justice System Integration: B.C.’s C ivil Resolution Tribunal’ (2017) 34 Windsor Y B Access Just CDCJ(2018) 5 46 process."
120,"From beginning to end, the CRT process is intended to take 60 to 90 days for most cases, and the average total cost to the parties is roughly the same as in Small Claims Court, or about $200.21 ODR AND ACCESS TO JUSTICE (ARTICLE 6 AND 13) 39."
120,"As has been noted above, ODR has the ability to revolutionise the public justice system."
120,"If designed and implemented c orrectly, it has the ability to drastically enhance 20 Shannon Salter, ‘ODR and Justice System Integration: B.C.’s Civil Resolution Tribunal’ (2017) at pg."
120,CDCJ(2018) 5 47 access to justice for persons who would ordinarily be outcasts in the justice system.
120,"However, if developed in the wrong hands it may have an opposite effect and actually reduce access to justice by placi ng technological barriers to persons who do not ordinarily have the capacity to use technology."
120,"If ODR is the future of justice, which it seems is the case, then it is of fundamental importance to develop standards for ODR; standards by which ODR can be d eveloped and implemented and under which justice can be carried out."
120,"Judgment shall be pronounced publicly but the press and public may be excluded from all or part of the trial in the interests of morals, public order or national security in a democratic society, where the interests of juveniles or the protection of the private life of the parties so require, or to the extent strictly necessary in the opinion of the cou rt in special circumstances where publicity would prejudice the interests of justice .” 43."
120,"To realise these elements of a fair trial, it is quite obviously essential that persons have the right of access to court, for without access to justice there cannot be justice."
120,"Moreover, ODR can have various implications for the right of access to court (or access to justice)."
120,The use of online courts has the ability revolutionise access to justice for litigants.
120,The development of new procedures to resolve disputes online can revolutionise access to justice to persons who would usually be unable to understand court procedures without hiring a lawyer.26 The use of ODR could level the playing field of parties who would ordinarily find it hard to access courts.
120,"It could improve the justice system to make it more accessible for those who liv e far from legal centres or who struggle to afford the costs of seeking justice,27 by providing cheaper, alternative means to resolving disputes."
120,"ODR processes may be able to facilitate access to justice in that, if designed and developed correctly, ODR s ystems can be economically viable, efficient, fast and flexible.28 This is quite an obvious characteristic of online systems."
120,"Increased high internet access reflects social and generational change of how people now lead their lives, but what of the vulnerable users and those without access?29 Requiring parties to use technology to resolve disputes could inhibit access to justice if there is a great discrepancy between the parties and their access to technology.30 The move to online and virtual justice also threatens to significantly increase the number of unrepresented defendants, to further discriminate against vulnerable defendants, to inhibit the relationship between defence lawyers and their clients, and , as some argue, make justice less open.31 65."
120,"Given the discussion about advantages and disadvantages above, it is important to note that parties must always have the right of access to justice."
120,"Although ADR is permissible and parties are allowed to waive their right to access a court, when certain means of resolving a d ispute become compulsory, it must be guaranteed that such means give the parties the right to access justice."
120,"Thus, if ODR is implemented into the court system or used in a compulsory ADR process, the right of the parties to access justice cannot be violat ed."
120,"If some litigants do not have access to, or the ability to use, technology and the internet, these litigants will be exclu ded from the administration of justice."
120,"Therefore, if ODR is implemented, there should (a) either be an alternative paper -based traditional means of having a dispute resolved for parties who do not have this access to technology and the internet or (b) a c omprehensive system of legal 26 J Rozenberg QC, ‘Justice Online: Just as Good?’ (2017)."
120,"27 L Tickle, The Guardian, ‘Online Justice: why co urts should explore emerging digital possibilities (2017)."
120,"29 Robert Thomas, ‘Current Developments in UK Tribunals: Challe nges for Administrative Justice’ (2016)."
120,"30 O Bowcott, The Guardian, ‘Government’s £1bn plan for online courts ‘challenges open justice’ (2017)."
120,"31 O Bowcott, The Guardian, ‘Government’s £1bn plan for online courts ‘challenges open justice’ (2017)."
120,This may have an impact on the way in which ODR systems are designed and there may be undue influenc e placed on the administrators of the ODR system to retrieve such information at the expense of the distribution of justice.
120,"One author argues that the move to online and virtual justice threatens to significantly increase the n umber of unrepresented defendants, to further discriminate against vulnerable defendants, to inhibit the relationship between defence lawyers and their clients, and to make justice less open.39 This is most certainly a point that deserves attention."
120,"If tech nology is used (or allowed to be used) in a way that does not address concerns relating to access to justice and fairness, then those persons who are in a vulnerable position and who have less access to resources could be even more prejudiced than they alr eady are, at the hands of technology."
120,"“The Court reiterates that the public character of proc eedings before the judicial bodies referred to in Article 6 § 1 protects litigants against the administration of justice in secret with no public scrutiny; it is also one of the means whereby confidence in the courts, superior and inferior, can be maintain ed.”50 “By rendering the administration of justice visible, publicity contributes to the achievement of the aim of Article 6 § 1, namely a fair trial, the guarantee of which is one of the fundamental principles of any democratic society, within the meaning of the Convention.”51 46 Werner v Austria (1998) 26 EHRR 310,349 ; Scarth v UK (1999) 27 E.H.R.R."
120,"Trust in a justice system is vital to its legitimacy and success.55 If the public cannot scrutinise cases and decisions that are ma de, then there may no public approval of the justice system, which leads to it illegitimacy and failure."
120,"55 L Tickle, The Guardian, ‘Online Justice: why courts should explore emerging digital possibilities (2017 )."
120,CDCJ(2018) 5 58 not lead to better justice.
120,"This would correspond to the pyramid mod el of dispute resolution which integrates legal advice (the parties informing themselves about their legal rights and their legal position) , negotiation and conflict resolution techniques (restorative justice), facilitated negotiation and mediation, and ad judication (potentially several stages, including the possibility of review and appeal)."
120,"The idea behind this tiered model of dispute resolution is that most disputes are solved at the lower levels, thus being cost effective while at the same time giving more disputants access to justice."
120,A detailed discussion of data protection law and its application to civil and administrative justice systems is beyond the remit of this research.
120,"Instead we only point to some pertinent issues of ODR, civil and administrative justice and data protection."
120,"Data protection law in the EU provides for the lawfulness of processing of personal data where “processing is necessary for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller” .77 Thus in a nutshell, provided the processing of personal data is necessary (not excessive, proportionality test) for providing justice to litigants and running a justice system it is lawful under data protection law.78 115."
120,"Generally speaking, like in other areas of digitization, ODR may have a negative impact on data protection and privacy in that online justice is likely to generate a much 75 J."
120,"May 2018 in the Member States of the EU 78 To the extent that the data processing falls outside the scope of EU law there may also be an argument that data protection law is not applicable see Art 2 CDCJ(2018) 5 61 greater wealth of data (including metadata, for example who accessed a particular court record when and from where), increas es the possibilities of data processing, searching, data mining and the use of artificial intelligence (which is the other side of the coin of increased access to justice) and online data (including court data) may be more mobile (easy online transfer), st icky (in the sense that data remains on storage devices until erased) and vulnerable to unauthorised, remote access (computer hacking from anywhere in the world)."
120,"Furthermore as far as cybersecurity is concerned, digitalised courts are not only vulnerable to hacking (data protection & privacy implication s) but also vulnerable to other forms of malicious attack, affecting the integrity of data and the functioning of the justice system (one only needs to remember the large -scale Ransomware Wannacry attack of last year as an example of the impact79)."
120,"There is no doubt that while the application of these standards may be necessary to ensure that the development and implementation of an ODR system complies with the right to a fair trial, they may nonetheless prove burdensome to the development and implementation of an ODR system within the justice system."
120,"It is a broadly phrased concept that, for the purposes of this Report, entails the idea that the use of technology, particularly online technology, to resolve disputes might disenfranchise certain portions of the population from access to justice."
120,If one is to devel op a public justice system that improves access to justice then such a system cannot come to be implemented if it will effectively deny certain persons access to justice.
120,A similar argument about literacy could be made as follows: not everyone within every society can read and write but that does not mean go vernments prevent people from accessing justice through written proceedings.
120,The digital divide also applies to the difference in access to justice between developed and developing states.
120,"If ODR is to be implemented into public justice systems, these systems must be designed in such a way that there is equality of arms between the litigants."
120,This raises the question of why AI is problematic from the viewpoint of Article 6 ECHR and more generally for the idea of justice.
120,However the use of AI in policing (for example Predpol - used to prioritize police resources based on existing crime spots) or within the criminal justice sys tem (for example to decide on matters of whether a suspect is released on bail) have been criticized for being (racially) prejudiced and creating new types of discrimination.85 The concern here is that computer based decisions are inflexible and are not abl e to create exceptions or use human discretion.
120,This may go to the very core of our notion of access to justice and lead to a denial of justice.
120,AI is increasingly used in the context of the civil and criminal justice systems where artificial intelligenc e is being developed to eventually support or replace decision -making by human judges.
120,"87ibid CDCJ(2018) 5 67 insufficient resources from which most justice systems suffer, there is a danger that support systems based on artificial intelligence are inappropriately used by judges to “delegate” decisions to technological systems that were not developed fo r that purpose and are perceived as being more ‘objective' even when this is not the case."
120,(5) The use of o nline courts has the ability revolutionise access to justice for litigants.
120,The development of new procedures to resolve disputes online can revolutionise access to justice to persons who would usually be unable to understand court procedures without hirin g a lawyer.
120,This is a massive improvemen t of access to justice for litigants.
120,Requiring parties to use technology to resolve disputes could inhibit access to justice if there is a great discrepancy between the parties and their acces s to technology.
120,"The move to online and virtual justice also threatens to significantly increase the number of unrepresented defendants, to further discriminate against vulnerable defendants, to inhibit the relationship between defence lawyers and their c lients, and, as some argue, make justice less open."
120,"Traditionally members of the public have been granted physical access to the court buildi ng, but many countr ies in Europe do not allow public broadcasting of trials on TV for the reason that this may influence advocates and judges who then ”play” to populist sentiments of crowd watching which may not lead to better justice."
120,"This would correspond to the pyramid model of dispute resolution which integrates legal advice (the parties informing CDCJ(2018) 5 70 themselves about their legal rights and their legal position through the use of expert systems/ar tificial intelligence ), negotiation and conflict resolution techniques (restorative justice), facilitated negotiation and mediation, and adjudication (potentially several stages, including the possibility of review and appeal)."
120,"The idea behind this tiered model of dispute resolution is tha t most disputes are solved at the lower levels, thus being cost -effective while at the same time giving more disputants access to justice."
120,"(17) Generally speaking, like in other areas of digitization, ODR may have a negative impact on data protection and privacy in that online justice is likely to generate a much greater wealth of data (including metadata, for example who accessed a particular court record when and from where), increases the possibilities of data processing, searching, data mining and the use of artificial intelligence (which is the other side of the coin of increased access to justice) and online data (including court data) may be more mobile (easy online transfer), sticky (in the sense that data remains on storage devices until erased) and vulnerable to unauthorised, remote access (computer hackin g from anywhere in the world)."
120,"(25) Given the pressure of high caseloads and insufficient resources from which most justice systems suffer, there i s a danger that support systems based on artificial intelligence are inappropriately used by judges to “delegate” decisions to technological systems that were not developed for that purpose and are perceived as being more ‘objective' even when this is not the case."
120,CDCJ(2018) 5 74 THE COUNCIL OF EUROPE ACTIVITY The activity is a study with the following aims: - to analyse the compatibility of Online Dispute Resolution with the right to a fair tr ial both in terms of the challenges to the right of a fair trial as well as opportunities afforded by Online Dispute Resolution to provide greater access to justice and enhanced due process; - to examine whether online dispute resolution could open up new avenues of redress for infringements of ECHR rights (Article 13).
120,It will improve access to justice and accordingly fair trial.
120,Do you think that ODR processes and procedures could work within the civil justice system?
120,"CDCJ(2018) 5 88 Pablo Cortes , Prof in Civil Justice at Leicester Law School."
120,Pablo is a chair in Civil Justice at Leicester Law School.
120,He is a fellow of the National Centre for Technology and Dispute Resolutions (University of Massachusetts) and a member of the Online Dispute Resolution (ODR) Taskforce of the International Mediation Ins titute and of the ODR Advisory Group of the Civil Justice Council.
120,"Definitely, it will e nhance access to justice in case the mechanism has been designed properly."
120,"In general, it ’s not a problem, it’s an access to justice."
120,In e -justice Czech Republic is in a low position.
120,We have to give access to justice online to people in villages.
120,Do you think that ODR processes and procedures could work within the civil justice CDCJ(2018) 5 92 system?
120,There was a project in Soviet Union aimed to create machine justice – computer that was supposed to resolve disputes.
120,In 2001 the Minister of Justice had a plan – Phoenix system – online dispute resolution.
120,"But this week, the Minister of Justice announced the new system – JustOn."
120,Unique system for the consumer and civil justice system.
120,Do you think that ODR processes and procedur es could work within the civil justice system?
120,Do you see risks that certain individuals (with physical or mental disabilities/sight problems/ socially disadvantaged/the elderly) will find it more difficult to obtain access to justice?
120,"For instance, the Minister of Justice presented the plan to introduce AI court for dispute in regard to fines for illegal parking."
120,Looking at civil litigation and the administrative courts (not the criminal courts and criminal justice system) Two aspects: 1) use of ODR techniques in the COURTS and 2) possible interface between the courts and Alternative Dispute Resolution (ADR)/ Online Dispute Resolution (ODR).
120,"I have been personally involved and have led multiple ODR initiatives in BC, including:  Development of Consumer Protection BC ODR consumer pilot in 2011 with Modria  Development of Property Assessment Appeal Board (an administrative tribunal) ODR initiative beginning in 2011 with Modria  Development of the Civil Resolution Tribunal (CRT) (an online administrative tribunal with civil jurisdiction) in 2011  Instructed the drafters on legislation to make ODR part of the body of law in BC and to create the authority for the CDCJ(2018) 5 98 CRT in 2011 -2012  Participated in the design for the technology and processes for the CRT beginning in 2012 (ongoing)  Drafted the CRT rules of procedure 2015 -2016  Led the knowledge engineering work for the CRT Solution Explorer ODR expert system (similar to phase 1 of the proposed online courts for Eng & W)  Former CDN delegate to th e United Nations Commission on International Trade Law ODR working group  Instructed Legal Information Technology law school courses at the University of Victoria and Osgoode Hall (York U) law schools, including a multi -week ODR simulation involving student s from Canada, the US and England  Currently co -instructing knowledge engineering courses at Thompson Rivers University and University of Ottawa Law Schools  Participated in one of the Civil Justice Council ODR Working Group meetings in London, provided on a nd off consultation with individual members, HMCS representatives and judiciary.  Consulted with Lord Justice Briggs leading up to his reports on ODR  Part of a team developing new ODR initiatives for BC that touch on other areas for administrative tribunal s, family justice other administration of justice issues More: http://darinthompson.ca/about/ II."
120,The CRT may be the only public system based ODR tribunal of its kind in the world - Ontario is planning to create a new “Condo Authority” that is apparently going to include ODR - There is also a low volume small claims O DR pilot led by the Vancouver -based Justice Education Society - The Vancouver -based Legal Services Society currently offers “MyLawBC” which is based on the Rechtwijzer and Modria platforms.
120,Are you aware of any ODR processes and procedures which have been integrated into the civil and administrative justice procedure?
120,"If so, do you think that ODR works in this regard? - The Property Assessment Appeal Board and the CRT, each mentioned above, are both deeply integrated into the civil/admin justice context."
120,"What is your prediction as to the ODR development in your country/ in general (5 or 10 years)? - I continue to be amazed at the inaction among lead ing justice stakeholders when it comes to conceptualizing and piloting ODR initiatives, let alone implementing them. - I can’t confidently say any new initiatives will reach the stage of piloting or implementation in the next 5 hears. - However, I know in BC that ODR has become “normalized” very deeply in a relatively short amount of time (5 years). - We had to “break the ice” and actually use ODR – even small scale initiatives – to make this happen."
120,"I have taken several from the concept phase to the implementation phase, covering the tech, legislation, rules, workflows, user -focused design work, evaluation and more, and am firmly convinced that ODR is an effective response to many of the challenges facing justice systems everywhere."
120,"In your opinion, what are the main issues regardi ng ODR’s influence on fair trial considerations (Article 6 of the European Convention of Human Rights)? - In a relative sense, I haven’t come across any specific ODR issues that have a more significant impact than those already found in the current court process. - I believe the “digital divide” is narrower than the gap in access to justice for most people."
120,"Do you see risks that certain individuals (with physical or mental disabilities/sight problems/ socially disadvantaged/the elderly) will find it more difficult to obtain access to justice? - Depending on the design of any ODR system, it’s a definite possibility."
120,"What impact will ODR and automation have on access to justice? - It can be both positive and negative 10 minutes CDCJ(2018) 5 102 - Careful user -focused design, user testing, consultation, ongoing user feedback collection, contin uous improvement, etc. can all contribute to making an ODR system superior to a traditional court or tribunal – but there’s not guarantee that this will happen merely by deciding to “do ODR” VI."
120,"While ODR is hard to define, it should be used more within the justice system."
120,"The current system is burdensome, and we should do more to ensure that there is access to justice and fairne ss."
120,Does the person who has access to technology and the skills to use it ha ve better access to justice than another person who does not have access to such technology?
120,Information might not be a good steward for justice.
120,"We could find out 10 years down the line, after an ODR system has been implemented, that companies who develop ed the platforms and software have used the system to gain an advantage through their control over information, and which has negative implications for the CDCJ(2018) 5 105 justice system."
120,Justice based kiosks.
120,"The introduction of technology into the justice system will not happen within the next 10 years, particularly in the USA."
120,There is a culture in the US that disputes should be resolved in person – this is the understanding of justice.
120,Face -to-face in is imbedded in the justice culture.
120,Arbitration provides a good opportunity to create own justice system.
120,"In justice system? – already is to some extent – law firms use it to determine settlement points, to think through information."
120,Otherwise issues may arise regarding access to justice.
120,Technology must make it easier but not to hinder access to justice.
120,Benefit to society – speedy justice .
120,ODR and change to the current justice system Impression on civil law jurisdiction embracing change to justice system by implementing ODR?
120,"There is a need to come with support from all stakeholders – judges, attorneys, politicians – have their say – is it good for justice?"
120,"Not against access to justice – adhere to this, not obliged to arbitrate can mediate."
120,He used aspects of Game Theory and notions of fairness and justice to develop these concepts about ODR.
120,Access to Justice ODR can definitely enhance access to justice.
120,Technology can provide people with access to justice who would not ordinarily or traditionally have had it.
120,"Summary John’s view is that ODR is a very useful tool to enhancing access to justice, ensuring efficiency and effectiveness in justice system."
120,"It can be used, if implemented correctly and ethically, to enhance access to justice and t o ensure justice is carried out effectively and efficiently."
120,"It is a fundamental aspect of justice that parties meet face -to-face when assessing each other’s cases, assessing ev idence and arguing their respective cases before court."
120,Shannon was initially involved with law from an administrative law perspective but was attracted to the potential use of ODR to address access to justice issues.
120,Bring the justice to where the system is.
120,There is no need to replicate the traditional court system which is not conducive to fairness and access to justice.
120,Access to justice – easier online.
121,"The benefit of establishing clear, common rules of criminal liability will benefit a proper administration o f justice."
121,In order to maintain good co-operation in criminal matters among the members of the Council of Europe several issues should be addressed including the question of how different approaches in testing and using auto mated vehicles can translate into “permissible risks” not criminali sed in domestic law (like the different uses o f technologies in cars) as well as the question of whether an auto mated vehicle may eventually have to answer the law as an e -person (similar to corporations as legal persons) or whether criminal justice is for “human persons ” only.
121,"It is foreseeable that any process to set regulatory standards in this area will also require input from a range of stakeholders, including, but not limited to: - Criminal justice system : o Prosecutors and investigators , o Trial courts , o Ministry of Justice / central administrations . - Education and academia : o Robotics engineers , o Ethicists, o Legal scholars (technology law, information law, criminal lawyers) . - Public authorities : o Regulatory agencies , o Publicly owned autonomous systems (civil, not military) , o Government infrastructural systems . - Private actors : o Robotics Manufacturers , o Programmers and Software developers , o Private companies , o AI researchers and development firms ."
123,"8 December 2020 CEPEJ(2020) 15Rev EUROPEAN COMMISSION FOR THE EFFIC IENCY OF JUSTICE (CEPEJ) Possible introduction of a mechanism for certif ying artificial intelligence tools and services in the sphere of justice and the judiciary : Feasibility S tudy In December 2018, the European Commission for the Efficiency of Justice (CEPEJ) adopt ed the Ethical Charter on the use of artificial intelligence in judicial systems and their environment ."
123,31 3 Feasibility st udy on the possible introduction of a mechanism for certif ying artificial intelligence tools and services Introduction Justice is not currently the preferred focus of companies that are innova ting in the field of artificial intelligence .
123,"The in -depth s tudy on the use of AI in judicial systems, notably AI applications processing judicial decisions and data , reprodu ced i n Appendix I to the CEPEJ Charte r6, defines the main categories of artificial intelligence in the sphere of justice for illustrative purposes as follows : - Advanced case -law search engines - Online dispute resolution , - Assistance in drafting deeds - Analysis (predictive, scales ), - Categorisation of contracts according to different criteria and detection of divergent or incompatible contractual clauses, - ""Chatbots "" to inform litigants or support them in their legal proceedings ."
123,"Two additional categories with strong ethics implications could also be discussed, namely algorithmic justice, which could be seen as comparable to the aforementioned category of ""online dispute resolution"", and tools for enhanced judges' decision -making , which could be linked to the ""Analys is"" category, still at an experimental stage chiefly geared to aid for determining damages and sanctions."
123,"Besides these considerations l inked to the categories of artificial intelligence and its state of technological advancement in terms of contextual learning, we should distinguish between AI applications in the justice sphere according to their functions and purposes ."
123,"Specifically in the judicial field where artificial intelligence tools provide aid for decision -making for judges, if, for example, the machine propose s a detention measure rather than a security measure, the defendant and society are entitled to demand an explanation for that choice if it guide s an official decision of justice."
123,The reasoning of decisions of justice demands a certain level of explainability.
123,The justice sphere has not been included in the areas listed for experimentation33.
123,"The sole reference to artificial intelligence in the justice sphere in this document is to be seen in a survey finding that only half of the respondents are comfortable with 26 Article 6, Regulation (EC) No 1980/2000 of the European Parliament and of the Council of 17 July 2000 on a revised Community eco -label award scheme."
123,"9 AI in the area of justice, compared to 80% in the area of transport ation34, which appears to have been the reason why it was exclu ded from the pilot experiments ."
123,"Among other things it hinges on the concept of Human rights by design , which serves as the key strategy line of the CEPEJ European Ethical Charter on the use of artificial intelligence in judicial systems. - Proportion ate processing of person al data (priv acy) and clear purpose s - Anonymisation of the parties and particip ants (physi cal individual s) and their counsels o Checking by consultation of data sets - Absence of evalu ation and class ification of physi cal individuals or legal entities on the basis of judicial decisions o Checking by consultation of the interface - Anonymisation of the name of the judge and the location of the court in decisions u sed for predictive justice ( with th e aim of avoiding forum shopping ) o Checking by consultation of data sets - Hermetic separation of artificial intelligence services having different purpos es (such as dissoci ating the search engine service from the aid for decision -making service) o Checking of databases and data sources used by each system - Right of access to the judge and the right to a fair trial - Presence of clear information indicating, where applicable, th at a report generated by an artificial intelligence system is not explainable ."
123,"If successfully applied to artificial intelligence in the sphere of justice, the human rights by design approach could be applied more widely to artificial intelligence systems used in other fields and could also potentially be tes ted in legislative processes, after enactment of legislation, to limit the need for the review of compatibility of domestic legislation with international conventions and treaties before courts of law."
123,"The use of artificial intelligence in the legal and judicial sphere represents an important societal challenge, particularly in the field of algorithmic justice."
123,"While technological advances may bring improvements to the judicial system, facilitate the work of legal professionals and improve access to justice and information for defendant s/litigants , increased vigilance is necessary in this sector which the European Commission descri bes as a high -risk sector."
123,"28 Appendixes Summary table of indicators and certification criteria Objective Criteria Assessment method Target AI category Proportionate processing of personal data Anonymisation of the parties and participants (physical individuals) and their counsels Consultation of data sets Unprocessed data All Absence of evaluation and classification of physical individuals or legal entities on the basis of judicial decisions Checking of interface Interface Connectionist Checking of database Limit forum shopping Anonymisation of the judge and the court ’s location in decisions used for predictive justice Consultation of data sets Unprocessed data Connectionist Clear purposes for processing Hermetic separation of artificial intelligence services Checking of databases and data sources used by each system Databases All Fair trial Information indicating to the judge and the defendant, if relevant that a report generated by an artificial intelligence system is not explainable (See also below : Defendant ’s/litigant's right to opt out of the use of artificial intelligence ) Checking of AI category and checking of existence and clarity of information (See also below : Checking of a notification system for the defendant ’s/litigant's decision and for effective redirection to conventional proceedings before a court within the meaning of A rticle 6 of the ECHR ) Learning model and interface Connectionist Judges’ independence in their decision making process Safeguard against the profiling of judges A/B testing checking of search results Search engine and processed data All Match between the criterion displayed and the actual pattern of classification of search results Auditing of search results Search engine All Transparency of weighting of criteria for multicriteria searches Checking of the existence of explanatory information and auditing of search results Interface and search engine All Verification by auditing of search results Checking of the existence of Interface and search engine All 29 Summary table of indicators and certification criteria Transparency of criteria used for searches by “relevance” explanatory information and auditing of search results Verification by auditing of search results Ethics and Human rights by design No human rights violation Report presenting decision trees and explaining how fundamental rights and freedoms are taken into account Report Symbolic No human rights violation Report presenting training data and methods and explaining how fundamental rights and freedoms are taken into account Report Connectionist Avoiding discrimination based on sensitive data Elimination of the tags that could be linked to parties ’ sensitive data (home address, income, family situation, registered capital) Checking by consultation of data sets Unprocessed data Not under public authority control A/B testing using information and tags that could be linked to sensitive data by changing, where applicable, one of the following parameters during each test: name, home address, income, family situation, registered capital, relevant specific contextual information, etc."
124,"Page 10 - Unboxing Artificial IntelligenceIf an AI system is used for interaction with individuals in the context of public services, especially justice, welfare, and healthcare, the user needs to be notified and the possibility of recourse to a professional upon request and without delay must be communicated."
130,"Mechanisms and processes in place should ensure that access to remedies is speedy and child-fr iendly, and provides appropriate redress to children.69 .S tates should ensure that in all cases access to courts or judicial review of administr ative remedies and other procedures are available, in line with the principles set out in the Guidelines of the Committee of Ministers of the Council of Europe on child-fr iendly justice (2010).7 0.S tates should, where appropriate, also provide children and/or their parents or legal representatives with non-judicial mechanisms, administrative or other means t o seek remedy, such as through ombudspersons for children and other national human rights institutions and data-protection authorities."
134,"Such committees may play an especially important role in areas where transparency and stakeholder engagement can be more difficult due to competing interests and rights , such as in the field s of predictive justice, crime prevention and detection ."
137,"Finally, AI raises many different sector -specific issues concerning the various AI fields of application (labour, justice administration, crime control, contract relationships , etc.) and the consequences of AI use (e.g. sustainability, environment impact , political impact etc.) , which must be addressed separately ."
137,"Where societal issues are significant , legal, ethical or sociological expertise , as well as domain specific knowledge , will be essential .46 Such committees may play an even more important role in areas where transparency and stakeholders’ engagement are difficult to achieve , such as predictive justice, crime detection or predictive policing ."
137,"5 Sector -specifi c issues AI has a significant impact on many sectors of our society and economy (e.g. predictive policing, justice, precision medicine, marketing , political propaganda) ."
137,“It’s Reducing a Human Being to a Percentage”; Perceptions of Justice in Algorithmic Decisions.
138,"Venice Commission :: Council of Europe EN FR Login Venice Commission Council of Europe Home The Council in brief Human Rights Democracy Rule of Law Organisation 46 Countries Topics Newsroom Council of Europe Human Rights and Rule of Law Venice Commission EN | FR | DE | IT | RU The Commission About us Types of activities Founding documents News Programme References Members Member states Individual members Map of member States Positions Statements Democratic institutions and fundamental rights Constitutional reforms Fundamental rights Democratic institutions Rule of law Judicial reforms Ombudsman Elections, referendums and political parties Council for Democratic Elections Conferences of Electoral Management Bodies Seminars and assistance Political parties VOTA database Council of Europe and elections Constitutional justice Regional co-operation Constitutional Courts CODICES E-Bulletin World Conference on Constitutional Justice Non-European Partners Southern Mediterranean Overview of activities Highlights by beneficiary Recent events UniDem Med Campus List of UniDem seminars Intercultural Workshops on Democracy Arabic Speaking EMBs Tunisia : support to independent bodies Central Asia Kyrgyzstan – support to electoral reform Central Asia Rule of Law Programme List of events Latin America Overview of activities Recent events Sub-commission on Latin America Main documents Statute Main reference documents Compilations of studies and opinions Annual reports Documents Opinions Ongoing opinions Follow-up Studies Recent documents access by: Countries Topics Series Language Search Web Resources Newsletter Publications Articles on the Commission Links Library Constitutions Contact us For the media Reset password CDL-AD(2019)016-eJoint Report of the Venice Commission and of the Directorate of Information Society and Action against Crime of the Directorate General of Human Rights and Rule of Law (DGI), on Digital Technologies and Elections, adopted by the Council of Democratic Elections at its 65th meeting (Venice, 20 June 2019) and by the Venice Commission at its 119th Plenary Session (Venice, 21-22 June 2019) Show related documents (1) Choose a year all 2019 CDL-AD(2019)016 French 07/02/2020 - Public Rapport conjoint de la Commission de Venise et de la Direction de la société de l’information et de la lutte contre la criminalité, Direction générale Droits de l’homme et État de droit (DGI) sur les technologies numériques et les élections, adopté par le Conseil des élections démocratiques lors de sa 65e réunion (Venise, 20 juin 2019) et par la Commission de Venise lors de sa 119e session plénière (Venise, 21-22 juin 2019) View in full screen Activities Human Rights and Rule of Law DemocracyWho we areHuman Rights Convention Council of Europe Treaties Press Multimedia NewsroomWeb TV Photo galleries Campaigns Useful links Employment Call for tenders Archives Archived web pages SitemapAmicaleAdministrative TribunalE-cards Contact us Secretary General & Deputy Secretary General Media Contacts External Offices Visit us Newsletters Patronage Form close Disclaimer - © Council of Europe 2014 - © photo credit - Webmaster Bookmarks Print RSS © Council of Europe 2007-2025"
14,"Also from Council of Europe, on 22 October, 2020, the Parliamentary Assembly of the Council of Europe (PACE) adopted seven reports concerning the impact of AI: the need for democratic governance of AI ​78 ​; the role of AI in policing and criminal justice systems ​79 ​; preventing discrimination caused by AI ​80 ​; ethical and legal frameworks for the research and development 78 See ​Need for democratic governance of artificial intelligence ​, available at https://pace.coe.int/en/files/28742/html ​."
14,"79 See ​Justice by algorithm - the role of artificial intelligence in policing and criminal justice systems ​, available at https://pace.coe.int/en/files/28723/html ​."
14,She further noted that: The deaths of George Floyd and countless others have prompted a transnational uprising against systemic racism in law enforcement [...] Part of the human rights response must include greater scrutiny of how the design and use of digital technologies is further entrenching this systemic racism. ​113 Achiume echoes much recent work on AI governance from a human rights perspective when she proclaims that ensuring racial justice and the protection of human rights will require prohibiting certain applications of AI.
14,"It was indicated that the question of red lines is under serious discussion on multiple sides, and that the possibility of a ban remains on the table, especially regarding so-called remote biometric identification systems, and the use of AI in sensitive domains such as criminal justice."
14,"44 Europe’s Approach to Artificial Intelligence: How AI Strategy is Evolving We have seen how even simple algorithms, such as that used in the UK’s A-Level grading fiasco, can amplify unfair and discriminatory outcomes and mobilize people to demand justice amid chants of “fuck the algorithm”​155 ​."
14,"Richard Benjamins, Observatorio del impacto social y ético de la inteligencia artificial (ODISEIA) Nuria Oliver, Commissioner for the President of the Valencian Region on AI Strategy and Data Science to fight COVID-19, Spain Brussels roundtable: Speakers Nuria Oliver, Commissioner for the President of the Valencian Region on AI Strategy and Data Science to fight COVID-19, Spain Krzysztof Izdebski, Policy Director of ePaństwo Foundation, Poland Meeri Haataja, CEO & co-founder of Saidot, Finland Friederike Reinhold, senior policy advisor for AlgorithmWatch, Germany Veronika Žolnerčíková, CyberSecurity & CyberCrime Center of Excellence at Masaryk University (C4E), Co-creator of Czech National strategy on AI, Czech Republic 47 Europe’s Approach to Artificial Intelligence: How AI Strategy is Evolving Karma Peiro, Data Journalist & Co-director of the Visualization and Transparency Foundation, Spain Sarah Chander, Senior Policy Advisor at European Digital Rights (EDRi), Belgium Hanna Zinner, Artificial Intelligence and Digital Industry, DG CNECT, European CommissionMarcel Kolaja, European Parliament Vice President and member of the Czech Pirate Party Andreas Hartl, Head of Division, Strategy Artificial Intelligence, Data Economy, Blockchain, Federal Ministry for Economic Affairs and Energy, Germany Audience Jim Dratwa, Team Leader, European Group on Ethics, European Commission Killian McDonagh Dit, Directorate-General for Justice and Consumers, European Commission Anna Moscibroda, Directorate General for Justice and Consumers, European Commission Zoi Kardasiadou, Directorate General for Justice and Consumers, European Commission Aimilia Givropoulou, assistant to MEP Patrick Breyer Anne van Heijst, assistant to MEP Liesje van Schreinemacher Despoina Riga, assistant to MEP Anna-Michelle Assimakopoulou Natalia Joanna Boniecka, assistant to MEP Andrzej Halicki Georgios Theodotou, assistant to MEP Elena Kountoura Matt Mahmoudi, Researcher/Advisor on Artificial Intelligence & Human Rights at Amnesty International Ella Jakubowska, Policy & Campaigns on biometrics at European Digital Rights 48 Europe’s Approach to Artificial Intelligence: How AI Strategy is Evolving Sample Agenda ​."
140,"A shared statement of civil rights concerns’, signed by 119 civil rights organisations in the US’ (2018) http://civilrightsdocs.info/pdf/criminal -justice/Pretrial -Risk-Assessment Full.pdf accessed on 4 October 2018."
140,"Binns et al., ‘‘It’s reducing a human being to a percentage ’; Perceptions of justice in algorithmic decisions ’, CHI 2018, April 21–26, 2018, Montréal, QC, Canada, https://dl.acm.org/citation.cfm?id=3173951 accessed 1 October 2018."
140,"Fredman S. ‘Intersectional discrimination in EU gender equality and non discrimination law, European network of legal ex perts in gender equality and non-discrimination’ (Report for European Commission, Directorate -General for Justice and Consumers), May 2016 https://publications.europa.eu/en/publication -detail/ -/publication/d73a9221 b7c3 -40f6-8414 -8a48a2157a2f/language -en accessed on 9 October 2018."
140,"Kilbertus N. et al., ‘Blind justice: Fairness with encrypted sensitive attributes’ (2018) Proceedings of the 35th International Conference on Machine Learning (ICML 2018)."
140,"Rieke A, Robinson DG and Yu H, ‘Civil rights, big data, and our algorithmic future: A September 2014 report on social justice and technology (Version 1.2), Washington, DC: Upturn, PDF version, https://bigdata.fairness.io accessed 1 October 2018."
140,"Taylor L, ‘What is data justice?"
141,"In 2019, Jobin and colleagues (2019) identified 84 published sets of ethical pr inciples for AI, which they concluded converged on five areas: transparency, justice and fairness, non-maleficence, responsibility and privacy."
141,"Violations can prevent people from enjoying their rights, but they do not st op the rights existing.f Human rights are essential: They are essential for freedom, justice and peace.3.1.2."
141,"Guidelines of the Committee of Ministers of the Council of Europe on child-friendly justice (2010), h ttps://rm.coe.int/16804b2cf3."
141,"(2019), Artificial intelligence: human rights, social justice and development , Global Information Society Watch 2019, Association for Progressive Communications.R ehak R."
142,"Merlin gets quite a few of the films correct, including other superhero movies like X Men: Apocalypse , Doctor Strange , and Batman v Supe rman: Dawn of Justice ."
142,"AI ethics can be viewed from several points: data protection, freedom of expression, cultural diversity, productivity and economics, social justice, individual’s happiness, human autonomy and uniqueness, stability of society and so on."
143,"125 List of abbreviations AGI Artificial general intelligence AI Artificial intelligence AI4SG AI fo r social good ANN Artificial neural networks AVMSD Audiovisual Media Services Directive CAN Creative Adversarial Network CDPA Copyright Designs and Patents Act CGI Computer -generated CJEU Court of Justice of the European Union CPU Traditional pr ocessors DNN Deep neural networks DSP Demand -side-platform EASA European Advertising Standards Alliance ECHR European Convention on Human Rights ECtHR European Court on Human Rights EDPB European Data Protection Board EGE European Group on Ethics in Science and New Technologies EPG Electronic programme guides EPRS European Parliamentary Research Service GAN Generative adversarial networks GDPR General Data Protection Regulation GPS General Problem Solver” GPU Graphics processor units IAB Interactive Advertising Bureau IP Intellectual Property IPR Intellectual Property Rights LT Logic Theorist (first reasoning program ) NLG Natural language generation NLP Natural language processing PSB Public service broadcasters ROI Return on investme nt RTB Real-time bidding SRO Advertising self -regulatory organisations SSP Supply -side platform SVM Support vector machines VFX Visual special effects WMFH Work -made -for-hire XAI Explainable AI ARTIFICIAL INTELLIGENCE IN THE AUDIOVISUAL SECTOR © European Audiovisual Observatory (Council of Europe) 20 20 Page 1 The black box As mentioned in the forewor d of this publication, AI is both a fascinating and scary development."
143,The Court of Justice of the European Union’s landmark Google Spain case180 encapsulates the paramount role that big tech c ompanies now play in the news field and their resistance to the laws governing it.
143,"175 Krishna A. , “IBM CEO’s Letter to Congre ss on Racial Justice Reform ”, 8 June 2020, https://www.ibm.com/blogs/policy/facial -recognition -susset -racial -justice -reforms/ ."
143,"Nevertheless, a human ‘author’ in the widest sense is always present, and must have the right to claim ‘authorship’ of the program”.443 In the Court of Justice of the European Union (CJEU) Painer case, Advocate Gene ral Verica Trstenjak stressed the same point by noting that “only human creations are therefore protected, which can also include those for which the person employs a technical aid, such as a camera”.444 National legislation of EU member states confirms this approach."
143,Justice Whitford assigned copyright protection for the automated output to the plaintiff and refused the notion that copyright in the work could be vested in the computer.
143,"In a judgment concerning photographs of screen star Marlene Di etrich (who had died several years prior) the Federal Court of Justice held that in any unauthorised exploitation of a picture, the owner of the personalit y right is entitled to compensation irrespective of the gravity of the infringement.697 7.4.2."
144,"They include: • risks of large-scale harm from malicious attacks • unethical system design or unintended system failure • loss of authentic, real and meaningful human contact • the chilling effect of data repurposing • the exercise of digital power without responsibility • the hidden privatisation of decisions about public values (including distributive justice) & • the exploitation of human labour to train algorithms."
144,"DGI(2019)05 2 9 by political actors and organisations seeking to tailor and target campaign messages to i ndividuals who are identified as most likely to be persuaded by them,64 and, increasingly, by cri minal justice authorities who seek to assess the ‘risk’ which particular individuals are al gorithmically identified as posing to public safety in order to make custody decisions about i ndividuals (whether criminal suspects or those convicted of criminal offences).65 It is in this socio-economic context that public anxieties have emerged concerning the societal e ffects of advanced digital technologies (including AI), particularly given the increasing use of d ata-driven profiling."
144,"Council of Europe Study 3 0 which organisations utilising these systems typically defend on the basis of that it prevents u sers from ‘gaming’ the s ystem.72 Accordingly, these systems risk interfering with rights to d ue process protected under Article 6 (including the presumption of innocence), particularly in ci rcumstances where the consequences for the affected individual are serious and life-li miting.73 Particularly worrying is the increasing use of AI systems in criminal justice contexts to inform custodial and sentencing decisions, primarily in the USA, although they are being take n up elsewhere (including the UK).74 Yet, as Hildebrandt has observed, we have become resi stant to the notion that the outcomes of an AI tool might be incorrect, incomplete or even i rrelevant with regard to potential suspects.75 ( b) The right to freedom of expression: Art 10 The operation of algorithmic profiling may significantly affect the Art 10 right to freedom of ex pression, which includes the right to receive and impart information, given the powerful i nfluence which global digital platforms now exert over our informational environment at both an individual and societal level."
144,"The Rathenau Institut endorses Hildebrandt’s vi ews, and has suggested that the Council of Europe consider establishing a framework of minimum norms to be taken into account wh en a ‘court’ (interpreted for this purpose as including all decision -making au thorities within the legal system, particularly those involved in making custody decisions concerning i ndividuals within the criminal justice system) uses AI – helping to prevent member states from devising th eir own individual frameworks which is likely to result in uneven and varying degrees of protection under A rt 6 ECHR provided by individual member states: Van Est and Gerritsen (2017) 42-43."
144,"DGI(2019)05 3 3 acute in relation to the use of machine learning techniques to inform custody and sentencing d ecisions within the US criminal justice system, due to allegations that such techniques o perate in ways that are substantially biased against black and other racial minorities.89 In respo nse to these concerns, a growing body of work concerned with devising technical ap proaches for countering such bias has emerged.902 .1.2 Societal risks associated with data-driven profiling Co ntemporary applications of data-driven profiling technologies may also undermine i mportant collective interests and values, only some of which fall within the scope of existing h uman rights protection."
144,108 Law enforcement applications of AI for individual profiling within the criminal justice system are especially t roubling.
144,"Yet, even in relation to AI sy stems that directly affect and interface with the public, citizens and other affected groups an d organisations will typically not be given any meaningful opportunity to participate in i dentifying these values or value trade-offs that these systems are configured to reflect.127 The u se of ML in risk-scoring systems used to evaluate the ‘recidivism risk’ of convicted criminals see king release from custody offers a vivid example: although the criminal justice system in co ntemporary democracies is founded on, and is expected to give effect to, several important cri minal justice values, these scoring systems have hitherto been designed to optimise only wi th one such value: public protection.128 As AI technologies become embedded as tools for o ptimising the efficiency of social coordination (such as smart navigation systems or smart i nfrastructure management, for example), they will inevitably make decisions that prioritise so me values over others and impact directly on individuals and groups, some of whom may b enefit and others who may not."
144,"In relation to c riminal justice risk assessment, see Selbst 2018 and Oswald et al 2018."
145,FAIR TRIAL AND DUE PROCESS The trend towards using automated processing techniques and algorithms in crime prevention and the criminal justice system is growing .
145,"While it is unclear how prevalent such decisions created by algorithms are in the criminal justice system generally, the mere potential of their use raises serious concerns with regard to Article 6 of the ECHR and the principle of equal ity of arms and adversarial proceedings as established by the European Court of Human Rights.5 Furthermore, algorithms are increasingly used in the context of the civil and criminal justice systems where artificial intelligence is being developed to event ually support or replace decision -making by human judges."
145,"51 See Laurel Eckhouse, “Big data may be reinforcing racial bias in the criminal justice system”, available at: https://www.washingtonpost.com/opinions/big -data-may-be-reinforcing -racial-bias-in-the-criminal -justice system/2017/02/10/d63de518 -ee3a-11e6-9973-c5efb7ccfb0d_story.html?utm_term=.720084735d73 (last visited on 25 September 2017) ; and ProPublica, Angwin, Julia, Surya Mattu, and Lauren Kirchner, “Machine Bias: There’s Softwar e Used Across the Country to Predict Future Criminals."
145,"At present t he public sector in Europe is employing automated decision -making in areas as diverse as social security, taxation, health care and the justice system (van Haastert 2016; Tufekci et al."
145,"Whether in the criminal justice, social media, healthcare, insurance or banking sector, to name just a few examples, each area will need specific regulatory responses to ensure greater transparency and accountability of automated data -processing and algorit hmic decision -making systems."
145,"Laurel Eckhouse, “Big data may be reinforcing racial bias in the crim inal justice system”, available at: https://www .washingtonpost.com/opinions/big -data-may-be-reinforcing -racial -bias-in-thecriminal -justice -system/2017/02/10/d63de518 -ee3a-11e6-9973c5efb7ccfb0d_story.html?utm_term=.720084735d73 ."
15,"In general, AIAs aim to identify potential risks and impacts—including to health, sa fety, ethics and, in some implementations, to human rights —arising from the development and depl oyment of an algorithmic system as well as appropriate risk mitigation strategies, such as use of “algorithmic audits” , “datasheets for datasets” , and “model cards. ”2 Implementations of AIAs are gaining momentum as a v iable AI governance strategy, finding their way into binding regulation and legislation.3Corporate policies are also requiring implementation of AIAs as a mechanism to reduce legal risks stemmi ng from liability and negligence.4The European Commissionʼs Artificial Intelligence Act s uggests a risk-based approach to AI governance, prohibiting certain harmful applications of AI and calling for developers to go through a form of impact assessment (called a “conformity assessment” ) for high-risk applications to identify necessary oversight mechanisms.5The Algorithmic Accountability Act proposed in the U nited States Congress in 2019 would have required compani es with large user bases to conduct impact assessments of highly sensitive ADS (the Act is exp ected to be reintroduced).6In 2021, the National Institute of Standards and Technology (NIST) was ta sked by Congress to develop an “AI risk management framework” to guide the “reliability, ro bustness, and trustworthiness of AI systems” used in the federal government.7In 2021, the National Security Commission on Artific ial Intelligence issued a report recommending that gove rnment agencies deploying AI systems conduct ex ante risk assessments and ex post impact assessments to “increase public transparency 7""Commerce, Justice, Science And Related Agencies Ap propriations Bill, 2021 - Report Together With Mino rity Views,"" House Committee on Appropriations, July 2020, https://appropriations.house.gov/sites/democrats.ap propriations.house.gov/files/July%209th%20report%20 for%20circulation_0.pdf , 23.6Algorithmic Accountability Act, 116th Cong."
15,"(2021) define AIAs as “emerging gove rnance practices for delineating accountability, rendering visible the harms caused by algorithmic s ystems, and ensuring practical steps are taken to ameliorate those harms. ”34Typical sources of risk to be identified include the presence of bias in datasets used to train an AI system, as well as the fairness and explainability of the model; identification of potential impacts can include con textual considerations related to equity and justice, as well as the economic interests, health, and well-being of users or populations potentially aﬀected by the proposed system."
15,"Toronto Waterfront Revitalization Corporation, et a l., (Ontario Superior Court of Justice File No."
157,"Venice Commission :: Council of Europe EN FR Login Venice Commission Council of Europe Home The Council in brief Human Rights Democracy Rule of Law Organisation 46 Countries Topics Newsroom Council of Europe Human Rights and Rule of Law Venice Commission EN | FR | DE | IT | RU The Commission About us Types of activities Founding documents News Programme References Members Member states Individual members Map of member States Positions Statements Democratic institutions and fundamental rights Constitutional reforms Fundamental rights Democratic institutions Rule of law Judicial reforms Ombudsman Elections, referendums and political parties Council for Democratic Elections Conferences of Electoral Management Bodies Seminars and assistance Political parties VOTA database Council of Europe and elections Constitutional justice Regional co-operation Constitutional Courts CODICES E-Bulletin World Conference on Constitutional Justice Non-European Partners Southern Mediterranean Overview of activities Highlights by beneficiary Recent events UniDem Med Campus List of UniDem seminars Intercultural Workshops on Democracy Arabic Speaking EMBs Tunisia : support to independent bodies Central Asia Kyrgyzstan – support to electoral reform Central Asia Rule of Law Programme List of events Latin America Overview of activities Recent events Sub-commission on Latin America Main documents Statute Main reference documents Compilations of studies and opinions Annual reports Documents Opinions Ongoing opinions Follow-up Studies Recent documents access by: Countries Topics Series Language Search Web Resources Newsletter Publications Articles on the Commission Links Library Constitutions Contact us For the media Reset password CDL-AD(2020)037-eStudy - Principles for a fundamental rights-compliant use of digital technologies in electoral processes, approved by the Council for Democratic Elections at its 70th meeting (online, 10 December 2020) and adopted by the Venice Commission at its 125th Plenary Session (online, 11-12 December 2020) Show related documents (3) Choose a year all 2020 CDL(2020)043 English 24/11/2020 - Public Draft principles for a fundamental rights-compliant use of digital technologies in electoral processes (H."
158,"On the other hand, there is some consensus in crediting AI with the potential of being a formidable transformative force that is impacting, or will impact, our societies and solve many problems in all areas of human intervention, such as education, medicine, justice, agriculture or climate change ."
158,"The trouble with the AI revolution is that it is held up as a solution to all problems, not just in media but also in criminal justice and governance in education in health care, in this push towards a quantum-filled society ."
158,"D’un autre côté, il y a un certain consensus sur le fait que l’IA est potentiellement une extraordinaire force de transformation qui a ou aura un impact sur nos sociétés et résoudra de nombreux problèmes dans tous les domaines d’intervention humaine, tels que l’éducation, la médecine, la justice, l’agriculture ou le changement climatique ."
158,"Dans cette marche forcée vers une société quantique, le problème, c’est que la révolution de l’IA est présentée comme une solution à tous les problèmes, non seulement dans les médias, mais aussi au niveau de la justice pénale, de la gouvernance de l’éducation et des soins de santé ."
158,"The structure has published a series of studies, among them analysing issues related to Human-AI collaboration, algorithmic risk in US criminal justice system, the impact of AI on the economy and labour market ."
158,"De CarvalhoCascais Jovem President of Youth Party Ana Teresa Santos Fundação Calouste GulbenkianProject Manager Republic of MoldovaIrina Buzu NGO Action for Justice Vice President Russian FederationAidar Khusainov Tatarstan Youth Public Fund “Select” Institute of Applied SemioticsTeacher, Researcher Slovenia Simon Vrbanič National Youth Council of SloveniaProject Manager Turkey Kadir Soran Emoner7840 Robotics & AI Co-founder Goksel Ucak European Network Member of Independent Living Youth Cihat Ucak Personal Assistant to G ."
159,"Considering the impact of AI systems on everyday life , in addition to the accelerated trends and risks due to COVID19 , the present Declaration highlights : a) The exclusionary consequences of the fast-paced development of AI technologies driven by the private sector that leave many stake holders, especially youth actors and human rights activists , but also policy makers, behind, and result in normatively questionable and ineffective self -regulation in the private sector b) The need to develop and ensure l egal safeguards both by international organisations through existing or new legal instruments and by national governments responsible for securing and implementing them at national level c) The a bsence of youth in the emerging AI governance processes as a denial of the right to participation in democratic pro cesses which impedes a whole sector from co -shaping the discourse about development, assessment, implementation and regulation of AI technologies d) The imperative to respect ethical principles which must be at the core of all AI developments and deployment (transparency, justice and fairness, responsibility, safety and security, privacy) e) The need to assess the value of AI technologies on the impact of their consequences and benefits on individuals and soc iety."
16,"In general, AIAs aim to identify potential risks and impacts—including to health, sa fety, ethics and, in some implementations, to human rights —arising from the development and depl oyment of an algorithmic system as well as appropriate risk mitigation strategies, such as use of “algorithmic audits” , “datasheets for datasets” , and “model cards. ”2 Implementations of AIAs are gaining momentum as a v iable AI governance strategy, finding their way into binding regulation and legislation.3Corporate policies are also requiring implementation of AIAs as a mechanism to reduce legal risks stemmi ng from liability and negligence.4The European Commissionʼs Artificial Intelligence Act s uggests a risk-based approach to AI governance, prohibiting certain harmful applications of AI and calling for developers to go through a form of impact assessment (called a “conformity assessment” ) for high-risk applications to identify necessary oversight mechanisms.5The Algorithmic Accountability Act proposed in the U nited States Congress in 2019 would have required compani es with large user bases to conduct impact assessments of highly sensitive ADS (the Act is exp ected to be reintroduced).6In 2021, the National Institute of Standards and Technology (NIST) was ta sked by Congress to develop an “AI risk management framework” to guide the “reliability, ro bustness, and trustworthiness of AI systems” used in the federal government.7In 2021, the National Security Commission on Artific ial Intelligence issued a report recommending that gove rnment agencies deploying AI systems conduct ex ante risk assessments and ex post impact assessments to “increase public transparency 7""Commerce, Justice, Science And Related Agencies Ap propriations Bill, 2021 - Report Together With Mino rity Views,"" House Committee on Appropriations, July 2020, https://appropriations.house.gov/sites/democrats.ap propriations.house.gov/files/July%209th%20report%20 for%20circulation_0.pdf , 23.6Algorithmic Accountability Act, 116th Cong."
16,"(2021) define AIAs as “emerging gove rnance practices for delineating accountability, rendering visible the harms caused by algorithmic s ystems, and ensuring practical steps are taken to ameliorate those harms. ”34Typical sources of risk to be identified include the presence of bias in datasets used to train an AI system, as well as the fairness and explainability of the model; identification of potential impacts can include con textual considerations related to equity and justice, as well as the economic interests, health, and well-being of users or populations potentially aﬀected by the proposed system."
16,"Toronto Waterfront Revitalization Corporation, et a l., (Ontario Superior Court of Justice File No."
162,"EUROPEAN COMMISSION FOR THE EFFICIENC Y OF JUSTICE (CEPEJ)E uropean ethical Charter on the use of A rtificial Intelligence in judicial syst ems and their environmentA dopted at the 31st plenary meeting of the CEPE J (Strasbourg, 3-4 December 2018) Adopted at the 31st plenary meeting of the CEPE J (Strasbourg, 3-4 December 2018)C ouncil of EuropeEUROPEAN COMMISSION FOR THE EFFICIENC Y OF JUSTICE (CEPEJ)E uropean Ethical Charter on the U se of Artificial Intelligence in J udicial Systems and their environment French edition:C ommission européenne pour l’efficacité de la justic e (CEPEJ) – Charte éthique eur opéenne d’utilisation de l’intelligence ar tificielle dans les systèmes judiciair es et leur environnementT he opinions expressed in this work are the r esponsibility of the authors and do not nec essarily reflect the official policy of the C ouncil of Europe."
162,"All other c orrespondence concerning this documen t should be addressed t o European Commission for the Efficienc y of Justice (CEPEJ) c epej@coe.intC over and layout: D ocuments and Publications P roduction Department (SPDP), C ouncil of Europe P hoto: ShutterstockT his publication has not been c opy-edited by the SPDP Editorial Unit t o correct typographical and g rammatical errors.© C ouncil of Europe, February 2019 P rinted at the Council of Europe ► Page 3ContentsI NTRODUCTION 5 T HE FIVE PRINCIPLES OF THE ETHICAL CHARTER ON THE USE O F ARTIFICIAL INTELLIGENCE IN JUDICIAL SYSTEMS AND THEIR E NVIRONMENT 7 1."
162,"H ow is AI to be applied in civil, commercial and administrative justice?"
162,"I ssues specific to criminal justice: prevention of offences, risk of recidivism a nd assessment of the level of danger 4 8 8 ."
162,T he potential and limitations of predictive justice tools 5 7 1 0.
162,The urgent need f or cyberethics to provide a framework for the development of artificial i ntelligence algorithms while respecting fundamental rights 5 9 Page 4 ► European Commission for the Efficiency of Justice (CEPEJ)APPENDIX II – WHICH USES OF AI IN EUROPEAN JUDICIAL SYSTEMS?
162,"6 3 U ses to be encouraged 6 4 P ossible uses, requiring considerable methodological precautions 6 4 U ses to be considered following additional scientific studies 6 6 U ses to be considered with the most extreme reservations 6 6 A PPENDIX III – GLOSSARY 6 9 A PPENDIX IV – CHECKLIST FOR INTEGRATING THE CHARTER’S P RINCIPLES INTO YOUR PROCESSING METHOD 7 6 C HECKLIST FOR EVALUATING YOUR PROCESSING METHODS 7 7 ► Page 5IntroductionA cknowledging the increasing importance of artificial intelligence1 (AI) in our modern societies, and the expected benefits when it will be fully used at the service of the efficiency and quality of justice, the CEPEJ for-mally adopts the 5 fundamental principles entitled “European Ethical Charter on the use of AI in the judicial sy stems and their environment” ."
162,"T he use of such tools and services in judicial systems seeks to improve the effi-T he use of such tools and services in judicial systems seeks to improve the effi-c iency and quality of justice, and should be encouraged."
162,"It must, however, be car-c iency and quality of justice, and should be encouraged."
162,"It must, however, be car-r ied out with responsibly, with due regard for the fundamental rights of individu-r ied out with responsibly, with due regard for the fundamental rights of individu-a ls as set forth in the European Convention on Human Rights and the Convention a ls as set forth in the European Convention on Human Rights and the Convention o n the Protection of Personal Data, and in compliance with other fundamental o n the Protection of Personal Data, and in compliance with other fundamental p rinciples set out below, which should guide the framing of public justice policies p rinciples set out below, which should guide the framing of public justice policies i n this field.i n this field.J udicial decision processing by artificial intelligence, according to their develop-J udicial decision processing by artificial intelligence, according to their develop-e rs, is likely, in civil, commercial and administrative matters, to help improve the e rs, is likely, in civil, commercial and administrative matters, to help improve the p redictability of the application of the law and consistency of court decisions, sub-p redictability of the application of the law and consistency of court decisions, sub-j ect to compliance with the principles set out below."
162,"Page 6 ► European Commission for the Efficiency of Justice (CEPEJ)Application of the CharterT he principles of the Charter should be subject to regular application, moni-t oring and evaluation by public and private actors, with a view to continuous impr ovement of practices."
162,"Page 10 ►3Principle of quality and security : with regard to the pro-c essing of judicial decisions and data, use certified sources and intangible data with models conceived in a multi-disci-plinar y manner, in a secure technological environment■ D esigners of machine learning models should be able to draw widely on the expertise of the relevant justice system professionals (judges, prosecutors, la wyers, etc.) and researchers/lecturers in the fields of law and social sciences (f or example, economists, sociologists and philosophers).■ F orming mixed project teams in short design cycles to produce functional models is one of the organisational methods making it possible to capitalise on this multidisciplinar y approach.■ Existing ethical safeguards should be constantly shared by these project t eams and enhanced using feedback.■ Da ta based on judicial decisions that is entered into a software which implemen ts a machine learning algorithm should come from certified sources and should not be modified until they have actually been used by the learning mechanism."
162,"The whole process must therefore be traceable to ensure that no modification has occurred to alter the content or meaning of the decision being pr ocessed. ■ T he models and algorithms created must also be able to be stored and executed in secure environments, so as to ensure system integrity and in tangibility. ► Page 114Principle of transparency, impartiality and fairness: make da ta processing methods accessible and understandable, author ise external audits■ A balance must be struck3 between the intellectual property of certain pr ocessing methods and the need for transparency (access to the design pr ocess), impartiality (absence of bias)4, fairness and intellectual integrity (pr ioritising the interests of justice) when tools are used that may have legal c onsequences or may significantly affect people’s lives."
162,"Page 12 ►5Principle “under user control”: preclude a prescriptive appr oach and ensure that users are informed actors and in c ontrol of their choices■ U ser autonomy must be increased and not restricted through the use of ar tificial intelligence tools and services.■ P rofessionals in the justice system should, at any moment, be able to r eview judicial decisions and the data used to produce a result and continue not to be necessarily bound by it in the light of the specific features of that par ticular case.■ T he user must be informed in clear and understandable language whether or not the solutions offered by the artificial intelligence tools are binding, of the different options available, and that s/he has the right to legal advice and the right to access a court."
162,"S/he must also be clearly informed of any prior pr ocessing of a case by artificial intelligence before or during a judicial process and have the right to object, so that his/her case can be heard directly by a c ourt within the meaning of Article 6 of the ECHR. ■ G enerally speaking, when any artificial intelligence-based information sy stem is implemented there should be computer literacy programmes for users and deba tes involving professionals from the justice system. ► Page 13Appendix II n-depth study on the use of AI in judicial sy stems, notably AI applic ations processing judicial decisions and da tapr epared by Mr Xavier Ronsin, First President of the Court of Appeal of R ennes, scientific expert (France), and M r Vasileios Lampos, principal research fellow at the Computer Science depar tment of University College London (UCL), scientific expert (United K ingdom), and with the contribution of Ms Agnès Maîtrepierre, judge, member of the C onsultative Committee of the Convention for the Protection of Individ-uals with regard to Automatic Processing of Personal Data of the Council of E urope (France)T he following experts also contributed to fintune the Study:M r Francesco Contini, Senior Researcher at the Research Institute on Judicial S ystems – National Research Council (IRSIG-CNR), Bologna (Italy)M r Francesco De Santis, Professor of Human Rights Procedures, University of Naples (I taly)M r Jean Lassègue, philosopher and epistemologist, research fellow at the Cen-tr e National de Recherche Scientifique (CNRS) and associate researcher at the I nstitut des Hautes Etudes sur la Justice (IHEJ) (France)Ms Dory Reiling, Honorary Senior Judge, Independent Expert on Information T echnology and Judicial Reform (Netherlands) M r Aleš Završnik, Chief Researcher at the Institute of Criminology, Associate P rofessor at the Faculty of Law, University of Ljubljana (Slovenia) and EURIAS R esearcher 2017-18 at Collegium Helveticum in Zürich (Switzerland) Page 14 ► European Commission for the Efficiency of Justice (CEPEJ)INTRODUCTION1."
162,"These private companies even aim to predict judges’ decisions with “predictive justice” tools, although we will see tha t this may not be the best description for them5.3."
162,"Work on a sample of 584 decisions of the European Court of Human Rights: Nikolaos A letras, Dimitrios Tsarapatsanis, Daniel Preoţiuc-Pietro, Vasileios Lampos, “Predicting judicial decisions of the European Court of Human Rights: a Natural Language Processing perspec tive” , published on 24 October 2016, [Online], https://peerj.com/articles/cs-93/ Appendix I – In-depth study on the use of AI in judicial systems ► Page 154.I n the line of the thought process initiated in its “Guidelines on how to dr ive change towards Cyberjustice” ,8 the CEPEJ proposes to provide public decision-makers and justice professionals with keys for a better understand-ing of the “predictive justice” phenomenon.5."
162,"Page 16 ► European Commission for the Efficiency of Justice (CEPEJ) document highlights these positive examples and generally advocates the use of AI by legal professionals according to their needs, provided that due r egard is shown for the individual rights guaranteed by the ECHR and Coun-cil of Europe standards, particularly in criminal matters."
162,"Some private operators did not seem very receptive to this survey and the members of the CEPEJ, who belong for the most part to ministries of justice or higher councils of justice, w ere able to quote only the tools currently used by the public sphere.14."
162,La tvia stated that it was exploring the possibilities of machine learning f or the administration of justice.
162,"See summary bibliography in Appendix IV – substantial contributions from Benoît Charpentier as well as Giuseppe Contissa and Giovanni Sartori (h ttps://media.wix.com/ugd/c21db1_14b -04c49ba7f46bf9a5d88581cbda172.pdf ) and Emmanuel Barthe (h ttp://www.precisement.org/blog/I ntelligence-artificielle-en-droit-derriere-la-hype-la-realite.html#nb14) (F rench only) Page 18 ► European Commission for the Efficiency of Justice (CEPEJ) SoftwareS tateT ypeD octrine.frF ranceF ranceS earch engineS earch engineP rédicticeF ranceA nalysis (except criminal cases)C ase Law AnalyticsFranceA nalysis (except criminal cases)A nalysis (except criminal cases)Jur isData Analytics (L exisNexis)FranceS earch engine, Analysis (except cr iminal cases)L uminanceU nited Kingdom AnalysisU nited Kingdom AnalysisW atson/Ross (IBM) USAA nalysisH ARTU nited Kingdom Analysis (criminal, risk of U nited Kingdom Analysis (criminal, risk of r eoffending)r eoffending)L ex Machina (L exisNexis)USAA nalysis2."
162,"An open data approach to judicial decisions is t herefore a prerequisite for the work of legal tech companies specialising in search t herefore a prerequisite for the work of legal tech companies specialising in search e ngines or trend analysis (“predictive justice”).e ngines or trend analysis (“predictive justice”).P rocessing of these data raises a number of issues, such as changes in the for-P rocessing of these data raises a number of issues, such as changes in the for-m ation of case-law and protection of personal data (including the names of m ation of case-law and protection of personal data (including the names of p rofessionals).p rofessionals).19."
162,Page 20 ► European Commission for the Efficiency of Justice (CEPEJ)purposes regarding individuals or groups.
162,"Predictive justice using artificial intelli-genc e, advanced search engines applying extremely precise criteria and legal robots are all algorithmic applications which are fed with data but have nothing t o do with the policy of open data itself.26."
162,"ISRM ARYesNo N ot a membre of CdED ata not supplied Page 22 ► European Commission for the Efficiency of Justice (CEPEJ)29.W ith regard to the protection of personal data, 23 countries declared tha t they are pseudonymising15 at least some types of disputes (e.g. per-sonal status, family status) by erasing data making the parties or witnesses iden tifiable (names, addresses, telephone numbers, identity numbers, bank ac count numbers, tax numbers, health status, etc.)."
162,"Ho wever, there is a real difficulty in measuring the impact of open data on the efficiency and quality of justice."
162,"They include greater awareness of judicial activity and case la w trends, the increased quality of a justice system that knows it is being obser ved and the creation of a completely new factual reference base."
162,"Article 12 of the French Code of Civil Procedure Page 24 ► European Commission for the Efficiency of Justice (CEPEJ)from the supposed majority case-law trend on how to resolve the dis-put e (while complying with the relevant rules of law), would this not be tantamount to removing them from office?"
162,"Page 26 ► European Commission for the Efficiency of Justice (CEPEJ)of cross-referencing with other databases, makes it impossible, in practice, to guar antee that the person concerned cannot be re-identified."
162,"Page 28 ► European Commission for the Efficiency of Justice (CEPEJ)seems that the challenge lies in reconciling often conflicting requirements: mak ing public activities transparent by allowing citizens to know and evalu-a te their judges, on one hand, while protecting the privacy of professionals (whose functions should not limit their fundamental guarantees in this field), on the other hand."
162,"See the example of the Swiss Federal Court, whose case-law can be downloaded: h ttps://w ww.bger.ch/fr/index/juridiction/jurisdiction-inherit-template/jurisdiction-recht.htm; or, f or the cantons: h ttp://ge.ch/justice/dans-la-jurisprudence (Canton of Geneva for example).28."
162,T he theoretical functionalities of “predictive justice” sof tware5 6.
162,These probabilities are establ ished through the statistical modelling of previous decisions using methods f rom two broad computer science domains: natural language processing Page 30 ► European Commission for the Efficiency of Justice (CEPEJ)and machine learning.
162,"I n relation specifically to justice, predictive justice systems are designed f or use by legal departments, insurers (both for their internal needs and for their policyholders) as well as lawyers for them to anticipate the outcome of litiga tion."
162,"G enerally speaking, it is also important to keep in mind the anthro-pomor phic notion that computing machines are intelligent and that their desig ners have managed to slip a mind inside their mechanisms.30 Unfortu-na tely, this idea still permeates many analyses of predictive justice that lend these devices immediate or future capabilities for the near replication of human intelligence."
162,"Specifically for predictive justice, the eng ine builds links between the different lexical groups composing judicial decisions."
162,Page 32 ► European Commission for the Efficiency of Justice (CEPEJ)at the input stage (facts and reasoning) and those at the output stage (the oper ative part of the decision) then classified.– The reliability of the model (or function) built strongly depends on the qualit y of the data used and the choice of machine learning technique.65.
162,"Li Gong, “La traduction automatique statistique, comment ça marche ?” , Interstices.info, published on 29 October 2013, [Online], https://interstices.info/jcms/nn_72253/la-traduction-aut omatique-statistique-comment-ca-marche (page accessed on 14 December 2017).Data Rules/Templates Resu lts Machinel earning Page 34 ► European Commission for the Efficiency of Justice (CEPEJ)training process, like a child learning in its environment."
162,Other practical applications for these technologies are already aff ecting our daily lives and are beginning to appear in the professional w orld of justice.3770.
162,"In the social sciences, to which law and justice belong , failure would even appear inevitable in the absence of a convincing model of cognition."
162,"Page 36 ► European Commission for the Efficiency of Justice (CEPEJ)a set of rules whose meaning remains undetermined, which the legal the-or ist Herbert L."
162,Page 38 ► European Commission for the Efficiency of Justice (CEPEJ)Fig.
162,Page 40 ► European Commission for the Efficiency of Justice (CEPEJ)administrative courts of appeal in France have made it possible to develop an indica tor of the rejection rate of appeals against obligations to leave French t erritory taken by the administrative authorities.
162,"F urthermore, how can we account for two distinct philosophical and cultur al approaches to judicial decisions, whereby, in some European coun-tr ies, including France, there is a culture of precedent and a detailed knowl-edge by judges of the factual databases of all 1st and 2nd instance decisions Appendix I – In-depth study on the use of AI in judicial systems ► Page 41(Ariane database) in the field of administrative justice, while other countries or systems favour the intellectual independence of each court, along with a desir e to deal with each situation on a case-by-case basis?92."
162,"H ow is AI to be applied in civil, commercial and administr ative justice?T he state of development of machine learning techniques does not allow today to r each reliable results regarding the “prediction” of judicial decisions."
162,"On the other h and, their application in the field of civil, commercial and administrative justice h and, their application in the field of civil, commercial and administrative justice i s to be considered for the creation of scales or the pre-litigation resolution of dis-i s to be considered for the creation of scales or the pre-litigation resolution of dis-p utes online, when a later appeal to the judge remains possible.p utes online, when a later appeal to the judge remains possible.93."
162,"Page 42 ► European Commission for the Efficiency of Justice (CEPEJ)97.A t the same time, public decision-makers see this as an opportunity to bett er regulate the flow of new proceedings through the courts and provide themselv es with a lever to reduce judicial operating costs."
162,"Ho wever, these interesting approaches are not unbiased and must not deprive citiz ens of access to a judge or call into question the adversarial principle.E xperiments conducted in FranceA t the initiative of the Ministry of Justice, the two courts of appeal in Rennes and A t the initiative of the Ministry of Justice, the two courts of appeal in Rennes and D ouai agreed to test predictive justice software on various litigation appeals in D ouai agreed to test predictive justice software on various litigation appeals in s pring 2017, which in reality was an analysis of civil, social and commercial deci-s pring 2017, which in reality was an analysis of civil, social and commercial deci-s ions of all French courts of appeal. s ions of all French courts of appeal."
162,"The result of the exper-i ment, contradictorily debated between the two courts of appeal, the Ministry i ment, contradictorily debated between the two courts of appeal, the Ministry o f Justice and the legal tech company who designed the product unfortunately o f Justice and the legal tech company who designed the product unfortunately s tated the absence of added value of the tested version of the software for the s tated the absence of added value of the tested version of the software for the w ork of reflection and decision-making of the magistrates. w ork of reflection and decision-making of the magistrates."
162,Page 44 ► European Commission for the Efficiency of Justice (CEPEJ)6.2.
162,"F or those who advocate such solutions, which are of interest to a num-ber of legal professions and the private sector, access to justice could be sig-nifican tly improved by a broad solution combining ODR and AI (or at least e xpert systems, see section 3 above for the distinction)."
162,Recently the Court of Justice of the E uropean Union in Luxembourg has answered on the requests for a preliminary ruling c oncerning these joined cases (ECLI:EU:C:2018:882)55.
162,"Darin Thompson, “Creating new pathways to justice using simple artificial intelligence and online disput e resolution” , Osgoode Hall Law School of York University.56. http://www.cyberjustice.ca/projets/odr-plateforme-daide-au-reglement-en-ligne-de-litiges/ Appendix I – In-depth study on the use of AI in judicial systems ► Page 45107.But on what basis would any compensation proposed by such a system be calculated?"
162,"The explanatory Page 46 ► European Commission for the Efficiency of Justice (CEPEJ)108.T he potential benefits of an ODR system, its degree of integration into a complete judicial process (from pre-litigation to actual litigation) and the almost decisive role of AI in the execution of the process must therefore be pr operly assessed on a case-by-case basis.109."
162,"If one speaks of a court, it must be the form of or ganisation defined by the European Convention on Human Rights and not simply a private justice institution with the mere appearance of state justic e60."
162,"Royaume-Uni, §§ 28-366 3.Resolution 2054 (2015) of the Parliamentary Assembly of the Council of Europe (P ACE), 10 November 2015, h ttp://assembly.coe.int/nw/xml/XRef/Xref-XML2HTML-EN.asp?fileid=22245&lang=en Page 48 ► European Commission for the Efficiency of Justice (CEPEJ) for certain operators (institutions, companies with means, computer liter-a te persons) and, on the contrary, pose difficulties for certain population t ypes that are more uncertain or less familiar with computers."
162,"In these systems, we can-not rule out the risk that such norms will place indirect pressure on judges when decisions are taken and prompt their approval, or that the executive will monit or those who depart from the norm.R ight to counselA t the beginning of this chapter, we mentioned the advantages derived from the application of predictive justice tools for lawyers and, in particular, the possibilit y of providing their clients with better informed advice by empiri-cally and systematically assessing the chances of a procedure’s success."
162,"I ssues specific to criminal justice: prevention of offences, risk of r ecidivism and assessment of the level of dangerE ven they are not specifically designed to be discriminatory, the use of statistics a nd AI in criminal proceedings has shown a risk of prompting the resurgence of a nd AI in criminal proceedings has shown a risk of prompting the resurgence of d eterministic doctrines to the detriment of doctrines of individualisation of the d eterministic doctrines to the detriment of doctrines of individualisation of the s anction, which have been widely acquired since 1945 in most European judicial s anction, which have been widely acquired since 1945 in most European judicial s ystems.s ystems.117."
162,"C riminal justice tools should therefore be designed in accordance with these fundamental principles of rehabilitation, 65including the role of the judge in the individualisation of the sentence, based on objective elements of personalities (training, employment, regular medicals and social care) without any other form of analysis than that carried out by specifically trained pr ofessionals, such as probation officers."
162,"Page 50 ► European Commission for the Efficiency of Justice (CEPEJ)first category includes “predictive policing” instruments that are used to pre-v ent certain types of offences with elements of regularity in their occurrence such as burglary, street violence, theft from/of vehicles."
162,"In the literature, these tools are often referred to as “algorithmic justice” or “automated justic e” , or “simulated justice” ."
162,"Page 52 ► European Commission for the Efficiency of Justice (CEPEJ)126.I n tests initially conducted in 2013, during which suspect behaviour w as observed over a two-year period after commission of the crime, HART pr edictions were found to be 98 % effective at predicting low risk and 88 % eff ective at high risk of recidivism."
162,Page 54 ► European Commission for the Efficiency of Justice (CEPEJ)judges in criminal trials.
162,Suppor ters often argue that they are neutral and that they rely on fac tual and objective methods that help to make justice more accurate and transparent.
162,"It is incumbent upon the criminal justice system to recognize that in the coming months and years, additional research data will become available."
162,The justice system must keep up with the research and continually assess the use of these t ools. ”78.
162,"Appendix I – In-depth study on the use of AI in judicial systems ► Page 55137.I n criminal matters, there are also potential risks of discrimination when one considers that these tools, which are constructed and interpreted by humans , can reproduce unjustified and already existing inequalities in the cr iminal justice system concerned; instead of correcting certain problematic policies , technology may end up legitimising them."
162,Page 56 ► European Commission for the Efficiency of Justice (CEPEJ) 140.T he considerations expressed earlier regarding the potentially negative eff ects of these tools on the impartiality of the judge are also valid in criminal ma tters: a judge who decides against the prediction of an algorithm is likely t o take risks as he assumes greater responsibility.
162,The potential and limitations of predictive justice toolsT he term predictive justice should be dismissed because it is ambiguous and mis-l eading.
162,"I n section 3, we already highlighted the ambiguity and fallacy of the c oncept of predictive justice and how it operates a slow shift in the collec-tiv e mind, leading us to believe that machines, devoid of any emotion, will one day be better able to make the act of judging more reliable."
162,"Similarly, researcher Aurélien Grosdidier considers t hat an algorithm, in itself, is capable of nothing other than allowing us – at b est – to grasp part of the designer’s intention and extends the questioning Page 58 ► European Commission for the Efficiency of Justice (CEPEJ)to the entire information processing chain (designer’s intention, production of computer code, execution of computer code and context of execution then maintenance)."
162,"As mentioned earlier, the risk is that, in the absence of a statistical representation of reality or of being able to predict anything, the results of predictive justice software will be set as standards without any v alidation by the legal system and in conflict with it.150."
162,"Page 60 ► European Commission for the Efficiency of Justice (CEPEJ)10.1.T he importance of debating, testing and continually r eviewing the application of these tools prior to the implemen tation of public policies154."
162,"In addition, judicial training and law schools can pla y a key role in raising awareness among justice professionals on these issues , so that they can better understand and practically contribute to cur-r ent developments.156."
162,"A right to e xamine the components and characteristics of the instruments proposed b y the private sector (or those developed by independent and specialised public institutes, a solution which should be encouraged) seems equally impor tant so that the justice service can effectively carry out its mission."
162,It also seems strongly advisable to r egularly assess the impact of these tools on the work of justice professionals.10.2.
162,Justice professionals must be closely involved to be able to properly assess the risks and the impact of these applica tions on judicial systems.161.
162,"Other a pplications (“predictive justice”) should be assigned to the field of research and a pplications (“predictive justice”) should be assigned to the field of research and f urther development (in consultation with legal professionals in order to ensure f urther development (in consultation with legal professionals in order to ensure t hat they fully tie in with actual needs) before contemplating use on a significant t hat they fully tie in with actual needs) before contemplating use on a significant s cale in the public sphere.s cale in the public sphere.I n criminal matters, this is a very sensitive issue but it should not be ignored."
162,"In the l ight of the many existing questions as to their compatibility with a certain num-l ight of the many existing questions as to their compatibility with a certain num-b er of fundamental rights, the use of algorithms to calculate the potential risks of b er of fundamental rights, the use of algorithms to calculate the potential risks of r ecidivism of an individual brought to justice should be considered with the most r ecidivism of an individual brought to justice should be considered with the most e xtreme reservations."
162,Page 64 ► European Commission for the Efficiency of Justice (CEPEJ) Uses to be encouraged► Case-law enhancement : machine Learning techniques have been incr easingly deployed in the field of natural language processing in the past years (this includes initial efforts in natural language under-standing) and are a considerable asset for finding search options to c omplement current keyword or full-text search.
162,"Document templates (court applications, lease ag reements, etc.) could also be generated online.► Creation of new strategic tools : the use of data science and artificial in telligence techniques on court activity data can help improve the efficienc y of justice by making it possible, for example, to carry out quan titative and qualitative evaluations and to make projections (e.g. futur e human and budgetary resources)."
162,"It is recommended that legal profes-sionals , especially judges, be involved in the implementation of these t ools, in terms of taking ownership of these tools and of analysing the r esults in conjunction with factors relating to the specific features of the court in question or the quality of justice (for example, the need t o preserve access to justice).P ossible uses, requiring considerable metho dological precautions► Help in the drawing up of scales in certain civil disputes : an analysis of all judicial decisions is not statistically meaningful if all the causative fac tors (explicit and implicit in the decisions) are not identified."
162,"Appendix II – In-depth study on the use of AI in judicial systems ► Page 65►Support for alternative dispute settlement measures in civil matters: in some European countries, “predictive justice” tools are used by insur ance companies to evaluate the chances of success of a dispute and to steer the litigant towards another method of dispute resolu-tion when it is felt that there is little chance of success."
162,"However, this type of Page 66 ► European Commission for the Efficiency of Justice (CEPEJ) quantitative approach can generate a strong “performative effect” (in a g iven location, there is a greater chance of discovering an offence and this then reinforces the system)."
162,"Page 70 ► European Commission for the Efficiency of Justice (CEPEJ)However, the term artificial intelligence is criticised by experts who distin-guish between “strong” AIs (yet able to contextualise specialised and varied pr oblems in a completely autonomous manner) and “weak” or “moderate” AIs (high performance in their field of training)."
162,"Page 72 ► European Commission for the Efficiency of Justice (CEPEJ)MM ACHINE LEARNING M achine learning makes it possible to construct a ma thematical model from data, incorporating a large number of variables tha t are not known in advance."
162,"Page 74 ► European Commission for the Efficiency of Justice (CEPEJ)Open data should not be confused with unitary public information available on websites, where the entire database cannot be downloaded (for exam-ple , a database of court decisions)."
162,"The software can therefore be freely used, modified and r edistributed.P PERSONAL DATA Any information concerning an identified or identifiable na tural person (the “person concerned”), directly or indirectly.T hese include sensitive data relating to genetic data, biometric data uniquely iden tifying an individual, data relating to offences, criminal proceedings and c onvictions and related security measures, and any data for information they r eveal on racial or ethnic origin, political opinions, trade union membership, r eligious or other beliefs, health or sex life.PREDIC TIVE JUSTICE P redictive justice is the analysis of large amounts of judicial decisions by artificial intelligence technologies in order to make pre-dic tions for the outcome of certain types of specialised disputes (for exam-ple , redundancy payments or alimentary pensions).T he term “predictive” used by legal tech companies comes from the branches of science (principally statistics) that make it possible to predict future results thr ough inductive analysis."
162,"The European Court of Human R ights oversees the implementation of the C onvention in the member states.www.coe.intThe Charter provides a framework of principles that can guide policy makers , legislators and justice professionals when they grapple with the rapid development of Artificial Intelligence in national judicial pr ocesses.T he CEPEJ’s view is that the application of Artificial Intelligence in the field of justice can contribute to improve the efficiency and qualit y."
162,"It is essential t o ensure that Artificial Intelligence remains a tool in the service of the gener al interest and that its use respects individual rights.T he Charter defines five core principles to be respected in the field of Artificial Intelligence and justice: respect of fundamental rights; nondiscrimination; quality and security; transparency, impartiality and fairness; “under user control” ."
166,At the informal video conference of the Ministers of Justice on 9 October 2020 the Presidency informed Ministers on the advanced state of negotiations and announced further work by the Presidency.
166,"Digital technologies have an increasing and largely positive effect on the daily lives of Europea ns, for example in industry, services, research, justice and publ ic security."
166,"We acknowledge and stress the importance of coherence with the valuable work and initiatives carried out on fundamental and human rights in the context of digitalisation by the European institutions and agencies, in particular the European Commission, the European Parliament, the EU Agency for Fundamental Rights , and in the relevant case -law of the European Court of Justice , as well as in other fora, in particular the Council of Europe and its Ad Hoc Committee on AI, the OSCE, the OECD and the United Nations."
166,AI and Justice 27.
166,"Access to justice, transparency and expl icability of judicial processes and decision -making, an independent judiciary and legal certainty are essential to the proper functioning of the justice system in accordance with the rule of law."
166,"Moreover, non -digital access to law and justice will remain essential."
166,"In this re gard, we refer to the Council Conclusions of 9 October 2020 on ‘Access to justice – seizing the opportunities of digitalisation’."
168,52 CHAPITRE 2 LA RECEPTION PRAGMATIQUE ET DIFFERENCIEE DES DECISIONS DE JUSTICE ...........................................
168,54 Section 1 - La pluralité des usages des décisions de justice ......................................
168,55 § 2 - Les usages liés à la décision de justice : convaincre et justifier ......................................
168,61 Section 2 - La perception inégale des décisions de justice .......................................
168,62 § 1 - Les facteurs tenant à la dimension institutionnelle de la justice .....................................
168,75 CHAPITRE 1 PREVENIR LES RISQUES LIES A L ’OPEN DATA DES DECISIONS DE JUSTICE ................................................
168,76 Section 1 - Éviter l’indifférenciation des décisions de justice .....................................
168,76 § 1 - Assurer une organisation plus rationnelle de la diffusion des décisions de justice ......
168,"93 § 2 - Conférer une place, dans la motivation des décisions de justice, à la citation des décisions antérieures ........................................................................................."
168,112 CHAPITRE 2 METTRE A PROFIT LES OPPORTUNITES OFFERTES PAR L ’OPEN DATA DES DECISIONS DE JUSTICE .................
168,La diffusion des données décisionnelles et la jurisprudence · 11 RECOMMANDATIONS DU GROUPE DE RÉFLEXION Éviter l’indifférenciation des décisions de justice Assurer une organisation plus rationnelle de la diffusion des décisions de justice ; RECOMMANDATION n° 1 Assurer une organisation plus lisible et plus rationnelle du système de diffusion des décisions de justice en France.
168,"RECOMMANDATION n° 4 Les décisions des juridictions du fond présentant un intérêt juridique particulier et qui peuvent être adressées pour mise en valeur sur l’interface de programmation d’application Judilibre sont notamment celles qui répondent à l’un des critères suivants – ces critères étant susceptibles de se combiner, ce qui est de nature à renforcer l’intérêt de la décision :  Est considérée comme présentant toujours un intérêt juridique particulier (en raison d’un critère formel décelable prima facie ) : - Une décision opérant un renvoi préjudiciel à la Cour de justice de l’Union européenne ; - Une décision de transmission d’une question prioritaire de constitutionnalité ; - Une décision conduisant à la saisine du Tribunal des conflits à fin de règlement d’un conflit d’attribution entre les deux ordres de juridiction .  Peut être identifiée comme présentant un intérêt juridique particulier (critère substantiel, nécessitant une analyse plus fine de la décision, dans son environnement juridique) : - Une décision qui procède à un contrôle de conventionalité au regard de la Convention de sauvegarde des droits de l’ Homme et des libertés fondamentales ; - Une décision qui tranche une question de droit sur laquelle la Cour de cassation ne s’est pas prononcée (texte nouveau, problème nouveau d’articulation de plusieurs textes) ; - Une décision qui statue sur une question inédite ou qui adopte une qualification ou une interprétation nouvelle, spécialement lorsqu’elle est rendue dans un domaine relevant de l’appréciation souveraine des juges du fond ou si elle n’est pas susceptible de pourvoi en cassation ; - Une décision qui marque une inflexion de la position antérieure de la juridiction ; La diffusion des données décisionnelles et la jurisprudence · 13 - Une décision portant sur une question qui donne lieu à un débat jurisprudentiel ou doctrinal bien identifié ; - Une décision ayant une importance sociétale ; - Une décision rendue dans le cadre d’un contentieux rare ou d’un contentieux émergent, spécialement lorsqu’elle est susceptible de concerner un grand nombre de juridictions."
168,"14 · La diffusion des données décisionnelles et la jurisprudence RECOMMANDATION n°8 Modifier l’article 5.5 du règlement intérieur de la profession d’avocat de la manière suivante : « La communication [entre avocats des pièces] se fait dans les conditions suivantes : les décisions de justice non diffusées en open data sont versées aux débats ; pour la doctrine et les décisions de justice diffusées en open data , les références complètes sont communiquées à l’autre avocat ou accessibles par lien hypertexte, si les écritures sont accessibles numériquement »."
168,"Conférer une place, dans la motivation des décisions de justice, à la citation des décisions antérieures RECOMMANDATION n° 10 Tout en évitant l’écueil d’une motivation « par référence », permettre aux juridictions du fond de faire état de décisions précédemment rendues par des juridictions La diffusion des données décisionnelles et la jurisprudence · 15 du fond entre d’autres parties, spécialement les décisions des juridictions du fond signalées par la Cour de cassation pour leur intérêt particulier1."
168,Former les étudiants à l’utilisation des services algorithmiques de traitement des décisions de justice.
168,"Ajouter aux ressources auxquelles ont accès les étudiants, l’accès à des services algorithmiques de traitement des décisions de justice."
168,16 · La diffusion des données décisionnelles et la jurisprudence RECOMMANDATION n°13 Mettre en place une mutualisation des moyens à l’échelle des barreaux afin d’offrir à l’ensemble des avocats un accès à des services algorithmiques de traitement des décisions de justice.
168,Ajouter l’accès à des services algorithmiques de traitement des décisions de justice aux ressources accessibles nationalement aux magistrats et aux juges non professionnels.
168,"RECOMMANDATION n°15 Renforcer la formation, initiale et continue, des magistrats et des avocats sur la place d’une décision de justice dans l’ordonnancement juridique, sur son utilisation dans l’instance judiciaire et sur la rédaction des écritures des parties et des décisions de justice à cet égard."
168,"Donner mission à ce Conseil : - de centraliser les informations et, notamment, les difficultés relatives à la mise en œuvre de la diffusion des décisions de justice ; La diffusion des données décisionnelles et la jurisprudence · 17 - d’être un organe de réflexion, d’échanges et de recommandations sur les pratiques, méthodes de travail et outils mis en œuvre dans le cadre de l’ open data des décisions de justice ; - de nouer et développer des partenariats aux niveaux européen et international ; - de coordonner les actions d’application des réflexions et reco mmandations issues des travaux du Conseil."
168,RECOMMANDATION n°18 Permettre le signalement des divergences entre décisions de justice par une application accessible sur le site de la Cour de cassation aux utilisateurs inscrits.
168,"RECOMMANDATION n°26 Inscrire cette bonne pratique dans les outils et fiches méthodologiques de rédaction du jugement civil destinées à aider les juges dans la rédaction des décisions de justice, mais également, le cas échéant, dans les protocoles de procédure existants ou à venir entre les barreaux et les juridictions."
168,Encourager la recherche relative aux décisions rendues par les juridictions du fond RECOMMANDATION n°31 Développer les espaces de publication pouvant accueillir des travaux universitaires exploitant les ressources offertes par l’ open data des décisions de justice.
168,"20 · La diffusion des données décisionnelles et la jurisprudence Favoriser l’essor de recherches collectives, y compris pluridisciplinaires, mettant en œuvre l’exploitation des ressources offertes par l’ open data des décisions de justice."
168,Promouvoir dans les instances universitaires – notamment au sein du Conseil national des universités – une réflexion sur la valorisation des travaux universitaires et de recherche exploitant les ressources offertes par l’ open data des décisions de justice.
168,"Développer les échanges au sein de la communauté juridique RECOMMANDATION n°32 Promouvoir la conclusion de partenariats entre les universités et les juridictions afin de mieux traiter les ressources offertes par l’ open data des décisions de justice et, spécialement, les décisions signalées."
168,"Or, à l’ère des données judiciaires ouvertes, la connaissance des décisions de justice sera rendue plus facile et il pourrait en résulter un changement dans la façon dont la jurisprudence doit ê tre appréhendée."
168,L’avènement de l’ open data des décisions de justice .
168,"Or, ce que l’on appelle couramment l’ open data , qui peut être traduit par données ouvertes , peut également concerner les décisions de justice qui, numérisées, sont autant de données décisionnelles susceptibles de servir ces objectifs."
168,"111- 13 dans le code de l’organisation ju diciaire (COJ), qui dispose depuis lors, en son alinéa 1, que « les décisions rendues par les juridictions judiciaires sont mises à la disposition du public à titre gratuit » ; son article 20 ajoute à l’article L.10 du code de justice administrative un ali néa 2, aux termes duquel les « jugements sont mis à la disposition du public à titre gratuit »."
168,"Par cette ouverture des données décisionnelles, une plus grande effectivité sera donnée à l’exigence de publicité d es décisions de justice, en ce que les décisions rendues publiquement, et seulement elles7, seront rendues plus aisément accessibles à ceux qui voudraient les consulter, qu’ils soient praticiens, universitaires ou justiciables."
168,Mais l’open data des décisions de justice porte au-delà : il soulève aussi la question de la jurisprudence .
168,"Les prémices de la diffusion numérique des décisions de justice permettent de s’en c onvaincre : déjà, Légifrance avait « vocation à diffuser gratuitement des données juridiques publiques »8 et avait « pour objet de faciliter l ’accès du public aux textes en vigueur ainsi qu'à la jurisprudence »9."
168,"L’open data des décisions de justice le permettra également, ce qui invite à s’interroger à nouveaux frais sur les rapports que peuvent entretenir diffusion des décisions de justice et jurisprudence. Évolution historique de la notion de jurisprudence ."
168,"Puis, progressivement, ce sens ancien s’est perdu « pour ne plus désigner que les décisions de justice et leur autorité »12, ce qui a pu faire écrire à Aubry et Rau qu’ « en droit romain le mot jurisprudence se prenait exclusivement pour désigner la science du droit."
168,"Dans un premier sens, la jurisprudence est l’ « ensemble des décisions de justice rendues pendant une certaine période soit dans une matière (jurisprudence immobilière), soit dans une branche du Droit (jurisprudence civile, fiscale, etc.), soit dans l’ensemble du Droit »16."
168,"En vérité, il conviendra de n’en exclure aucune : précisément, la mission du groupe de réflexion a consisté à se demander si, par l’effet de l’ open data des décisions de justice, la jurisprudence pourrait changer de signification et laisser une place plus importante aux décisions des juridictions du fond."
168,Il existe en effet un lien étroit entre la diffusion des décisions de justice et la jurisprudence.
168,"L’on comprend que grâce au livre imprimé, tous ceux en quête du meilleur droit et de la meilleure justice ont pu s’inspirer d’exemples bien plus nombreux, anciens ou nouveaux, pris dans leur ressort ou dans des ressorts éloignés, d’exemples jugés les plus remarquables, puisés dans les meilleurs recueils, identifiés au nombre de leurs rééditions."
168,L’apport du recueil d’arrêts imprimé dépasse donc largement l’histoire de la jurisprudence pour toucher tout le droit et la justice d’avant la Révolution »26.
168,"C’est dire que la plus grande diffusion des décisions de justice est une condition de l’existence de la jurisprudence, voire de son essor."
168,"D EUMIER , « Contribution », in L’open data des décisions de justice , rapport remis le 9 janvier 2017 au Garde des Sceaux, p."
168,Le rapport est disponible en ligne à l’adresse suivante : https://www.justice.gouv.fr/publication/open_data_rapport.pdf .
168,"DECHAUX, « L'open data des décisions de justice se fera dans le respect de l'État de droit », AJDA 2021, p.1696."
168,"26 · La diffusion des données décisionnelles et la jurisprudence décisions de jurisprudence », regroupant ainsi « les termes de justice dite prédictive, actuarielle ou quantitative »32."
168,"Des outils plus qualitatifs, ensuite, qui ne se limitent pas à l’analyse statistique de décisions, mais qui ont pour objectif une analyse des arguments des parties et de la motivation des décisions, dans le but de mettre en relation des décisions de justice entre elles afin de retrouver, dans la masse des décisions, les arguments et motivations identiques, susceptibles de conduire aux mêmes décisions."
168,"M ENECEUR , « Justice et intelligence artificielle : la confiance naîtra d ’une réglementation internationale », Dalloz IP/IT 2021, p."
168,"C ADIET , « Quelques observations, en demi-teinte, sur la prévisibilité du jugem ent et la jurisprudence concrète », in La justice du 21ème siècle – Le citoyen au cœur du service public de la justice , Les actes du débat national, Ministère de la Justice, 2014, pp."
168,"La barémisation de la justice : une approche par l’analyse économique du d roit, dir."
168,"BOURREAU -DUBOIS , rapport de la mission de recherche Droit et justice, févr."
168,"27 et s. ; La barémisation de la justice , colloque organisé le jeudi 17 décembre 2020 à la Cour de cassation et disponible à l’adresse suivante : https://www.courdecassation.fr/agenda-evenementiel/la-baremisation- dela-justice ."
168,"D EUMIER , Contribution au rapport L’open data des décisions de justice , nov."
168,190 ; le rapport est disponible à l’adresse suivante : https://www.justice.gouv.fr/publication/open_data_rapport.pdf .
168,"Les questions que le groupe de réflexion est invité à se poser ne rencontrent pas – il va sans dire – un écho identique dans tous les pays : certains confèrent dès à présent une plus grande importance normative aux décisions des juges du fond, tandis que pour d’autres, l’ open data des décisions de justice n’est pas à l’ordre du jour, quand les deux phénomènes ne jouent pas de concert, comme c’est le cas en Allemagne42."
168,"Faut-il en cadrer d’une quelconque manière la possibilité pour les parties et leurs représentants de faire valoir, au cours du procès, des décisions de justice – notamment rendues par les juridictions du fond – au soutien de leurs prétentions ?"
168,"Le groupe de réflexion a ainsi eu à l’esprit, tout au long de ses travaux, les enjeux économiques attachés à l’ open data des décisions de justice et, plus particulièrement, à l’exploitation des données judiciaires par les éditeurs juridiques et les LegalTech ."
168,"Aujourd’hui plus encore qu’hier, les décisions de justice représentent une valeur économique et leur réutilisation est un marché sur lequel sont d’ores et déjà en concurrence des opérateurs privés. À cet égard, le rôle des pouvoirs publics est à questionner et ne saurait se limiter à la seule mise à disposition des données décisionnelles."
168,"Ici comme ailleurs, le bon fonctionnement du service public de la justice appelle un financement adapté."
168,"D’autre part, ces propositions ne pourront être mises en œuvre de manière vertueuse qu e si elles sont menées à bien dans un esprit de coopération loyale entre les différents acteurs de la justice concernés."
168,"Afin de pouvoir formuler utilement des recommandations aussi justes que possible au regard de ce que l’ open data des décisions de justice pourrait changer à la jurisprudence, il a semblé de bonne méthode au groupe de réflexion d’approfondir les relations qu’entretiennent aujourd’hui la diffusion des décisions de justice et la jurisprudence, afin d’établir précisément ce que changera l’ouverture des données judiciaires en cours."
168,"Autrement dit, dans les développements qui vont suivre, un état des lieux précis de la diffusion des décisions de justice et de la jurisprudence sera tracé (I), avant de dessiner les perspectives ouvertes par l’ open data , qui appelleront des recommandations (II)."
168,La diffusion des données décisionnelles et la jurisprudence · 31 PARTIE 1 ÉTAT DES LIEUX La mission confiée au groupe de réflexion offre l’occasion inédite de faire un état des lieux complet des formes de diffusion des décisions de justice en France.
168,Les voies de diffusion des décisions de justice sont multiples et n’ont pas toujours été pensées de manière coordonnée.
168,"Dans le même temps, la réflexion dont le groupe de travail a été saisie incite aussi à mener une réflexion approfondie sur la réception des décisions de justice en France. À l’observateur attentif, il apparaît que cette réception n’est pas globale et indifférenciée."
168,"Au caractère croissant et protéiforme de la diffusion des décisions de justice (chapitre 1) répond, en définitive, une réception pragmatique et différenciée des décisions de justice (chapitre 2)."
168,"32 · La diffusion des données décisionnelles et la jurisprudence Chapitre 1 - La diffusion croissante et protéiforme des décisions de justice L’une des conditions d’existence de la jurisprudence est la diffusion des décisions rendues, leur « publicité » disait-on naguère46. À défaut d’être connue et diffusée, nulle décision ne peut, en effet, faire jurisprudence."
168,"C’est ainsi qu’avant toute démarche visant à analyser quelle pourra être l’incidence de la diffusion massive des données décisionnelles à la fois sur la notion de jurisprudence, sur le rôle des parties et sur l’office du juge, le groupe de réflexion a estimé indispensable de dresser un état des lieux portant sur les modes actuels de diffusion des décisions de justice en France48, ainsi que sur leurs modalités et leurs finalités."
168,"Section 1 - Essor des modes de diffusion légalement encadrés Les textes légaux et réglementaires ont autorisé la diffusion des décisions de justice, en faisant coexister des modes de diffusion internes à l’institution judiciaire ( § 1), avec des modes de diffusion tournés vers l’extérieur de l’institution judiciaire ( § 2)."
168,"La diffusion des données décisionnelles et la jurisprudence · 33 A - Modes de diffusion internes aux juridictions judiciaires Au début des années 2000, ont été développées, dans une finalité documentaire, des bases de données des d écisions de justice internes à l’institution judiciaire."
168,"Ces bases de données dites « intègres »49, c’est -à-dire parfaitement fidèles et authentiques, ne sont accessibles qu’aux personnels du ministère de la Justice (magistrats et fonctionnaires des service s du ministère de la Justice, ainsi que toutes les directions et toutes les personnes habilitées du ministère de la Justice), à partir du Réseau privé virtuel justice (RPVJ), qui constitue une « sorte d’intranet ». Évelyne Serverin, directrice de recherche, constate, à propos de ces bases documentaires : « c’est le principe documentaire qui domine, avec l’application de l’informatique documentaire aux sources juridiques »50."
168,"S ERVERIN , « De l’informatique juridique aux services de justice prédictive, la longue route de l’accès du public aux décisions de justice dématérialisées », in Archives de philosophie du droit , Dalloz, 2018/1, tome 60, pp."
168,"Réservée aux magistrats et aux services dépendant du ministère de la Justice, il s’agit d’un intranet permettant d’accéder au gisement que représente l’intégralité des décisions rendues par les cours d’appel et ainsi d’informer, au -delà de la norme, de l’expérience de toutes les juridictions."
168,"Il faut prendre la pleine mesure de ce qu’a représenté l’introduction du principe d’une diffusion intégrale de l’ensemble des décisions : à bien des égards, elle opère une véritable rupture, quasiment paradigmatique, dans l’histoire de la diffusion des décisions de justice, faisant passer d’une conception des décisions de justice comme vecteurs de l’interprétation authentique de la loi, à une mettre ces décisions à la disposition du public dans les conditions définies aux articles R."
168,Les conditions dans lesquelles ces décisions lui sont transmises son t fixées par les dispositions régissant les applications informatiques du ministère de la Justice et du Conseil national des greffiers des tribunaux de commerce ».
168,"Les conditions dans lesquelles ces arrêts et décisions sont transmises au service et exploitées par celui-ci sont fixées par un arrêté du garde des sceaux, ministre de la Justice »."
168,"La diffusion des données décisionnelles et la jurisprudence · 35 conception des décisions de justice comme instruments de la connaissance de la pratique des cours d’appel, désormais jugée digne d’intérêt58."
168,"Le président Bernard Stirn souligne à son sujet que Juradinfo permet ainsi des « échanges rapides de jurisprudence sur des questions nouvelles qui peuvent se poser simultanément dans nombre de juridictions »72. § 2 - La diffusion hors l’institution judiciaire Outre la diffusion légalement encadrée des décisions de justice, déployée de manière interne à l’institution judiciaire, les décisions de justice sont aussi diffusées à l’extérieur de l’institution judiciaire."
168,"Ce dispositif a récemment évolué en raison de la tendance à une diffusion massive en ligne des décisions de justice, notamm ent de l’ open data des décisions de la Cour de cassation qui a été mis en œuvre, bientôt suivi par la diffusion massive en ligne de l’ensemble des décisions des juridictions judiciaires."
168,"431 -9 du COJ : « Il est fait rapport annuellement au président de la Répub lique et au garde des sceaux, ministre de la Justice, de la marche des procédures et de leur s délais d ’exécution. »."
168,"B - Diffusion mise en œuvre par un service public de base de données juridiques La pratique d’une diffusion sélective élargie des décisions. À côté de la diffusion sélective mise e n œuvre par la Cour de cassation elle -même, a progressivement été créé un service public de la diffusion des décisions de justice, pris en charge, depuis 1999, par Légifrance, et reposant sur une diffusion sélective plus large, portant à la fois sur des arrêts de la Cour de cassation80 et sur des décisions rendues par les juridictions du fond, après anonymisation."
168,"De plus, le bulletin mensuel du Tribunal supérieur de justice publie, sur son site, les « “thèses ” […] de façon organisée, pour la reche rche »84."
168,"En droit allemand, même si la publication des décisions de justice est une obligation qui a « une assise constitutionnelle »85, les dispositions en matière de publication sont assez « parcellaires […] les règles variant selon les Länder »86."
168,"De plus, le Conseil national de justice « a mis en place un e banque nationale de précédents obligatoires et le STF dispose de publications ayant pour but la diffu sion nationale et internationale de précédents : bulletins et case law compilati on."
168,"Justice (BGH), 5 avr."
168,"Le site internet piloté conjointement par le ministère fédéral de la Justice et l’office fédéral de la justice publie « une sélection de décisions de la Cour constitutionnelle fédérale, des Cours suprêmes fédérales ainsi que du Tribunal fédéral des brevets sur Internet à partir de l'année 2010 »89."
168,"C’est pourquoi il est demandé, « afin de renforcer la confiance en la justice par davantage de transparence91, qu’une réglementation intervienne en matière de publication des décisions de justice pour que celles- ci, à condition qu’elles portent sur une question de principe (grundsätzliche Bedeutung ), soient plus facilement accessibles »92."
168,"Frédérique Ferrand observe ainsi : « si, aujourd’hui, toutes les décisions de la Cour fédér ale de Justice rendues depuis le 1er janvier 2000 sont accessibles sur son site internet – y compris certaines décisions non motivées rejetant le recours en contestation du refus d’autorisation de pourvoi par la juridiction d’appel –, il n’en va pas de mêm e des arrêts antérieurs."
168,L’avènement d’un modèle exhaustif et non sélectif de diffusion des décisions de justice.
168,"Ainsi, sans modifier les dispositions relatives aux bases de données Jurinet et JuriCA, la loi n°2016-1321 du 7 octobre 2016 pour une République numérique a posé le principe d’ouverture par défaut des données publiques communicables, a créé la notion de service public de la donnée, a donné à l’open data un fondement législatif et a posé le principe de l’ open data des décisions de justice qui s’inscrit dans une politique plus générale d’ouverture des données publiques."
168,"Rappelons que, aux termes de la loi, l’ open data des décisions de justice consiste dans la mise à la disposition du public « à titre gratuit sous forme électronique » (art."
168,"Il s’agit là d’une extension du principe de publicité des décisions de justice, consacré par l’article 6 § 1 de la Convention de sauvegarde des droits de l’ Homme et des libertés fondamentales98."
168,"Le jugement doit être re ndu publiquement, mais l’accès de la salle d’audience peut être interdit à la presse et au public pendant la totalité ou u ne partie du procès dans l’intérêt de la moralité, de l’ordre public ou de la sécurité nationale dans une société démocratique, lorsque les intérêts des mineurs ou la protection de la vie privée des parties au pr ocès l’exigent, ou dans la 42 · La diffusion des données décisionnelles et la jurisprudence public n’est possible que « sous réserve des dispositions particulières qui régissent l'accès aux décisions de justice et leur publicité » (même article)."
168,"Lors de l’adoption de la loi, les objectifs présentés pour l’ open data des décisions de justice étaient principalement de trois ordres."
168,"Enfin, accroître la transparence, la connaissance et le savoir des citoyens, donc renforcer leur confiance dans la justice et les institutions."
168,"Si la mise à disposition du public des décisions de justice s’inscrit dans une politique plus générale d’ouverture des données publiques, les décisions de justice constituent néanmoins des données particulières, en raison de leur source, à savoir les institutions juridictionnelles, et de leur objet, à savoir les droits des justiciables."
168,"C’est la raison pour laquelle une mission sur l’ open data des décisions de justice a été confiée au professeur Loïc Cadiet, professeur à l’ université Paris 1 Panthéon-Sorbonne, qui a rendu au garde des Sceaux son rapport en novembre 201799. À la suite de ce rapport, la loi n° 2019-222 du 23 mars 2019 de programmation 2018- 2022 et de réforme pour la justice a modifié l’article L."
168,"La violation de cette interdiction est une infraction délictuelle. mesure jugée strictement nécessaire par le tribunal, lorsque dans des circonstance s spéciales la publicité serait de nature à porter atteinte aux intérêts de la justice »."
168,99 Rapport intitulé « L’open data des décisions de justice.
168,Mission d’étude et de préfiguration sur l’ouverture au public des décisions de justice ».
168,"L’open data des décisions de justice est, depuis, entré dans sa phase de réalisation."
168,"Conformément à un arrêté du 28 avril 2021101 fixant le calendrier de la mise en open data des décisions de justice pour l’ordre judiciaire102, les décisions de la Cour de cassation ont été mises en ligne le 1er octobre 2021."
168,Ce mouvement va induire un changement d’échelle considérable dans la diffusion des décisions de justice.
168,"100 Ce décret prévoit notamment les modalités de la mise en open data , au nombre desquelles figurent les modalités d’occultation des décisions de justice."
168,"Il a été complété par le décret n° 2021-1276 du 30 septembre 2021 relatif aux traitements automatisés de données à caractère p ersonnel dénommés « Décisions de la justice administrative » et « Judilibre » qui autorise, notamment, le traitement, par la Cour de cassation, des décisions de l’ordre judiciaire – traitement dénommé Judilibre – traitement qui, par nature, contient des données sensibles."
168,"44 · La diffusion des données décisionnelles et la jurisprudence Section 2 - Diversification des modes de diffusion spontanée Au-delà des modes de diffusion des décisions de justice légalement prévus et encadrés par les textes législatifs et réglementaires, il existe une multitude de modes spontanés de diffusion qui participent à la connaissance des décisions de justice, à leur appropriation, voire à leur analyse : certains de ces modes voient le jour de manière interne à l’institution judiciaire ( § 1) ; d’autres sont plus larges et sont destinés au public (§ 2). § 1 - La diffusion spontanée interne à l’institution judiciaire Au sein de l’institution judiciaire coexistent plusieurs modes de diffusion spontanée des décisions judiciaires."
168,"Or, les juridictions ne sont pas dotées des moyens humains suffisants pour ce faire, si ce n’est pour un contentieux réduit et avec l’aide ponctuelle de personnel s « contractuels » qui doivent venir en soutien des magistrats (magistrat honoraire, juriste assistant, voire assistant de justice)."
168,"Les procureurs généraux près les cours d’appel organisent en effet des réunions de concertation afin d’harmoniser les pratiques, notamment en matière de circulation routière ou de justice commerciale."
168,"Si la Cour de cassation est un acteur majeur de cette diffusion externe (A), les cours d’appel prennent également part à cet effort ( B), sans exclure l’intervention d’autres acteurs, non juridictionnels, de la di ffusion des décisions de justice (C )."
168,C - Initiatives spontanées venant d’acteurs non juridictionnels La diffusion spontanée des décisions de justice à l’extérieur de l’institution judiciaire est aussi l’œuvre d’acteurs autres que les seules juridictions.
168,"De manière plus générale, la doctrine128 contribue à la diffusion des décisions de justice, notamment par le biais de commentaire dans des revues d’édition juridique129, en faisant connaître à la communauté des juristes la manière dont les juges interprètent la loi pour trancher les litiges130, étant précisé que 124 C."
168,"128 En Allemagne, la doctrine cite davantage les arrêts de la Cour fédérale de Justice, mais « elle n’hésite pas pour autant à citer des décisions des juridictions du fond, surtout d ans la production doctrinale sous forme de "" Kommentar "" très prisée en Allemagne, qui consiste (pour des universitaires, mais auss i des magistrats et des avocats) à commenter un code article par article » : v."
168,"Outre l’absence d’arrêt de la Cour fédérale de Justice sur le sujet, « la jurisprudence du fond est citée […] lorsque la décision du fond vise une hypothèse un peu différente de celle sur laquelle un arrêt de principe a été rendu par la Haute juridiction."
168,"L’auteure ajoute que « cela dépend beaucoup de la matière […] Il s’agit La diffusion des données décisionnelles et la jurisprudence · 53 ce rôle de diffusion n’est que le préalable à la valorisation de la décision de justice faite par la doctrine, dans son rôle de réception de ces décisions, qui sera analysé plus loin131."
168,"Tout aussi traditionnellement, les éditeurs juridiques diffusent aussi, auprès de leurs abonnés, les décisions de justice, tant de la Cour de cassation que des juridictions du fond, en proposant des services de différentes natures, notamment la sélection des décisions, leur analyse et leur commentaire."
168,"Plus largement, la presse généraliste et la presse spécialisée diffusent aussi certaines décisions de justice."
168,"Enfin, le panorama de la diffusion des décisions de justice ne serait pas complet si n’était évoquée leur diffusion sur les réseaux sociaux ."
168,"Ceux- ci sont bien sûr utilisés par l’institution judiciaire pour diffuser ses décisions de justice, le cas échéant accompagnées d’un communiqué132."
168,"Mais, bien souvent, la diffusion des décisions de justice échappe totalement à l’institution judiciaire, qui n’en a alors pas l’initiative."
168,"Les réseaux sociaux offrent en effet une liberté inédite d’expression et de partage, en même temps qu’ils constituent un vecteur, horizontal, de débat, auquel n’échappe pas le domaine singulier des décisions de justice. À cet égard, si les réseaux sociaux offrent, dans l’absolu, un lieu inédit et stimulant de diffusion d’informati ons ainsi qu’un espace de dialogue et d’explication des décisions de justice diffusées aux justiciables, ils peuvent aussi engendrer de mauvais usages, en particulier par la logique réductionniste qui les anime et conduit, notamment, à une contraction souvent périlleuse du temps de la réflexion. alors d’étayer la pratique des juges de la famille face à des institutions dont les co nditions d’application sont très liées à la situation factuelle »."
168,"132 Créé en 2013, le compte Twitter de la Cour de cassation a, au 31 décembre 2021, 149 986 abonnés : Rapport annuel 2021, à paraître 54 · La diffusion des données décisionnelles et la jurisprudence Chapitre 2 - La réception pragmatique et différenciée des décisions de justice Le développement de la portée jurisprudentielle des décisions de justice passe assurément par leur diffusion ; mais si cette dernière est une étape nécessaire, elle n’est pas pour autant suffisante."
168,"Seule l’utilisation faite des décisions de justice par les acteurs juridiques concrétise véritablement cette réception et permet la construction d’une véritable jurisprudence : « Produit d ’un travail d'élaboration déjà considérable, la communication constitue la première étape du processus jurisprudentiel, en mettant certains arrêts à la disposition des acteurs du “champ juridique ” (professionnels du droit ou profanes exerçant une fonction juridique ou judiciaire, comme les juges consulaires, les conseillers prud ’hommes, les défenseurs syndicaux, etc.)."
168,"Mais ces décisions ne deviendront références jurisprudentielles que si elles sont mobilisées par les intéressés dans une argumentation ou une motivation »133. À bien des égards, la réception des décisions de justice est guidée par l’approche pragmatique qu’en ont les acteurs , guidés par des considérations utilitaires."
168,C’est dire qu’il importe de s’intéresser aux différents usages des décisions de justice (Section 1).
168,"Ces usages étant identifiés, il est possible de déterminer plus finement les raisons pour lesquelles il est recouru à certaines décisions de justice plutôt qu’à d’autres, ce qu’ont contribué à faire ressortir les auditions conduites et les contributions écrites reçues par le groupe de réflexion. À travers la perception différenciée des décisions de justice par les acteurs (Section 2), il est possible d’identifier les facteurs qui peuvent contribuer à la portée jurisprudentielle d’une décision, fût -elle rendue par une juridiction du fond."
168,Section 1 - La pluralité des usages des décisions de justice Les décisions de justice peuvent être utilisées à des fins diverses.
168,"Avant même toute phase contentieuse, les décisions de justice servent à la juste appréhension du droit et de l’application de la règle de droit, comme en témoignent déjà les recueils d’arrêts dans l’ancien droit, « d’abord destinés à la formation de jeunes juristes »134."
168,"Aussi, c’est avant toute chose dans le but de connaître le droit applicable et de le comprendre que les décisions de justice sont utilisées (§ 1), pour ensuite, au stade de la décision de justice à prendre, permettre de convaincre la juridiction et de justifier la décision (§ 2)."
168,"Tout étudiant en droit en fait l’expérience dès sa première année d’étude : les décisions de justice, les arrêts de la Cour de cassation tout spécialement, permettent de connaître et de comprendre le droit ainsi que son application."
168,"D ONDERO , « Justice prédictive : la fin de l’aléa judiciaire ? », D."
168,"La consultation des décisions des juridictions du fond permet alors de s’initier à un nouveau contentieux, palliant ainsi l’absence de formations organisées en cas de changement de poste ou les carences de telles formations. § 2 - Les usages liés à la décision de justice : convaincre et justifier Le savoir acquis par la consultation des décisions de justice ne présente pas qu’un intérêt en soi : à l’évidence, ce savoir a le pl us souvent vocation à être exploité, spécialement par les praticiens."
168,"Pour le dire autrement, les décisions de justice peuvent servir à convaincre (A) et à justifier (B)."
168,"En effet, plus encore que les justiciables eux-mêmes, les avocats seront en mesure d’utiliser les décisions de justice pour convaincre le juge."
168,F ERRAND dans sa contribution écrite : « L’avocat qui plaide en première instance ou en appel n’hésitera pas à faire référen ce à la jurisprudence non seulement de la Cour fédérale de Justice ( Bundesgerichtshof ) mais également de la juridiction devant laquelle il plaide ainsi que de juridictions de même degré (ou de degré supérieur s’il plaide en première instance) ».
168,"Dans leurs mémoires, les décisions de justice, y compris les décisions rendues par la Cour de cassation, ont eu plus de difficultés à s’imposer."
168,"Si, « jusqu’à une période récente, les avocats aux Conseils ne citaient pas la jurisprudence des cours d ’appel dans les mémoires, mais uniquement celle de la Cour de cassation, du Conseil d’État, de la Cour de justice de l’Union européenne et de la Cour européenne des droits de l’homme »159, désormais, des arrêts de cour d’appel peuvent être cités, bien que cela reste marginal160 : « Les avocats peuvent souligner une tendance convergente ou divergente des cours d’appel sur la question objet du pourvoi."
168,Il en va différemment lorsque la juridiction s’emploie à justifier sa décision : l’utilisation des décisions de justice est alors généralement bien plus limitée.
168,"La cause de cette grande réserve est spécialement à trouver, selon nombre de m agistrats auditionnés, dans l’enseignement dispensé à l’École nationale de la magistrature, où le fascicule de méthodologie de rédaction du jugement civil proscrit la référence à d’autres décisions de justice, exception faite de la jurisprudence de la Cour européenne des droits de l’ Homme comme le confirme le directeur adjoint de l’École lors de son audition."
168,"Section 2 - La perception inégale des décisions de justice Toutes les décisions de justice ne sont pas également utilisées par les justiciables et les juristes, ce dont on a pu se convaincre en examinant les usages des décisions de justice : de façon générale, il apparaît nettement que si les décisions des juridictions du fond ne sont pas ignorées, elles occupent une place moins importante que les décisions de la Cour de cassation."
168,"Certes, toute décision de justice est dotée d’une certaine autorité – on parlait en droit romain de l’ auctoritas – par cela seul qu’elle est une décision de justice."
168,"C HAINAIS , « La motivation, entre dits et non-dits », Les cahiers de la justice , 2014, n° 2, p."
168,"La justesse et la légitimité de sa position hiérarchique font l’objet d ’une pleine reconnaissance de la part des individus181, à commencer par les justiciables et les acteurs de la justice."
168,"Toutefois, cette autorité, ce crédit, n’est pas partagé de manière identique par toutes les juridictions et toutes les décisions de justice."
168,"B ERNABE , « L’autorité du juge et la recherche de l ’adhésion », Les Cahiers de la Justice , 2013, n° 2, p."
168,"De cette démarche, il résulte que des facteurs tenant à la dimension institutionnelle de la justice (§ 1) ainsi que des facteurs tenant à la nature du contentieux (§ 2) et au signalement des décisions (§ 3) permettent de mesurer la portée jurisprudentielle dont sont potentiellement dotées certaines décisions rendues par des juridictions du fond."
168,"La diffusion des données décisionnelles et la jurisprudence · 65 § 1 - Les facteurs tenant à la dimension institutionnelle de la justice La justice présente une dimension institutionnelle qui joue un rôle essentiel, sans doute le premier, dans la perception que l’on peut avoir de la portée jurisprudentielle des décisions de justice. À l’évidence, l’existence d’une hiérarchie entre les juridictions est un facteur important dans la détermination de la portée jurisprudentielle d’une décision190."
168,Ce qui vaut en matière administrative191 vaut également en droit privé : « La vocation jurisprudentielle d’une décision de justice est parallèlement liée à la hiérarchie des juridictions.
168,"Ainsi, comme ceux du Conseil d’État, « ils ont institutionnellement une plus forte vocation jurisprudentielle que toutes les autres décisions de justice »193, et ce, quel que soit le nombre de ces autres décisions194."
168,"Les décisions de justice sont donc dotées d’une autorité inégale, la Cour de cassation étant, de toutes les juridictions, celle dont les décisions sont le plus susceptibles de faire jurisprudence, au regard de sa situation institutionnelle."
168,"La proportion de pourv oi est donc de moins de 10 %, chiffre similaire pour les deux années précédentes » (l’analyse se fondant sur des informations extraites des Chiffres clés de la justice 2020 )."
168,"En matière pénale, les Chiffres clés de la justice 2021 font état, en 2020, d’un total de 663 293 décisions rendues en première instance, de 94 0 57 décisions rendues en appel et de 7 397 décisions de la Cour de cassation."
168,"La diffusion des données décisionnelles et la jurisprudence · 71 § 3 - Les facteurs tenant au signalement des décisions Enfin, venant s’ajouter aux précédents facteurs, il se peut que des décisions de justice gagnent en autorité pour la simple raison qu’elles font l’objet d’un signalement à l’attention du public, ce signalement venant essentiellement de la communauté des juristes, qui participe ainsi du processus jurisprudentiel, comme Évelyne Serverin a pu le montrer dans sa thèse de doctorat238."
168,"La diffusion des données décisionnelles et la jurisprudence · 73 Mais il se rencontre également à une moindre échelle pour tout type de décision de justice commenté par la doctrine, qui peut conduire à conférer sinon une autorité, du moins un certain rayonnement, à telle ou telle décision, en droit privé comme en droit public248, dans un pays de droit civil comme la France ou dans des pays de Common Law249. À cet égard, il existe, là encore, une disparité entre les décisions de la Cour de cassation et les décisions des juridictions du fond."
168,"En définitive, de l’examen de la réception des décisions de justice, à travers leurs usages et leur perception, il ressort que les décisions de justice dans leur ensemble sont reçues de manière inégale."
168,"En conclusion, si l’on prend soin de mettre en rapport la réception inégale des décisions de justice avec leur diffusion croissante et protéiforme, il est permis de développer une approche plus fine de la situation actuelle et, par extension, saisir avec plus de précision ce que pourrait changer, à l’avenir, l’ open data des décisions de justice."
168,"D’un côté, il serait excessif de considérer qu’aujourd’hui l’essentiel des décisions importantes est difficilement accessible, tant il est vrai que l’on a assisté à un essor aussi remarquable que protéiforme des voies de diffusion des décisions de justice."
168,"La diffusion des données décisionnelles et la jurisprudence · 75 PARTIE II PERSPECTIVES La mise en œuvre de l’ open data des décisions de justice ouvre des perspectives stimulantes, sinon vertigineuses, quant aux évolutions qui pourraient affecter la jurisprudence en conséquence."
168,Or les perspectives ouvertes par l’ open data des décisions de justice au regard de la jurisprudence présentent assurément ces deux aspects.
168,"76 · La diffusion des données décisionnelles et la jurisprudence Chapitre 1 - Prévenir les risques liés à l’ open data des décisions de justice Comme toute évolution rendue possible par de nouvelles technologies, l’ open data des décisions de justice, en permettant aux citoyens et à l’ensemble des acteurs juridiques d’accéder à la connaissance de l’ensemble des données judiciaires, engendre potentiellement deux grands types de risques."
168,Le premier risque identifiable est celui d’un nivellement des décisions de justice.
168,"Or toutes les décisions de justice ne se valent pas : il n’est pas possible d’aborder indifféremment le jugement d’un tribunal judiciaire et un arrêt de la Cour de cassation, ou encore, un arrêt d’espèce et un arrêt de principe."
168,Le risque d’une indifférenciation des décisions de justice rend ainsi absolument nécessaire un travail de hiérarchisation des décisions de justice afin d’éviter que les décisions qui ont un intérêt pour l’évolution du droit soient « noyées » dans la masse des décisions de justice diffusées257 (Section 1).
168,"Un second grand type de risque tient à l’appauvrissement de la créativité juridique dans la mesure où le traitement algorithmique des décisions de justice, en faisant apparaître récurrences et régularités dans la m anière de juger, peut, sous couvert d’une harmonisation certes louable en son principe, favoriser l’avènement de tendances conformistes dans l’application des règles de droit."
168,"Section 1 - Éviter l’indifférenciation des décisions de justice Si la jurisprudence émerge du contentieux, elle ne se confond pas avec lui."
168,L’open data des décisions de justice impose de distinguer « l’important de l’insign ifiant »261.
168,"Pour ce faire, la prise en compte de l’ open data nécessite d’assurer une organisation plus rationnelle de la diffusion des décisions de justice (§ 1)."
168,"L’ open data impose dès lors l’élaboration d’une telle classification, voire une hiérarchisation des décisions de justice (§ 2)."
168,"Cette invocation de plus en plus fréquente pourrait notamment avoir pour conséquence de brouiller la visibilité des lignes jurisprudentielles, raison pour laquelle il serait utile de l’encadrer (§ 3). § 1 - Assurer une organisation plus rationnelle de la diffusion des décisions de justice 258 I."
168,"SAYN, in Loïc C ADIET , L’op en data des décisions de justice , Rapport à Madame la Garde des sceaux, ministre de la Justice, novembre 2017, p."
168,"COTTIN , « Jurisprudence et contentieux, une (r)évolution à attendre », in Justice et numériq ue : Quelles (r)évolutions ?"
168,"S AUVE , « Introduction », in La Justice prédictive , Dalloz , 2018, p."
168,C’est dire qu’il est nécessaire d’améliorer la cohérence du système de diffusion des décisions de justice en France.
168,"111 -10 COJ vise « la mise à la disposition du public, sous forme électronique, d es décisions de justice rendues par les juridictions judiciaires »."
168,Le groupe de réflexion considère qu’une meilleure organisation du système de diffus ion des décisions de justice simplifiera et améliorera l’accès à la connaissance du droit. § 2 – Œuvrer à une hiérarchisation des décisions rendues par des juridictions du fond 266 V.
168,RECOMMANDATION n°1 Assurer une organisation plus lisible et plus rationnelle du système de diffusion des décisions de justice en France.
168,"Là encore, l’ open data des décisions de justice pourrait rendre plus visible encore ce phénomène, mais l’augmentation de la masse de décisions de justice à traiter induite par l’ouverture des données décisionnelles va accroître la tâche des juristes cherchant à exploiter rigoureusement les décisions des juridictions du fond. À cet égard, le risque est que le s professionnels du droit soient dépassés par la masse de données disponibles et rencontrent des difficultés à faire le départ entre les décisions importantes et celles qui ne le sont pas."
168,"Dès lors, afin d’éviter l’indifférenciation générale des décisions de justice, le groupe de réflexion est d’avis qu’il est nécessaire de favoriser la mise en œuvre d’une certaine hiérarchisation des décisions des juridictions du fond mises à la disposition du public à la faveur de l’ open data afin de les mettre en valeur sur les bases de données juridiques."
168,"Il en va ainsi des décisions de transmission d’une question prioritaire de constitutionnalité et des décisions faisant renvoi préjudiciel à la Cour de justice de l’Union européenne, qui devront être particulièrement signalées."
168,"En effet, l’accès au pourvoi étant conditionné par certains critères, lesquels ont été « étendus à l’accès à l’appel pour les tout petits litiges, on constate que la jurisprudence des juridictions d’appel a été valo risée officiellement c omme susceptible d’unifier le droit localement et de le d évelopper, comme dans le cas de vases communicants : la Cour fédérale de Justice étant moins accessible et rendant moins d’arrêts, la jurispr udence d’appel en est valorisée, mais s’incline toujours d evant le dernier mot de la Cour fédérale de Justice » : F."
168,"En tout état de cause, le signalement par les juridictions n’est évidemment pas exclusif du travail de la doctrine qui, de son côté, continuera de signaler les décisions de justice qui méritent intérêt, les raisons qui expliquent cet intérêt et les liens de corrélation susceptibles d’exister entre les différentes décisions de justice, avec l’aide possible d’outils élaborés à partir des algorithme s."
168,"L’intérêt du signalement des décisions présentant un intérêt juridique particulier ne doit pas occulter le fait que l’importance d’une décision de justice se mesure souvent en faisant un rapprochement entre les positions des différentes juridictions, ce qui n’est pas indifférent, tant s’en faut, lorsqu’on prend en considération la jurisprudence des juges du fond ; une telle analyse relève d’un travail principalement doctrinal."
168,"86 · La diffusion des données décisionnelles et la jurisprudence RECOMMANDATION n°4 Les décisions des juridictions du fond présentant un intérêt juridique particul ier et qui peuvent être adressées pour mise en valeur sur l’interface de programmation d’application Judilibre sont notamment celles qui répondent à l’un des critères suivants, ces critères étant susceptibles de se combiner, ce qui est de nature à renforcer l’intérêt de la décision : Est considérée comme présentant toujours un intérêt juridique particulier (en raison d’un critère formel décelable prima facie) : - une décision opérant un renvoi préjudiciel à la Cour de justice de l’Union européenne ; - une décision de transmission d’une question prioritaire de constitutionnalité ; - une décision conduisant à la saisine du Tribunal des conflits au fin de règlement d’un conflit d’attribution entre les deux ordres de juridiction ; Peut être identifiée comme présentant un intérêt juridique particulier (critère substantiel, nécessitant une analyse plus fine de la décision, dans son environnement juridique) : - une décision qui procède à un contrôle de conventionalité au regard de la Convention de sauvegarde des droits de l’ Homme et des libertés fondamentales ; - une décision qui tranche une question de droit sur laquelle la Cour de cassatio n ne s’est pas prononcée (texte nouveau, problème nouveau d’articulation de plusieurs textes) ; - une décision qui statue sur une question inédite ou qui adopte une qualification ou une interprétation nouvelle, spécialement lorsqu’elle est rendue dans un domaine relevant de l’appréciation souveraine des juges du fond ou si elle n’est pas susceptible de pourvoi en cassation ; - une décision qui marque une inflexion de la position antérieure de la juridiction ; - une décision portant sur une question qui donne lieu à un débat jurisprudentiel ou doctrinal bien identifié ; - une décision ayant une importance sociétale ; - une décision rendue dans le cadre d’un contentieux rare ou d’un contentieux émergent, spécialement lorsqu’elle est susceptible de concerner un grand nombre de juridictions."
168,"Afin que ces informations soient correctement reçues, il sera sans doute nécessaire à terme de penser à nouveaux frais la présentation des décisions de justice et de tendre vers une rédaction plus harmonisée afin, à la fois, d’en faciliter la compréhension et, aussi, de permettre leur exploitation algorithmique nécessaire à l’identification des solutions pouvant « faire jurisprudence »286."
168,"Ces informations siégeant dans la motivation des décisions de justice sont diverses : outre les règle s de droit appliquées, les lecteurs de ces décisions prendront connaissance de manières de résoudre un cas, des données propres à différentes espèce s, d’argumentations des plaideurs restituées complètement, en fait autant qu’en droit, et , bien sûr, des raisonnements suivis par les juges."
168,286 Une réflexion sur la rédaction des décisions de justice est en cours au sein d’u n autre groupe de travail.
168,"Il faut la distinguer de la formule « jurisprudence des juges d u fond », laquelle met en avant l’idée que les juges du fond « délivrent également une interprétation du droit : ici, et pour correspondre à l’objet exploité par l’outil justice prédictive, seules intéressent leurs appréciations au fond et plus précisément celles qui mènent à des évaluations chiffrées."
168,Le Lord Chief Justice a publié un “Practice Direction ” qui explique quels arrêts précédents peuvent être cités dans les plaidoiries.
168,"292 Ce mode opératoire proposé par le groupe de réflexion, qui induit des évolutions dans les modalités de diffusion des décisions de justice, a déjà un précédent comme cela pu être évoqué auparavant."
168,"Les décisions de justice mises à disposition du public dans le cadre de l’ open data sont déjà, et seront plus encore à l’avenir, mobilisées afin, notamment, d’identifier des formes de récurrences dans les solutions."
168,"RECOMMANDATION n°8 Modifier l’article 5.5 du règlement intérieur de la profession d’avocat de la manière suivante : « La communication [entre avocats des pièces] se fait dans les conditions suivantes : les décisions de justice non diffusées en open data sont versées aux débats ; pour la doctrine et les décisions de justice diffusées en open data , les références complètes sont communiquées à l’autre avocat ou accessibles par lien hypertexte, si les écritures sont accessibles numériquement »."
168,"92 · La diffusion des données décisionnelles et la jurisprudence performatif293 de ce qui est parfois qualifié, à tort, de « justice prédictive », mais aussi de « jurimétrie »294 est souvent rangé parmi les possibles dérives de l’intelligence artificielle appliquée au domaine de la justice."
168,Justice dite « prédictive ».
168,"Pour mémoire, la notion de justice prédictive ou l’idée de prédire la justice vient des praticiens du droit américain, qui évoluent dans un système juridique où les décisions de justice, qui sont la principale source de droit, sont particulièrement imprévisibles et où, par conséquent, existe un fort besoin de prévision."
168,"Or la justice prédictive n’est pas une justice puisqu’il ne s’agit pas de trancher ; elle n’est pas davantage prédictive, puisqu’il ne s’agit en rie n de « prévoir » l’avenir, mais simplement de prendre en compte des données statistiques passées295."
168,"Cette idée a été reprise par des informaticiens du droit qui utilisent « l’intelligence artificielle » - ou, pour retenir la terminologie plus neutre et objective de la Commission nationale consultative des droits de l’ Homme (CNCDH), les « systèmes algorithmiques d’aide à la décision » (SAAD)298 - pour exploiter les décisions de justice massivement diffusées en ligne."
168,Son utilisation dans le domaine du droit - avec l’usage de logiciels capables de lire un écrit et d’en communiquer le sens qui n’en sont eux -mêmes qu’à leurs débuts - est le moyen de relever le défi que représente l’exploitation d’une quantité inédite de décisions de justice.
168,"Enfin, la lutte contre le risque d’un conformisme juridique impo se d’adapter la formation des étudiants, mais également des praticiens du droit, et de développer l’accès aux outils algorithmiques d’analyse des décisions de justice (§ 3). § 1 - Élaborer un cadre normatif pour réguler les outils dits d’intelligence artificielle dont les résultats ont une incidence sur la fabrique de la jurisprudence Rappels liminaires sur la notion d’intelligence artificielle."
168,"T EIXEIRA - « Predictive Justice and Lawyer Decision », intervention lors du séminaire consacré à la jurimétrie organisé le 9 mai 2022 par le Centre de recherche en droit Antoin e Favre de l’université Savoie Mont-Blanc - indiquait ainsi que l’o bjectif de la jurimétrie est de comprendre les décisions rendues dans le passé afin de fournir de l’information, objective, sur ce qui peut se pas ser à l’avenir, pour une meilleure appréhension du procès."
168,Coexistence de plusieurs niveaux d’exploitation des décisions de justice massivement diffusées en ligne.
168,"L’exploitation des décisions de justice, mises à la disposition du public dans le cadr e de l’ open data , par les systèmes algorithmiques, peut se faire à plusieurs niveaux."
168,"En effet, d’après les recherches du Conseil de l’Europe, le risque principal lié à l’utilisation de l’intelligence artificielle en matière d’ open data des décisions de justice réside dans les risques qu’elle fait peser sur les droits fondamentaux304, à savoir au premier chef le droit à un procès équitable au sens le plus large (garantie du droit d’accès au juge, égalité des armes, respect du contradictoire, etc.), mais également la protection des données à caractère personnel, le respect de la vie privée et la non-discrimination."
168,"De même, la CNCDH, dans l’avis précité, a également mis en avant la justice prédictive au titre des utilisations de l’ intelligence artificielle qui sont particulièrement préoccupantes pour le respect des droits de l’ Homme."
168,"La question de l’opportunité et de la nature du contrôle de la ré utilisation des données de justice, plus large que le simple contrôle du système algorithmique, a fait l’objet de nombreux travaux306, dont une réflexion dans le cadre d’un groupe de travail 303 Lors du séminaire précité consacré à la jurimétrie, J."
168,"306 Dont, pour ne citer qu’eux : la charte éthique européenne d’utilisation de l’intelligence artificielle dans les systèmes judiciaires et leur environnement adoptée lors de la 31ème réunion plénière de la Commission 96 · La diffusion des données décisionnelles et la jurisprudence copiloté par le ministère de la Justice, le Conseil d’État et la Co ur de cassation, qui a achevé ses travaux en décembre 2021 et dont le rapport, auquel le groupe de réflexion renvoie, est à paraître."
168,"4 e t 5 CPC) , l’influence de ces outils sur les décisions de justice peut s’avérer déterminante307."
168,"En développant une culture excessive du « précédent », étrangère à la tradition juridique française, ces outils d’analyse des décisions de justice, développés par les entreprises privées de la LegalTech , sont susceptibles, indirectement, d’appauvrir les débats judiciaires et d’altérer les capacités d’interprétation des magistrats, aboutissant ainsi à une factualisation du droit et une stérilisation de la jurisprudence."
168,"La diffusion des données décisionnelles et la jurisprudence · 97 Commission européenne, ne définit qu’une seule application de l’ intelligence artificielle appliquée à la justice, dans l’article 8 de son annexe III visant « les systèmes d’IA destinés à aider les autorités judiciaires à rechercher et à interpréter les faits et la loi, et à appliquer la loi à un ensemble concret de faits »."
168,"Le groupe de réflexion considère que l’élaboration de ce cadre normatif serait de nature à anticiper et prévenir deux dérives opposées, à savoir, d’un côté, celle d’une opaci té croissante de ces outils, utilisés dans le cadre judiciaire, et, d’un autre côté, la multiplication potentielle de débats extrêmement techniques, potentiellement dilatoires, de nature à détourner du contentieux principal soumis au juge, pouvant aller ju squ’à la nécessité de désigner un expert pour trancher le débat sur les algorithmes sous-jacents aux analyses produites ou sous-jacents au choix des décisions de justice communiquées, suscitant ainsi un procès dans le procès."
168,"98 · La diffusion des données décisionnelles et la jurisprudence § 2 - Conférer une place , dans la motivation des décisions de justice, à la citation des décisions antérieures Risque d’une mutation du rapport traditionnel des juges aux décisions antérieures."
168,"Sous l'Ancien Régime, les décisions de justice n’étaient pas motivées »315."
168,"On ne reviendra pas ici sur l’ensemble des conditions que doit remplir la motivation d’une décision de justice, qui sont bien connues."
168,"Eu égard à l’objet du présent rapport, on s’attardera ici sur la condition en vertu de laquelle la motivation doit être intrinsèque à la décision de justice."
168,"Le principe est, pour toute décision de justice que le juge a l ’obligation de motiver, que cette motivation doit se suffire à elle- même."
168,"Cette place de la décision de justice , en France, dans la fabrique et la formalisation d’une autre décision de justice s’écarte radicalement de ce qui s’observe en Common Law ."
168,Le premier renvoie au fait que « les décisions de justice sont une source d’influence dans le raisonnement juridique […].
168,"Le « precedent » peut être non contraignant (« persuasive precedent »), mais « le juge doit prendre en compte certaines décisions de justice pour motiver sa décision de manière acceptable."
168,"Là encore, la sécurité juridique et la volonté de maintenir « un ordre hiérarchique au sein du système des tribunaux »332, justifient cette pratique, qui implique une fréquente citation des décisions de justice entre elles."
168,"GAUTIER , « Contre le visa des précédents dans les décisions de justice », D."
168,"Cette solution est d’ailleurs celle qui a été adoptée par la Cour fédérale de Justice en Allemagne qui, comme l’indique la professeure Frédérique Ferrand dans sa contribution écrite, fait « régulièrement référence, dans ses motifs, à des décisions émanant des juridictions du fond."
168,"D’une certaine façon, la Cour fédérale de Justice, en montrant sa connaissance des décisions du fond, entend situer sa propre jurisprudence dans ce terreau de fait et en renforcer ainsi l’accepta bilité »345."
168,"Enfin, le groupe de réflexion est d’avis que favoriser la contradiction entre les parties est l’une des manières de lutter contre le risque que représente l’avènement d’une forme de conformisme jurisprudentiel en lien avec l’ open data : chacun faisant valoir ses décisions et contestant la portée de celles qu’invoque son adversaire, le juge est d’emblée conduit à apprécier avec un œil critique la matière rendue disponible par l’ open data des décisions de justice, telle que traitée par d’éventuels algorithmes."
168,"Ainsi, le choix d’un circuit simplifié pour un pourvoi en cassation pourra notamment se fonder sur l’existence de décisions antérieurement rendues. les situations de fait auxquelles elles sont confrontées ainsi que leurs prises de p osition et dire in fine quelle solution ou interprétation la Cour fédérale de Justice entend retenir »."
168,"106 · La diffusion des données décisionnelles et la jurisprudence § 3 - Pallier le risque d’un conformisme jurisprudentiel par la formation des acteurs Le groupe de réflexion est convaincu de l’importance d’adapter la formation et de favoriser le développement de l’accès aux outils algorithmiques d’analyse des décisions de justice, que l’on songe à la formation initiale des étudiants ou à la formation continue des praticiens du droit."
168,"Cela se comprend assez bien pour ce qui concerne la formation au maniement des services algorithmiques permettant le traitement des décisions de justice, notamment celles des juridictions du fond, car ces outils sont encore peu développés."
168,"Conjointement, le groupe de réflexion recommande la formation des étudiants aux services algorithmiques permettant le traitement des décisions de justice."
168,"D EUMIER , Contribution au rapport L’open data des décisions de justice , op. cit., p."
168,"En troisième lieu, l’esprit critique des étudiants devra être exercé à l’égard des services algorithmiques permettant le traitement des décisions de justice."
168,"Tout d’abord, un effort de formation continue doit être fait à l’égard des acteurs , en démocratisant l’accès aux services algorithmiques de traitement des décisions de justice."
168,Démocratiser l’accès des praticiens aux services algorithmiques de traitement des décisions de justice.
168,"Ajouter aux ressources auxquelles ont accès les étudiants, l ’accès à des services algorithmiques de traitement des décisions de justice."
168,"De la sorte, une certaine éga lité entre les acteurs du procès serait mieux assurée, évitant ainsi la trop grande disparité que peuvent connaître certains pays dans l’exploitation des décisions de justice357. À cette fin, des abonnements pourraient opportunément être souscrits au niveau national, négociés par le ministère de la Justice et bénéficier à l’ensemble des juridictions."
168,RECOMMANDATION n°13 Mettre en place une mutualisation des moyens à l’échelle des barreaux afin d’offrir à l’ensemble des avocats un accès à des services algorithmiques de traitement des décisions de justice.
168,"En raison du nombre important d’écoles de formation des avocats dispersées sur l’ensemble du territoire, cette formation pourrait notamment avoir lieu au moment du stage juridictionnel des auditeurs de justice, en lien avec les écoles locales d’avocats ."
168,"Enfin, la formation des praticiens du droit ne peut uniquement porter sur l’usage des outils algorithmiques d’analyse des décisions ; elle doit aussi être relative aux conséquences de l’ open data des décisions de justice sur les pratiques professionnelles et, notamment, sur la place des décisions des juridictions du fond dans l’ordonnancement juridique, sur leur utilisation dans l’instance judiciaire et sur les modalités de rédaction des écritures des parties et des décisions de justice. À cet égard, il peut être noté que, jusqu’à présent, les recommandations méthodologiques délivrées par l’École nationale de la magistrature et relatives à la rédaction des jugements et des arrêts prohibait la citation expresse d’une décision de justice et la mention de sa référence."
168,"Il apparaît ainsi que les enjeux induits par l’open data des décisions de justice au regard de la notion de jurisprudence et des pratiques des acteurs de la justice sont vastes, divers et sont appelés à s’amplifier dans les prochaines années, l’ open data n’en étant encore qu’à ses débuts."
168,"Pour ces raisons, le groupe de réflexion est d’avis qu’il est nécessaire de créer une instance de concertation nationale, sous l’autorité de la Cour de cassation, qui aura notamment pour mission : - de centraliser les informations, en particulier les difficultés et les retours d’expérience sur la mise en œuvre de la diffusion des décisions de justice ; - d’être un organe de réflexion, d’échanges et de recommandations sur les pratiques, les méthodes de travail et les outils mis en œuvre dans le cadre de l’ open data ; - de nouer des partenariats aux niveaux européen et international, et de coordonner les actions pour mettre en application ces réflexions et ces recommandations."
168,"Ce conseil, qui pourra être dénommé « Conseil des données judiciaires ouvertes » (CDJO) , aura toute son utilité car l’ open data des décisions de justice est, par nature, une question transversale, qui mobilise des acteurs différents et requiert des réflexions et des actions à plusieurs niveaux et dans plusieurs disciplines. À titre d’exemple, le Conseil des données judiciaires ouve rtes pourra opportunément être l’interlocuteur privilégié des universités et des écoles de formation des praticiens pour la mise en œuvre des recommandations énoncées plus haut358."
168,"RECOMMANDATION n° 15 Renforcer la formation, initiale et continue, des magistrats et des avocats sur la place d’une décision de justice dans l’ordonnancement juridique, sur son utilisation dans l’instance judiciaire et sur la rédaction des écritures des parties et des décisions de justice à cet égard."
168,"La diffusion des données décisionnelles et la jurisprudence · 113 Son secrétariat général pourrait être assuré par le Service de documentation, des études et du Rapport (SDER) de la Cour de cassation, qui pilote, pour la Cour de cassation, la mise en œuvre de l’ open data des décisions de justice."
168,"Donner mission à ce Conseil : - de centraliser les informations et, notamment, les difficultés relatives à la mise en œuvre de la diffusion des décisions de justice ; - d’être un organe de réflexion, d’échanges et de recommandations sur les pratiques, méthodes de travail et outils mis en œuvre dans le cadre de l’ open data des décisions de justice ; - de nouer et développer des partenariats aux niveaux européen et international ; - de coordonner les actions d’application des réflexions et recommandations issues des travaux du Conseil."
168,"114 · La diffusion des données décisionnelles et la jurisprudence Chapitre 2 - Mettre à profit les opportunités offertes par l’open data des décisions de justice Comme toute évolution rendue possible par les nouvelles technologies, l’ open data des décisions de justice ouvre des perspectives qu’on ne saurait appréhender sous le seul prisme d’événements potentiellement néfastes dont on redo uterait la survenue et qu’il s’agirait essentiellement de prévenir."
168,"En particulier, il est apparu au groupe de réflexion que la diffusion massive des décisions de justice devrait être l’occasion d’ améliorer le processus de construction de la jurisprudence359."
168,"Parce que l’ open data donne effectivement à voir l’intégralité des d écisions rendues publiquement, l’ensemble des juridictions , à commencer par la Cour de cassation, qui ne connaît aujourd’hui que d’un nombre limité de décisions de justice , pourrait venir y puiser des enseignements au service d’une finalité double, à savoir atténuer le mal que peut constituer l’insécurité juridique suscitée par des décisions rendues en sens contraire sur des questions identiques et, dans le même temps, accroître la qualité des décisions rendues en les nourrissant de l’expérience des juridictions du fond."
168,"Mais d’un autr e côté, la jurisprudence est un droit vivant, dans lequel divergences et les revirements occupent une place importante, ce qui peut sembler contradictoires avec l’impératif de sécurité juridique364. À ces considérations classiques, sur lesquelles on ne s’attardera pas ici, l’ open data des décisions de justice ajoute des dimensions nouvelles en faisant apparaître au grand jour des zones du droit et de la jurisprudence dans lesquelles la sécurité juridique paraît mise à mal."
168,"D EUMIER , Contribution au rapport L’open data des décisions de justice , op. cit., p.191 : « Du point de vue de l’interprétation de la loi, l’égalité devant le droit induit une exig ence d’uniformité de son interprétation par tous les juges : à défaut, les règles de droit ne seraient pas les m êmes selon que l’on est jugé à Lyon ou à Toulouse »."
168,"Au demeurant, sur le plan historique, l’augmentation de la diffusion des décisions de justice dans les recueils de jurisprudence a contribué à l’avènement de la fonction unificatrice de la Cour de cassation."
168,"A - Identification de l’opportunité : vers une meilleure connaissance du phénomène jurisprudentiel L’open data des décisions de justice devrait permettre de documenter de manière exhaustive un phénomène qui ne l’est que partiellement aujourd’hui, à savoir la divergence d’interprétation d’une même rè gle de droit par plusieurs juridictions."
168,"S ERVERIN , « De l’informatique juridique aux services de justice prédictive, la longue route de l’ac cès du public aux décisions de justice dématérialisées », op. cit., p."
168,"D’autre part, l’ open data des décisions de justice pourrait conduire à révéler des oppositions, voire des contradictions, entre les décisions prises par des juridictions du fond, au sujet de questions non tranchées par la Cour de cassation."
168,"D UBUS , contribution écrite : l’auteur souligne que l’ open data des décisions de justice conduirait à envisager différemment le rôle jurisprudentiel du Conseil d’État, s on rôle étant « désormais d’identifier, au sein de cette nébuleuse d’innovations naturell ement contradictoires, la règle qui lui semble la plus pertinente."
168,"D EUMIER , Contribution au rapport L’open data des décisions de justice , op. cit., p.190 : « Si les machines révélaient un taux significatif de non-application de la jurispruden ce de la Cour de cassation, hors de toute volonté motivée de faire évoluer celle-ci, il faudra sérieusement réin terroger les ressorts sur lesquels repose l’autorité de la jurisprudence dans notre système »."
168,RECOMMANDATION n°18 Permettre le signalement des divergences entre décisions de justice par une application accessible sur le site de la Cour de cassation aux utilisat eurs inscrits.
168,"Code de justice administrative , Dalloz, 2022, comm. sous l’article L.113 -1 : « De fait, avec, au 1er avril 2013, plus de 300 avis rendus depuis l ’entrée en vigueur – le 1er janvier 1989 – de cette procédure créée par l'article 12 de la loi du 31 décembre 1987, le mécanisme a été utilisé dan s des proportions conformes aux attentes »."
168,L’open data des décisions de justice et l’exigence renforcée de sécurité juridique qui pourrait en résulter conduisent à envisager cette question à nouveaux frais.
168,"La diffusion des données décisionnelles et la jurisprudence · 125 3°) Bénéficier d’une procédure d’arrêt pilote Parmi les divergences d’interprétation que permettrait d’identifier plus facilement l’open data , certaines pourront concerner des litiges sériels, c’est -à-dire des litiges susceptibles de donner lieu à de nombreuses actions en justice similaires."
168,Un traitement plus systématique de ces divergences pourrait être mis en œuvre à des fins de bonne administration de la justice.
168,"L’article 620 du code de procédure pénale prévoit : « Lorsque, sur l ’ordre formel à lui donné par le ministre de la Justice, le procureur général près la Cour de cassation dénonce à la chambre criminelle des actes judiciaires, arrêts ou jugements contraires à la loi, ces actes, arrêts ou jugements peuvent être annulés »."
168,"Toutefois, là encore, cet instrument est peu utilisé411, constat qui a d’ailleurs pu justifier en partie la 407 La matière administrative connaît du recours dans l'intérêt de la loi, dont l’orig ine est à trouver dans la jurisprudence du Conseil d’État et qui concerne les actes administratifs comme les décisions de justice ; v. par ex."
168,L’open data des décisions de justice pourrait conduire à infléchir ces tendances.
168,"En permettant d’accéder très largement aux décisions de justice et en mettant les magistrats en situation de prendre connaissance des pratiques jurisprudentielles des autres juridictions et, partant, d’y comparer leur propre pratique, l’ open data des décisions de justice devrait de facto tendre à ce que les juges soient plus naturellement amenés à identifier des divergences et à les interroger le cas échéant, conduisant ainsi à un plus grand souci d’harmonisation420."
168,"L OUVEL , « Comment sauver le soldat Justice ? », interview par L."
168,"En permettant aux juges de comparer leur pratique jurid ictionnelle par rapport à une moyenne statistique, de connaître les tendances jurisprudentielles de leurs collèg ues, la “justice prédictive ” favorisera la mise en cohérence de l ’activité juridictionnelle des différentes juridictions du fond et l’harmonisation des jurisprudences, et ainsi contribuera à améliorer la prévisibilité d e la justice et la sécurité juridique »."
168,"1°) Simplifier la recherche des décisions antérieures Dans l’attente de l’accomplissement de l’ open data des décisions de justice et de la création d’outils algorithmiques permettant d’identifier précisément et rapidement les décisions des juges du fond ayant préalablement statué sur une question de droit donnée, des moyens devront être mis à la disposition des juridictions pour connaître ces décisions."
168,"Elle gagnerait à être utilisée, plus qu’elle ne l’est aujourd’hui, à des fins de connaissance des contentieux , en lien avec l’ Observatoire des litiges judiciaires et les services statistiques du ministère de la Justice et en cohérence avec les travaux actuellement conduits à la Cour de cassation sur la nomenclature des affaires orientées (NAO)428."
168,"A MRANI -MEKKI , « Le point de vue d’une universitaire », in La justice prédictive , Actes du colloque du 12 février 2018, Dalloz, 2018, p."
168,"Dans cette perspective, elle pourrait utilement trouver sa place dans les outils et fiches méthodologiques de rédaction du jugement civil, élaborés à l’initiative de la Cour de cassation et par l’ENM, destinées à aider les juges dans la rédaction des décisions de justice, ou encore sous la forme d’une recommandation, au sein des protocoles de procédure, existants ou à venir, entre les barreaux et les juridictions."
168,"B UAT-MENARD , « La justice dite “prédictive ” : prérequis, risques et attentes."
168,"L’expérience française », Les cahiers de la justice 2019, p."
168,"138 · La diffusion des données décisionnelles et la jurisprudence À cet égard, l’ open data des décisions de justice pourrait ouvrir des perspectives nouvelles dès lors qu’il deviendra plus facilement possible, à hauteur de cassation, de prendre en compte les décisions des juridictions du fond qui seraient de nature à servir le développement du droit."
168,"En somme, en un processus de création continue, l’ open data des décisions de justice pourrait concrétiser la métaphore du « roman écrit à la chaîne » de Dworkin, considérant notamment que chaque juge participe de l’écriture du droit en ayant à cœur de conserver sa cohérence, tout en assurant son développement : le juge de cassation pouvant désormais mieux lire ce roman dont les pages écrites avant lui par les juges du fond étaient auparavant souvent manquantes, il serait susceptible de s’en inspirer davantage445."
168,"445 Ibidem : « Le flux des décisions de justice a une cohérence et un sens que les j uges découvrent un peu plus à chaque sentence, comme les écrivains d ’un même roman astreints à une cohérence narrative."
168,"La diffusion des données décisionnelles et la jurisprudence · 139 § 2 - Exploitation de l’op portunité Afin que les ressources offertes par l’ open data des décisions de justice puissent servir pleinement le développement du droit, deux leviers méritent d’être actionnés : il est nécessaire que les décisions des juridictions du fond soient davantage recherchées et analysées devant la Cour de cassation (A ) et qu’elles puissent y être mieux prises en compte lors de la rédaction de l’arrêt ( B)."
168,"J EULAND , « Justice prédictive : de la factualisation au droit potentiel », Revue pratique de la prospective et de l'innovation , oct."
168,Mais cette analyse ponctuelle ne saurait suffire à tirer tout le bénéfice possib le de l’ open data des décisions de justice.
168,"C ROZE , contribution au rapport L’open data des décisions de justice , op. cit., p."
168,2°) Favoriser l’essor de recherches collectives portant su r les décisions des juridictions du fond Le groupe de réflexion recommande en outre de favoriser l’essor de recherches collectives permettant l’exploitation des ressources offertes par l’ open data des décisions de justice.
168,"Les laboratoires universitaires ont bien sûr naturellement vocation à être le lieu de telles recherches, le cas échéant en lien avec d’autres structures propices à l’accueil, à la coordination ou au financement de tels travaux, à commencer par l’Institut des études et de la recherche sur le droit et la justice récemment créé, qui prend la suite de l’Institut des hautes études sur la justice et de la Mission de recherche Droit et justice , dont on sait le rôle majeur qu’ils ont joué, depuis plus de vingt ans, dans la structur ation des recherches collectives pluridisciplinaires sur le droit et la justice471."
168,"Mission de recherche Droit et Justice, États généraux de la recherche sur le droit et la justice, Paris, LexisNexis, 2018."
168,La diffusion des données décisionnelles et la jurisprudence · 147 Le groupe de réflexion est enfin d’avis d’encourager et de mettre en valeur les recherches exploitant les ressources offertes par l’ open data des décisions de justice.
168,Le groupe de réflexion est d’avis que le ministère de l’ Enseignement supérieur devrait prendre toute sa part à cet effort en développant une politique proactive de financements supplémentaires des thèses afin de favoriser les recherch es d’ampleur prenant pour objet l’ open data des décisions de justice ou explorant de manière systématique les données juridiques ouvertes relatives au thème abordé.
168,"D EUMIER , Contribution au rapport L’open data des décisions de justice , op. cit., p.192, soulignant que le résultat des recherches sur la justice du fond « reste malheureusement peu relayé par les autres écrits doctrinaux »."
168,"D - Développer les échanges au sein de la communauté juridique Pris isolément, les travaux des avocats, des juridictions et de l’université, tout en ayant une valeur propre, ne suffiront sans doute pas à exploiter pleinement le matériau très riche offert par l’ open data des décisions de justice pour contribuer au développement du droit."
168,RECOMMANDATION n° 31 Développer les espaces de publication pouvant accueillir des travaux universitaires exploitant les ressources offertes par l’ open data des décisions de justice.
168,"Favoriser l’essor de recherches collectives, y compris pluridiscipli naires, mettant en œuvre l’exploitation des ressources offertes par l’ open data des décisions de justice."
168,Promouvoir dans les instances universitaires – notamment au sein du Conseil national des universités – une réflexion sur la valorisation des travaux universitaires et de recherche exploitant les ressources offertes par l ’open data des décisions de justice.
168,"L’open data des décisions de justice, assorti des propositions qui ont déjà pu être formulées dans le présent rapport, invite à recommander l’institutionnali sation de ce type de partenariat, que certains magistrats ont au demeurant appelé de leurs vœux lors de leur audition par le groupe de réflexion."
168,"RECOMMANDATION n° 32 Promouvoir la conclusion de partenariats entre les universités et les juri dictions afin de mieux traiter les ressources offertes par l’ open data des décisions de justice et, spécialement, les décisions signalées."
168,"De ces deux points de vue, l’ open data des décisions de justice pourrait venir éclairer le développement du droit et participer d’une bonne légistique."
168,"D EUMIER , Contribution au rapport L’open data des décisions de justice , op. cit., pp."
168,"Dans la première partie de ce rapport, l’état de diffusion actuel des décisions de justice a été présenté et leur réception par les différents acteurs de la justice a été examinée."
168,"Il en est résulté le constat d’une diffusion déjà importante des décisions ayant une vocation jurisprudentielle, bien que certaines d’entre elles demeurent difficiles d’accès. À cet égard, l’ouverture des données décisionnelles sera précieuse et pourra augmenter la portée jurisprudentielle de ces décisions, tant il est vrai que la diffusion d’une décision de justice est une con dition première de son rayonnement jurisprudentiel."
168,"Au-delà de cette prévision raisonnable, le groupe de réflexion tient à souligner combien il est en définitive difficile d’anticiper la réaction des acte urs de la justice à l’open data et, partant, le devenir de la jurisprudence, ce dernier étant largement tributaire de l’appréhension des décisions de justice par les praticiens et les universitaires."
168,"Parmi e ux, l’indifférenciation des décisions de justice – tendant à considérer que toutes les décisions de justice se valent quant à leur portée jurisprudentielle – est apparue comme un écueil à éviter."
168,"Cette perspective écartée, le groupe de réflexion a ensuite identifié un autre risque, celui d’un raisonnement juridique qui, sous l’influence de l’open data des décisions de justice, ressortirait singulièrement appauvri en raison de la tendance qu’il pourrait susciter chez les juges et chez les avocats à se conformer mécaniquement aux décisions précédemment rendues."
168,"Dans cette perspective, le groupe de réflexion s’est attaché à formul er une série de recommandations dont la mise en œuvre conduira à envisager autrement les décisions des juridictions du fond, dans leur rapport à la notion de jurisprudence, puisque certaines d’entre elles seront davantage mises en avant qu’elles ne le sont aujourd’hui : étant situées au sein d’ une hiérarchisation, voire parfois évoquées dans d’autres d écisions de justice, elles jouiront d’une plus grande portée jurisprudentielle."
168,"Instru its par les auditions et les consultations écrites de praticiens, d’universitaires, d’éditeurs juridiques et de LegalTech , les membres du groupe de réflexion ont entrepris, d’abord, d’effectuer un état des lieux de la diffusion des décisions de justice et de leur réception par les justiciables et les professionnels du droit, afin de déterminer précisément la situation actuelle que l’ open data pourrait affecter."
168,"Instruits par les auditions et les consultations écrites de praticiens, d’universi taires, d’éditeurs juridiques et de LegalTech, les membres du groupe de ré lexion ont entrepris, d’abord, d’effectuer un état des lieux de la diffusion des décisions de justice et de leur réception par les justiciables et les professionnels du droit, ain de déterminer précisément la situation actuelle que l’open data pourrait affecter."
17,"The Foundation funds research that informs social policy, primarily in education, welfare and justice."
17,"In addition to the Ada Lovelace Institute, the Foundation is also the founder and co-funder of the Nuffield Council on Bioethics and the Nuffield Family Justice Observatory."
170,"Projet AJC | ACT Project | Autonomisation des acteurs Judiciaires par la Cyberjustice et l’intelligence artificielle | Autonomy Through Cyberjustice Technologies and AI Laboratoire de CYBERJUSTICE Laboratory Espace exclusif – membres AJC en AJC Présentation Entrevues des chefs de groupe Entrevues des chercheurs Infrastructure de recherche Gouvernance Comité scientifique Actualités Nous joindre Organisation Groupes de travail Chantier 1 – Subproject 1 Chantier 2 – Subproject 2 Chantier 3 – Subproject 3 Chantier 4 – Subproject 4 Chantier 5 – Subproject 5 Chantier 6 – Subproject 6 Chantier 7 – Subproject 7 Chantier 8 – Subproject 8 Chantier 9 – Subproject 9 Chantier 10 – Subproject 10 Chantier 11 – Subproject 11 Chantier 12 – Subproject 12 Chantier 13 – Subproject 13 Chantier 14 – Subproject 14 Chantier 15 – Subproject 15 Chantier 16 – Subproject 16 Chercheurs Partenaires Partenaires institutionnel Partenaires issus du milieu de l’action sociale et communautaire Partenaires issus du milieu universitaire Partenaires issus du monde professionnel Partenaires issus de l’industrie Publications Bibliothèque numérique sur la cyberjustice – Cyberjustice Digital Library Rapport mi-parcours | Annexe bibliographique Articles scientifiques Guides de meilleures pratiques Livres ou chapitres de livres Documents de travail Inventaires Blogues Articles de presse Présentations Conférences et activités Études de cas & Évaluations Gouvernance juridique Conférences 2025 ACT Project Conference AI, Large Language Models and Justice L’accessibilité : la nouvelle frontière de la justice en ligne Fintech: Réguler aujourd’hui les technologies financières de demain Vidéos Conférences enregistrées Rencontre annuelle | Juin 2020 Webinaires des partenaires Webconférences cyberjustice AJC Présentation Entrevues des chefs de groupe Entrevues des chercheurs Infrastructure de recherche Gouvernance Comité scientifique Actualités Nous joindre Organisation Groupes de travail Chantier 1 – Subproject 1 Chantier 2 – Subproject 2 Chantier 3 – Subproject 3 Chantier 4 – Subproject 4 Chantier 5 – Subproject 5 Chantier 6 – Subproject 6 Chantier 7 – Subproject 7 Chantier 8 – Subproject 8 Chantier 9 – Subproject 9 Chantier 10 – Subproject 10 Chantier 11 – Subproject 11 Chantier 12 – Subproject 12 Chantier 13 – Subproject 13 Chantier 14 – Subproject 14 Chantier 15 – Subproject 15 Chantier 16 – Subproject 16 Chercheurs Partenaires Partenaires institutionnel Partenaires issus du milieu de l’action sociale et communautaire Partenaires issus du milieu universitaire Partenaires issus du monde professionnel Partenaires issus de l’industrie Publications Bibliothèque numérique sur la cyberjustice – Cyberjustice Digital Library Rapport mi-parcours | Annexe bibliographique Articles scientifiques Guides de meilleures pratiques Livres ou chapitres de livres Documents de travail Inventaires Blogues Articles de presse Présentations Conférences et activités Études de cas & Évaluations Gouvernance juridique Conférences 2025 ACT Project Conference AI, Large Language Models and Justice L’accessibilité : la nouvelle frontière de la justice en ligne Fintech: Réguler aujourd’hui les technologies financières de demain Vidéos Conférences enregistrées Rencontre annuelle | Juin 2020 Webinaires des partenaires Webconférences cyberjustice Conférence 2025 du partenariat AJC À la une À la une Actualités Quoi savoir avant d’aller à la Conférence AJC 202516 septembre 2025 Merci de vous être inscrit à la conférence annuelle du partenariat AJC (Autonomisation des acteurs judiciaires par la cyberjustice) 2025 !"
170,"L’événement aura lieu les 15 et 16 octobre au Laboratoire de cyberjustice, situé dans la salle B-2215 de l’Université de Montréal. À tout moment, si vous avez besoin d’aide, le personnel de la conférence sera […] Lire la suite À la une Actualités Événements Conférence le mercredi 5 mars : « Considerations on AI Governance and concrete applications in the field of Law and Justice »3 mars 2025 Le mercredi 5 mars 2025 à 13:00, heure de Montréal (19:00, heure de Madrid) se tiendra en hybride la conférence « Consideraciones sobre la gobernanza de la IA y aplicaciones concretas en el ámbito del Derecho y la Justicia » (Considerations on AI Governance and concrete applications in the field of Law and Justice), organisée par la […] Lire la suite À la une Actualités IA générative & Résolution des litiges | Publication de Karim Benyekhlef, Valentin Callipel et Aurore Clément10 décembre 2024 Le Pr Karim Benyekhlef, Valentin Callipel et Aurore Clément viennent de publier « IA générative & Résolution des litiges »."
170,Ils explorent dans cet article l’apport que pourrait représenter l’utilisation de briques d’IA générative au développement et au succès de plateformes de règlement en ligne des litiges. publication intégrale ﻿IERDJ_EDC-volume-2-301024Télécharger Lire la suite À la une Actualités Offre d’emploi | 2 auxiliaires de recherche au Laboratoire de cyberjustice14 novembre 2024 Le Laboratoire de cyberjustice est un espace unique de réflexion et de création où les processus de justice sont modélisés et réimaginés afin d’améliorer l’accès à la justice.
170,"Nos travaux se distinguent par l’expérimentation d’innovations technologiques, comme l’intelligence artificielle, pour optimiser le fonctionnement actuel de la justice, de manière à en accroître l’efficacité, à en […] Lire la suite Voir les précédents Nouvelles À la une Actualités Quoi savoir avant d’aller à la Conférence AJC 202516 septembre 2025 Merci de vous être inscrit à la conférence annuelle du partenariat AJC (Autonomisation des acteurs judiciaires par la cyberjustice) 2025 !"
170,"Cet article explore la controverse entourant la demande de traduction des plus […] Lire la suite À la une Actualités Événements Découvrez la conférence ‘Montreal 2024, Generative AI and Justice’ à travers nos vidéos7 août 2024 Le Laboratoire de cyberjustice a le plaisir de vous inviter à la conférence Montreal 2024: Generative AI and Justice, qui se tiendra le 1er octobre 2024 au laboratoire."
170,"Informations pratiques Lieu de la conférence : Laboratoire de cyberjustice (B-2215), Pavillon Jean-Brillant, 3200 rue Jean-Brillant, Montréal, Québec H3T 1N8 Date : 2024/10/01 de 9:00 à 17:30 Inscription […] Lire la suite À la une Événements Conférence à venir : La justice à l’épreuve de l’IA."
170,(11 septembre 2024)24 juillet 2024 Le Laboratoire de cyberjustice a le plaisir de vous inviter à la conférence La justice à l’épreuve de l’IA.
170,"Informations pratiques Quand : 11 septembre 2024 de 16:30 à 19:30 Où: Salon François-Chevrette, A-3464, Pavilion Maximilien-Caron, 3101 chemin de la Tour, Montréal, Québec, H3T 1N8 […] Lire la suite À la une Actualités Conférence à venir : « Montreal 2024, Generative AI and Justice » (1 octobre 2024)18 juin 2024 Le Laboratoire de cyberjustice a le plaisir de vous inviter à la conférence Montreal 2024, Generative AI and Justice, qui se tiendra le 1er octobre 2024 au Laboratoire."
170,Cette conférence est une occasion unique pour les acteurs du droit et de la justice de mieux comprendre et de se positionner sur les usages émergents […] Lire la suite À la une Actualités Dans les médias Prof.
170,"Hannes Westermann, premier intervenant des webinaires « AI & Access to Justice » du Stanford Legal Design Lab18 juin 2024 Le Laboratoire de cyberjustice a le plaisir de vous annoncer que Prof."
170,Hannes Westermann a été le premier intervenant des webinaires “AI & Access to Justice” du Stanford Legal Design Lab.
170,"Dans ce premier webinaire intitulé “Generative AI for Access to Justice: Challenges and Opportunities”, Prof."
170,"Jinzhe Tan (Laboratoire de cyberjustice) dans le cadre du cycle de conférences de 2024 « AI, Large Language Models, and Justice Considerations for Legal Practitioners Judges, Law Schools and Public Legal Educators » Biographie […] Lire la suite À la une Actualités Web-conférences cyberjustice Vidéo – Conférence « L’IA générative dans le domaine juridique : une approche nuancée » (DL4T) de Prof."
170,"Amy Salyzyn (UOttawa) & Dre Katie Szilagyi (University of Manitoba) dans le cadre du cycle de conférences de 2024 « AI, Large Language Models, and Justice Considerations for Legal Practitioners Judges, Law Schools and Public Legal Educators » […] Lire la suite À la une Actualités Événements Nouvelles Conférence à venir : « AI and Judging » de Pre Tania Sourdin (7 mai 2024)6 mai 2024 Le Laboratoire de cyberjustice a le plaisir de vous inviter à la conférence en ligne « AI and Judging« de Pre Tania Sourdin."
170,"Cliquer ici pour vous inscrire Informations pratiques Quand : 7 mai 2024, 16h30 F Format : Sur Zoom Biographie Pre Tania Sourdin is President of the Academic Senate at the University […] Lire la suite À la une Actualités Rapport de recherche – « Le numérique et l’intelligence artificielle comme outil de justice sociale : les initiatives par et pour les groupes et communautés marginalisés »1 mai 2024 Le Laboratoire de cyberjustice a le plaisir de vous présenter le rapport de recherche intitulée Le numérique et l’intelligence artificielle comme outil de justice sociale : les initiatives par et pour les groupes et communautés marginalisés par Pre Karine Gentelet (UQO), membre du Laboratoire de cyberjustice et du projet AJC."
170,Ce rapport met en lumière les initiatives […] Lire la suite À la une Actualités Offre d’emploi | Étudiant.e en informatique aux cycles supérieurs1 mai 2024 Le Laboratoire de cyberjustice est un espace unique de réflexion et de création où les processus de justice sont modélisés et réimaginés afin d’améliorer l’accès à la justice.
170,"Nos travaux se distinguent par l’expérimentation d’innovations technologiques, comme l’intelligence artificielle, pour optimiser le fonctionnement actuel de la justice, de manière à en accroître l’efficacité, à en […] Lire la suite À la une Actualités Nouvelles Offre d’emploi | 2 auxiliaires de recherche au Laboratoire de cyberjustice22 avril 2024 Le Laboratoire de cyberjustice est un espace unique de réflexion et de création où les processus de justice sont modélisés et réimaginés afin d’améliorer l’accès à la justice."
170,"Nos travaux se distinguent par l’expérimentation d’innovations technologiques, comme l’intelligence artificielle, pour optimiser le fonctionnement actuel de la justice, de manière à en accroître l’efficacité, à en […] Lire la suite À la une Actualités Événements Nouvelles Conférence à venir: Colloque sur l’intelligence artificielle et le droit pénal « Des ordres et (désordres) de l’intelligence artificielle : Propagande – Pornographie – Profilage » (25 avril 2024)22 avril 2024 La Chaire Lexum et le Laboratoire de cyberjustice ont le plaisir de vous inviter au colloque sur l’intelligence artificielle et le droit pénal « Des ordres et (désordres) de l’intelligence artificielle : Propagande – Pornographie – Profilage."
170,"Marina Pavlović dans le cadre du cycle de conférences de 2024 « AI, Large Language Models, and Justice Considerations for Legal Practitioners Judges, Law Schools and Public Legal Educators » Biographie des conférenciers Prof."
170,La Bourse doctorale de la Chaire LexUM en information juridique et du Laboratoire de cyberjustice est conçue pour encourager deux […] Lire la suite À la une Actualités Appel à candidatures – Projet « Intelligence artificielle pour la découvrabilité »2 avril 2024 POSTE : Étudiant en droit des nouvelles technologies Le Laboratoire de cyberjustice est un espace unique de réflexion et de création où les processus de justice sont modélisés et réimaginés afin d’améliorer l’accès à la justice.
170,"Nos travaux se distinguent par l’expérimentation d’innovations technologiques, comme l’intelligence artificielle, pour optimiser le fonctionnement actuel de la justice, de […] Lire la suite À la une Actualités Web-conférences cyberjustice Conférence à venir: (Free)lance content and GenerativeAI: The persisting plight of freelance authors across the creative industries de Dre Pina D’Agostino (9 avril 2024)2 avril 2024 date 9 avril 2024, 13h00 Réunion zoom https://mcgill.zoom.us/meeting/register/tZEqcOyppzguHd3ddDeKt5Ylo5x5BS9dDBLq description sommaire Recycling existing copyright-protected works in new media is an age-old recurrence, which continues to challenge copyright law and its future on a global scale."
170,"Mark Daley (Western University) dans le cadre du cycle de conférences de 2024 « AI, Large Language Models, and Justice Considerations for Legal Practitioners Judges, Law Schools and Public Legal Educators » Biographie du conférencier Mark is the Chief AI Officer at Western University and a […] Lire la suite À la une Événements Conférence à venir: Understanding Large Language Models de Dr."
170,"Plusieurs fonctionnalités ont été évoquées, telles que la détection de messages incendiaires, la capacité de proposer une reformulation de ceux-ci, ainsi que la possibilité de demander à l’agent […] Lire la suite À la une Appel à communications: Conférence « Can Artificial Intelligence Contribute to Justice? »28 février 2024 The-International-Association-of-Law-2Télécharger Lire la suite À la une Actualités Conférence à venir : Symposium « Problematic Generative AI » (9 février 2024)16 janvier 2024 Le Laboratoire de cyberjustice vous convie au symposium « Problematic Generative AI »."
170,"Ce numéro de la RIDP, intitulé « Artificial Intelligence and Administration of Criminal Justice », présente les résultats d’une recherche collective entreprise en 2020."
170,"Il s’inspire des travaux antérieurs influents de l’OCDE sur l’accès à la justice, par exemple les […] Lire la suite À la une Actualités Offre d’emploi | Auxiliaire.s de recherche au Laboratoire de cyberjustice4 décembre 2023 Le Laboratoire de cyberjustice est un espace unique de réflexion et de création où les processus de justice sont modélisés et réimaginés afin d’améliorer l’accès à la justice."
170,"Nos travaux se distinguent par l’expérimentation d’innovations technologiques, comme l’intelligence artificielle, pour optimiser le fonctionnement actuel de la justice, de manière à en accroître l’efficacité, à en […] Lire la suite À la une Conférences de la Chaire Lexum Conférence à venir : IA, enjeux de pouvoir, de puissance et de souveraineté dans un monde en transition de Dre Asma Mhalla (4 décembre 2023)1 décembre 2023 La Chaire Lexum et le Centre de recherche en droit public ont le plaisir de vous inviter à la conférence « IA, enjeux de pouvoir, de puissance et de souveraineté dans un monde en transition » de Dre Asma Mhalla."
170,"Cliquer ici pour vous inscrire Informations pratiques Quand : 4 décembre 2023, 16h30 Format : Présentiel et distanciel Où […] Lire la suite À la une Conférences et colloques La Conférence Cyberjustice Europe 2023 en images24 novembre 2023 La conférence Cyberjustice Europe 2023 a été un succès, et nous souhaitons exprimer nos remerciements à l’équipe de l’Institut des Études et de la Recherche sur le Droit et la Justice, ainsi qu’au Conseil de l’Europe, avec qui nous avons collaboré pour organiser cet événement."
170,Cette conférence a été une opportunité unique de discuter de l’impact […] Lire la suite À la une Actualités Publication à venir (15 novembre 2023) – Les intelligences artificielles au prisme de la justice sociale – Considering Artificial Intelligence Through the Lens of Social Justice10 novembre 2023 Le livre « Les intelligences artificielles au prisme de la justice sociale – Considering Artificial Intelligence Through the Lens of Social Justice » sous la direction de Pre Karine Gentelet sera publiée le 15 novembre 2023 par PUL (Presses de l’Université Laval).
170,"La Commission avait également sollicité certains acteurs à partager […] Lire la suite À la une Rapport du sous-projet 11: L’accès à la justice par l’IA – Par et pour les communautés marginalisées et/ou sous-représentées30 octobre 2023 Karine Gentelet Ce rapport écrit par Pre Karine Gentelet (UQO), Mme Marie Zumstein & Mme Lily-Cannelle Mathieu a pour objectif de détailler les raisons pour lesquelles des tensions peuvent survenir lors du déploiement d’un outil d’IA dédiée à l’accès à la justice auprès de populations marginalisées."
170,"Ce rapport a pour objectif d’établir une cartographie des différentes Legaltechs œuvrant dans le domaine de la « Justice prédictive » en France et à l’étranger, dans le but d’informer […] Lire la suite À la une Événements Visite de la délégation du Conseil national des barreaux et du cabinet d’avocats FÉRAL au Laboratoire de cyberjustice26 octobre 2023 Nous sommes ravis d’avoir accueilli la délégation du Conseil national des barreaux et l’équipe du cabinet d’avocats FÉRAL dans notre laboratoire."
170,A lawyer […] Lire la suite À la une Actualités From Wetware to Robots to Airware: Imagining a Trajectory for AI-facilitated JusticeAlexis Leblanc-Roy 20 septembre 2023 This installation is intended to interrogate the involvement of AI in the justice system.
170,"Your comments, if you choose to make any, will help us understand how the public feels about the possibility of AI judges, substantive vs. procedural reasons, and adjudicative vs. predictive justice systems."
170,"Télécharger ici Lire la suite À la une Actualités Lunch and Learn: Large Language Models – Applications in the legal field10 février 2023 Le mercredi, 8 février dernier a eu lieu le Lunch and Learn: Large Language Models – Applications in the legal field où l’équipe du Laboratoire a eu l’occasion de participer à une séance de brainstorming sur l’utilisation de ChatGPT dans le domaine juridique avec des contributions de Karim Benyekhlef, Valentin Callipel, Mark Likhten, Philippe Langlais (Département d’informatique […] Lire la suite Actualités À l’invitation du ministère de la Justice du Canada, le Pr."
170,"Karim Benyekhlef et Me Valentin Callipel représenteront le Canada dans le cadre du dialogue Canada-Europe sur la numérisation de la justice13 janvier 2023 Karim Benyekhlef, directeur du Laboratoire de cyberjustice, et Valentin Callipel, chargé de mission, rencontreront des experts européens et canadiens dans le cadre d’une discussion portant sur l’échange des meilleures pratiques en matière de numérisation de la justice."
170,"Il s’agit du Martin Felsky Award pour leur article intitulé « Judging by the Numbers : Judicial Analytics, the Justice System and its Stakeholders »."
170,"Le Martin Felsky Award a été […] Lire la suite À la une Événements La justice en ligne comme solution aux barrières à l’accès à la justice21 septembre 2022 • 15:00Laboratoire de cyberjustice & En ligne (Hybride)3 août 2022 Présentateur(trice)s Julia Atack, Yannick Labelle, Responsable des affaires juridiques et auteure de la recherche Résumé de la présentation De nombreuses barrières se dressent devant les consommateurs qui désirent avoir accès à la justice."
170,"Malgré les multiples mesures envisagées ou tentées par les législateurs canadiens, les solutions proposées jusqu’à présent ne semblent pas être à la […] Lire la suite À la une Table ronde sur la « Justice décentralisée et Web 3.0 » – Que pouvons-nous apprendre des projets de résolution de conflits en ligne par blockchain ?29 juillet 2022 Dans le cadre de la rencontre annuelle du Projet AJC Issue du Web 3.0 – une idée de nouvelle itération du World Wide Web basée sur la technologie blockchain qui intègre des concepts tels que la décentralisation et l’économie basée sur les jetons – la « justice décentralisée » est une nouvelle approche de la résolution des […] Lire la suite À la une Actualités Événements Conférence internationale du partenariat AJC4 octobre 2022 6 octobre 2022Laboratoire de cyberjustice7 juillet 2022 La conférence internationale de mi-parcours du partenariat AJC, qui se déroulera du 4 au 6 octobre 2022, arrive à grands pas!"
170,"Elle se déroulera maintenant du 4 […] Lire la suite Actualités Existe-t-il un juste usage et une réelle utilité de l’IA en justice ?| Karim Benyekhlef30 juin 2022 Karim Benyekhlef Dans le cadre du congrès Time World 2022, ayant eu lieu du 5 au 7 mai 2022, Pr Benyekhlef s’est penché sur la question de l’impact de l’utilisation de l’intelligence artificielle sur le droit."
170,Il a présenté une conférence intitulée « Existe-t-il un juste usage et une réelle utilité de l’IA en justice ? ».
170,La discussion portera sur comment un cadre d’alphabétisation fonctionnelle peut être utilisé pour réduire la complexité des formulaires des cours et des tribunaux et ultimement améliorer l’accès à la justice.
170,"Depuis sa création, il a […] Lire la suite Événements The role of courts and access to justice in the digital era 9 juin 2022 10 juin 2022En ligne - Online & Radboud University Nijmegen29 avril 2022 Les inscriptions sont ouvertes pour la conférence hybride « The role of courts and access to justice in the digital era » (Université Radboud de Nimègue) qui se déroulera les 9 et 10 juin 2022."
170,"Dans le cadre du Cycle d’ateliers « L’accessibilité : la nouvelle frontière de la justice en ligne », nous vous invitons à l’atelier « Cultural Accessibility »."
170,"Elle est associée au Centre de recherche en droit, technologie et société et professeure agrégée au Département des sciences sociales […] Lire la suite À la une Actualités Justice et IA | Karim Benyekhlef participe à la série de balados UtopIA19 avril 2022 Karim Benyekhlef Pr Karim Benyekhlef, directeur du Laboratoire de cyberjustice, a participé, avec Pr Jocelyn Maclure, au balado « Justice et IA », animé par Christian Auger."
170,Description de l’épisode Une société gouvernée par les algorithmes peut-elle rendre justice?
170,Comment les acteur.rice.s de la justice perçoivent-ils l’avènement de cette technologie?
170,Une justice automatisée est-elle en marche?
170,"Summary Online Dispute Resolution (ODR) can increase access to justice, but the expense and scarcity of facilitators […] Lire la suite À la une Événements Artificial Intelligence and Access to Justice: Perspectives from the legal and technical domain29 mars 2022 • 16:30Laboratoire de cyberjustice & En ligne - Online11 mars 2022 Cet atelier se déroulera en anglais."
170,Nye a plus de 20 ans d’expérience dans la direction de projets sophistiqués et multidisciplinaires dans le secteur de la justice en Ontario.
170,En anglais Conférencier Pr Kieran Tranter is the Chair of […] Lire la suite À la une Nouvelles Le Laboratoire de cyberjustice obtient le statut d’observateur auprès du Réseau européen sur la cyberjustice8 février 2022 Le Laboratoire de cyberjustice est heureux d’annoncer qu’il a obtenu le statut d’observateur auprès du Réseau européen sur la cyberjustice (European Cyberjustice Network) de la CEPEJ (Commission européenne pour l’efficacité de la justice) du Conseil de l’Europe.
170,Les bases de données sur lesquelles […] Lire la suite À la une Événements AJC|ACT Workshop: «What have we learned from the accelerated experience of remote hearings during the pandemic?»8 février 2022 • 9:00 11:30En ligne - Online17 janvier 2022 En anglais Introduction The pandemic had an unprecedented accelerating effect on the transition towards remote hearings within the justice system.
170,"[…] Lire la suite À la une Nouvelles Nomination du professeur Karim Benyekhlef au Conseil scientifique du nouvel Institut des Études et de la Recherche sur le Droit et la Justice (IERDJ)10 janvier 2022 Karim Benyekhlef Le Laboratoire de cyberjustice est heureux d’annoncer la nomination du professeur Karim Benyekhlef au Conseil scientifique du nouvel Institut des Études et de la Recherche sur le Droit et la Justice (IERDJ), issu de la fusion de l’Institut des hautes études sur la justice et de la Mission de recherche Droit et justice, deux organismes de recherche […] Lire la suite À la une Événements Afrofuturism, Critical Race Theory, and the Future of Policing3 février 2022 • 16:30En ligne - Online7 janvier 2022 Dans le cadre du Cycle de conférences « Droit et Littérature: Représentations littéraires des identités et transcriptions juridiques », le Laboratoire de cyberjustice vous invite à la conférence « Afrofuturism, Critical Race Theory, and the Future of Policing » présentée par Pr Bennett Capers (Fordham Law School)."
170,"Cette subvention est accordée pour 3 ans (2021-2024) pour le projet « Les incidences de l’architecture logicielle des tribunaux en ligne sur l’accès à la justice », avec les professeurs Karim Benyekhlef et Pierre-Luc […] Lire la suite Nouvelles Le professeur Pierre-Luc Déziel publie une étude sur l’incidence des technologies sur la formation des juristes au Québec24 mars 2021 Une équipe de la Faculté de droit de l’Université Laval dirigée par le professeur Pierre-Luc Déziel et composée de Hélène Zimmermann et Satchel Dell’olio Delpech publie une étude relative à l’incidence des technologies de l’information et des communications sur la formation des juristes au Québec."
170,"Financée par le ministère de la Justice du Québec, l’étude […] Lire la suite À la une Le Laboratoire de cyberjustice sélectionné pour le Comité en gouvernement ouvert du Québec23 mars 2021 Le Laboratoire de cyberjustice est heureux d’annoncer qu’il a été sélectionné en tant qu’organisme de la société civile pour participer au Comité en gouvernement ouvert du Québec du Secrétariat du Conseil du trésor."
170,Le mandat du comité sera : *de conseiller le Secrétariat du Conseil du trésor quant à l’élaboration de nouveaux plans d’action pour un […] Lire la suite Nouvelles Podcast | Jena McGill and Amy Salyzyn on Judicial Analytics8 mars 2021 Amy Salyzyn Listen to Jena McGill and Amy Salyzyn talk about their upcoming paper “Judging by Numbers: How will Judicial Analytics Impact the Justice System and its Stakeholders?” Jena and Amy explain some of the benefits of judicial analytics software and a few concerns that arise with its use.
170,"Also available on Spotify Read this paper on SSRN McGill, Jena and […] Lire la suite Nouvelles Kevin Ashley, chercheur du projet AJC, reçoit une subvention de 357 000$ pour le projet Using AI to Increase Fairness by Improving Access to Justice29 janvier 2021 Kevin Ashley Le Laboratoire de cyberjustice est heureux d’annoncer que la National Science Foundation (USA) attribue, dans le cadre du programme Fairness in Artificial Intelligence, une subvention de 357 000$ (3 ans) au projet Using AI to Increase Fairness by Improving Access to Justice mené par le professeur Kevin Ashley (University of Pittsburgh), chef du Chantier 2 […] Lire la suite À la une Publication de l’ouvrage collectif AI and Law: a Critical Overview dirigé par Karim Benyekhlef28 janvier 2021 Karim Benyekhlef Le Laboratoire de cyberjustice et la Chaire LexUM en information juridique sont heureux d’annoncer la publication de l’ouvrage collectif AI and Law: a Critical Overview aux éditions Thémis."
170,"Le livre sera disponible début 2021 en version imprimée, […] Lire la suite Nouvelles Chaire Abeona-ENS-OBVIA | Appel à contribution pour un ouvrage collectif sur « Justice sociale et IA »17 novembre 2020 Karine Gentelet Cet ouvrage collectif s’inscrit dans le cadre des travaux de la Chaire Abeona-ENS-OBVIA et aura pour objectif de proposer une réflexion renouvelée et multidisciplinaire sur les enjeux des usages de l’intelligence artificielle à partir d’une perspective de justice sociale."
170,"Devant les enjeux de mobilité, […] Lire la suite Nouvelles Rapport | To Surveil and Predict : A Human Rights Analysis of Algorithmic Policing in Canada 5 octobre 2020 Ce rapport rédigé par Kate Robertson — avocate et chercheuse au Citizien Lab, Cynthia Khoo — chercheuse au Citizen Lab et avocate spécialisée dans la technologie et les droits de l’homme — et Yolanda Song — avocate chez Stevenson Whelton LLP et associée de recherche pro bono à l’IHRP — examine les technologies algorithmiques qui […] Lire la suite Nouvelles Tribune de Karim Benyekhlef et Valentin Callipel |Algorithmes et Justice : une prudente avancée1 octobre 2020 Karim Benyekhlef / Valentin Callipel Karim Benyekhlef — directeur du Laboratoire de cyberjustice — et Valentin Callipel — chargé de mission au Laboratoire — s’intéressent dans une tribune publiée par Business & Legal Forum For Ethics & Performance aux enjeux des algorithmes dans le domaine judiciaire."
170,"Le Privacy Shield en est l’illustration parfaite, reflétant à lui seul les difficultés d’un couple américano-européen tentant tant bien que mal de recoller les morceaux d’un compromis juridiquement […] Lire la suite Nouvelles Winkler Institute for Dispute Resolution ANNUAL REPORT 2019-2020 17 septembre 2020 Trevor Farrow / Valentin Callipel Basé à la Osgoode Hall Law School à Toronto et nommé en l’honneur de l’ancien juge en chef de l’Ontario Warren Winkler, le Winkler Institute for Dispute Resolution est un centre de recherche qui travaille depuis 2014 dans le domaine du règlement des litiges, l’accès à la justice, et l’avenir de la profession juridique et […] Lire la suite Nouvelles Prof."
170,"Karine Gentelet, nouvelle titulaire de la Chaire Abeona-ENS-OBVIA Intelligence artificielle et justice sociale10 septembre 2020 Karine Gentelet Prof."
170,Karine Gentelet – chercheuse AJC – est récipiendaire de la Chaire 2020-2021 Abeona-École normale supérieure (ENS)-Observatoire international sur les impacts sociétaux de l’IA et du numérique (OBVIA) au concours IA et justice social.
170,"Cette chaire permet à un·e professeur·e invité·e de développer, pendant une année, des travaux sur l’intelligence artificielle (IA) et la justice […] Lire la suite Nouvelles CFCJ | The Justice Crisis : Un nouveau livre sur l’accès à la Justice au Canada3 septembre 2020 Les Jacobs / Trevor Farrow The Justice Crisis: The Cost and Value of Accessing Law publié sous la direction de Trevor Farrow et Lesley A."
170,"Jacobs – chercheurs AJC – fournit un aperçu approfondi, basé sur de nouvelles recherches empiriques, de ce qui fonctionne et ne fonctionne pas pour améliorer l’accès à la justice civile et familiale au Canada."
170,"Alors que les algorithmes sont censés améliorer l’efficience et la qualité des services publics, certains se sont […] Lire la suite Blogue Retour sur l’expérience judiciaire en temps de pandémie : quelle technologisation de notre justice ?6 août 2020 Écrit par Jie Zhu, auxiliaire de recherche au Laboratoire de cyberjustice – Été 2020."
170,La Bourse doctorale de la Chaire LexUM en information juridique et du Laboratoire de cyberjustice est conçue pour encourager deux […] Lire la suite À la une Actualités Offre d’emploi | 2 auxiliaires de recherche au Laboratoire de cyberjustice14 novembre 2024 Le Laboratoire de cyberjustice est un espace unique de réflexion et de création où les processus de justice sont modélisés et réimaginés afin d’améliorer l’accès à la justice.
170,"Nos travaux se distinguent par l’expérimentation d’innovations technologiques, comme l’intelligence artificielle, pour optimiser le fonctionnement actuel de la justice, de manière à en accroître l’efficacité, à en […] Lire la suite Voir les précédents Calendrier Actualités Conférence annuelle 2025 : Autonomisation des acteurs judiciaires par la cyberjustice (AJC)15 octobre 2025 16 octobre 2025Laboratoire de cyberjustice (B-2215)30 juin 2025 Actualités Nous joindre Espace exclusif – membres AJC Inscription - Infolettre Adresse courriel © 2018 AJC • Crédits et mentions légales propulsé par forcerouge sur OpenUM.ca,un projet de la Chaire L.R."
171,"Projet AJC | ACT Project | Autonomisation des acteurs Judiciaires par la Cyberjustice et l’intelligence artificielle | Autonomy Through Cyberjustice Technologies and AI Laboratoire de CYBERJUSTICE Laboratory Espace exclusif – membres AJC en AJC Présentation Entrevues des chefs de groupe Entrevues des chercheurs Infrastructure de recherche Gouvernance Comité scientifique Actualités Nous joindre Organisation Groupes de travail Chantier 1 – Subproject 1 Chantier 2 – Subproject 2 Chantier 3 – Subproject 3 Chantier 4 – Subproject 4 Chantier 5 – Subproject 5 Chantier 6 – Subproject 6 Chantier 7 – Subproject 7 Chantier 8 – Subproject 8 Chantier 9 – Subproject 9 Chantier 10 – Subproject 10 Chantier 11 – Subproject 11 Chantier 12 – Subproject 12 Chantier 13 – Subproject 13 Chantier 14 – Subproject 14 Chantier 15 – Subproject 15 Chantier 16 – Subproject 16 Chercheurs Partenaires Partenaires institutionnel Partenaires issus du milieu de l’action sociale et communautaire Partenaires issus du milieu universitaire Partenaires issus du monde professionnel Partenaires issus de l’industrie Publications Bibliothèque numérique sur la cyberjustice – Cyberjustice Digital Library Rapport mi-parcours | Annexe bibliographique Articles scientifiques Guides de meilleures pratiques Livres ou chapitres de livres Documents de travail Inventaires Blogues Articles de presse Présentations Conférences et activités Études de cas & Évaluations Gouvernance juridique Conférences 2025 ACT Project Conference AI, Large Language Models and Justice L’accessibilité : la nouvelle frontière de la justice en ligne Fintech: Réguler aujourd’hui les technologies financières de demain Vidéos Conférences enregistrées Rencontre annuelle | Juin 2020 Webinaires des partenaires Webconférences cyberjustice AJC Présentation Entrevues des chefs de groupe Entrevues des chercheurs Infrastructure de recherche Gouvernance Comité scientifique Actualités Nous joindre Organisation Groupes de travail Chantier 1 – Subproject 1 Chantier 2 – Subproject 2 Chantier 3 – Subproject 3 Chantier 4 – Subproject 4 Chantier 5 – Subproject 5 Chantier 6 – Subproject 6 Chantier 7 – Subproject 7 Chantier 8 – Subproject 8 Chantier 9 – Subproject 9 Chantier 10 – Subproject 10 Chantier 11 – Subproject 11 Chantier 12 – Subproject 12 Chantier 13 – Subproject 13 Chantier 14 – Subproject 14 Chantier 15 – Subproject 15 Chantier 16 – Subproject 16 Chercheurs Partenaires Partenaires institutionnel Partenaires issus du milieu de l’action sociale et communautaire Partenaires issus du milieu universitaire Partenaires issus du monde professionnel Partenaires issus de l’industrie Publications Bibliothèque numérique sur la cyberjustice – Cyberjustice Digital Library Rapport mi-parcours | Annexe bibliographique Articles scientifiques Guides de meilleures pratiques Livres ou chapitres de livres Documents de travail Inventaires Blogues Articles de presse Présentations Conférences et activités Études de cas & Évaluations Gouvernance juridique Conférences 2025 ACT Project Conference AI, Large Language Models and Justice L’accessibilité : la nouvelle frontière de la justice en ligne Fintech: Réguler aujourd’hui les technologies financières de demain Vidéos Conférences enregistrées Rencontre annuelle | Juin 2020 Webinaires des partenaires Webconférences cyberjustice Conférence 2025 du partenariat AJC À la une À la une Actualités Quoi savoir avant d’aller à la Conférence AJC 202516 septembre 2025 Merci de vous être inscrit à la conférence annuelle du partenariat AJC (Autonomisation des acteurs judiciaires par la cyberjustice) 2025 !"
171,"L’événement aura lieu les 15 et 16 octobre au Laboratoire de cyberjustice, situé dans la salle B-2215 de l’Université de Montréal. À tout moment, si vous avez besoin d’aide, le personnel de la conférence sera […] Lire la suite À la une Actualités Événements Conférence le mercredi 5 mars : « Considerations on AI Governance and concrete applications in the field of Law and Justice »3 mars 2025 Le mercredi 5 mars 2025 à 13:00, heure de Montréal (19:00, heure de Madrid) se tiendra en hybride la conférence « Consideraciones sobre la gobernanza de la IA y aplicaciones concretas en el ámbito del Derecho y la Justicia » (Considerations on AI Governance and concrete applications in the field of Law and Justice), organisée par la […] Lire la suite À la une Actualités IA générative & Résolution des litiges | Publication de Karim Benyekhlef, Valentin Callipel et Aurore Clément10 décembre 2024 Le Pr Karim Benyekhlef, Valentin Callipel et Aurore Clément viennent de publier « IA générative & Résolution des litiges »."
171,Ils explorent dans cet article l’apport que pourrait représenter l’utilisation de briques d’IA générative au développement et au succès de plateformes de règlement en ligne des litiges. publication intégrale ﻿IERDJ_EDC-volume-2-301024Télécharger Lire la suite À la une Actualités Offre d’emploi | 2 auxiliaires de recherche au Laboratoire de cyberjustice14 novembre 2024 Le Laboratoire de cyberjustice est un espace unique de réflexion et de création où les processus de justice sont modélisés et réimaginés afin d’améliorer l’accès à la justice.
171,"Nos travaux se distinguent par l’expérimentation d’innovations technologiques, comme l’intelligence artificielle, pour optimiser le fonctionnement actuel de la justice, de manière à en accroître l’efficacité, à en […] Lire la suite Voir les précédents Nouvelles À la une Actualités Quoi savoir avant d’aller à la Conférence AJC 202516 septembre 2025 Merci de vous être inscrit à la conférence annuelle du partenariat AJC (Autonomisation des acteurs judiciaires par la cyberjustice) 2025 !"
171,"Cet article explore la controverse entourant la demande de traduction des plus […] Lire la suite À la une Actualités Événements Découvrez la conférence ‘Montreal 2024, Generative AI and Justice’ à travers nos vidéos7 août 2024 Le Laboratoire de cyberjustice a le plaisir de vous inviter à la conférence Montreal 2024: Generative AI and Justice, qui se tiendra le 1er octobre 2024 au laboratoire."
171,"Informations pratiques Lieu de la conférence : Laboratoire de cyberjustice (B-2215), Pavillon Jean-Brillant, 3200 rue Jean-Brillant, Montréal, Québec H3T 1N8 Date : 2024/10/01 de 9:00 à 17:30 Inscription […] Lire la suite À la une Événements Conférence à venir : La justice à l’épreuve de l’IA."
171,(11 septembre 2024)24 juillet 2024 Le Laboratoire de cyberjustice a le plaisir de vous inviter à la conférence La justice à l’épreuve de l’IA.
171,"Informations pratiques Quand : 11 septembre 2024 de 16:30 à 19:30 Où: Salon François-Chevrette, A-3464, Pavilion Maximilien-Caron, 3101 chemin de la Tour, Montréal, Québec, H3T 1N8 […] Lire la suite À la une Actualités Conférence à venir : « Montreal 2024, Generative AI and Justice » (1 octobre 2024)18 juin 2024 Le Laboratoire de cyberjustice a le plaisir de vous inviter à la conférence Montreal 2024, Generative AI and Justice, qui se tiendra le 1er octobre 2024 au Laboratoire."
171,Cette conférence est une occasion unique pour les acteurs du droit et de la justice de mieux comprendre et de se positionner sur les usages émergents […] Lire la suite À la une Actualités Dans les médias Prof.
171,"Hannes Westermann, premier intervenant des webinaires « AI & Access to Justice » du Stanford Legal Design Lab18 juin 2024 Le Laboratoire de cyberjustice a le plaisir de vous annoncer que Prof."
171,Hannes Westermann a été le premier intervenant des webinaires “AI & Access to Justice” du Stanford Legal Design Lab.
171,"Dans ce premier webinaire intitulé “Generative AI for Access to Justice: Challenges and Opportunities”, Prof."
171,"Jinzhe Tan (Laboratoire de cyberjustice) dans le cadre du cycle de conférences de 2024 « AI, Large Language Models, and Justice Considerations for Legal Practitioners Judges, Law Schools and Public Legal Educators » Biographie […] Lire la suite À la une Actualités Web-conférences cyberjustice Vidéo – Conférence « L’IA générative dans le domaine juridique : une approche nuancée » (DL4T) de Prof."
171,"Amy Salyzyn (UOttawa) & Dre Katie Szilagyi (University of Manitoba) dans le cadre du cycle de conférences de 2024 « AI, Large Language Models, and Justice Considerations for Legal Practitioners Judges, Law Schools and Public Legal Educators » […] Lire la suite À la une Actualités Événements Nouvelles Conférence à venir : « AI and Judging » de Pre Tania Sourdin (7 mai 2024)6 mai 2024 Le Laboratoire de cyberjustice a le plaisir de vous inviter à la conférence en ligne « AI and Judging« de Pre Tania Sourdin."
171,"Cliquer ici pour vous inscrire Informations pratiques Quand : 7 mai 2024, 16h30 F Format : Sur Zoom Biographie Pre Tania Sourdin is President of the Academic Senate at the University […] Lire la suite À la une Actualités Rapport de recherche – « Le numérique et l’intelligence artificielle comme outil de justice sociale : les initiatives par et pour les groupes et communautés marginalisés »1 mai 2024 Le Laboratoire de cyberjustice a le plaisir de vous présenter le rapport de recherche intitulée Le numérique et l’intelligence artificielle comme outil de justice sociale : les initiatives par et pour les groupes et communautés marginalisés par Pre Karine Gentelet (UQO), membre du Laboratoire de cyberjustice et du projet AJC."
171,Ce rapport met en lumière les initiatives […] Lire la suite À la une Actualités Offre d’emploi | Étudiant.e en informatique aux cycles supérieurs1 mai 2024 Le Laboratoire de cyberjustice est un espace unique de réflexion et de création où les processus de justice sont modélisés et réimaginés afin d’améliorer l’accès à la justice.
171,"Nos travaux se distinguent par l’expérimentation d’innovations technologiques, comme l’intelligence artificielle, pour optimiser le fonctionnement actuel de la justice, de manière à en accroître l’efficacité, à en […] Lire la suite À la une Actualités Nouvelles Offre d’emploi | 2 auxiliaires de recherche au Laboratoire de cyberjustice22 avril 2024 Le Laboratoire de cyberjustice est un espace unique de réflexion et de création où les processus de justice sont modélisés et réimaginés afin d’améliorer l’accès à la justice."
171,"Nos travaux se distinguent par l’expérimentation d’innovations technologiques, comme l’intelligence artificielle, pour optimiser le fonctionnement actuel de la justice, de manière à en accroître l’efficacité, à en […] Lire la suite À la une Actualités Événements Nouvelles Conférence à venir: Colloque sur l’intelligence artificielle et le droit pénal « Des ordres et (désordres) de l’intelligence artificielle : Propagande – Pornographie – Profilage » (25 avril 2024)22 avril 2024 La Chaire Lexum et le Laboratoire de cyberjustice ont le plaisir de vous inviter au colloque sur l’intelligence artificielle et le droit pénal « Des ordres et (désordres) de l’intelligence artificielle : Propagande – Pornographie – Profilage."
171,"Marina Pavlović dans le cadre du cycle de conférences de 2024 « AI, Large Language Models, and Justice Considerations for Legal Practitioners Judges, Law Schools and Public Legal Educators » Biographie des conférenciers Prof."
171,La Bourse doctorale de la Chaire LexUM en information juridique et du Laboratoire de cyberjustice est conçue pour encourager deux […] Lire la suite À la une Actualités Appel à candidatures – Projet « Intelligence artificielle pour la découvrabilité »2 avril 2024 POSTE : Étudiant en droit des nouvelles technologies Le Laboratoire de cyberjustice est un espace unique de réflexion et de création où les processus de justice sont modélisés et réimaginés afin d’améliorer l’accès à la justice.
171,"Nos travaux se distinguent par l’expérimentation d’innovations technologiques, comme l’intelligence artificielle, pour optimiser le fonctionnement actuel de la justice, de […] Lire la suite À la une Actualités Web-conférences cyberjustice Conférence à venir: (Free)lance content and GenerativeAI: The persisting plight of freelance authors across the creative industries de Dre Pina D’Agostino (9 avril 2024)2 avril 2024 date 9 avril 2024, 13h00 Réunion zoom https://mcgill.zoom.us/meeting/register/tZEqcOyppzguHd3ddDeKt5Ylo5x5BS9dDBLq description sommaire Recycling existing copyright-protected works in new media is an age-old recurrence, which continues to challenge copyright law and its future on a global scale."
171,"Mark Daley (Western University) dans le cadre du cycle de conférences de 2024 « AI, Large Language Models, and Justice Considerations for Legal Practitioners Judges, Law Schools and Public Legal Educators » Biographie du conférencier Mark is the Chief AI Officer at Western University and a […] Lire la suite À la une Événements Conférence à venir: Understanding Large Language Models de Dr."
171,"Plusieurs fonctionnalités ont été évoquées, telles que la détection de messages incendiaires, la capacité de proposer une reformulation de ceux-ci, ainsi que la possibilité de demander à l’agent […] Lire la suite À la une Appel à communications: Conférence « Can Artificial Intelligence Contribute to Justice? »28 février 2024 The-International-Association-of-Law-2Télécharger Lire la suite À la une Actualités Conférence à venir : Symposium « Problematic Generative AI » (9 février 2024)16 janvier 2024 Le Laboratoire de cyberjustice vous convie au symposium « Problematic Generative AI »."
171,"Ce numéro de la RIDP, intitulé « Artificial Intelligence and Administration of Criminal Justice », présente les résultats d’une recherche collective entreprise en 2020."
171,"Il s’inspire des travaux antérieurs influents de l’OCDE sur l’accès à la justice, par exemple les […] Lire la suite À la une Actualités Offre d’emploi | Auxiliaire.s de recherche au Laboratoire de cyberjustice4 décembre 2023 Le Laboratoire de cyberjustice est un espace unique de réflexion et de création où les processus de justice sont modélisés et réimaginés afin d’améliorer l’accès à la justice."
171,"Nos travaux se distinguent par l’expérimentation d’innovations technologiques, comme l’intelligence artificielle, pour optimiser le fonctionnement actuel de la justice, de manière à en accroître l’efficacité, à en […] Lire la suite À la une Conférences de la Chaire Lexum Conférence à venir : IA, enjeux de pouvoir, de puissance et de souveraineté dans un monde en transition de Dre Asma Mhalla (4 décembre 2023)1 décembre 2023 La Chaire Lexum et le Centre de recherche en droit public ont le plaisir de vous inviter à la conférence « IA, enjeux de pouvoir, de puissance et de souveraineté dans un monde en transition » de Dre Asma Mhalla."
171,"Cliquer ici pour vous inscrire Informations pratiques Quand : 4 décembre 2023, 16h30 Format : Présentiel et distanciel Où […] Lire la suite À la une Conférences et colloques La Conférence Cyberjustice Europe 2023 en images24 novembre 2023 La conférence Cyberjustice Europe 2023 a été un succès, et nous souhaitons exprimer nos remerciements à l’équipe de l’Institut des Études et de la Recherche sur le Droit et la Justice, ainsi qu’au Conseil de l’Europe, avec qui nous avons collaboré pour organiser cet événement."
171,Cette conférence a été une opportunité unique de discuter de l’impact […] Lire la suite À la une Actualités Publication à venir (15 novembre 2023) – Les intelligences artificielles au prisme de la justice sociale – Considering Artificial Intelligence Through the Lens of Social Justice10 novembre 2023 Le livre « Les intelligences artificielles au prisme de la justice sociale – Considering Artificial Intelligence Through the Lens of Social Justice » sous la direction de Pre Karine Gentelet sera publiée le 15 novembre 2023 par PUL (Presses de l’Université Laval).
171,"La Commission avait également sollicité certains acteurs à partager […] Lire la suite À la une Rapport du sous-projet 11: L’accès à la justice par l’IA – Par et pour les communautés marginalisées et/ou sous-représentées30 octobre 2023 Karine Gentelet Ce rapport écrit par Pre Karine Gentelet (UQO), Mme Marie Zumstein & Mme Lily-Cannelle Mathieu a pour objectif de détailler les raisons pour lesquelles des tensions peuvent survenir lors du déploiement d’un outil d’IA dédiée à l’accès à la justice auprès de populations marginalisées."
171,"Ce rapport a pour objectif d’établir une cartographie des différentes Legaltechs œuvrant dans le domaine de la « Justice prédictive » en France et à l’étranger, dans le but d’informer […] Lire la suite À la une Événements Visite de la délégation du Conseil national des barreaux et du cabinet d’avocats FÉRAL au Laboratoire de cyberjustice26 octobre 2023 Nous sommes ravis d’avoir accueilli la délégation du Conseil national des barreaux et l’équipe du cabinet d’avocats FÉRAL dans notre laboratoire."
171,A lawyer […] Lire la suite À la une Actualités From Wetware to Robots to Airware: Imagining a Trajectory for AI-facilitated JusticeAlexis Leblanc-Roy 20 septembre 2023 This installation is intended to interrogate the involvement of AI in the justice system.
171,"Your comments, if you choose to make any, will help us understand how the public feels about the possibility of AI judges, substantive vs. procedural reasons, and adjudicative vs. predictive justice systems."
171,"Télécharger ici Lire la suite À la une Actualités Lunch and Learn: Large Language Models – Applications in the legal field10 février 2023 Le mercredi, 8 février dernier a eu lieu le Lunch and Learn: Large Language Models – Applications in the legal field où l’équipe du Laboratoire a eu l’occasion de participer à une séance de brainstorming sur l’utilisation de ChatGPT dans le domaine juridique avec des contributions de Karim Benyekhlef, Valentin Callipel, Mark Likhten, Philippe Langlais (Département d’informatique […] Lire la suite Actualités À l’invitation du ministère de la Justice du Canada, le Pr."
171,"Karim Benyekhlef et Me Valentin Callipel représenteront le Canada dans le cadre du dialogue Canada-Europe sur la numérisation de la justice13 janvier 2023 Karim Benyekhlef, directeur du Laboratoire de cyberjustice, et Valentin Callipel, chargé de mission, rencontreront des experts européens et canadiens dans le cadre d’une discussion portant sur l’échange des meilleures pratiques en matière de numérisation de la justice."
171,"Il s’agit du Martin Felsky Award pour leur article intitulé « Judging by the Numbers : Judicial Analytics, the Justice System and its Stakeholders »."
171,"Le Martin Felsky Award a été […] Lire la suite À la une Événements La justice en ligne comme solution aux barrières à l’accès à la justice21 septembre 2022 • 15:00Laboratoire de cyberjustice & En ligne (Hybride)3 août 2022 Présentateur(trice)s Julia Atack, Yannick Labelle, Responsable des affaires juridiques et auteure de la recherche Résumé de la présentation De nombreuses barrières se dressent devant les consommateurs qui désirent avoir accès à la justice."
171,"Malgré les multiples mesures envisagées ou tentées par les législateurs canadiens, les solutions proposées jusqu’à présent ne semblent pas être à la […] Lire la suite À la une Table ronde sur la « Justice décentralisée et Web 3.0 » – Que pouvons-nous apprendre des projets de résolution de conflits en ligne par blockchain ?29 juillet 2022 Dans le cadre de la rencontre annuelle du Projet AJC Issue du Web 3.0 – une idée de nouvelle itération du World Wide Web basée sur la technologie blockchain qui intègre des concepts tels que la décentralisation et l’économie basée sur les jetons – la « justice décentralisée » est une nouvelle approche de la résolution des […] Lire la suite À la une Actualités Événements Conférence internationale du partenariat AJC4 octobre 2022 6 octobre 2022Laboratoire de cyberjustice7 juillet 2022 La conférence internationale de mi-parcours du partenariat AJC, qui se déroulera du 4 au 6 octobre 2022, arrive à grands pas!"
171,"Elle se déroulera maintenant du 4 […] Lire la suite Actualités Existe-t-il un juste usage et une réelle utilité de l’IA en justice ?| Karim Benyekhlef30 juin 2022 Karim Benyekhlef Dans le cadre du congrès Time World 2022, ayant eu lieu du 5 au 7 mai 2022, Pr Benyekhlef s’est penché sur la question de l’impact de l’utilisation de l’intelligence artificielle sur le droit."
171,Il a présenté une conférence intitulée « Existe-t-il un juste usage et une réelle utilité de l’IA en justice ? ».
171,La discussion portera sur comment un cadre d’alphabétisation fonctionnelle peut être utilisé pour réduire la complexité des formulaires des cours et des tribunaux et ultimement améliorer l’accès à la justice.
171,"Depuis sa création, il a […] Lire la suite Événements The role of courts and access to justice in the digital era 9 juin 2022 10 juin 2022En ligne - Online & Radboud University Nijmegen29 avril 2022 Les inscriptions sont ouvertes pour la conférence hybride « The role of courts and access to justice in the digital era » (Université Radboud de Nimègue) qui se déroulera les 9 et 10 juin 2022."
171,"Dans le cadre du Cycle d’ateliers « L’accessibilité : la nouvelle frontière de la justice en ligne », nous vous invitons à l’atelier « Cultural Accessibility »."
171,"Elle est associée au Centre de recherche en droit, technologie et société et professeure agrégée au Département des sciences sociales […] Lire la suite À la une Actualités Justice et IA | Karim Benyekhlef participe à la série de balados UtopIA19 avril 2022 Karim Benyekhlef Pr Karim Benyekhlef, directeur du Laboratoire de cyberjustice, a participé, avec Pr Jocelyn Maclure, au balado « Justice et IA », animé par Christian Auger."
171,Description de l’épisode Une société gouvernée par les algorithmes peut-elle rendre justice?
171,Comment les acteur.rice.s de la justice perçoivent-ils l’avènement de cette technologie?
171,Une justice automatisée est-elle en marche?
171,"Summary Online Dispute Resolution (ODR) can increase access to justice, but the expense and scarcity of facilitators […] Lire la suite À la une Événements Artificial Intelligence and Access to Justice: Perspectives from the legal and technical domain29 mars 2022 • 16:30Laboratoire de cyberjustice & En ligne - Online11 mars 2022 Cet atelier se déroulera en anglais."
171,Nye a plus de 20 ans d’expérience dans la direction de projets sophistiqués et multidisciplinaires dans le secteur de la justice en Ontario.
171,En anglais Conférencier Pr Kieran Tranter is the Chair of […] Lire la suite À la une Nouvelles Le Laboratoire de cyberjustice obtient le statut d’observateur auprès du Réseau européen sur la cyberjustice8 février 2022 Le Laboratoire de cyberjustice est heureux d’annoncer qu’il a obtenu le statut d’observateur auprès du Réseau européen sur la cyberjustice (European Cyberjustice Network) de la CEPEJ (Commission européenne pour l’efficacité de la justice) du Conseil de l’Europe.
171,Les bases de données sur lesquelles […] Lire la suite À la une Événements AJC|ACT Workshop: «What have we learned from the accelerated experience of remote hearings during the pandemic?»8 février 2022 • 9:00 11:30En ligne - Online17 janvier 2022 En anglais Introduction The pandemic had an unprecedented accelerating effect on the transition towards remote hearings within the justice system.
171,"[…] Lire la suite À la une Nouvelles Nomination du professeur Karim Benyekhlef au Conseil scientifique du nouvel Institut des Études et de la Recherche sur le Droit et la Justice (IERDJ)10 janvier 2022 Karim Benyekhlef Le Laboratoire de cyberjustice est heureux d’annoncer la nomination du professeur Karim Benyekhlef au Conseil scientifique du nouvel Institut des Études et de la Recherche sur le Droit et la Justice (IERDJ), issu de la fusion de l’Institut des hautes études sur la justice et de la Mission de recherche Droit et justice, deux organismes de recherche […] Lire la suite À la une Événements Afrofuturism, Critical Race Theory, and the Future of Policing3 février 2022 • 16:30En ligne - Online7 janvier 2022 Dans le cadre du Cycle de conférences « Droit et Littérature: Représentations littéraires des identités et transcriptions juridiques », le Laboratoire de cyberjustice vous invite à la conférence « Afrofuturism, Critical Race Theory, and the Future of Policing » présentée par Pr Bennett Capers (Fordham Law School)."
171,"Cette subvention est accordée pour 3 ans (2021-2024) pour le projet « Les incidences de l’architecture logicielle des tribunaux en ligne sur l’accès à la justice », avec les professeurs Karim Benyekhlef et Pierre-Luc […] Lire la suite Nouvelles Le professeur Pierre-Luc Déziel publie une étude sur l’incidence des technologies sur la formation des juristes au Québec24 mars 2021 Une équipe de la Faculté de droit de l’Université Laval dirigée par le professeur Pierre-Luc Déziel et composée de Hélène Zimmermann et Satchel Dell’olio Delpech publie une étude relative à l’incidence des technologies de l’information et des communications sur la formation des juristes au Québec."
171,"Financée par le ministère de la Justice du Québec, l’étude […] Lire la suite À la une Le Laboratoire de cyberjustice sélectionné pour le Comité en gouvernement ouvert du Québec23 mars 2021 Le Laboratoire de cyberjustice est heureux d’annoncer qu’il a été sélectionné en tant qu’organisme de la société civile pour participer au Comité en gouvernement ouvert du Québec du Secrétariat du Conseil du trésor."
171,Le mandat du comité sera : *de conseiller le Secrétariat du Conseil du trésor quant à l’élaboration de nouveaux plans d’action pour un […] Lire la suite Nouvelles Podcast | Jena McGill and Amy Salyzyn on Judicial Analytics8 mars 2021 Amy Salyzyn Listen to Jena McGill and Amy Salyzyn talk about their upcoming paper “Judging by Numbers: How will Judicial Analytics Impact the Justice System and its Stakeholders?” Jena and Amy explain some of the benefits of judicial analytics software and a few concerns that arise with its use.
171,"Also available on Spotify Read this paper on SSRN McGill, Jena and […] Lire la suite Nouvelles Kevin Ashley, chercheur du projet AJC, reçoit une subvention de 357 000$ pour le projet Using AI to Increase Fairness by Improving Access to Justice29 janvier 2021 Kevin Ashley Le Laboratoire de cyberjustice est heureux d’annoncer que la National Science Foundation (USA) attribue, dans le cadre du programme Fairness in Artificial Intelligence, une subvention de 357 000$ (3 ans) au projet Using AI to Increase Fairness by Improving Access to Justice mené par le professeur Kevin Ashley (University of Pittsburgh), chef du Chantier 2 […] Lire la suite À la une Publication de l’ouvrage collectif AI and Law: a Critical Overview dirigé par Karim Benyekhlef28 janvier 2021 Karim Benyekhlef Le Laboratoire de cyberjustice et la Chaire LexUM en information juridique sont heureux d’annoncer la publication de l’ouvrage collectif AI and Law: a Critical Overview aux éditions Thémis."
171,"Le livre sera disponible début 2021 en version imprimée, […] Lire la suite Nouvelles Chaire Abeona-ENS-OBVIA | Appel à contribution pour un ouvrage collectif sur « Justice sociale et IA »17 novembre 2020 Karine Gentelet Cet ouvrage collectif s’inscrit dans le cadre des travaux de la Chaire Abeona-ENS-OBVIA et aura pour objectif de proposer une réflexion renouvelée et multidisciplinaire sur les enjeux des usages de l’intelligence artificielle à partir d’une perspective de justice sociale."
171,"Devant les enjeux de mobilité, […] Lire la suite Nouvelles Rapport | To Surveil and Predict : A Human Rights Analysis of Algorithmic Policing in Canada 5 octobre 2020 Ce rapport rédigé par Kate Robertson — avocate et chercheuse au Citizien Lab, Cynthia Khoo — chercheuse au Citizen Lab et avocate spécialisée dans la technologie et les droits de l’homme — et Yolanda Song — avocate chez Stevenson Whelton LLP et associée de recherche pro bono à l’IHRP — examine les technologies algorithmiques qui […] Lire la suite Nouvelles Tribune de Karim Benyekhlef et Valentin Callipel |Algorithmes et Justice : une prudente avancée1 octobre 2020 Karim Benyekhlef / Valentin Callipel Karim Benyekhlef — directeur du Laboratoire de cyberjustice — et Valentin Callipel — chargé de mission au Laboratoire — s’intéressent dans une tribune publiée par Business & Legal Forum For Ethics & Performance aux enjeux des algorithmes dans le domaine judiciaire."
171,"Le Privacy Shield en est l’illustration parfaite, reflétant à lui seul les difficultés d’un couple américano-européen tentant tant bien que mal de recoller les morceaux d’un compromis juridiquement […] Lire la suite Nouvelles Winkler Institute for Dispute Resolution ANNUAL REPORT 2019-2020 17 septembre 2020 Trevor Farrow / Valentin Callipel Basé à la Osgoode Hall Law School à Toronto et nommé en l’honneur de l’ancien juge en chef de l’Ontario Warren Winkler, le Winkler Institute for Dispute Resolution est un centre de recherche qui travaille depuis 2014 dans le domaine du règlement des litiges, l’accès à la justice, et l’avenir de la profession juridique et […] Lire la suite Nouvelles Prof."
171,"Karine Gentelet, nouvelle titulaire de la Chaire Abeona-ENS-OBVIA Intelligence artificielle et justice sociale10 septembre 2020 Karine Gentelet Prof."
171,Karine Gentelet – chercheuse AJC – est récipiendaire de la Chaire 2020-2021 Abeona-École normale supérieure (ENS)-Observatoire international sur les impacts sociétaux de l’IA et du numérique (OBVIA) au concours IA et justice social.
171,"Cette chaire permet à un·e professeur·e invité·e de développer, pendant une année, des travaux sur l’intelligence artificielle (IA) et la justice […] Lire la suite Nouvelles CFCJ | The Justice Crisis : Un nouveau livre sur l’accès à la Justice au Canada3 septembre 2020 Les Jacobs / Trevor Farrow The Justice Crisis: The Cost and Value of Accessing Law publié sous la direction de Trevor Farrow et Lesley A."
171,"Jacobs – chercheurs AJC – fournit un aperçu approfondi, basé sur de nouvelles recherches empiriques, de ce qui fonctionne et ne fonctionne pas pour améliorer l’accès à la justice civile et familiale au Canada."
171,"Alors que les algorithmes sont censés améliorer l’efficience et la qualité des services publics, certains se sont […] Lire la suite Blogue Retour sur l’expérience judiciaire en temps de pandémie : quelle technologisation de notre justice ?6 août 2020 Écrit par Jie Zhu, auxiliaire de recherche au Laboratoire de cyberjustice – Été 2020."
171,La Bourse doctorale de la Chaire LexUM en information juridique et du Laboratoire de cyberjustice est conçue pour encourager deux […] Lire la suite À la une Actualités Offre d’emploi | 2 auxiliaires de recherche au Laboratoire de cyberjustice14 novembre 2024 Le Laboratoire de cyberjustice est un espace unique de réflexion et de création où les processus de justice sont modélisés et réimaginés afin d’améliorer l’accès à la justice.
171,"Nos travaux se distinguent par l’expérimentation d’innovations technologiques, comme l’intelligence artificielle, pour optimiser le fonctionnement actuel de la justice, de manière à en accroître l’efficacité, à en […] Lire la suite Voir les précédents Calendrier Actualités Conférence annuelle 2025 : Autonomisation des acteurs judiciaires par la cyberjustice (AJC)15 octobre 2025 16 octobre 2025Laboratoire de cyberjustice (B-2215)30 juin 2025 Actualités Nous joindre Espace exclusif – membres AJC Inscription - Infolettre Adresse courriel © 2018 AJC • Crédits et mentions légales propulsé par forcerouge sur OpenUM.ca,un projet de la Chaire L.R."
172,"Alarming reports have detailed how discriminatory algorithms are already deployed in the justice system, wherein judges use these tools for sentencing that purport to predict the likelihood a criminal defendant will reoffend.21 In Automating Inequality , Virginia Eubanks details how government actors implement automated and surveillance technologies that harm marginalized groups.22 Eubanks studied automated systems in the US that discriminated against the poor’s receipt of DATA & SOCIETY 11 GOVERNING ARTIFICIAL INTELLIGENCEgovernment assistance."
172,"Baluarte and Christian De Vos, From Judgment to Justice: Implementing International and Regional Human Rights Decisions , Open Society Justice Initiative (November 2010), https:/ / www.opensocietyfoundations.org/sites/default/files/from-judgment-to-justice-20101122.pdf ."
174,46 3.6 Justice and solidarity ..........................................................................................
174,212 7.3 Algorithmic systems in the dispensation of justice .......................................................
174,"Justice and Solidarity In view of the vast amounts of power being accumulated using data and technologies, and the new threats of exclusion and discrimination, the safeguarding of equitable access and distributive justice is an urgent task."
174,"Regardless of the position that data protection authorities and the European Court of Justice will ultimately take with regard to the prohibition under the GDPR of “tying” or “bundling” consent with the provision of a service, the Data Ethics Commission believes that consumers must be offered reasonable alternatives to releasing their data for commercial use (e. g. appropriately designed pay options )."
174,8 The Data Ethics Commission advises the Federal Government not to consider the issues falling under the heading of “digital inheritance” as having been settled by the Federal Court of Justice’s 2018 ruling.
174,"69 In the areas of law-making and the dispensation of justice , algorithmic systems may at most be used for peripheral tasks."
174,"The first took place on 7 February 2019 at the Federal Ministry of Justice and Consumer Protection ( Bundesministerium der Justiz und für Verbraucherschutz ), and centred around the issue of “Selfdetermination and external determination in the age of artificial intelligence”."
174,"Another vital aspect of self-determination is that people must not only be allowed to assume responsibility , but must do so and do justice to the task."
174,"3.6 Justice and solidarity Observance of the principles of justice by society and its institutions is another fundamental factor that allows us to live together in peace, prosperity, freedom and democracy."
174,"The availability of large volumes of data and the digitalisation of processes e.g. in the workplace and the healthcare sector raises other questions relating to equitable access and distributive justice , however, for example in relation to income and the provision of healthcare; these developments may mean that scarce resources can be distributed more fairly, but they may also mean that individual groups of people suffer disadvantage or discrimination."
174,There is also a close link between justice and opportunities for participation.
174,"Finally, questions of justice arise in connection with situations where the use of algorithmic systems – in particular self-learning algorithmic systems – means that individuals or groups of people suffer discrimination for no justifying reason."
174,"This raises questions with regard to sustainable economic and ecological development, and also questions of international justice concerning the use of natural resources and global responsibility for future generations."
174,"To further this aim, in October 2018, the Federal Ministry of Justice and Consumer Protection launched an initiative to clarify the principles and concepts of corporate digital responsibility (www.bmjv.de/cdr )."
174,"The issue raises fundamental questions about distributive and participatory justice, and about what a just economic system looks like."
174,"10 By way of examples: European Commission: Building a European data economy, 10 January 2017, COM(2017) 9 final (available at: https:/ /ec.europa. eu/transparency/regdoc/rep/1/2017/EN/COM-2017-9-F1-EN-MAIN-PART-1.PDF ); Arbeitsgruppe “Digitaler Neustart” der Konferenz der Justizministerinnen und Justizminister der Länder [Working Group “Digital New Start” of the Conference of Ministers of Justice of the Länder]: Report of 15 May 2017, pp."
174,"However, given the huge number of individuals that contribute to the generation and processing of data, the level of complexity of a fair remuneration system and the 24/7 monitoring that would be required to measure data flows would be out of all proportion to any potential gains in terms of justice."
174,"Personal data are therefore often referred to in shorthand terms as “counter-performance” for digital content or services, for example in the original draft of Article 3(1) of the Digital Content Directive (although the term was removed at a later point in the legislative procedure).11 The extent to which the economic model described above is, in fact, compatible with the prohibition under Article 7(4) GDPR of “tying” or “bundling” consent with the provision of a service12 must ultimately be clarified by the European Court of Justice."
174,"16 Judgment by the German Federal Court of Justice of 12 July 2018, ref."
174,III ZR 183/17.The principle set forth by the Federal Court of Justice – that an estate should be transferred to the deceased’s heirs – is linked to the existence of a contractual relationship.
174,"Systems already exist which can relieve state bodies of repetitive tasks (thereby expediting processes and freeing up human resources for complex cases) and which, in certain set-ups, improve the consistency and quality of state activity or, in the form of chatbots or voice assistants, for example, can facilitate citizens’ access to justice."
174,7.3 Algorithmic systems in the dispensation of justice The Data Ethics Commission is of the view that the use of algorithmic systems in the dispensation of justice is permissible only for peripheral tasks .
174,"Justice is administered “in the name of the people”, and that means, at least in contentious proceedings as well as in administrative court proceedings and criminal proceedings, always administered by human judges."
174,"Due to the often high level of trust placed in the supposed “infallibility” of technical systems (automation bias) as well as the low level of willingness to make divergent decisions, in particular if this is associated with an additional burden of reasoning and proof and the risk of a “miscarriage of justice” (default effects), even legally non-binding proposals for decisions for judgments by algorithmic systems are generally highly problematic from the perspective of the parties concerned."
174,"Such systems could, for example, work out whether decisions were influenced by external factors and, if so, which ones in order to provide judges in future with ways to prevent such distortions themselves and thus contribute to better and more consistent dispensation of justice."
174,"Dr Mario Martini ●Professor of Public Administration, Public Law, Administrative Law and European Law at the German University of Administrative Sciences Speyer (DUV Speyer) ●Head of the Programme Area “Transfor mation of the State in the Digital Age” and Deputy Director of the German Research Institute for Public Administration (FÖV) Klaus Müller ●Executive Director of the Federation of German Consumer Organisations (vzbv) ●Lecturer at Heinrich Heine University Düsseldorf (HHU) Paul Nemitz ●Principle Advisor at the European Commis sion, Directorate-General for Justice and Consumers Prof."
174,"Dr Thomas Wischmeyer ●Assistant Professor (Tenure Track) for Public Law and Information Law at the University of Bielefeld Current as of: 10 October 2019 Imprint Berlin, December 2019 Opinion of the Data Ethics CommissionPublisher Data Ethics Commission of the Federal GovernmentFederal Ministry of the Interior, Building and CommunityAlt-Moabit 140, 10557 BerlinFederal Ministry of Justice and Consumer ProtectionMohrenstraße 37, 10117 Berlin E-mail datenethikkommission_gs@bmi.bund.dedatenethikkommission_gs@bmjv.bund.de Website www.datenethikkommission.de Design Atelier Hauer + Dörfler GmbH, Berlin Photo credits p."
175,"These opportunities can make a lasting contribution to freedom, justice and prosperity above all when people’s individual rights are protected and social cohesion is strengthe ned."
180,"4 Soraya Amrani Mekki, ""Justice prédictive et accès au juge"", La Justice Prédictive, Actes du Colloque of 12 February 2018 organised by Conseil d’Etat and Cour de cassation Lawyers Council for its bicentenary in partnership with the Paris-Dauphine PSL University, Paris, Dalloz, 2018."
180,"15-25 of 1 December 2015 on security in stations; Report titled ""Lutte contre la fraude aux prestations sociales : à quel prix pour les droits des usagers ?"" , September 2017, Parcoursup decisions (2018-323 of 21 December 2018 and 2019-21 of 18 January 2019), Opinion 18-26 of 31 October 2018 on the Draft Programming and Reform Act for Justice, opinion 19-11 of 5 September 2019 on the Draft Act on Bioethics.Introductory remarks 4 Algorithms: preventing automated discrimination | 2020At first glance, algorithms sort, categorise and organise information by eliminating any prejudice and bias specific to human beings."
182,"Accept additional cookies Reject additional cookies View cookies Hide cookie message Skip to main content GOV.UK Navigation menu Menu Menu Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments Departments, agencies and public bodies News News stories, speeches, letters and notices Guidance and regulation Detailed guidance, regulations and rules Research and statistics Reports, analysis and official statistics Policy papers and consultations Consultations and strategy Transparency Data, Freedom of Information releases and corporate reports Search GOV.UK × Search GOV.UK Search Search GOV.UK Search Home Business and industry Science and innovation Artificial intelligence Establishing a pro-innovation approach to regulating AI Department forScience, Innovation& Technology Office for Artificial Intelligence Department forDigital, Culture,Media & Sport Department forBusiness, Energy& Industrial Strategy Policy paper Establishing a pro-innovation approach to regulating AI Updated 20 July 2022 This was published under the 2019 to 2022 Johnson Conservative government Contents Ministerial foreword by the Secretary of State for Digital, Culture, Media and Sport Ministerial foreword by the Secretary of State for Business, Energy and Industrial Strategy Executive summary Context The scope A new pro-innovation approach Putting our approach into practice Next steps Share your views Print this page © Crown copyright 2022 This publication is licensed under the terms of the Open Government Licence v3.0 except where otherwise stated."
182,"Cancel Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments News Guidance and regulation Research and statistics Policy papers and consultations Transparency How government works Get involved Support links Help Privacy Cookies Accessibility statement Contact Terms and conditions Rhestr o Wasanaethau Cymraeg Government Digital Service All content is available under the Open Government Licence v3.0, except where otherwise stated © Crown copyright"
183,"Accept additional cookies Reject additional cookies View cookies Hide cookie message Skip to main content GOV.UK Navigation menu Menu Menu Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments Departments, agencies and public bodies News News stories, speeches, letters and notices Guidance and regulation Detailed guidance, regulations and rules Research and statistics Reports, analysis and official statistics Policy papers and consultations Consultations and strategy Transparency Data, Freedom of Information releases and corporate reports Search GOV.UK × Search GOV.UK Search Search GOV.UK Search Home Business and industry Press release New national innovation centre to put UK at forefront of big data A new £30m National Innovation Centre for Data (NICD) aims to see the next Google or Facebook started in the UK and help the country capitalise on a potential £40bn a year boost to the economy."
183,"Cancel Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments News Guidance and regulation Research and statistics Policy papers and consultations Transparency How government works Get involved Support links Help Privacy Cookies Accessibility statement Contact Terms and conditions Rhestr o Wasanaethau Cymraeg Government Digital Service All content is available under the Open Government Licence v3.0, except where otherwise stated © Crown copyright"
184,"Accept additional cookies Reject additional cookies View cookies Hide cookie message Skip to main content GOV.UK Navigation menu Menu Menu Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments Departments, agencies and public bodies News News stories, speeches, letters and notices Guidance and regulation Detailed guidance, regulations and rules Research and statistics Reports, analysis and official statistics Policy papers and consultations Consultations and strategy Transparency Data, Freedom of Information releases and corporate reports Search GOV.UK × Search GOV.UK Search Search GOV.UK Search Home Government Public services Guidelines for AI procurement Department forScience, Innovation& Technology Office for Artificial Intelligence Department forDigital, Culture,Media & Sport Department forBusiness, Energy& Industrial Strategy Guidance Guidelines for AI procurement Published 8 June 2020 Contents Introduction Top 10 Considerations AI-specific considerations within the procurement process 1."
184,"Cancel Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments News Guidance and regulation Research and statistics Policy papers and consultations Transparency How government works Get involved Support links Help Privacy Cookies Accessibility statement Contact Terms and conditions Rhestr o Wasanaethau Cymraeg Government Digital Service All content is available under the Open Government Licence v3.0, except where otherwise stated © Crown copyright"
185,"Accept additional cookies Reject additional cookies View cookies Hide cookie message Skip to main content GOV.UK Navigation menu Menu Menu Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments Departments, agencies and public bodies News News stories, speeches, letters and notices Guidance and regulation Detailed guidance, regulations and rules Research and statistics Reports, analysis and official statistics Policy papers and consultations Consultations and strategy Transparency Data, Freedom of Information releases and corporate reports Search GOV.UK × Search GOV.UK Search Search GOV.UK Search Home Business and industry Science and innovation Artificial intelligence National AI Strategy Department forScience, Innovation& Technology Office for Artificial Intelligence Department forDigital, Culture,Media & Sport Department forBusiness, Energy& Industrial Strategy Guidance National AI Strategy - HTML version Updated 18 December 2022 Contents Our ten-year plan to make Britain a global AI superpower Executive summary Summary of key actions Introduction Pillar 1: Investing in the long-term needs of the AI ecosystem Pillar 2: Ensuring AI benefits all sectors and regions Pillar 3: Governing AI effectively Next steps Print this page © Crown copyright 2022 This publication is licensed under the terms of the Open Government Licence v3.0 except where otherwise stated."
185,"Cancel Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments News Guidance and regulation Research and statistics Policy papers and consultations Transparency How government works Get involved Support links Help Privacy Cookies Accessibility statement Contact Terms and conditions Rhestr o Wasanaethau Cymraeg Government Digital Service All content is available under the Open Government Licence v3.0, except where otherwise stated © Crown copyright"
186,"Accept additional cookies Reject additional cookies View cookies Hide cookie message Skip to main content GOV.UK Navigation menu Menu Menu Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments Departments, agencies and public bodies News News stories, speeches, letters and notices Guidance and regulation Detailed guidance, regulations and rules Research and statistics Reports, analysis and official statistics Policy papers and consultations Consultations and strategy Transparency Data, Freedom of Information releases and corporate reports Search GOV.UK × Search GOV.UK Search Search GOV.UK Search Home Business and industry Industrial strategy Artificial Intelligence Sector Deal Department forScience, Innovation& Technology Department forBusiness & Trade Office for Artificial Intelligence Department forDigital, Culture,Media & Sport Department forBusiness, Energy& Industrial Strategy Policy paper AI Sector Deal Updated 21 May 2019 This was published under the 2016 to 2019 May Conservative government This policy paper was withdrawn on 25 June 2025 In June 2025, the government published its Modern Industrial Strategy - a new economic approach to back our strengths and realise Britain’s potential."
186,"Cancel Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments News Guidance and regulation Research and statistics Policy papers and consultations Transparency How government works Get involved Support links Help Privacy Cookies Accessibility statement Contact Terms and conditions Rhestr o Wasanaethau Cymraeg Government Digital Service All content is available under the Open Government Licence v3.0, except where otherwise stated © Crown copyright"
187,"Accept additional cookies Reject additional cookies View cookies Hide cookie message Skip to main content GOV.UK Navigation menu Menu Menu Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments Departments, agencies and public bodies News News stories, speeches, letters and notices Guidance and regulation Detailed guidance, regulations and rules Research and statistics Reports, analysis and official statistics Policy papers and consultations Consultations and strategy Transparency Data, Freedom of Information releases and corporate reports Search GOV.UK × Search GOV.UK Search Search GOV.UK Search Home Business and industry Industrial strategy Independent report Growing the artificial intelligence industry in the UK This independent review, carried out by Professor Dame Wendy Hall and Jérôme Pesenti reports on how the Artificial Intelligence industry can be grown in the UK."
187,"Cancel Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments News Guidance and regulation Research and statistics Policy papers and consultations Transparency How government works Get involved Support links Help Privacy Cookies Accessibility statement Contact Terms and conditions Rhestr o Wasanaethau Cymraeg Government Digital Service All content is available under the Open Government Licence v3.0, except where otherwise stated © Crown copyright"
188,"Accept additional cookies Reject additional cookies View cookies Hide cookie message Skip to main content GOV.UK Navigation menu Menu Menu Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments Departments, agencies and public bodies News News stories, speeches, letters and notices Guidance and regulation Detailed guidance, regulations and rules Research and statistics Reports, analysis and official statistics Policy papers and consultations Consultations and strategy Transparency Data, Freedom of Information releases and corporate reports Search GOV.UK × Search GOV.UK Search Search GOV.UK Search Home Business and industry Industrial strategy Policy paper Artificial Intelligence Sector Deal A Sector Deal between government and the Artificial Intelligence (AI) sector."
188,"Cancel Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments News Guidance and regulation Research and statistics Policy papers and consultations Transparency How government works Get involved Support links Help Privacy Cookies Accessibility statement Contact Terms and conditions Rhestr o Wasanaethau Cymraeg Government Digital Service All content is available under the Open Government Licence v3.0, except where otherwise stated © Crown copyright"
190,"Fairness and non discrimination Safety and Security Privacy Justice and fairness Non- maleficence Privacy OFFICIAL DSTG -TR-3786 OFFICIAL 50 Supply Chain Test & Evaluation Misuse and risks Authority pathway Data subjects result in unfair discrimination agains t individuals, communities or groups Privacy protection and security: Throughout their lifecycle, AI systems should respect and uphold privacy rights and data protection, and ensure the security of data Contestability: When an AI system significantly im pacts a person, community, group or environment, there should be a timely process to allow people to challenge the use or output of the AI system have control over their identity Awareness of Misuse: A/IS creators shall guard against all potential misuses and risks of A/IS in operation."
192,"Accept additional cookies Reject additional cookies View cookies Hide cookie message Skip to main content GOV.UK Navigation menu Menu Menu Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments Departments, agencies and public bodies News News stories, speeches, letters and notices Guidance and regulation Detailed guidance, regulations and rules Research and statistics Reports, analysis and official statistics Policy papers and consultations Consultations and strategy Transparency Data, Freedom of Information releases and corporate reports Search GOV.UK × Search GOV.UK Search Search GOV.UK Search Home Health and social care National Health Service Digital and data-driven health and care technology Departmentof Health &Social Care Guidance A guide to good practice for digital and data-driven health technologies Updated 19 January 2021 Contents Introduction 1."
192,"Cancel Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments News Guidance and regulation Research and statistics Policy papers and consultations Transparency How government works Get involved Support links Help Privacy Cookies Accessibility statement Contact Terms and conditions Rhestr o Wasanaethau Cymraeg Government Digital Service All content is available under the Open Government Licence v3.0, except where otherwise stated © Crown copyright"
193,"Accept additional cookies Reject additional cookies View cookies Hide cookie message Skip to main content GOV.UK Navigation menu Menu Menu Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments Departments, agencies and public bodies News News stories, speeches, letters and notices Guidance and regulation Detailed guidance, regulations and rules Research and statistics Reports, analysis and official statistics Policy papers and consultations Consultations and strategy Transparency Data, Freedom of Information releases and corporate reports Search GOV.UK × Search GOV.UK Search Search GOV.UK Search Home Health and social care National Health Service Digital and data-driven health and care technology Departmentof Health &Social Care Guidance A guide to good practice for digital and data-driven health technologies Updated 19 January 2021 Contents Introduction 1."
193,"Cancel Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments News Guidance and regulation Research and statistics Policy papers and consultations Transparency How government works Get involved Support links Help Privacy Cookies Accessibility statement Contact Terms and conditions Rhestr o Wasanaethau Cymraeg Government Digital Service All content is available under the Open Government Licence v3.0, except where otherwise stated © Crown copyright"
205,"Our results reveal a global convergence emerging around five ethical principles (transparency, justice and fairness, non-maleficence, responsibility and privacy), with substantive divergence in relation to how these principles are interpreted; why they are deemed important; what issue, domain or actors they pertain to; and how they should be implemented."
205,"Protecting individuals’ privacy and data in the artificial intelligence world Intel Corporation USA Introducing Unity’s Guiding Principles for Ethical AI – Unity Blog Unity Technologies USA Digital Decisions Center for Democracy & Technology USA Science, Law and Society (SLS) Initiative The Future Society USA AI Now 2018 Report AI Now Institute USA Responsible bots: 10 guidelines for developers of conversational AI Microsoft USA Preparing for the future of Artificial Intelligence Executive Office of the President; National Science and Technology Council; Committee on Technology USA The National Artificial Intelligence Research and Development Strategic Plan National Science and Technology Council; Networking and Information Technology Research and Development Subcommittee USA 5 AI Now 2017 Report AI Now Institute USA Position on Robotics and Artificial Intelligence The Greens (Green Working Group Robots) EU Report with recommendations to the Commission on Civil Law Rules on Robotics European Parliament EU Ethics Guidelines for Trustworthy AI High-Level Expert Group on Artificial Intelligence EU AI4People—An Ethical Framework for a Good AI Society: Opportunities, Risks, Principles, and Recommendations AI4People EU European ethical Charter on the use of Artificial Intelligence in judicial systems and their environment Concil of Europe: European Commission for the efficiency of Justice (CEPEJ) EU Statement on Artificial Intelligence, Robotics and 'Autonomous' Systems European Commission, European Group on Ethics in Science and New Technologies EU Artificial Intelligence and Machine Learning: Policy Paper Internet Society international Report of COMEST on Robotics Ethics COMEST/UNESCO international Ethical Principles for Artificial Intelligence and Data Analytics Software & Information Industry Association (SIIA), Public Policy Division international ITI AI Policy Principles Information Technology Industry Council (ITI) international Ethically Aligned Design."
205,"These are, by frequency of the number of sources in which they were featured: transparency, justice and fairness, non-maleficence, responsibility, privacy, beneficence, freedom and autonomy, trust, dignity, sustainability, and solidarity (cf."
205,"7 Table 2 – Ethical principles identified in existing AI guidelines Ethical principle Number of documents Included codes Transparency 73/84 Transparency, explainability, explicability, understandability, interpretability, communication, disclosure, showing Justice & fairness 68/84 Justice, fairness, consistency, inclusion, equality, equity, (non-)bias, (non-)discrimination, diversity, plurality, accessibility, reversibility, remedy, redress, challenge, access and distribution Non-maleficence 60/84 Non-maleficence, security, safety, harm, protection, precaution, prevention, integrity (bodily or mental), non-subversion Responsibility 60/84 Responsibility, accountability, liability, acting with integrity Privacy 47/84 Privacy, personal or private information Beneficence 41/84 Benefits, beneficence, well-being, peace, social good, common good Freedom & autonomy 34/84 Freedom, autonomy, consent, choice, self-determination, liberty, empowerment Trust 28/84 Trust Sustainability 14/84 Sustainability, environment (nature), energy, resources (energy) Dignity 13/84 Dignity Solidarity 6/84 Solidarity, social security, cohesion No single ethical principle appeared to be common to the entire corpus of documents, although there is an emerging convergence around the following principles: transparency, justice and fairness, non-maleficence, responsibility, and privacy."
205,"Justice, fairness, and equity Justice is mainly expressed in terms of fairness23,25,27–29,48,50,58,60,66,72–77, and of prevention, monitoring or mitigation of unwanted bias23,28,33,40,47,52,54,58,64,69,73,74,78–80 and discrimination28,33,36,38,44,45,50,55,56,60,68,81–84, the latter being significantly less referenced than the first two by the private sector."
205,"Whereas some sources focus on justice as respect for diversity31,38,56,59,65,66,70,72,78,80,85,86, inclusion31,45,47,51,72,80 and equality41,45,51,59,60,72,78, others call for a possibility to appeal or challenge decisions28,35–37,74,79, or the right to redress33,42,45,46,50,68,85 and remedy45,48."
205,"9 If specified, the preservation and promotion of justice are proposed to be pursued through: (a) technical solutions such as standards50,68,89 or explicit normative encoding28,37,43,67; (b) transparency54,62, notably by providing information36,38,79 and raising public awareness of existing rights and regulation28,59; (c) testing52,58,67,69, monitoring54,56 and auditing39,46,50,67, the preferred solution of notably data protection offices; (d) developing or strengthening the rule of law and the right to appeal, recourse, redress, or remedy37,38,42,45,46,48,68,74,79; (e) via systemic changes and processes such as governmental action42,45,87,92 and oversight94, a more interdisciplinary47,65,85,93 or otherwise diverse58,59,70,85,87,95 workforce, as well as better inclusion of civil society or other relevant stakeholders in an interactive manner28,33,41,46,55,57,58,65,68,69,79,80,86 and increased attention to the distribution of benefits25,33,38,48,63,76."
205,"Our analysis shows the emergence of an apparent cross-stakeholder convergence on promoting the ethical principles of transparency, justice, non-maleficence, responsibility, and privacy."
205,"Although no single ethical principle is explicitly endorsed by all existing guidelines, transparency, justice and fairness, non-maleficence, responsibility and privacy are each referenced in more than half of all guidelines."
205,"In particular, the prevalence of calls for transparency, justice and fairness points to an emerging moral priority to require transparent processes throughout the entire AI continuum (from transparency in the development and design of algorithms to transparent practices for AI use), and to caution the global community against the risk that AI might increase inequality if justice and fairness considerations are not adequately addressed."
205,"Both these themes appear to be intertwined with the theme of responsibility, as the promotion of both transparency and justice seems to postulate increased responsibility and accountability on the side of AI makers and deployers."
205,Justice and Justification: Reflective Equilibrium in Theory and Practice.
205,"Associa-tion/Society 26-Feb-2019 self Manual in-clusion European ethical Charter on the use of Artificial Intelligence in judicial systems and their environment ""The five principles of the Ethical Char-ter on the Use of Artificial Intelli-gence in Judicial Systems and their environment"" Concil of Europe: Eu-ropean Commission for the efficiency of Justice (CEPEJ) EU IGO/supra-na-tional xx-Feb-2019 multiple (public and private stakeholders) Manual in-clusion Ethically Aligned De-sign: A Vision for Pri-oritizing Human Well-being with Autono-mous and Intelligent Systems, First Edition (EAD1e) General Principles Institute of Electrical and Electronics Engi-neers (IEEE), The IEEE Global Initiative on Ethics of Autono-mous and Intelligent Systems interna-tional Prof."
205,"Justice, Fairness & Equity VIII."
205,Discrimination (duplicate in Justice&Fairness) VI.
210,"Apply EUR-Lex Access to European Union law This document is an excerpt from the EUR-Lex website You are here EUROPA EUR-Lex home EUR-Lex - 52021DC0118 - EN Help Print Menu EU law Treaties Treaties currently in force Founding Treaties Accession Treaties Other treaties and protocols Chronological overview Legal acts Consolidated texts International agreements Preparatory documents EFTA documents Lawmaking procedures Summaries of EU legislation Browse by EU institutions European Parliament European Council Council of the European Union European Commission Court of Justice of the European Union European Central Bank European Court of Auditors European Economic and Social Committee European Committee of the Regions Browse by EuroVoc EU case-law Case-law Reports of cases Directory of case-law Official Journal Access the Official Journal Official Journal L series daily view Official Journal C series daily view Browse the Official Journal Legally binding printed editions Special editions National law and case-law National transposition National case-law JURE case-law Information Themes in focus EUR-Lex developments Statistics ELI register About ELI Technical information ELI implementation overview Resources for implementing ELI ELI highlights ELI testimonials Legislation in schema.org EU budget online Quick search Use quotation marks to search for an ""exact phrase""."
210,"Using Green Public Procurement criteria 34 can boost demand for a green digital transformation The digital transformation should also enable modern and efficient justice systems 35 , enforcement of consumer rights and an increased effectiveness of public action including law enforcement and investigation capacities 36 – what is illegal offline is also illegal online, and law enforcement must be best equipped to deal with more and more sophisticated digital crimes."
210,"The digital principles are rooted in primary EU law, notably the Treaty on European Union (TEU), the Treaty on the Functioning of the European Union (TFEU), the Charter of Fundamental Rights and the case-law of the Court of Justice of the European Union, as well as in secondary legislation 37 ."
210,"(34) https://ec.europa.eu/environment/gpp/eu_gpp_criteria_en.htm (35) Communication from the Commission on the Digitalisation of justice in the European Union A toolbox of opportunities, COM(2020) 710 final."
210,Help pages Contact Sitemap Follow us X Legal Legal notice Cookies policy Accessibility Privacy statement Information About EUR-Lex Newsletter Useful links Other services European Data EU tenders EU research results EU Whoiswho EU publications N-Lex EU Law Tracker Discover more on europa.eu Contact the EU Call us 00 800 6 7 8 9 10 11 Use other telephone options Write to us via our contact form Meet us at one of the EU centres Social media Search for EU social media channels Legal Languages on our websites Privacy policy Legal notice Cookies EU institutions European Parliament European Council Council of the European Union European Commission Court of Justice of the European Union (CJEU) European Central Bank (ECB) European Court of Auditors European External Action Service (EEAS) European Economic and Social Committee European Committee of Regions (CoR) European Investment Bank European Ombudsman European Data Protection Supervisor (EDPS) European Data Protection Board European Personnel Selection Office Publications Office of the European Union Agencies Switch to mobile Switch to desktop
213,"The Member States share a ""society in which pluralism, non -discrimination, tolerance, justice, solidarity and equality between women and men prevail."" 3 Launching a European initi ative on AI In May 2017, the Commission published its mid-term review of the Digital Single Market strategy6."
213,"This includes in vestments in projects in key application areas such as health, connected and automated driving, agriculture, manufacturing, energy, next generation internet technologies, security and public administrations (including justice)."
219,"These values are common to the societ ies of all Member States in which pluralism, non -discrimination, tolerance, justice, solidarity and equality prevail."
224,"In Tajikistan, the Support to Civil Registry System Reform project, which received financial support from the EU, aims at improving the civil registry system in cooperation with the government – specifically, the Ministries of Justice, Health and Education7."
224,"It strives to help others increase the effective use of technology and cut costs for further social change, equality, justice, human rights, good governance and accountability. https://www.theengineroom.org/ ●The EU Gender Action Plan (GAP) III provides an agenda for gender equality and women’s empowerment in EU external action, including a policy framework for the EU. https://eur-lex.europa.eu/legal-content/EN/ TXT/?uri=CELEX%3A52020JC0017&qid=1617813800070 ●The European Democracy Action Plan aims to empower citizens and build more resilient democracies across the EU. https://eur-lex. europa.eu/legal-content/EN/TXT/?uri=COM%3A2020%3A790%3AFIN& qid=1607079662423 ●HIVOS is a development aid organisation based in the Netherlands that provides financial support to organisations in Africa, Latin America and Asia."
224,"It focuses on civil rights, climate justice, gender equality, diversity and inclusion. https://hivos.org/ ●The Institute for Technology and Society of Rio de Janeiro (ITS Rio), Brazil, is a non-profit organisation with a team of professors and researchers from different academic institutions that advocate for privacy, freedom of expression and access to knowledge, focusing on the debate on technology, the internet and their regulation. https://itsrio.org/ en/en-home/ ●The International Federation for Human Rights is a globally active NGO, supporting local actors and organisations to address human rights abuse and further democratic processes. https://www.fidh.org/en/ ●Intervozes is an organisation that works for the realisation of the human right to communication in Brazil, fighting for the right to communication, freedom of expression, democratic media, and a free and plural internet. https://intervozes.org.br ●Robert Krimmer is a professor of e-governance at the University of Tartu in Estonia and Tallinn University of Technology."
229,"""Why Machine Learning May Lead to Unfairness: Evidence from Risk Assessment for Juvenile Justice in Catalonia"", Best Paper Award, International Conference on AI and Law , 2019 Certain AI programmes for facial analysis display gender and racial bias, demonstrating low errors for determining the gender of lighter -skinned men but high errors in determining gender for darker -skinned women ."
229,Individuals and legal entities may face difficulties with effective access to justice in situations where such decisions may negatively affect them .
229,"This is without prejudice to the question whether, for the purpose of liability to end -users or other parties suffering harm and ensuring effective access to justice, which party should be liable for any damage caused ."
230,"Assessment List for Trustworthy AI (ALTAI) 27 Fairness: Fairness refers to a variety of ideas known as equity, impartiality, egalitarianism, non-discrimination and justice."
231,"Acknowledge and address the potential tensions between th ese principles.  Pay particular attention to situations involving more vulnerable groups such as children , persons with disabilities and others that have historically been disadvantaged or are at risk of exclusion , and to situations which are characterised by asymmetries of power or information, such as between employers and workers , or between businesses and consumers.2  Acknowledge that , while bringing substantial benefits to individuals and society, AI systems also pose certain risks and may have a negative impact , including impacts which may be difficult to anticipate, identify or measure (e.g. on democracy, the rule of law and distributive justice , or on the human mind itself .) Adopt adequate measures to mitigate these risks when appropriate, and proportionately to the magnitude of the risk."
231,"10 by reference to dignity, freedoms, equality and solidarity, citizens’ rights and justice."
231,"Respect for democracy, justice and the rule of law ."
231,"Additionally, fairness implies that AI practitioners should respect the principle of proportionality between means and ends, and consider carefully how to Fairness is closel y linked to the rights to Non -discrimination, Solidarity and Justice (reflected in Articles 21 and following)."
231,Explicability and Responsibility are closely linked to the rights relating to Justice (as reflected in Article 47).
231,"14  Acknowledge that, while bringing substantial benefits to individuals and society, AI systems also pose certain risks and may have a negative impact, including impacts which may be difficult to anticipate, identify or measure (e.g. on democracy, the rule of law and distributive justice, or on the human mind itself.) Adopt adequate measu res to mitigate these risks when appropriate, and proportionately to the magnitude of the risk."
231,"In general terms , it deals with questions like “What is a good action?”, “What is the value of a human life?”, “What is justice?”, or “What is the good life?”."
233,Access to justice and effective redress are key elements of building consumer trust and thus are an important part of Trustworthy AI.
236,Justice and Consumersand other emerging digital technologiesLiability for Artificial Intelligence Report from the Expert Group on Liability and New Technologies – New Technologies Formation This document was written by the Expert Group on Liability and New Technologies – New Technologies Formation.
236,"(b) a coherent and appropriate response of the legal system to threats to the interests of individuals, in particular because victims of harm caused by the operation of emerging digital technologies receive less or no compensation compared to victims in a functionally equivalent situation involving human conduct and conventional technology; (c) effective access to justice, in particular because litigation for victims becomes unduly burdensome or expensive."
236,"71 See also the variety of causes of action in the Czech Civil Code (< http:// obcanskyzakonik.justice.cz/ images / pdf/ Civil -Code.pdf >): Article 2924 (damage caused by an operating gainful activity unless all reasonable care exercised), Article 2925 (damage caused by a particularly hazardous operation, ‘if the possibility of serious damage cannot be reasonably excluded in advance even by exercising due care’), Article 2937 (damage caused by a thing, though with a reversal of the bu rden of proof that the defendant had properly supervised it)."
236,"(b) a coherent and appropriate response of the legal system to threats to the interests of individuals, in particular because victims of harm caused by the operation of emerging digital technologies receive less or no compensation compared to victims in a functionally equivalent situation involving human cond uct and conventional technology; (c) effective access to justice, in particular because litigation for victims becomes unduly burdensome or expensive."
236,Impact o f these ch allenges and need fo r action New Technologies Formation 35 corrective justice argument and an argument about providing the right incentives to avoid harm.
236,This again translates into arguments both of corrective justice and of the right incentives.
236,"The application of traditional liability rules may also lead to unsatisfactory results because, while the victim might theoretically receive compensation, litigation would be unduly burdensome and expensive , leaving them without effective access to justice."
239,"39% 56%5% Yes No Don't know For example, in The Netherlands , the Ministry of Justice and Safety now has a number of people working in the Justice and Law Enforcement department tasked on focusing on AI."
239,"2020 37 As presented at the Data Justice Lab in 2019 on AI Realism and structural alternatives 50 With that purpose in mind, one should consider how existing data governan ce regimes and national regulatory practices can be transforming and not just intensifying existing power asymmetries ."
239,"As an example, the strategy highlights the use of hackathons in the justice domain to develop AI solutions for concrete policy issues."
239,A number of policy do mains where the Dutch government is exploring the use of AI or will stimulate other ac tors to use AI in their fields are mention ed and are listed below :  The use of AI in the field of security and justice.
239,"A good starting point can be Article 2 of the Treaty on the European Union, which defines the values on which the Union is founded and are common to the Member States as ‘a society in which pluralism, non discrimination, tolerance, justice, solidarity an d equality between women and men prevail ’51 An additional set of shared European values (rights and freedoms) is defined by the Charter of Fundamental Rights of the European Union52 and only apply in cases where Member States implement EU regulation directly or transpose it into national legislation."
239,"In addition, there are also preventive administrative measures, such as the decision of the Belgian police regulator to forbid piloting the use of face recognition technology at the Zaventem ai rport57 ; or the negative advice by the French data protection regulator regarding two pilots using facial recognition technology in French schools58; or the cease and desist letter issued by the French data protection regulator to the French Ministry of the Interior regarding the use of Automatic number plate recognition (ANPR) systems 59 54 http://www.sigmaweb.org/publications/principles -public -administration.htm 55 https://www.europarl.europa.eu/charter/pdf/text_en.pdf 56 The French Justice Reform Act, Article 33, https://www.legifrance.gouv.fr/affichTexteArticle.do;jsessionid=98B09D0394DAE57F1618DC21F30405F6.tplgfr34s_1?idArticle=JORFAR TI 000038261761&categorieLien=id&cidTexte=JORFTEXT000038261631&dateTexte = 57 https://www.vrt.be/vrtnws/nl/2019/09/20/politie -mag-geen-automatische -gezichtsherkenning -gebruiken -op-de 58 https://www.cnil.fr/fr/experimentation -de-la-reconnaissance -faciale -dans-deux-lycees -la-cnil-precise -sa-position 59 https://www.cnil.fr/fr/radars -troncons -mise-en-demeure -du-ministere -de-linterieur 74 In our initial framework it is thus proposed to consider the multiple elements of AI in public services that can be grouped into macro -areas labelled as: Digital Infrastruct ure, Organisation al Resources, Digital Government Development and Digital Society Development, as described in Figure 16 below."
241,"Moreover, a few specific cases, mentioned as running at the time of first gathering, were later found to have been discontinued because of various reasons , including significant criticism received from the general public , pressure from adversarial political forces or even executive orders from local courts of criminal justice."
241,"Adequate security safeguards should be put in place to avoid potential abuse. — Fairness and justice : The development of AI should promote fairness and justice, the rights a nd interests of stakeholders and promote equality of opportunity."
241,"Previous research had analyse d 84 ethical AI documents published by various business es, NGOs and (international) governmental organizations, highlight ing that some principles such as tra nsparency, fairness, justice, and responsibility were quite common in all."
241,The impact of using algorithms for managerial decisions on public employees’ procedural justice.
243,"To further ensure trustworthy AI, most governments are adopting new legislative frameworks for AI technologies , which are often sector specific and cover areas such as autonomous driving, healthcare and e -justice."
243,"The Federal Ministry also highlights the use of AI for evaluating judicial proceedings, as mentioned in its National e -justice strategy ."
243,"The six principles for AI relate to self -determination (i.e. ensuring that citizens can make informed and independent decisions) and to human dignity, equality and justice (i.e. ensuring that there is no infringement of human rights and maintaining respec t for diversity)."
243,"In addition, public sector operators should be secured sufficient resources and i ncentives to engage in such development, paying particular attention to sort out the rights of the outcomes of co -development;  The Ministry of Justice and the Ministry of Finance are currently examining national regulation of automated decision -making."
243,"5.13.4 Regulation Hungary’s nationa l AI strategy aims to ensure a responsible, reliable and human -centred utilisation of AI technologies by means of the following policies:  Creating an ethical framework : developing an AI code of conduct by the first half of 2021 in collaboration between the Ministry of Justice, the Ministry for Innovation and Technology, AI Innovation Hub and the Central Statistical Office ;  Setting up an Artificial Intelligence Regulation and Ethics Knowledge Centre : the aim is to create and coordinate an extensive pool of experts to help resolve legal issues and matters of ethics relating to the regulation of AI and the implementation of the strategy ;  Establishing a regulatory framework for AI: t he obje ctive is to amen d the current regulatory system to suit AI and to align it to EU regulations ;  Building data management regulation : the objective is to set up regulations for the use and exchange of public and private data and to define rules regarding d ata monetisation."
243,"The Latvian strategy identifies priority sectors with a high potential for AI applicatio ns in the country, such as transport (Intelligent transport systems), culture, justice (AI as support for decision making and drafting legislation), agriculture (automated control), and translation."
243,"Regarding ethics, the government adopts the European ethical guidelines outlined by the European Commission for the Efficiency of Justice."
243,"66 1) International bodies and AI, 2) Swiss intelligence of interests in the European AI (Digital Europe Programme) activities, 3) Changes in the world of work, 4) AI in industry and services, 5) AI in education, 6) A pplication of AI in science and research, 7) AI in cybersecurity and security policy, 8) AI, Media & Public, 9) Automated mobility and AI, 10) AI in healthcare, 11) AI in the financial secto r, 12) AI in agriculture, 13) Energy, climate, environment and AI, 14) AI in administration, 15) Further development of the general legal framework on AI, 16) AI in justice, 17) AI, data and intellectual property law."
243,"While the establishment of the legal basis is ensured by a wide range of institutions, the FDFA will specifically focus on the following policies to further develop the general legal framework on AI:  Examining the emergence of AI -specific international law and its impac t on Switzerland;  Following -up developments with regard to the visibility of AI systems in interaction with consumers;  Monitoring developments in AI -based decision -making in the justice system (predictive justice)."
244,"To further ensure trustworthy AI, most governments are adopting new legislative frameworks for AI technologies , which are often sector specific and cover areas such as autonomous driving, healthcare and e -justice."
244,"The Federal Ministry also highlights the use of AI for evaluating judicial proceedings, as mentioned in its National e -justice strategy ."
244,"The six principles for AI relate to self -determination (i.e. ensuring that citizens can make informed and independent decisions) and to human dignity, equality and justice (i.e. ensuring that there is no infringement of human rights and maintaining respec t for diversity)."
244,"In addition, public sector operators should be secured sufficient resources and i ncentives to engage in such development, paying particular attention to sort out the rights of the outcomes of co -development;  The Ministry of Justice and the Ministry of Finance are currently examining national regulation of automated decision -making."
244,"5.13.4 Regulation Hungary’s nationa l AI strategy aims to ensure a responsible, reliable and human -centred utilisation of AI technologies by means of the following policies:  Creating an ethical framework : developing an AI code of conduct by the first half of 2021 in collaboration between the Ministry of Justice, the Ministry for Innovation and Technology, AI Innovation Hub and the Central Statistical Office ;  Setting up an Artificial Intelligence Regulation and Ethics Knowledge Centre : the aim is to create and coordinate an extensive pool of experts to help resolve legal issues and matters of ethics relating to the regulation of AI and the implementation of the strategy ;  Establishing a regulatory framework for AI: t he obje ctive is to amen d the current regulatory system to suit AI and to align it to EU regulations ;  Building data management regulation : the objective is to set up regulations for the use and exchange of public and private data and to define rules regarding d ata monetisation."
244,"The Latvian strategy identifies priority sectors with a high potential for AI applicatio ns in the country, such as transport (Intelligent transport systems), culture, justice (AI as support for decision making and drafting legislation), agriculture (automated control), and translation."
244,"Regarding ethics, the government adopts the European ethical guidelines outlined by the European Commission for the Efficiency of Justice."
244,"66 1) International bodies and AI, 2) Swiss intelligence of interests in the European AI (Digital Europe Programme) activities, 3) Changes in the world of work, 4) AI in industry and services, 5) AI in education, 6) A pplication of AI in science and research, 7) AI in cybersecurity and security policy, 8) AI, Media & Public, 9) Automated mobility and AI, 10) AI in healthcare, 11) AI in the financial secto r, 12) AI in agriculture, 13) Energy, climate, environment and AI, 14) AI in administration, 15) Further development of the general legal framework on AI, 16) AI in justice, 17) AI, data and intellectual property law."
244,"While the establishment of the legal basis is ensured by a wide range of institutions, the FDFA will specifically focus on the following policies to further develop the general legal framework on AI:  Examining the emergence of AI -specific international law and its impac t on Switzerland;  Following -up developments with regard to the visibility of AI systems in interaction with consumers;  Monitoring developments in AI -based decision -making in the justice system (predictive justice)."
247,"URL: https://standards.ieee.org/content/dam/ie ee-standards/standards/web/documents/other/eadv2_glossary.pdf Equity By definition, equity is concerned with justice."
247,"URL: https://www.iso.org/obp/ui/fr/#iso:std:iso iec:22989:dis:ed -1:v1:en 3.6 F Fairness Fairness refers to a variety of ideas known as equity, impartiality, egalitarianism, non -discrimination and justice."
247,"URL: http://www.inc ompleteideas.net/book/ebook/the -book.html Rights That which is considered proper, correct, or consonant with justice, and related uses; The standard of permitted and forbidden action within a particular sphere."
25,"1.Core​ ​public​ ​agencies,​ ​such​ ​as​ ​those​ ​responsible​ ​for​ ​criminal​ ​justice,​ ​healthcare, welfare,​ ​and ​ ​education ​ ​(e.g​ ​“high ​ ​stakes”​ ​domains) ​ ​should ​ ​no ​ ​longer​ ​use​ ​“black​ ​box” AI​ ​and ​ ​algorithmic​ ​systems.​​ ​This​ ​includes​ ​the​ ​unreviewed​ ​or​ ​unvalidated​ ​use ​ ​of pre-trained​ ​models,​ ​AI​ ​systems​ ​licensed​ ​from​ ​third​ ​party​ ​vendors, ​ ​and​ ​algorithmic processes​ ​created​ ​in-house.​ ​The ​ ​use​ ​of​ ​such​ ​systems​ ​by​ ​public​ ​agencies​ ​raises​ ​serious due​ ​process​ ​concerns, ​ ​and​ ​at​ ​a​ ​minimum​ ​they​ ​should​ ​be ​ ​available​ ​for​ ​public​ ​auditing, testing,​ ​and​ ​review, ​ ​and​ ​subject​ ​to​ ​accountability​ ​standards."
25,"Expand ​ ​ AI ​ ​ bias ​ ​ research ​ ​ and ​ ​ mitigation ​ ​ strategies ​ ​ beyond ​ ​ a ​ ​ narrowly ​ ​ technical approach. ​ ​ ​ Bias ​ ​ issues ​ ​ are ​ ​ long ​ ​ term ​ ​ and ​ ​ structural, ​ ​ and ​ ​ contending ​ ​ with ​ ​ them necessitates ​ ​ deep ​ ​ interdisciplinary ​ ​ research. ​ ​ Technical ​ ​ approaches ​ ​ that ​ ​ look ​ ​ for ​ ​ a one-time ​ ​ “fix” ​ ​ for ​ ​ fairness ​ ​ risk ​ ​ oversimplifying ​ ​ the ​ ​ complexity ​ ​ of ​ ​ social ​ ​ systems. ​ ​ Within each ​ ​ domain ​ ​ – ​ ​ such ​ ​ as ​ ​ education, ​ ​ healthcare ​ ​ or ​ ​ criminal ​ ​ justice ​ ​ – ​ ​ legacies ​ ​ of ​ ​ bias ​ ​ and movements ​ ​ toward ​ ​ equality ​ ​ have ​ ​ their ​ ​ own ​ ​ histories ​ ​ and ​ ​ practices. ​ ​ Legacies ​ ​ of ​ ​ bias cannot ​ ​ be ​ ​ “solved” ​ ​ without ​ ​ drawing ​ ​ on ​ ​ domain ​ ​ expertise. ​ ​ Addressing ​ ​ fairness meaningfully ​ ​ will ​ ​ require ​ ​ interdisciplinary ​ ​ collaboration ​ ​ and ​ ​ methods ​ ​ of ​ ​ listening ​ ​ across different ​ ​ disciplines."
25,"AI ​ ​ Now ​ ​ 2017 ​ ​ Report 7 that ​ ​ help ​ ​ to ​ ​ better ​ ​ understand ​ ​ and ​ ​ mitigate ​ ​ biases ​ ​ that ​ ​ AI ​ ​ systems ​ ​ may ​ ​ perpetuate ​ ​ and even ​ ​ amplify ​ ​ due ​ ​ to ​ ​ biased ​ ​ training ​ ​ data, ​ ​ faulty ​ ​ algorithms ​ ​ or ​ ​ other ​ ​ factors. ​ ​ The ​ ​ third section, ​ ​ on ​ ​​ Rights ​ ​ and ​ ​ Liberties ​ , ​ ​ begins ​ ​ by ​ ​ recognizing ​ ​ the ​ ​ recent ​ ​ rise ​ ​ of ​ ​ political authoritarianism, ​ ​ and ​ ​ asks ​ ​ about ​ ​ the ​ ​ role ​ ​ of ​ ​ AI ​ ​ systems ​ ​ in ​ ​ either ​ ​ supporting ​ ​ or ​ ​ eroding citizens’ ​ ​ rights ​ ​ and ​ ​ liberties ​ ​ in ​ ​ areas ​ ​ like ​ ​ criminal ​ ​ justice, ​ ​ law ​ ​ enforcement, ​ ​ housing, ​ ​ hiring, lending ​ ​ and ​ ​ other ​ ​ domains. ​ ​ The ​ ​ last ​ ​ section, ​ ​ on ​ ​​ Ethics ​ ​ and ​ ​ Governance ​ , ​ ​ connects ​ ​ AI ​ ​ as ​ ​ we see ​ ​ it ​ ​ today ​ ​ with ​ ​ the ​ ​ history ​ ​ of ​ ​ AI ​ ​ research ​ ​ and ​ ​ development. ​ ​ It ​ ​ also ​ ​ looks ​ ​ at ​ ​​ whose concerns ​ ​ are ​ ​ ultimately ​ ​ reflected ​ ​ in ​ ​ the ​ ​ ethics ​ ​ of ​ ​ AI, ​ ​ and ​ ​ how ​ ​ ethical ​ ​ codes ​ ​ and ​ ​ other strategies ​ ​ could ​ ​ be ​ ​ developed ​ ​ in ​ ​ a ​ ​ time ​ ​ of ​ ​ political ​ ​ volatility."
25,"The ​ ​ danger ​ ​ of ​ ​ bias ​ ​ increases ​ ​ when ​ ​ these ​ ​ systems ​ ​ are ​ ​ applied, ​ ​ often ​ ​ in ​ ​ non-transparent ways, ​ ​ to ​ ​ critical ​ ​ institutions ​ ​ like ​ ​ criminal ​ ​ justice ​ ​ and ​ ​ healthcare. ​ ​ The ​ ​ social ​ ​ sciences ​ ​ and critical ​ ​ humanities ​ ​ have ​ ​ decades ​ ​ of ​ ​ research ​ ​ on ​ ​ bias ​ ​ within ​ ​ social ​ ​ systems ​ ​ that ​ ​ have ​ ​ much to ​ ​ offer ​ ​ the ​ ​ current ​ ​ debate ​ ​ on ​ ​ bias ​ ​ in ​ ​ AI ​ ​ and ​ ​ algorithmic ​ ​ systems. ​ ​ Since ​ ​​ AI ​ ​ Now ​ ​ ​ is ​ ​ deeply 37 interested ​ ​ in ​ ​ the ​ ​ social ​ ​ and ​ ​ political ​ ​ implications ​ ​ of ​ ​ AI, ​ ​ this ​ ​ report ​ ​ will ​ ​ use ​ ​ the ​ ​ word ​ ​ “bias” in ​ ​ its ​ ​ broader, ​ ​ normative ​ ​ sense ​ ​ in ​ ​ the ​ ​ following ​ ​ section, ​ ​ while ​ ​ acknowledging ​ ​ its ​ ​ close relationship ​ ​ with ​ ​ statistical ​ ​ usages."
25,AI ​ ​ Now ​ ​ 2017 ​ ​ Report 22 they ​ ​ might ​ ​ be ​ ​ used ​ ​ within ​ ​ populist ​ ​ and ​ ​ authoritarian ​ ​ contexts. ​ ​ What ​ ​ effects ​ ​ will ​ ​ these 96 systems ​ ​ have ​ ​ on ​ ​ vulnerable ​ ​ individuals ​ ​ and ​ ​ minorities? ​ ​ How ​ ​ will ​ ​ AI ​ ​ systems ​ ​ be ​ ​ used ​ ​ by ​ ​ law enforcement ​ ​ or ​ ​ national ​ ​ security ​ ​ agencies? ​ ​ How ​ ​ will ​ ​ AI’s ​ ​ use ​ ​ in ​ ​ the ​ ​ criminal ​ ​ justice ​ ​ system affect ​ ​ our ​ ​ understanding ​ ​ of ​ ​ due ​ ​ process ​ ​ and ​ ​ the ​ ​ principle ​ ​ of ​ ​ equal ​ ​ justice ​ ​ under ​ ​ the ​ ​ law?
25,"While ​ ​ predictive ​ ​ policing ​ ​ and ​ ​ the ​ ​ use ​ ​ of ​ ​ force ​ ​ have ​ ​ always ​ ​ been ​ ​ important ​ ​ issues, ​ ​ they ​ ​ take on ​ ​ new ​ ​ salience ​ ​ in ​ ​ populist ​ ​ or ​ ​ authoritarian ​ ​ contexts. ​ ​ As ​ ​ AI ​ ​ systems ​ ​ promise ​ ​ new ​ ​ forms ​ ​ of technical ​ ​ efficiency ​ ​ in ​ ​ the ​ ​ service ​ ​ of ​ ​ safety, ​ ​ we ​ ​ may ​ ​ need ​ ​ to ​ ​ confront ​ ​ a ​ ​ fundamental tension ​ ​ between ​ ​ technological ​ ​ efficiency ​ ​ and ​ ​ a ​ ​ commitment ​ ​ to ​ ​ ideals ​ ​ of ​ ​ justice."
25,"Scholars ​ ​ like ​ ​ Kate ​ ​ Crawford ​ ​ and ​ ​ Jason ​ ​ Schultz ​ ​ have ​ ​ identified ​ ​ a ​ ​ series ​ ​ of ​ ​ conflicts ​ ​ between AI ​ ​ techniques ​ ​ and ​ ​ constitutional ​ ​ due ​ ​ process ​ ​ requirements, ​ ​ such ​ ​ as ​ ​ how ​ ​ AI ​ ​ techniques 123 affect ​ ​ procedural ​ ​ considerations ​ ​ and ​ ​ equal ​ ​ justice ​ ​ under ​ ​ the ​ ​ law. ​ ​ The ​ ​ proliferation ​ ​ of predictive ​ ​ systems ​ ​ demands ​ ​ new ​ ​ regulatory ​ ​ techniques ​ ​ to ​ ​ protect ​ ​ legal ​ ​ rights. ​ ​ Danielle Citron ​ ​ and ​ ​ Frank ​ ​ Pasquale ​ ​ argue ​ ​ that ​ ​ safeguards ​ ​ to ​ ​ rights ​ ​ should ​ ​ be ​ ​ introduced ​ ​ at ​ ​ all ​ ​ stages of ​ ​ the ​ ​ implementation ​ ​ of ​ ​ an ​ ​ AI ​ ​ system, ​ ​ from ​ ​ safeguarding ​ ​ privacy ​ ​ rights ​ ​ in ​ ​ data ​ ​ collection to ​ ​ public ​ ​ audits ​ ​ of ​ ​ scoring ​ ​ systems ​ ​ that ​ ​ critically ​ ​ affect ​ ​ the ​ ​ public ​ ​ in ​ ​ areas ​ ​ like ​ ​ employment and ​ ​ healthcare."
25,"130 The ​ ​ criminal ​ ​ justice ​ ​ system’s ​ ​ implementation ​ ​ of ​ ​ risk ​ ​ assessment ​ ​ algorithms ​ ​ provides ​ ​ an example ​ ​ of ​ ​ the ​ ​ legal ​ ​ system’s ​ ​ use ​ ​ of ​ ​ AI ​ ​ and ​ ​ its ​ ​ attendant ​ ​ risks. ​ ​ Proponents ​ ​ of ​ ​ risk-based 131 sentencing ​ ​ argue ​ ​ that ​ ​ evidence-based ​ ​ machine ​ ​ learning ​ ​ techniques ​ ​ can ​ ​ be ​ ​ used ​ ​ in ​ ​ concert with ​ ​ the ​ ​ expertise ​ ​ of ​ ​ judges ​ ​ to ​ ​ improve ​ ​ the ​ ​ accuracy ​ ​ of ​ ​ prior ​ ​ statistical ​ ​ and ​ ​ actuarial methods ​ ​ for ​ ​ risk ​ ​ forecasting, ​ ​ such ​ ​ as ​ ​ regression ​ ​ analysis. ​ ​ Along ​ ​ these ​ ​ lines, ​ ​ a ​ ​ recent 132 study ​ ​ by ​ ​ computer ​ ​ scientist ​ ​ Jon ​ ​ Kleinberg, ​ ​ Sendhil ​ ​ Mullainathan, ​ ​ and ​ ​ their ​ ​ co-authors showed ​ ​ that ​ ​ a ​ ​ predictive ​ ​ machine ​ ​ learning ​ ​ algorithm ​ ​ could ​ ​ be ​ ​ used ​ ​ by ​ ​ judges ​ ​ to ​ ​ reduce ​ ​ the number ​ ​ of ​ ​ defendants ​ ​ held ​ ​ in ​ ​ jail ​ ​ as ​ ​ they ​ ​ await ​ ​ trial ​ ​ by ​ ​ making ​ ​ more ​ ​ accurate ​ ​ predictions of ​ ​ future ​ ​ crimes."
25,"135 Rebecca ​ ​ Wexler, ​ ​ “Life, ​ ​ Liberty, ​ ​ and ​ ​ Trade ​ ​ Secrets: ​ ​ Intellectual ​ ​ Property ​ ​ in ​ ​ the ​ ​ Criminal ​ ​ Justice ​ ​ System,” ​ ​ SSRN ​ ​ preprint: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2920883 ​ ."
25,"137 Richard ​ ​ Berk, ​ ​ Hoda ​ ​ Heidari, ​ ​ Shahin ​ ​ Jabbari, ​ ​ Michael ​ ​ Kearns ​ ​ and ​ ​ Aaron ​ ​ Roth, ​ ​ “Fairness ​ ​ in ​ ​ Criminal ​ ​ Justice ​ ​ Risk ​ ​ Assessments: The ​ ​ State ​ ​ of ​ ​ the ​ ​ Art,” ​ ​ arXiv:1703.09207, ​ ​ March ​ ​ 27, ​ ​ 2017."
250,"Stephen Quest, Director-General, JRC Joost Korte, Director-General, Employment, Social Affairs and Inclusion Gwenole Cozigou, Director for Sustainable Industry and Mobility, DG GROW Roberto Viola, Director-General, Communications Networks, Content and Technology Paul Nemitz, Principal Advisor in the Directorate General for Justice and Consumers GETTING IN TOUCH WITH THE EU In person All over the European Union there are hundreds of Europe Direct information centres."
252,"49 http://ec.europa.eu/justice/citizen/document/files/2015_public_consultation_booklet_en.pdf , p."
252,"149 of Consumer protection policies, strategies and statistics http://ec.europa.eu/justice/consumer -marketing/files/ucp_guidance_en.pdf ."
252,"Article 6 of the Directive, http://ec.europa.eu/justice/consumer marketing/files/ucp_guidance_en.pdf , p."
252,"122 http://ec.europa.eu/justice/consumer -marketing/files/ucp_guidance_en.pdf , p."
252,Rules for the protection of personal data inside and outside the EU. http://ec.europa.eu/justice/dataprotection/files/factsheets/factsheet_data_protection_eurobarometer_240615_en.p df .
252,"The Court of Justice enshrined the right to effective remedy in its judgment of 15 May 1986 as a general principle of Union law (Case 222/84 Johnston [1986] ECR 1651; see also judgment of 15 October 1987, Case 222/86 Heylens [1987] ECR 4097 and judgment of 3 December 1992, Case C -97/91 Borelli [1992] ECR I -6313)."
252,"Notably, in the Recommendation on common principles for injunctive and compensatory collective redress mechanisms in the Member States concerning violations of rights granted under Union Law, the Commission determined that the recourse to opt -out collective redress mecha nisms may be justified “by reasons of sound administration of justice”, see Article 21, , Commission Recommendation of 11.06.2013 on common principles for injunctive and compensatory collective redress mechanisms in the Member States concerning violations of rights granted under Union Law (2013/396/EU) http://eur -lex.europa.eu/legal content/EN/TXT/?uri=OJ:JOL_2013_201_R_NS0013 ."
253,"In addition to strong enforcement of the General Data Protection Regulation (GDPR) and safeguards such as human rights impacts assessments, software transparency and the availability of datasets for public scrutiny, it is vital that the upcoming regulatory proposal establishes in law clear limitations a s to what can be considered lawful uses of AI , to unequivocally address the following issues: • the enabling of biometric m ass surveillance and monitori ng of public spaces; • the exacerbation of structural discrimination , exclusion and collective harms; • the restriction of and discriminatory access to vital services such as health -care and social security; • the surveillance of workers and infringement of workers’ fundamental rights; • the impeding of fair access to justice and procedural rights; • the use of systems which make inferences and predictions about our most sensitive characteristics, beha viours and thoughts; • and, crucially, the manipulation or control of human behaviour and associated threats to human dignity, agency, and collective democracy."
253,Use of risk assessment tools in the criminal justice system and pre -trial context The use of algorithms in criminal justice matters to profile individuals within legal decision -making processes presents seve re threats to fundamental rights.
253,"In addition, substantial evidence has shown that the introduction of such systems in criminal justice systems in Europe and elsewhere has resulted in unjust and discriminator y outcomes."
253,We argue that legal limits must be imposed on AI risk assessment systems in the criminal justice context.
253,"Legal restrictions or legislative red -lines on the uses which contravene fundamental rights, including, but not limited to, uses of AI at the border, predictive policing, systems which restrict access to social rights and benefits, and risk -assessment tool s in the criminal justice context; 3."
253,"Yours sincerely, European Digital Rights (EDRi), including: Access Now Bits of Freedom Chaos Computer Club D3 - Defesa dos Direitos Digitais Electronic Privacy Information Center (EPIC) Fitug Hermes Center Homo Digitalis IT-Pol Denmark Iuridicum Remedium Metamorphosis Foundation Panoptykon Foundation Privacy International Statewatch Other signatories: AI Now Institute, NYU Algorithm Watch Amnesty International App Drivers and Couriers Union (ADCU) Associazione Certi Diritti Associazione Luca Coscioni Associazione per gli Studi Giuridici sull'Immigrazione Big Brother Watch Center for Intersectional Justice (CIJ) Democratic Society Digitale Freiheit Dutch Section - International Commission of Jurists (NJCM) Each One Teach One (EOTO) e.V."
257,President: Pascal Pichonnaz First Vice-President: Lord John Thomas Second Vice-President: Anne Birgitte Gammeljord Treasurer: Pietro Sirena Speaker of the Senate: Reinhard Zimmermann Secretary-General: Vanessa Wilcox Scientific Director: Christiane Wendehorst ISBN: 978-3-9505192-7-3 © European Law Institute 2022 Cover image: ShutterstockThe European Law Institute This publication was co-funded by the European Union’s Justice Programme.
257,"21 Guiding Principle 8: No limitations to the exercise of rights and access to justice Automation shall not prevent, limit, or render unfeasible the exercise of rights and access to justice by affected persons."
257,"The provision of public services or the exercise of public functions likely to materially impact citizens’ rights and liberties should be subject to special regulatory scrutiny.10 Likewise, legislators may consider it unacceptable to admit fully automated dispute resolution as access to justice would thus be deprived of human intervention."
257,"Should damage or personal injuries be caused by an accident, a collision with buildings or windows, or by a drone crashing in a garden, the university, as the operator, bears the risk, without prejudice to the liability of the producer, if damage is caused by a defect of the product.Guiding Principle 8: No limitations to the exercise of rights and access to justice Automation shall not prevent, limit, or render unfeasible the exercise of rights and access to justice by affected persons."
257,"As a specific application of Guiding Principle 1, this Principle focuses on the risk that the exercise of rights by the affected person and effective access to justice may be prevented, hampered or limited by the inadequate use of automation."
257,"Second, where the affected person is deprived of the possibility of exercising a right or access to justice solely on the grounds that the contested decision was made by ADM."
258,"Other Legislation Convention on Access to Information, Public Participation in Decision-Making and Access to Justice in Environmental Matters (Aarhus Convention)."
258,What constitutes a sufficient interest and impairment of a right shall be determined consistently with the objective of giving the public concerned wide access to justice.
258,"Decision (2.6.) The term ‘decision’ is broader than typical definitions of administrative decision in national administrative procedure or administrative justice legislation (compare, eg, Article III-2 (1) of the ReNEUAL Model Rules)."
258,(16.5.) Paragraph 5 recalls some of the characteristics necessary for effective access to justice.
26,"AI Now produces interdisciplinary research to help ensure that AI systems are accountable to the communities and contexts they are meant to serve, and that they are applied in ways that promote justice and equity."
26,"Our workshop on Immigration, Data, and Automation in the Trump Era , co-hosted with the Brennan Center for Justice and the Center for Privacy and Technology at Georgetown Law, focused on the Trump Administration’s use of data harvesting, predictive analytics, and machine learning to target immigrant communities."
26,"Domains like health, education, criminal justice, and welfare all have their own histories, regulatory frameworks, and hazards."
26,"Facial recognition technology poses its own dangers, reinforcing skewed and potentially discriminatory practices, from criminal justice to education to employment, and presents risks to human rights and civil liberties in multiple countries."
26,"Yet, without a framework that accounts for social and political contexts and histories, these mathematical formulas for fairness will almost inevitably miss key factors, and can serve to paper over deeper problems in ways that ultimately increase harm or ignore justice."
26,Broadening perspectives and expanding research into AI fairness and bias beyond the merely mathematical is critical to ensuring we are capable of addressing the core issues and moving the focus from parity to justice.
26,"The following report develops these themes in detail, reﬂecting on the latest academic research, and outlines seven strategies for moving forward: 1.Expanding AI fairness research beyond a focus on mathematical parity and statistical fairness toward issues of justice 2.Studying and tracking the full stack of infrastructure needed to create AI, including accounting for material supply chains 3.Accounting for the many forms of labor required to create and maintain AI systems 4.Committing to deeper interdisciplinarity in AI 5.Analyzing race, gender, and power in AI 6.Developing new policy interventions and strategic litigation 7.Building coalitions between researchers, civil society, and organizers within the technology sector These approaches are designed to positively recast the AI ﬁeld and address the growing power imbalance that currently favors those who develop and proﬁt from AI systems at the expense of the populations most likely to be harmed."
26,1 There have been major movements from both inside and outside technology companies pushing for greater accountability and justice.
26,Facial recognition ampliﬁes civil rights concerns Concerns are intensifying that facial recognition increases racial discrimination and other biases in the criminal justice system.
26,"53 In its response to the ACLU, Amazon acknowledged that “the Rekognition results can be signiﬁcantly skewed by using a facial database that is not appropriately representative.” 54 Given the deep and historical racial biases in the criminal justice system, most law enforcement databases are unlikely to be “appropriately representative.” 55 Despite these serious ﬂaws, ongoing pressure from civil rights groups, and protests from Amazon employees over the potential for misuse of these technologies, Amazon Web Services CEO Andrew Jassy recently told employees that “we feel really great and really strongly about the value that Amazon Rekognition is providing our customers of all sizes and all types of industries in law enforcement and out of law enforcement.” 56 Nor is Amazon alone in implementing facial recognition technologies in unaccountable ways."
26,"17 1.2 The Risks of Automated Decision Systems in Government Over the past year, we have seen a substantial increase in the adoption of Automated Decision Systems (ADS) across government domains, including criminal justice, child welfare, education, and immigration."
26,"For years, criminal justice advocates and researchers have pushed for the elimination of cash bail, which has been shown to disproportionately harm individuals based on race and socioeconomic status while at the same time failing to enhance public safety."
26,"90 The shift from policies such as cash bail to automated systems and risk assessment scoring is still relatively new, and is proceeding even without substantial research examining the potential to amplify discrimination within the criminal justice system."
26,"91 Similarly, when California’s legislation passed earlier this year, many of the criminal justice advocates who pushed for the end of cash bail, and supported an earlier version of the bill, opposed its ﬁnal version due to the risk assessment requirement."
26,The National Association for the Advancement of Colored People (NAACP) and the Lawyers’ Committee for Civil Rights and 21 Economic Justice opposed the plan because of the school district’s failure to appreciate that parents of color and lower-income parents often rely on jobs that lack work schedule ﬂexibility and may not be able to afford additional child care.
26,"3.1 From Fairness to Justice Any debate about bias and fairness should approach issues of power and hierarchy, looking at who is in a position to produce and proﬁt from these systems, whose values are embedded in these systems, who sets their “objective functions,” and which contexts they are intended to work within."
26,"For example, making a facial recognition system perform equally on people with light and dark skin may be a type of technical progress in terms of parity, but if that technology is disproportionately used on people of color and low-income communities, is it really “fair?” This is why deﬁnitions of fairness face a hard limit if they remain purely contained within the technical domain: in short, “parity is not justice.” 169 32 3.2 Infrastructural Thinking In order to better understand and track the complexities of AI systems, we need to look beyond the technology and the hype to account for the broader context of how AI is shaping and shaped by social and material forces."
26,"192 Such initiatives are critical: as AI becomes more deeply embedded in areas like healthcare, criminal justice, hiring, housing, and educational systems, experts from these domains are essential if we are to ensure AI works as envisioned."
26,234 The last year revealed many of the hardest challenges for accountability and justice as AI systems moved deeper into the social world.
26,"45 21.Natalie Ram, “Innovating Criminal Justice,” Northwestern University Law Review 112, no."
26,"165.For a more general description of justice as fairness, see: John Rawls, Justice as Fairness: A Restatement , ed."
26,"167.Ben Green, “‘Fair’ Risk Assessments: A Precarious Approach for Criminal Justice Reform” (5th Workshop on Fairness, Accountability, and Transparency in Machine Learning, Stockholm, 2018), https://scholar.harvard.edu/ﬁles/bgreen/ﬁles/18-fatml.pdf ."
261,"F airness is discussed thr ough the lens of social justice , highlighting the STOA | Panel for the Future of Science and Technology II potential for algorithmic systems to systematically disadvantage, or even discriminate against, different social groups and demographics."
261,"The second step included a review of the types and degrees of impact that algorithmic systems have on social justice, fair decision -making and the associated technological and societal need/limits for algorithmic literacy, transparency, oversight and information symmetry."
261,"We discuss fairness through the lens of social justice and highlight the potential for algorithmic systems to systematically disadvantage, or even discriminate against, different social groups and demographics."
261,"Therefore, we also understand fairness within the lens of social justice, as opposed to individual cases in which there is a perceived imbalance of goods or penalties (' Why did she get more cookies than me?), an uneven applications of a rule (' You let him throw the ball out of turn '), a case of discrimination based on irrelevant factors that are not subject to rights claims ('You didn’t pick me for the team even though I’m faster than the person you did pick '), etc."
261,"Social justice is another complex term with many potential definitions [38, 39, 40, 41, 42]."
261,"Discussions of social justice (in academic , policy and public discourses) typically recognise that ensuring a fair distribution is complicated by inherent inequalities in contemporary society; there are various differences of perspective over the extent to which a fair distribution should accommod ate for, or attempt to address, such inequalities [44,45]."
261,"One high- profile campaigner is Joy Buolamwini, computer scientist at MIT and founder of the Algorithmic Justice League [54]."
261,"Algorithm based decision -making in the US criminal justice system In the early 2000s the US criminal justice system began using risk assessmen ts to assist decision making [91, 92]."
261,"In written evidence submitted to the UK government’s inquiry into Algori thms Used in decision -making [101], the Head of Criminal Justice at Durham Constabulary reported that i t was too early to make conclusions about the accuracy of HART, but research into it is being conducted in order to support evidence based good practice, and that the results of this research would be made available."
261,"In particular, we can highlight the following social values as potentially undermined through the operation of algorithmic systems for decision -making: ● Equality of opportunity/equality of ou tcome: if algorithmic systems and/or their outcomes are biased, this may block equality of opportunity and/or outcome and systematically disadvantage certain social groups. ● Equity: it has been argued by some [93, 52, 74 ] that bias in algorithms can be discriminatory, where it disadvantages demographic groups with protected characteristics. ● Freedom of choice. ● Justice: where citizens feel that algorithms are biased or even discriminatory, this can compromise their feeling that they live in a just society. ● Truth: if algorithmic processes distort reality or present false information as fact, this undermines citizens’ ability to determine what is true and to act on it accordingly. ● Autonomy: citizens’ ability to act and make decisions may be undermined by vari ous features of algorithmic processes."
261,Each of these values is closely entwined with understandings of fairness and social justice.
261,Various means to achieve fairness and social justice in algorithms have been suggested.
261,[111] considered is the use of algorithmic decision making in the criminal justice system and they note the controversy surrounding the use of C OMPAS in the US court system.
261,"As Rawls [42] describes, justice encompasses an overall acceptability that existing institutions generate mutual benefit and cooperation in society."
261,"Accoun tability Measures for Algorithmic System use by Public Authorities Algorithmic systems are currently being used in government, reshaping how criminal justice systems work via risk assessment algorithms and predictive policing [ 412, 413], optimizing energy use in critical infrastructure through AI -driven resource allocation [414, 415] and changing government resource allocation and monitoring practices [412, 413]."
261,"It also revealed a lack of general knowledge about the systems among the authorities, leading to situations where the students had to explain what ‘criminal justice algorithms’ were to the public servants in charge of providing the records on their use."
261,"4 87], restrictions of due process in criminal justice proceedings [4 88] and more."
261,The Times ' investigation led to broad media coverage and a Department of Justice inquiry into potential criminal behaviour by the company [5 68].
261,Justice and care: Essential readings in feminist ethics.
261,Sex and social justice.
261,Unveiling the meaning of social justice in Colombia.
261,Justice as fairness: A restatement.
261,Defining social justice in a socially unjust world.
261,Defining social justice.
261,Va lue differences underlying public views about social justice.
261,"[46] Michael Walzer, Spheres of Justice, (NY: Basic Books, 1983) [47] Foster, A."
261,"[54] Algorithmic Justice League https://www.ajlunited.org/ Accessed on: 28 September 2018 [55] Puri, R."
261,Algorithms in the Criminal Justice System: Assessing the Use of Risk Assessments in Sentencing.
261,"Criminal Justice and Behavior 31(3), 306– 323."
261,"A governance framework for algorithmic accountability and transparency 83 [99] Berk, Richard, Hoda Heidari, Shahin Jabbari, Michael Kearns, and Aaron Roth. ' Fairness in criminal justice risk assessments: the state of the art. ' arXiv preprint arXiv:1703.09207 (2017)."
261,"[416] Kade Crockford, ' Risk assessment tools in the criminal justice system: inaccurate, unfair, and unjust?,' ACLU of Massachusetts , March 8, 2018, https://privacysos.org/blog/risk -assessment -tools -criminal -justice system -inaccurate -unfair -unjust [417] Virginia Eubank s, Automating Inequality: How High -Tech Tools Profile, Police, and Punish the Poor, (New York: St."
261,"Martin’s Press, 2018); Nazgol Ghandnoosh, Black Lives Matter: Eliminating Racial Inequity in the Criminal Justice System (Washington DC: The Sentencing Project, 2015), http://sentencingproject.org/wp content/uploads/2015/11/Black -Lives -Matter.pdf [418] Insha Rahman, 'The State of Bail: A Breakthrough Year for Bai l Reform, ' Vera Institute of Justice, 2017, https://www.vera.org/state -of-justice -reform/2017/bail- pretrial [419] Dillon Reisman, Jason Schultz, Kate Crawford, Meredith Whi ttaker, 'Algorithmic Impact Assessments: A Practical Framework for Public Agency Accountability ', AI Now, April 2018 https://ainowinstitute.org/aiareport2018.pdf [420] Ali Winston, ' Transparency Advocates Win Release of NYPD ‘Predictive Policing’ Documents, ' The Intercept, Jan."
261,"29, 2017, https://www.axios.com/lawmakers -are-trying -to-understand -how- tech -giants -algorithms -work 1513307255- b4109efc -9566- 4e69- 8922- f37d9e829f1f.html [441] Eric Holder, ' Speech at the National Association of Criminal Defense Lawyers 57th Annual Meeting and 13th State Criminal Justice Network Conference' (Philadelphia, PA, Aug."
261,"1, 2014), Department of Justice, https://www.justice.gov/opa/speech/attorney -general- eric-holder-speaks -national -association -criminal defense -lawyers -57th A governance framework for algorithmic accountability and transparency 101 [442] John Fry, Anne Maxwell, Sarah Apere, Paddy McAweeney, Luke McSharry, and Ainhoa Gonz a�lez, 'Non Technical Summaries -Due Care and Attention, ' In 34th IAIA Annual Conference, http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.567.8444&rep=rep1&type=pdf ."
261,"Times, July 29, 2016, https://www.nytimes.com/roomfordeb ate/2014/08/06/is -big-data -spreading -inequality/big -datashould -be-regulated -by-technological- due -process [461] Wexler, ' Life, Liberty, and Trade Secrets '; Ram, ' Innovating Criminal Justice '."
261,"Department of Justice, Office of the Inspector General (2018), https://oig.justice.gov ."
261,"[475] Rebecca Wexler, ' Life, Liberty, and Trade Secrets: Intellectual Property in the Criminal Justice System, ' 70 Stan."
261,"Rev., (forthcoming 2018), https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2920883 [476] Natalie Ram, ' Innovating Criminal Justice, ' Northwestern L."
261,"3, 2017 [568] Mike Isaac, ' Justice Department Expands Its Inquiry Into Uber’s Greyball Tool, ' The New York Times, Mar."
262,Conclusions __________________________________________________________________ 70 AI and digital tools in workplace management and evaluation IX List of a bbreviations AGI Artificial general intelligence AI Artificial intelligence AIaaS AI as a service AI act Regulation of the European Parliament and of the Council laying down harmonised rules on artificial intelligence (Artificial Intelligence act) And amending certain union legislative acts AIDA Special Committee on Artificial Intelligence in a Digital Age BCI Brain -computer interface CDEI Centre for Data Ethics and Innovation Charter EU Charter of Fundamental Rights CIPD Chartered Institute of Personnel and Development CJEU Court of Justice of the European Union CNIL Commission Nationale de l 'Informatique et des Libertés DPA Data protection authority DPIA Data Protection Impact Assessment DPO Data protection officer ECHR European Convention on Human Rights ECtHR European Court of Human Rights EDPB European Data Protection Body EDPS European Data Protection Supervisor EESC European Economic and Social Committee ETUC European Trade Union Confederation EU-OSHA European Occupational Safety and Health at Work Authority FLI Future of Life Institute GDPR General Data Protection Regulation HBS Harvard Business School HRM Human resource management ICO Information Commissioner 's Office ILO International Labour Organization IP Internet protocol STOA | Panel for the Future of Science and Technology X ML Machine learning NFC Near -field communication OECD Organisation for Economic Co -operation and Development OSH Occupational safety and health PwC PricewaterhouseCoopers SMS Social media screening TUC Trade s Union Congress WEF World Economic Forum AI and digital tools in workplace management and evaluation 1 1.
262,"To that extent, as the Court of Justice of the European Union (CJEU) ruled, ' an employer that does not allow a w orker to exercise his right to paid annual leave must bear the consequences. '72 In no way should an employer be allowed to hide behind an algorithm in this respect."
262,"72 European Court of Justice 29 November 2017, Case No."
262,"73 European Court of Justice 21 February 2 018, Case No."
262,"Rudy Matzak; European Court of Justice 9 March 2021, Case No."
262,"Radiotelevizija Slovenija; European Court of Justice 9 March 2021, Case No."
262,"The purpose of this Act, as explained in Recital 1 of the draft, ' is to improve the functioning of the internal market by laying down a uniform legal framework in particular for the development, marketing and use of 82 'Directive 75/117 on equal pay for men and women must be interpreted as meaning that where an undertaking appli es a system of pay which is totally lacking in transparency, it is for the employer to prove that his practice in the matter of wages is not discriminatory, if a female worker establishes, in relation to a relatively large number of employees, that the average pay for women is less than that for men. ' European Court of Justice 17 October 1989, Case No."
262,"86 'AI is pervasive and will be used in diverse fields – such as consultancy, consumer products and services, mobility, online connectivity, energy production and distribution, police and justice administration – , where EU and MS liability rules are already sector -specific."
262,"Van der Mei, Anne Pieter, 'Fixed -Term work: Recent developments in the case law of the Court of Justice of the European Union' , European Labour Law Journal , 2020."
262,"Vecchione, Briana, Barocas, Solon and Karen Levy, ' Algorithmic Auditing and Social Justice: Lessons from the History of Audit Studies , Equity and Access ' in Algorithms, Mechanisms, and Optimization , 2021."
263,"Howev er, there may be derogations to these rules if necessary, to protect citizens' access to basic services. • Non -economic services , such as the police, justice and statutory social security schemes, are not subject to specific European legislation or to intern al market and competition rules. • Social services of general interest are those that respond to the needs of vulnerable citizens and are based on the principles of solidarity and equal access."
263,"Responsible innovation, anticipation and responsiveness: case studies of algorithms in decision support in justice and security, and an exploration of potential, unintended, undesirable, higher -order effects."
264,The jurisprudence of the Court of Justice of the EU on the use of AI 35 2.3.1.
264,"Policy recommendations for the best use of AI in the fisheries and its value chain 74 REFERENCES 76 Artificial Intelligence and the fisheries sector 5 LIST OF ABBREVIATIONS AFMA AI Australian Fisheries Management Authority Artificial Intelligence AIA proposal Proposal for a Regulation of the European Parliament and of the Council laying down harmonised rules on artificial intelligence (A rtificial Intelligence Act) AIS ANN BN Automatic Identification System Artificial Neural Network Bayesian Network CAP CCTV Common Agricultural Policy Closed -Circuit Television CFP Common Fisheries Policy CJEU CNN COM Court of Justice of the European Union Convolutional neural network Common Organi sation of the Markets DCF DL EGD EM EMFAF Data Collection Framework Deep Learning European Green Deal Electronic Monitoring European Maritime, Fisheries and Aquaculture Fund EU EUMOFA FAO European Union European Market Observatory for Fisheries and Aquaculture Food and Agriculture Organisation of the United Nations FCR Fisheries Control Regulation IPOL | Policy Department for Structural and Cohesion Policies 6 FPS Frontal protection systems FROODS Fishing Route Optimization Decision Support System GDP Gross Domestic Product GDPR GES GVA H2020 IATTC ICCAT General Data Protection Regulation Good Environmental Status Gross Value Added Horizon 2020 EU research and innovation funding programme Inter American Tropical Tuna Commission International Commission for the Conservation of Atlantic Tunas ICES IMO IOTC IUU LO MCRS ML International Council for the Exploitation of the Sea International Maritime Organization Indian Ocean Tuna Commission Illegal, Unreported and Unregulated Landing obligation Minimum Conservation Reference Size Machine Learning MPI MSFD MSY NMFS NOAA Ministry of Primary Industries of New Zealand Marine Strategy Framework Directive Maximum Sustainable Yield National Marine and Fisheries Services North Oceanic and Atmospheric Administration OJ PECH Committee PET Official Journal European Parliament’s Committee on Fisheries Protected Endangered and Threatened species Artificial Intelligence and the fisheries sector 7 RFMO SDG SME STECF SVM TAC TEU TFEU UN Regional fisheries management organi sation Sustainable Development Goal Small and Medium Enterprise Scientific Technical Economic Committee on Fisheries Support Vector Machine Total Allowable Catches Treaty on European Union Treaty on the Functioning of the European Union United Nations US VMS WCPFC United States of America Vessel Monitoring System Western and Central Pacific Fisheries Commission IPOL | Policy Department for Structural and Cohesion Policies 8 LIST OF FIGURES Figure 1: Conceptual diagram showing the role of AI in relation with other digitalisation activities 15 Figure 2: Classification of AI techniques and approaches in the AIA proposal expanded with further subcategories used in this study 42 Figure 3: Simplified diagram of an expert system 47 Figure 4: Simplified schema of the Fish Value Chain 55 Figure 5: Traceability aspects improvable by AI systems 56 Figure 6: Published papers related to fisheries, AI and traceability keywords 57 LIST OF TABLES Table 1: Non-exhaustive summary of the recitals and articles of the most relevant EU fisheries legislation containing elements making the use of AI systems possible 31 Table 2: Similarities, differences and keywords associated to specific ML methods 43 Artificial Intelligence and the fisheries sector 9 EXECUTIVE SUMMARY This study reviews the main applications of Artificial Intelligence (AI) systems in fisheries and identifies current challenges for fisheries that have the potenti al to be dealt with through AI."
264,"The third section (2.3) include s a reference to the scarce jurisprudence of the Court of Justice of the Europ ean Union (CJEU) that has so far, directly , or indirectly, considered AI related issues with projection on the fisheries sector."
264,"58 European Commission, Directorate -General for Justice and Consumers, Liability for artificial intelligence and other emerging digital technologies, Publications Office, 2019."
264,"The jurisprudence of the Court of Justice of the EU on the use of AI The CJEU as the judicial authority of the EU by virtue of Article 19 TEU, in cooperation with the judicial bodies of the EU Member States, ensures the uniform application and interpretation of EU law."
264,A n appeal has now been brought against this judgment before the Court of Justice 61.
264,Case on illegal mechanical device for fish classification A Court of Justice case was found where an illegal mechanical fish classification device was used .
264,"In its judgment of 11 February 2021 in Case K.M.62, the Court of Justice ruled on the reference for a preliminary ruling received from the Irish Court of Appeal under Article 267 TFEU."
264,"62 Judgment of the Court of Justice of 11 February 2021, K.M., C -77/20, ECLI:EU:C:2021:112."
264,"The Court of Justice was asked whether Article 89 and Article 90 of FCR , read in the light of the principle of proportionality enshrined in Article 49(3) of the Charter, were to be interpreted as precluding a national provision which, in order to penalise a n infringement of Article 32 of Regulation No 850/98, provided for the imposition of a fine and the mandatory confiscation of prohibited or non -compliant catches and fishing gear found on board the vessel concerned (paragraph 25)."
264,"The Cou rt of Justice found that the mandatory confiscation of prohibited or non -compliant catches and fishing gear may deter the persons concerned from infringing the prohibition on sorting equipment, laid down in Article 32(1) of Regulation No 850/98, by deprivi ng them of the illegally obtained benefits which they could otherwise enjoy, and of the possibility of continuing to use such equipment (paragraph 44)."
264,"65 Among other judgments, see: judgment of the Court of Justice of 16 July 2015, Chmielewski, C -178/03, ECLI:EU:C:2015:475, paragraph 21."
269,"European Parliament 2019-2024 TEXTS ADOPTED P9_TA(2021)0009 Artificial intelligence: questions of interpretation and application of international law European Parliament resolution of 20 January 2021 on artificial intelligence: questions of interpretation and application of international law in so far as the EU is affected in the areas of civil and military uses and of state authority outside the scope of criminal justice (2020/2013(INI)) The European Parliament, – having regard to the preamble to the Treaty on European Union, and to Articles 2, 3, 10, 19, 20, 21, 114,167, 218, 225 and 227 thereof, – having regard to the right to petition enshrined in Articles 20 and 227 of the Treaty on the Functioning of the European Union, – having regard to the Charter of Fundamental Rights of the European Union, – having regard to Council Directive 2000/43/EC of 29 June 2000 implementing the principle of equal treatment between persons irrespective of racial or ethnic origin1 (Racial Equality Directive), – having regard to Council Directive 2000/78/EC of 27 November 2000 establishing a general framework for equal treatment in employment and occupation2 (Equal Treatment in Employment Directive), – having regard to Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation)3 (GDPR), and to Directive (EU) 2016/680 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data by competent authorities for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, and on the free 1 OJ L 180, 19.7.2000, p."
269,"Languages, – having regard to the European ethical Charter on the use of Artificial Intelligence in judicial systems and their environment adopted by the Council of Europe Working Group on quality of justice (CEPEJ-GT-QUAL) in December 2018, – having regard to the OECD Council Recommendation on Artificial Intelligence adopted on 22 May 2019, – having regard to Rule 54 of its Rules of Procedure, – having regard to the opinions of the Committee on Foreign Affairs, the Committee on the Internal Market and Consumer Protection, the Committee on Transport and Tourism and the Committee on Civil Liberties, Justice and Home Affairs, – having regard to the report of the Committee on Legal Affairs (A9-0001/2021), Introduction A. whereas artificial intelligence (AI), robotics and related technologies are being developed quickly, and have a direct impact on all aspects of our societies, including basic social and economic principles and values; B. whereas AI is causing a revolution in military doctrine and equipment through a profound change in the way armies operate, owing mainly to the integration and use of new technologies and autonomous capabilities; C. whereas the development and design of so-called ‘artificial intelligence’, robotics and related technologies are done by humans, and their choices determine the potential of technology to benefit society; D. whereas a common Union framework must cover the development, deployment and use of AI, robotics and related technologies, and must ensure respect for human dignity and human rights, as enshrined in the Charter of Fundamental Rights of the European Union; E. whereas the Union and its Member States have a particular responsibility to make sure that AI, robotics and related technologies – as they can be used cross borders – are human-centred, i.e. basically intended for use in the service of humanity and the common good, in order to contribute to the well-being and general interest of their citizens; whereas the Union should help the Member States to achieve this, in particular those which begun to reflect on the possible development of legal standards or legislative changes in this field; F. whereas European citizens could benefit from an appropriate, effective, transparent and coherent regulatory approach at Union level that defines sufficiently clear conditions for companies to develop applications and plan their business models, while ensuring that the Union and its Member States retain control over the regulations to be established, so that they are not forced to adopt or accept standards set by others; G. whereas ethical guidance, such as the principles adopted by the High Level Expert Group on Artificial Intelligence, provides a good starting point but is not enough to ensure that businesses act fairly and guarantee the effective protection of individuals; H. whereas this particular responsibility implies a need to examine questions of interpretation and application of international law related to the active participation of the EU in international negotiations, in so far as the EU is affected by the civil and military uses of this kind of AI, robotics and related technologies, and questions of state authority over such technologies lie outside the scope of criminal justice; I. whereas it is essential to provide an appropriate and comprehensive legal framework for the ethical aspects of these technologies as well as for liability, transparency and accountability (in particular for AI, robotics and related technologies considered to be high risk); whereas this framework must reflect that the intrinsically European and universal humanist values are applicable to the entire value chain in the development, implementation and uses of IA; whereas this ethical framework must apply to the development (including research and innovation), deployment and use of IA, in full respect of Union law and the values set out in the Charter of Fundamental Rights of the European Union; J. whereas the purpose of this examination is to determine to what extent the rules of international public and private law and EU law are geared to dealing with these technologies, and to highlight the challenges and risks which the latter pose for state authority, so that they can be properly and proportionately managed; K. whereas the European Commission does not consider the military aspects of the use of artificial intelligence in its White Paper; L. whereas a harmonised European approach to these problems calls for a common definition of AI, and for steps to ensure that the fundamental values of the European Union, the principles of the Charter of Fundamental Rights and international human rights legislation are upheld; M. whereas AI is providing unprecedented opportunities to enhance performance in the transport sector by addressing the challenges of increasing travel demand, safety and environmental concerns, while making all transport modes smarter, more efficient and more convenient; N. whereas addressing AI in defence at the EU level is indispensable for the development of EU capabilities in this sector; Definition of artificial intelligence 1."
269,"Recalls that according to the Advisory Opinion of the International Court of Justice of 8 July 1996, the principle of originality cannot be cited in support of any derogation regarding compliance with current norms of international humanitarian law; 13."
269,"Insists on the importance of investing in human skills, including digital skills, in order to adapt to scientific progress involving AI-driven solutions, for individuals exercising regulated professions, including activities connected with the exercise of state authority, such as the administration of justice; calls on the Member States and the Commission to duly take this into account as part of the implementation of Directive 2005/36/EC1; 25."
269,"Believes that an effective mechanism for enforcing the rules on non-proliferation of LAWS and any future offensive AI-enabled technologies is of paramount importance for global security; State authority: examples from civil areas, including health and justice 51."
269,"Urges the Member States to assess the risks related to AI-driven technologies before automating activities connected with the exercise of state authority, such as the administration of justice; calls on the Member States to consider the need to provide for safeguards such as supervision by a qualified professional and strict rules on professional ethics; 54."
269,"Notes that AI is increasingly being used in the field of justice in order to take decisions which are more rational, more in keeping with the law in force, and quicker; welcomes the fact that the use of AI is expected to speed up judicial proceedings; 68."
269,"Stresses that the use of AI in justice could improve the analysis and collection of data and the protection of victims, and that this could be explored in research and development and accompanied by impact assessments, in particular regarding safeguards for due process and against bias and discrimination, with the precautionary principle being applied; recalls, however, that this is no substitute for human involvement in sentencing or decision-making; 70."
269,"Recalls the importance of the principles of governance, transparency, impartiality, accountability, fairness and intellectual integrity in the use of AI in criminal justice; 71."
269,"Urges the Member States to assess the risks related to AI-driven technologies before automating activities connected with the exercise of state authority, especially in the area of justice; calls on them to consider the need to provide safeguards, such as supervision by a qualified professional and rules on professional ethics; 72."
269,"Requests that the public is kept informed about the use of AI in the field of justice, and that such uses do not give rise to discrimination resulting from programming biases; stresses that the right of every individual to have access to a public official must be respected, as well as the right of the responsible official to personally take the decision and deviate from the information received from the AI when they deem it necessary in the light of the details of the matter in question; highlights the right of the defendant to appeal the decision in accordance with national legislation, without ever eliminating the final responsibility of the judiciary; 74."
270,"Indeed, several notions of fairness exist that are not only technically defined but also entangled with concepts of social justice, specifically the concept of privilege , held by virtue of belonging to certain social identity groups 34."
270,"These values are common to the Member S tates in a society in which pluralism, non -discrimination, tolerance, justice, solidarity and equality between women and men prevail. ' Furthermore, its article 3(3) states that the Uni on 'shall combat social exclusion and discrimination, and shall promote social justice and protection, equality between women and men, solidarity between generations and protection of the rights of the child. ' Similar ideas can be found in the Treaty on the Functioning of the European Union, especially in its Part Two, entitle d 'Non -Discrimination and Citizenship of the Union ' (see article 19.1.) and the EU Charter of Fundamental Rights (article 21)."
270,"Even worse, this contextually limited interpretation of the concept of discrimination has been endorsed by the Court of Justice of the EU43."
270,"There is a nice argument that supports such additional use of the concept: even though the European Court of Justice has never defined the notion of fairness in data protection law, it has used this notion of fairness in two different contexts: f air balance and transparency.48 If we consider that fairness has to do with the reasonable expectations of data subjects, then it should help us to avoid some of the discriminatory results that are not so easy to uncover : a data subject would hardl y allow t he type of processing that would cause him/her to suffer a damage that other people do not suffer."
270,"Available at: https://business.blogthinkbig.com/is -your -ai-system -discriminating -with out knowing -it-the-paradox -between -fairness -and-privacy/ Berk, Richard, et al. ' Fairness in Criminal Justice Risk Assessments: The State of the Art. ' Sociological Methods & Research, vo l."
270,"Gerards, J., Xenidis, R., Algorithmic discrimination in Europe: challenges and opportunities for gender equality and non -discrimination law, European Commission, Directorate -General for Justice and Consumers, Publications Office, 2021, https://data.europa.eu/doi/10.2838/77444 Gianclaudio Malgieri and Vincenzo Tiani, How the EU Council is rewriting the AI Act, REPORT - 6 December 2021, December 2021, at: https://brusselsprivacyhub.eu/publications/how -the-eu-council -isrewriting -the-ai-act, last accessed 24/03/2022."
271,Case Law 35 European Court of Human Rights (ECtHR) 35 Court of Justice of the European Union (CJEU) 37 National courts/data protection authorities 38 ETHICAL ASPECTS OF B IOMETRIC IDENTIFICAT ION 42 3.1.
271,Recommendations with regard to consent management 87 REFERENCES 89 ANNEX: PROPOSED WORD ING OF TITLE II AND TITLE IIA 96 Biometric Recognition and Behavioural D etection PE 696.968 5 LIST OF ABBREVIATIONS AI Artificial Intelligence AIA Artificial Intelligence Act AFIS Automated Fingerprint Identification System Art(s) Article (s) BCI Brain -Computer -Interface BDSG Bundesdatenschutzgesetz - German Federal Data Protection Act BIPA BVerfG Illinois Biometric Information Privacy Act Bundesverfassungsgericht - German Constitutional Court BVerwG Bundesverwaltungsgericht – German Federal Administrative Court CCPA CCTV California Consumer Privacy Act Closed -Circuit Television CFR Charter of Fundamental Rights of the European Union CJEU Court of Justice of the European Union DNA Deoxyribonucleic acid DSA Digital Services Act DSG Datenschutzgesetz - Austrian Data Protection Act EC European Commission ECG Electrocardiography ECHR European Convention on Human Rights ECtHR European Court of Human Rights Ed(s) Editor (s) Edn Edition IPOL | Policy Department for Citizens’ Rights and Constitutional Affairs 6 PE 696.968 EEG Electroencephalography EES Entry -Exit-System e.g. exempli gratia (for example) EGE etc.
271,"European Group on Ethics in Science and New Technologies et cetera (and so on) EU European Union EUDPR European Union Data Protection Regulation – Regulation (EU) 2018/1725 GDPR General Data Protection Regulation – Regulation (EU) 2016/679 i.e. id est (that is) IoT Internet of Things LED Law Enforcement Directive – Directive (EU) 2016/680 OGH Oberster Gerichtshof - Austrian Supreme Court of Justice OJ Official Journal of the European Union Para (s) Paragraph (s) PIPL SIS Personal Information Protection Law of the People’s Republic of China Schengen Information System SPG Sicherheitspolizeigesetz - Federal Security Police Act TEU TTDSG Treaty of the European Union (TEU) German Act on Data Protection and Privacy in T elecommunica tions and T elemedia UDHR Universal Declaration of Human Rights UK-DPA Data Protection Act of the United Kingdom UN United Nations Biometric Recognition and Behavioural D etection PE 696.968 7 LIST OF BOXES WITH ILLUSTRATIONS Illustration 1: Differentiating biometrics- based data and other personal data 68 Illustration 2: Differentiating ‘real -time’ and ‘post’ remote identification 70 Illustration 3: Relationship between ‘biometric categorisation’ and ‘biometric inferences’ 71 Illustration 4: Undesirable remote biometric identification beyond law enforcement 77 Illustration 5: Remote biometric identification in grey zones around law enforcement 78 Illustration 6: Data collection and storage in the context of biometric identification 80 Illustration 7: Justification of emotion recognition or biometric categorisation 82 Illustration 8: Emotion recognition or biometric categorisation used as legal evidence 83 Illustration 9: Personality profiles created with the help of a video game 85 Illustration 10: Biometric inferences drawn with regard to third parties 86 LIST OF FIGURES Figure 1: Authentication/identification, categorisation, and detection 21 Figure 2: Steps involved in biometric identification 43 Figure 3: Steps involved in biometric categorisation 54 Figure 4: Steps involved in biometric detection 58 Figure 5: Risk -based approach of the AIA Proposal 63 Figure 6: Biometric techniques under the risk levels of the AIA Proposal 64 LIST OF TABLES Table 1: Admissibility of biometric techniques (based on simplified assumptions) 65 Table 2: Limitations on scope with regard to identification measures 75 IPOL | Policy Department for Citizens’ Rights and Constitutional Affairs 8 PE 696.968 EXECUTIVE SUMMARY Background Biometric identification together with biometric categorisation, behavioural detection, emotion recognition, brain -computer -interfaces (BCIs), and similar techniques are being used to an increasing extent by public and private bodies."
271,58 Recommendations 3 and 7 European Parliament resolution of 20 January 2021 on artificial intelligence: questions of interpretation and application of international law in so far as the EU is affected in the areas of civil and military uses a nd of state authority outside the scope of criminal justice (2020/2013(INI)) .
271,"63 See Legislative Train Schedule , ‘Completion of EU Accession to the European Convention on Human Rights ’, available at <https://www.europarl.europa.eu/legislative-train/theme-area -of-justice -and -fundamental -rights/file-completion -of-euaccession -to-the -echr > (last accessed 09 July 2021)."
271,"102 Regulation (EU) No 603/2013 of the European Parliament and of the Council of 26 June 2013 on the establishment of 'Eurodac' for the comparison of fingerprints for the effective application of Regulation (EU) No 604/2013 establishing the criteria and mechanisms for determining the Member State responsible for examining an application for international protection lodged in one of the Member States by a third -country national or a s tateless person and on requests for the comparison with Eurodac data by Member States' law enforcement authorities and Europol for law enforcement purposes, and amending Regulation (EU) No 1077/2011 establishing a European Agency for the operational management of large -scale IT systems in the area of freedom, security and justice, OJ L 180, 1-30."
271,"Biometric Recognition and Behavioural D etection PE 696.968 37 Court of Justice of the European Union (CJEU) Currently, there is no EU case law regarding highly sophisticated identification techniques."
271,"The Austrian Supreme Court of Justice (Oberster Gerichtshof , OGH) ruled in favour of the employees and held that the biometric templates are obtained for the comparatively trivial aim of determining the employee’s times of coming a nd going."
271,"182 Austrian Supreme Court of Justice 18 October 2006, 9 Ob 109/06d; Austrian Supreme Court of Justice 22 January 2020, 9 Ob 120/19s."
271,"196 High Court of Justice (Divisional Court of Cardiff) 4 September 2019, EWCH 2341 (Admin), para 159."
271,"Any deficiencies in this regard may lead to severe unfairness or even to massive discrimination, inc luding on racial or ethnic grounds, and to the undermining of procedural rights, including access to justice and the right to a fair trial."
271,"Gutheil M and others, ‘ Interoperability of Justice and Home Affairs Informati on Systems’ (European Parliament 2018) ."
276,"Concludes that it is the EU’s responsibility to quickly set up a favourable regulatory environment for AI that provides for swift digital law-making, effective governance and balanced ethical standards, while at the same time preventing overregulation and giving enough leeway for innovation; urges that the adequate development and training of AI will require better access to high-quality data, common standards and incentives for voluntary data sharing; calls on its Committees on Legal Affairs (JURI), Internal PE680.928v01-00 34/38 PR\1224166EN.docx ENMarket and Consumer Protection (IMCO), Industry, Research and Energy (ITRE), Civil Liberties, Justice and Home Affairs (LIBE), and Constitutional Affairs (AFCO) to ensure that these goals are met; 160."
277,"For instance, AI poses risks to the right to personal data protection and priva cy, and equally so a risk of discrimination when algorithm s are used for purposes such as to profile people or to resolve situations in criminal justice.3 There are also some concerns about the impact of AI technologies and robotics on the labour market (e.g. jobs being destroyed by automation) ."
277,The eight principles with regard to AI are: harmony and friendliness; fairness and justice; inclusivity and sharing; respect for privacy; secure/safe and controllable; shared responsibility; open collabo ration; and agile governance.
278,"Proposal for a regulation of the European Parliament and of the Council laying down harmonised rules on artificial intelligence (artificial intelligence act) and amending certain Union legislative acts Committees responsible: Rapporteurs: Shadow rapporteurs: Internal Market and Consumer Protection (IMCO) and Civil Liberties, Justice and Home Affairs (LIBE) (jointly under Rule 58) Brando Benifei (S&D, Italy) and Dragoş Tudorache (Renew, Romania) Deirdre Clune, Axel Voss (EPP); Petar Vitanov (S&D); Svenja Hahn, (Renew); Sergey Lagodinsky, Kim Van Sparrentak (Greens/EFA); Rob Rooken, Kosma Złotowski (ECR ); Jean -Lin Lacapelle, Jaak Madison (ID); Cornelia Ernst, Kateřina Konecna (The Left) COM(2021)206 21.4.2021 2021/0106(COD) Ordinary legislative procedure (COD) (Parliament and Council on equal footing – formerly 'co-decision') Procedure completed."
278,"In Parliament , the file was assigned jointl y (under Rule 58) to the Committee on Internal Market and Consumer Protection (IMCO) and the Committee on Civil Liberties, Justice and Home Affairs (LIBE), with Brando Benifei (S&D, Italy) and Dragoş Tudorache, Renew, Romania) appointed as rapporteurs."
278,"13 The Annex refers to AI systems used in areas of critical infrastructures (e.g. road traffic ), education and vocational training , employment worker management and access to self -employment , access to essential private and public services and benefits (e.g. creditworthiness evaluation ), law enfo rcement, border control, administration of justice and democratic processes , biometric identification, categorisation and emotion recognition systems (outside the prohibited categories) ."
279,"AI tightly developed under human oversight and control), embed the principles of fairness and justice in algorithms, applied in all phases of AI systems’ design, implementation and testing, while following through bias complaints and other undesired effects reporting."
279,"During the 71st session of the United Nations General Assembly, on 29 September 2016, UNICRI (United Nations International Crime and Justice research Institute) announced the opening of the first Centre on A I and Robotics KEY FINDINGS There is not yet robust evidence of AI applications used for addressing significant and wideranging real -life problems or societal challenges."
279,"AI tightly developed under human oversight and control), embed the principles of fairness and justice in algorithms, applied in all phases of AI systems’ design, i mplementation and testing, while following through bias complaints and other undesired effects reporting."
28,"AI Now produces interdisciplinary research to help ensure that AI systems are accountable to the communities and contexts they are meant to serve, and that they are applied in ways that promote justice and equity."
28,"Our most recent publications include: ● Dirty Data, Bad Predictions: How Civil Rights Violations Impact Police Data, Predictive Policing Systems, and Justice​ , an article on how “dirty-policing” practices and policies shape the environment and the methodology by which data is created, raising the risk of creating inaccurate, skewed, or systematically biased “dirty data.” ● Anatomy of an AI System​ , a large-scale map and longform essay produced in partnership with ​ SHARE Lab​ , which investigates the human labor, data, and planetary resources required to operate an Amazon Echo. ● Discriminating Systems: Gender, Race, and Power in AI​ , a report that examines how discrimination and inequality in the AI sector are replicated in AI technology and offers recommendations for change. ● Disability, Bias, and AI​ , drawing on a wealth of research from disability advocates and scholars, this report examines what disability studies and activism can tell us about the risks and possibilities of AI. ● Excavating AI​ , an essay on the politics of images in machine learning training sets. ● Litigating Algorithms 2019 US Report: New Challenges to Government Use of Algorithmic Decision Systems​ , our second major report assessing recent court cases focused on government use of algorithms."
28,"Machine learning researchers should account for potential risks and harms and better document the origins of their models and data. ​ Advances in understanding of bias, fairness, and justice in machine learning research make it clear that assessments of risks and harms are imperative."
28,"This includes examples such as criminal justice advocates working to halt the use of discriminatory predictive policing tools, tenants-rights groups opposing facial recognition in housing, and a coalition of Latinx activists, tech workers, and students exposing and protesting lucrative tech company contracts with military and border agencies."
28,"Not only are James’ views counter to Google’s stated values, but they are directly counter to the project of ensuring that the development and application of AI prioritizes justice over profit.”​ 73​ Following the backlash, Google dissolved ATEAC after a little over a week.​ 74 Yet even if one believes that corporate AI ethics might help guide better tech practices on some level, it is clear that change in the design, development, and implementation of AI systems largely occurs when there is pressure on companies from workers, the press, and policymakers."
28,"Barbara Grosz, a professor of natural sciences, imagines a world in which “every time a computer scientist logs on to write an algorithm or build a system, a message will flash across the screen that asks, ‘Have you thought about the ethical implications of what you’re doing?’”​ 80​ The Design Justice Network takes this further, centering justice, not ethics, and calling on developers and designers to center affected communities in the process of creating technology together.​ 81 AI developers and researchers make important determinations that can affect billions of people, and helping them consider whom the technology benefits and harms is important."
28,"As during the dot-com boom and foreclosure crisis, numerous organizations and collectives formed to organize for housing justice."
28,"Accordingly, housing justice groups such as Social Housing Now (Căsi Sociala Acum) are in the midst of organizing against evictions and for the development of social housing.​ 97 Back in the North, there have been new forms of international solidarity in the works against AI displacement."
28,"Thus they have been organizing marches, Google bus blockades, and City Council demonstrations.​ 98​ Much of this has taken place in solidarity with organizers and groups in Berlin such as Google Is Not a Good Neighbor (​ Google ist kein guter Nachbar)​ , which in 2018 collectively blocked Google from launching a new tech campus in the neighborhood of Kreuzberg.​ 99​ Solidarity has also been found among New York City organizers who successfully fought the development of a new Amazon campus in 2019, and with activists in Toronto committed to thwarting gentrification induced by Sidewalk Labs.​ 100 During demonstrations, banners, light projections, video clips, and statements of support have expressed international solidarity, revealing a new trend toward urban justice.​ 101​ Much work remains to link struggles against forms of tech-sector displacement worldwide."
28,"Because AI technologies are often applied in ways that amplify and exacerbate historical patterns of inequality and discrimination, it is these historical practices—not AI systems alone—to which organizers and communities seeking justice are reacting."
28,"In July, Mijente joined Media Justice (an organization at the helm of San Francisco’s facial-recognition ban)​ 114​ and Tech Workers Coalition​ 115​ to host Take Back Tech."
28,"This work helped shed light on lucrative tech company contracts with military and border agencies, and mobilized tech workers and students, while also emphasizing the human cost of a deportation campaign rife with human rights abuses.​ 118​ Protesters catalyzed by the campaign have held regular demonstrations at Palantir’s headquarters in Palo Alto and at its New York City offices.​ 119 Organizations such as Never Again Action,​ 120​ and Jews for Racial and Economic Justice (JFREJ)​ 121​ have also led highly visible actions against Amazon, organizing street protests and sit-ins in Amazon bookstores to protest against the company’s ongoing work providing cloud computing services to ICE.​ 122​ And Immigrant rights groups such as Make the Road New York,​ 123 along with Mijente, JFREJ, and other advocates, have reached out to academics and computer science and technology professionals through petitions, demanding that prominent conferences drop Palantir as a sponsor, given the company’s role in empowering ICE.​ 124​ Community-organized opposition to Palantir’s role in ICE’s detention of immigrants resulted in UC Berkeley’s Privacy Law Scholars Conference,​ 125​ Lesbians Who Tech,​ 126​ and the Grace Hopper Celebration all pulling Palantir as a sponsor.​ 127 Athena, a recently launched coalition, takes this further."
28,"But they also organized around issues like Amazon’s treatment of warehouse workers and its sale of surveillance tech.​ 129​ Athena expands on this multi-issue approach, recognizing that Amazon is at the heart of a set of interlocking issues, including worker rights at warehouses, climate justice, and mass surveillance."
28,The pushback against AI thus builds upon the social justice work that organizers have engaged in for a much longer time.
28,"Worker organizing around AI is also part of a broader tech-worker movement focused on a broad range of social justice issues, including displacement,​ 145​ two-tiered workforces and the exploitation of contract workers,​ 146​ and climate change."
28,"Building on the emergence of globally oriented data protection approaches such as the European Union’s General Data Protection Regulation (GDPR), policymakers are moving quickly, driven both by the current sense of urgency to regulate the mass deployment of AI technologies lacking discernible safeguards and by the failure of ethical frameworks to adequately answer the call for accountability and justice."
28,"Addressing the specific case of forensic algorithms like automated software used to analyze DNA and predict potential suspects, the Justice in Forensic Algorithms Act of 2019​ 246​ prohibits companies from withholding information about their system, such as its source code, from a defendant in a criminal proceeding on trade-secrecy grounds."
28,"The documents showed that the Federal Bureau of Investigation (FBI) and ICE were using state driver’s license databases as “the bedrock of an unprecedented surveillance infrastructure” that relied on facial-recognition technology.​ 289​ The US Justice Department also recently announced plans to collect DNA data from migrants crossing the border, which could create more invasive monitoring of immigrants without any real limits.​ 290 Outside the US, governments are equally eager to pilot AI systems at border checkpoints."
28,"Though it declined to provide any details on how it is being used by customers, it indicated retail as a potential use case, illustrating how stores can feed live images of shoppers to detect emotional and demographic trends.​ 401 Employment has also experienced a surge in the use of affect recognition, with companies like HireVue and VCV offering to screen job candidates for qualities like “grit” and to track how often they smile.​ 402​ Call center programs Cogito and Empath use voice-analysis algorithms to monitor the reactions of customers and signal to call agents when they sound distressed.​ 403​ Similar programs have been proposed as an assistive technology for people with autism,​ 404​ while Boston-based company BrainCo is creating headbands that purport to detect and quantify students’ attention levels through brain-activity detection,​ 405​ despite studies that outline significant risks associated with the deployment of emotional AI in the classroom.​ 406 Affect-recognition software has also joined risk assessment as a tool in criminal justice."
28,"This is particularly concerning in contexts such as employment, education, and criminal justice."
28,"Despite the fact that social sciences and humanities approaches have a long history in information security and risk management,​ 491​ research that addresses both social and technical dimensions in security is necessary, but still relatively nascent.​ 492​ Central in this challenge is redrawing the boundaries of analysis and design to expand beyond the algorithm,​ 493​ and securing channels for all affected stakeholders to democratically steer system development and to dissent when concerns arise.​ 494 CONCLUSION Despite the growth of ethical frameworks, AI systems continue to be deployed rapidly across domains of considerable social significance—in healthcare, education, employment, criminal justice, and many others—without appropriate safeguards or accountability structures in place."
28,"See Vidushi Marda, “Introduction” in APC, Article 19, and SIDA, “Artificial Intelligence: Human Rights, Social Justice and Development,” Global Information Watch 2019, November 2019, https://giswatch.org/sites/default/files/gisw2019_artificial_intelligence.pdf​ ."
28,"Design Justice Network Principles, accessed November 24, 2019, https://designjustice.org/read-the-principles​ ."
28,"“The Anti-Eviction Mapping Project: Counter Mapping and Oral History Toward Bay Area Housing Justice.” ​ Annals of the American Association of Geographers​ 108, no."
28,"Media Justice, accessed November 24, 2019, ​ https://mediajustice.org/ 115."
28,"Jews for Racial and Economic Justice, accessed November 24, 2019, ​ https://jfrej.org/​ ."
28,"Sasha Costanza Chock, “Design Justice: Towards an Intersectional Feminist Framework for Design Theory and Practice,” ​ Proceedings of the Design Research Society 2018​ , June 3, 2018, https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3189696​ ."
28,"Amazon Employees for Climate Justice, “Open letter to Jeff Bezos and the Amazon Board of Directors,” Medium, April 10, 2019, https://medium.com/@amazonemployeesclimatejustice/public-letter-to-jeff-bezos-and-the-amazon-boardof-directors-82a8405f5e38​ ."
28,"Takano Introduces the Justice in Forensic Algorithms Act to Protect Defendants’ Due Process Rights in the Criminal Justice System,” Takano, September 17, 2019, https://takano.house.gov/newsroom/press-releases/rep-takano-introduces-the-justice-in-forensic-algorith ms-act-to-protect-defendants-due-process-rights-in-the-criminal-justice-system​ ."
28,"Bobby Allyn and Joel Rose, “Justice Department Announces Plan to Collect DNA from Migrants Crossing the Border,” NPR, October 21, 2019, https://www.npr.org/2019/10/21/772035602/justice-department-announces-plan-to-collect-dna-from-migr ants-crossing-the-bord​ ."
28,"Gray and Siddharth Surl, ​ Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass ​ (Boston: Houghton Mifflin Harcourt, 2019); Kate Crawford and Vladan Joler, Anatomy of an AI System, 2018, ​ https://anatomyof.ai​ ; Muqing Zhang, “Colonialism Is Alive in the Exploited Tech Work Force”, Outline​ , June 6, 2019 https://theoutline.com/post/7533/colonialism-is-alive-in-the-exploited-tech-work-force?zd=2&zi=exrbzkaf​ ; APC, Article 19, and SIDA, “GISWatch 2019 - Artificial Intelligence: Human rights, social justice and development,” November 2019, ​ https://giswatch.org/sites/default/files/gisw2019_artificial_intelligence.pdf​ ; AI Now 2019 Report | 87 Noopur Raval, “Developing a Framework for Postcolonial Digital Labor,” unpublished manuscript, 2017, https://www.academia.edu/35413303/Developing_a_framework_for_postcolonial_digital_labor​ ."
280,"European Parliament 2014-2019 TEXTS ADOPTED P8_TA(2019)0081 A comprehensive European industrial policy on artificial intelligence and robotics European Parliament resolution of 12 February 2019 on a comprehensive European industrial policy on artificial intelligence and robotics (2018/2088(INI)) The European Parliament, – having regard to its resolution of 16 February 2017 with recommendations to the Commission on Civil Law Rules on Robotics1, – having regard to its resolution of 1 June 2017 on digitising European industry2, – having regard to its resolution of 12 September 2018 on autonomous weapon systems3, – having regard to its resolution of 11 September 2018 on language equality in the digital age4, – having regard to the Commission proposal of 6 June 2018 establishing the Digital Europe programme for the period 2021-2027 (COM(2018)0434), – having regard to Council Regulation (EU) 2018/1488 of 28 September 2018 establishing the European High Performance Computing Joint Undertaking5, – having regard to Rule 52 of its Rules of Procedure, – having regard to the report of the Committee on Industry, Research and Energy and the opinions of the Committee on the Internal Market and Consumer Protection, the Committee on Legal Affairs, the Committee on Civil Liberties, Justice and Home Affairs and the Committee on the Environment, Public Health and Food Safety (A80019/2019), A. whereas transparent, ethics-embedded artificial intelligence (AI) and robotics have the 1 OJ C 252, 18.7.2018, p."
280,"Points out that the guiding ethical framework should be based on the principles of beneficence, non-maleficence, autonomy and justice, on the principles and values enshrined in Article 2 of the Treaty on European Union and in the Charter of Fundamental Rights, such as human dignity, equality, justice and equity, nondiscrimination, informed consent, private and family life and data protection, as well as on other underlying principles and values of Union law, such as non-stigmatisation, transparency, autonomy, individual responsibility and social responsibility, and on existing ethical practices and codes; 148."
281,"STUDY Panel for the Future of Science and Technology EPRS | European Parliamentary Research Service Scientific Foresight Un it (STOA) PE 72 9.533 – July 2022 EN Governing data and artificial intelligence for all Models for sustainable and just data governance Governing data and artificial intelligence for all Models for sustainable and just data governance With a particular focus on artificial intelligence (AI), t his study identif ies and examines policy options for the EU' s data governance framework that align with a data justice perspective."
281,"A data justice approach is one that centres on equity, recognition and representation of plural interests, and the creation and preservation of public goods as its principal goals."
281,"Four benchmarks for good data governance are proposed, in line with the principles of justice: preserving and strengthening public infrastructure and public goods, inclusiveness, contestability and accountability, and global responsibility."
281,"STOA | Panel for the Future of Science and Technology II AUTHOR S This study was written by Joan Lopez Solano, Aaron Martin, Siddharth de Souza and Linnet Taylor of the Global Data Justice project , Tilburg University , at the request of the Panel for the Future of Science and Technology (STOA) and managed by the Scientific Foresight Unit , within the Directorate -General for Parliamentary Research Services (EPRS) of the Secretariat of the European Parliament."
281,"The Global Data Justice project would like to acknowledge valuable contributions to the analysis in this report from: Maria Anagnostu, Shweta Degalahal, Paula Ferreira Vidal, Yash Kaushal, Andrew Key, Janne Joosten, Alexis Manus, Franklyn Ohai , Gargi Sharma and Zsuzsanna Véghné Ujj."
281,"533 ISBN: 978- 92-846- 9623- 9 doi: 10.2861/915401 QA-05-22-170- EN-N http://www.europarl.europa.eu/stoa (STOA website) http://www.eprs.ep.parl.union.eu (intranet) http://www.europarl.europa.eu/thinktank (internet) http://epthinktank.eu (blog) Governing data and artificial intelligence for all III Executive s ummary With particular regard to artificial intelligence (AI), t his study aims to identify and examine policy options for Europe' s data governance framework that align with a data justice perspective."
281,"A data justice approach is one that centres on equity, the recognition and representation of plural interests, and the creation and preservation of public goods as its principal goals."
281,"A data justice perspective is a particularly appropriate tool for this analysis , because AI is not a bottom -up class of technology , in terms of either development or use."
281,Policy options and alternatives: a data justice analysis ______________________________ 58 6.1.
281,"An important component of that representation can be framed as 'data justice ' - the view that data governance should not only seek to do no harm, but should positively contribute to people 's autonomy and to their ability to particip ate in society and make claims about their needs, on a more general level."
281,"1 Linnet Taylor, 'What Is Data Justice?"
281,"Technology, https://www.theguardian.com/technology/2017/dec/20/uber -european -court -of-justice -ruling -barcelona-taxi -drivers ecj-eu."
281,"Lessons from Cybersecurity Vulnerability Disclosure for Algorithmic Harms Discovery, Disclosure, and Redress ' (Algorithmic Justice League, January 2022), https://www.ajl.org/bugs ."
281,One such proposal from India is the creation of an Interoperable Criminal Justice Database.
281,"59 High Court of Tripura, ' Interoperable Criminal Justice System,' accessed April 26, 2022, https://thc.nic.in/user%20manual/ICJS -manual.pdf ."
281,"62 It was found for instance that the creation of registers of repeat offenders had an underlying caste bias, and rather than challenging the existence of such registers, they would now be part of a centralised data base where their use would be further cemented.The Indian Express, ' The Dangers of a Centralised Database for Justice System,' May 28, 2021, https://indianexpress.com/article/opinion/columns/the -dangers -of-a-centralised -database -for-justice -system -7333252/ ."
281,"For instance in the Dutch government 's misuse of data to predict fraud among 63 Linnet Taylor, ' What Is Data Justice?"
281,"These values relating to the economic growth and wel lbeing of EU Member States potentially stand in tension with the rights - and justice -based orientation of the other core value statements to do with digital strategy, for instance in the statement that the innovation principle is legislatively as important as the precautionary principle, which underlies much thinking about digital rights and data protection."
281,"One way to arbitrate between these differing visions is to address them through a justice lens, which asserts that there are tests we can apply to statements about good governance and related models, to see whether they align with the core as sumptions that make governance functional for people, and place it at the service of the public rather than in the interests of the most powerful and privileged."
281,"In 2017, the Global Data Justice project (the authors of this report, based in the Netherlands ) asserted three fundamental pillars of 'good ' data governance.159 These pillars offer a tool for understanding how public values can be incorporated in governance frameworks."
281,"If it has the effect of channelling power and profit toward the best- resourced and most powerful actors, whether governmental or corporate, a governance model is not in line with principles of social justice and requires reorienting."
281,"This justice -based reasoning leads to a set of core benchmarks for good governance of data: 159 Linnet Taylor, ' What Is Data Justice?"
281,"In terms of the first of these two, these infrastructure- related goods include the social safety net, scientific knowledge,163 public education and healthcare, access to justice, electoral processes and law enforcement."
281,"See: Karen Maex: ' Protect independent and public knowledge. ' Speech January 8th 2021 https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwiavsCj5_D4AhV LaQKHQzEA64QFnoECAUQAQ&url=https%3A%2F%2Fwww.uva.nl%2Fbinaries%2Fcontent%2Fassets%2Fuva%2Fnl%2Fo ver-de-uva%2Fspeech -karen -maex ---dies -2021.pdf&usg=AOvVaw2V5_UZK8444_8hFUU2XU9s 164 See the work of the Global Data Justice project on pandemic -related commercialisation of public goods: https://globaldatajustice.org/sphere -trans/ 165 For further explanation, see for example Timo Meynhardt, ' Public Value Inside: What Is Public Value Creation?, ' International Journal of Public Administration 32, no."
281,"Data regulation tends to cite both human rights and market efficiency, the former of which aligns well with a social justice -oriented governance model."
281,"In contrast, a social justice perspective starts from the assumption that all societies are unequal playing fields where people' s circumstances give them different degrees of agency and ability to claim their rights."
281,A social justice -oriented data governance model suggests additions to our way of conceptualising vulnerability in relation to technology.
281,"Beyond the notion that people are more easily harmed if they have certain minority or sensitive attributes, a social justice view would add another facet to these considerations: that of unequally distributed power and agency."
281,A data justice perspective demands that we broaden our conceptualisation of contestability beyond claims based on competition and consumer protection regulation.
281,"Taking a justice perspective, our analysis explores the extent to which these interests productively interact, where governance becomes skewed toward economic priorities at the expense of people, and how the plural interests of the EU 's diverse populations can be recognised and represented through the process of governing technologies."
281,"207 Nancy Fraser (2008). ' Abnormal justice. ' Critical inquiry , 34(3), 39. https://doi.org/10.1086/589478 208 European Parliament and Council of the European Union, ' Proposal for a Regulation of the European Parliament and of the Council laying down harmonised rules on Artificia l Intelligence (Artificial Intelligence Act) and amending certain Union legislative acts' Pub."
281,"In our discussion so far on thinking about data governance from a social justice standpoint, there are few considerations that have emerged that require further discussion."
281,"Policy options and alternatives: a data justice analysis In this section we will analyse policy options first in relation to the European Strategy for Data, and then in relation to the principal legislative files currently under development."
281,"233 Sohel Sarkar and Amay Korjan, eds., A Digital New Deal: Visions of Justice in a Post -Covid World (IT for Change and Just Net Coalition, 2021)."
281,"Starting from a definition of governance as arbitration between different interests with regard to publ ic and private goods, we have offered a justice- based analysis of the legislative context with regard to artificial intelligence and contributing data technologies and argue that along with considerations of its economic benefits, a strategy as to how Euro pean AI generates public value could be central to the EU 's policy aims."
281,"We then conducted an analysis of the core set of legislative files relating to AI, and explored how they could be align ed with these justice -based benchmarks for good governance."
281,"With a particular focus on artificial intelligence ( AI), th is study identifies and examines policy options for the EU' s data governance framework that align with a data justice perspective."
281,"We propose four benchmarks for good data governance according to principles of justice: pre serving and strengthening public infrastructures and public goods, inclusiveness, contestability and accountability, and global responsibility."
282,"It might also compound further the pro blems with international transfer of data after that the US Safe Harbour and later the EU -US Privacy Shield were invalidated by the Court of Justice (Schrems I and II case- law, C -362/14 and C -311/18), as illustrated by Kiner (2020)."
282,The Schrems II judgment of the Court of Justice and the future of data transfer regulation.
282,"European Law Blog: https://europeanlawblog.eu/2020/07/17/the -schrems -iijudgment -of-the-court -of-justice -and -the-future -of-data -transfer- regulation/ . • Krupi, T."
285,"P eace, inclusiv eness and justice, equity and interconnectedness should be promoted throughout the lifecycle of AI systems ."
285,"These include freedom, dignity and autonomy, privacy and data protection, non discrimination and equality, diversity, fairness, social justice, and internationally recognised labour rights'."
286,"At EU level, t he processing of biometric data has been actively encouraged and directly supported over the past years in the context of EU -level large -scale information technology ( IT) systems in the area of freedom, security and justice ( AFSJ )."
286,"A review of this architecture and of the most relevant rules on biometrics and on automated decision -making in EU data protection la w, as well as of the most important case law in this area emanating from the Cour t of Justice of the EU (CJEU) and the European Court of Human Rights (ECtHR) , shows that ongoing technological developments are taking place amid – and possibly also somehow despite – existing rights and principles , which might thus possibly need to be reinforced, clarified, or at least fine -tuned."
286,"The processing of biometric data has been actively supported at EU level23 in the context of EU -level large -scale IT systems in the Area of Freedom, Security and Justice (AFSJ)."
286,I t also presents the most important case law in this area emanating from the Court of Justice of the EU (CJEU) and the European Court of Human Rights (ECtHR).
286,"Legal aid shall be made available to those who lack sufficient resources in so far as such aid is necessary to ensure effective access to justice. ' 51 In this sense, see for instance EDPB and EDPS, Joint Opinion 5/2021 12."
286,"Fundamental rights case law Analysing the case law of the Court of Justice of the EU (CJEU) on biometrics, a series of points stand out."
286,"As underlined in a report for the Committee on Equality and Non- Discrimination of the Council of Europe 's Parliamentary Assembly, certain flaws in a the criminal justice system can have ' far-reaching human rights consequences ' (Lacroix 2020 12)."
286,"Other areas mentioned as involving the qualification of an AI system as high risk are management and operation of critical infrastructure , educational and vocational training ; employment , workers management and acces s to self -employment; access to and enjoyment of essential private services and public services and benefits; law enforcement ; migration, asylum and border control management ; administration of justice and democratic processes ."
286,"This could relate to ' emotion recognition.' '(e) AI systems intended to be used by law enforcement authorities for predicting the occurrence or reoccurrence of an actual or potential criminal offence based on profiling of Person identification, human rights and ethical principles 43 natural persons as referred to in Article 3(4) of Directive (EU) 2016/680 or assessing personality traits and characteristics or past criminal behaviour of natural persons or groups. ' '(f) AI systems intended to be used by law enforcement authorities for profiling of natural persons as ref erred to in Article 3(4) of Directive (EU) 2016/680 in the course of detection, investigation or prosecution of criminal offences. ' '(g) AI systems intended to be used for crime analytics regarding natural persons, allowing law enforcement authorities to s earch complex related and unrelated large data sets available in different data sources or in different data formats in order to identify unknown patterns or discover hidden relationships in the data. ' Under heading 7, on ' Migration, asylum and border cont rol management' , stand out: '(a) AI systems intended to be used by competent public authorities as polygraphs and similar tools or to detect the emotional state of a natural person; ' 'd) AI systems intended to assist competent public authorities for the examination of applications for asylum, visa and residence permits and associated complaints with regard to the eligibility of the natural persons applying for a status. ' Under heading 8, on ' Administration of justice and democratic processes ', are mention ed: '(a) AI systems intended to assist a judicial authority in researching and interpreting facts and the law and in applying the law to a concrete set of facts. ' The proposal foresees that Annex III might be amended by the European Commission via delegated acts (proposed Article 7(1) AIA)."
286,"European Union Agency for the Operatio nal Management of Large -Scale IT Systems in the Area of Freedom, Security and Justice (eu -LISA)."
289,"RR\1215422EN.docx PE650.508v02-00 ENUnited in diversityENEuropean Parliament 2019-2024 Plenary sitting A9-0186/2020 8.10.2020 REPORT with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies (2020/2012(INL)) Committee on Legal Affairs Rapporteur: Ibán García del Blanco Rapporteurs for the opinion (*): Urmas Paet, Committee on Foreign Affairs Alexandra Geese, Committee on Internal Market and Consumer Protection Valter Flego, Committee on Transport and Tourism Assita Kanko, Committee on Civil Liberties, Justice and Home Affairs (*) Associated committees – Rule 57 of the Rules of Procedure (Initiative – Rule 47 of the Rules of Procedure) PE650.508v02-00 2/130 RR\1215422EN.docx ENPR_INL CONTENTS Page MOTION FOR A EUROPEAN PARLIAMENT RESOLUTION............................................."
289,"84 OPINION OF THE COMMITTEE ON CIVIL LIBERTIES, JUSTICE AND HOME AFFAIRS .................................................................................................................................."
289,"RR\1215422EN.docx 5/130 PE650.508v02-00 ENRights and Fundamental Freedoms, and the European Charter for Regional or Minority Languages, – having regard to the OECD Council Recommendation on Artificial Intelligence adopted on 22 May 2019, – having regard to Rules 47 and 54 of its Rules of Procedure, – having regard to the opinions of the Committee on Foreign Affairs, the Committee on the Internal Market and Consumer Protection, the Committee on Transport and Tourism, the Committee on Civil Liberties, Justice and Home Affairs, the Committee on Employment and Social Affairs, the Committee on the Environment, Public Health and Food Safety and the Committee on Culture and Education, – having regard to the report of the Committee on Legal Affairs (A9-0186/2020), Introduction A. whereas the development, deployment and use of artificial intelligence (also referred to as ‘AI’), robotics and related technologies is carried out by humans, and their choices determine the potential of such technologies to benefit society; B. whereas artificial intelligence, robotics and related technologies that have the potential to generate opportunities for businesses and benefits for citizens and that can directly impact all aspects of our societies, including fundamental rights and social and economic principles and values, as well as have a lasting influence on all areas of activity, are being promoted and developed quickly; C. whereas artificial intelligence, robotics and related technologies will lead to substantial changes to the labour market and in the workplace; whereas they can potentially replace workers performing repetitive activities, facilitate human-machine collaborative working systems, increase competitiveness and prosperity and create new job opportunities for qualified workers while at the same time posing a serious challenge in terms of reorganisation of the workforce; D. whereas the development of artificial intelligence, robotics and related technologies can also contribute to reaching the sustainability goals of the European Green Deal in many different sectors; whereas digital technologies can boost the impact of policies as regards environmental protection; whereas they can also contribute to reducing traffic congestion and emissions of greenhouse gases and air pollutants; E. whereas, for sectors like public transport, AI-supported intelligent transport systems can be used to minimise queuing, optimise routing, enable persons with disabilities to be more independent, and increase energy efficiency thereby enhancing decarbonisation efforts and reducing the environmental footprint; F. whereas these technologies bring about new business opportunities which can contribute to the recovery of Union industry after the current health and economic crisis if greater use is made of them, for instance, in the transport industry; whereas such opportunities can create new jobs, as the uptake of these technologies has the potential PE650.508v02-00 6/130 RR\1215422EN.docx ENto increase businesses' productivity levels and contribute to efficiency gains; whereas innovation programs in this area can enable regional clusters to thrive; G. whereas the Union and its Member States have a particular responsibility to harness, promote and enhance the added value of artificial intelligence and make sure that AI technologies are safe and contribute to the well-being and general interest of their citizens as they can make a huge contribution to reaching the common goal of improving the lives of citizens and fostering prosperity within the Union by contributing to the development of better strategies and innovation in a number of areas and sectors; whereas, in order to exploit the full potential of artificial intelligence and make users aware of the benefits and challenges that AI technologies bring, it is necessary to include AI or digital literacy in education and training, including in terms of promoting digital inclusion, and to conduct information campaigns at Union level that give an accurate representation of all aspects of AI development; H. whereas a common Union regulatory framework for the development, deployment and use of artificial intelligence, robotics and related technologies (‘regulatory framework for AI’) should allow citizens to share the benefits drawn from their potential, while protecting citizens from the potential risks of such technologies and promoting the trustworthiness of such technologies in the Union and elsewhere; whereas that framework should be based on Union law and values and guided by the principles of transparency and explainability, fairness, accountability and responsibility; I. whereas such a regulatory framework is of key importance in avoiding the fragmentation of the Internal Market, resulting from differing national legislation and will help foster much needed investment, develop data infrastructure and support research; whereas it should consist of common legal obligations and ethical principles as set out in the proposal for a Regulation requested in the annex to this resolution; whereas it should be established according to the better regulation guidelines; J. whereas the Union has a strict legal framework in place to ensure, inter alia, the protection of personal data and privacy and non-discrimination, to promote gender equality, environmental protection and consumers’ rights; whereas such a legal framework consisting of an extensive body of horizontal and sectoral legislation , including the existing rules on product safety and liability, will continue to apply in relation to artificial intelligence, robotics and related technologies, although certain adjustments of specific legal instruments may be necessary to reflect the digital transformation and address new challenges posed by the use of artificial intelligence; K. whereas there are concerns that the current Union legal framework, including the consumer law and employment and social acquis, data protection legislation, product safety and market surveillance legislation, as well as antidiscrimination legislation may no longer be fit for purpose to effectively tackle the risks created by artificial intelligence, robotics and related technologies; L. whereas in addition to adjustments to existing legislation, legal and ethical questions relating to AI technologies should be addressed through an effective, comprehensive and future-proof regulatory framework of Union law reflecting the Union’s principles and values as enshrined in the Treaties and the Charter of Fundamental Rights that RR\1215422EN.docx 7/130 PE650.508v02-00 ENshould refrain from over-regulation, by only closing existing legal loopholes, and increase legal certainty for businesses and citizens alike, namely by including mandatory measures to prevent practices that would undoubtedly undermine fundamental rights; M. whereas any new regulatory framework needs to take into consideration all the interests at stake; whereas careful examination of the consequences of any new regulatory framework on all actors in an impact assessment should be a prerequisite for further legislative steps; whereas the crucial role of Small- and Medium sized enterprises (SMEs) and start-ups especially in the Union economy justifies a strictly proportionate approach to enable them to develop and innovate; N. whereas artificial intelligence, robotics and related technologies can have serious implications for the material and immaterial integrity of individuals, groups, and society as a whole, and potential individual and collective harm must be addressed with legislative responses; O. whereas, in order to respect a Union’s regulatory framework for AI, specific rules for the Union’s transport sector may need to be adopted; P. whereas AI technologies are of strategic importance for the transport sector, including due to them raising the safety and accessibility of all modes of transport, and creating new employment opportunities and more sustainable business models; whereas a Union approach to the development of artificial intelligence, robotics and related technologies in transport has the potential to increase the global competitiveness and strategic autonomy of the Union economy; Q. whereas human error is still involved in about 95% of all road traffic accidents in the Union; whereas the Union aimed to reduce annual road fatalities in the Union by 50% by 2020 compared to 2010, but, in view of stagnating progress, renewed its efforts in its Road Safety Policy Framework 2021 - 2030 - Next steps towards ""Vision Zero""; whereas in this regard, AI, automation and other new technologies have great potential and vital importance for increasing road safety by reducing the possibilities for human error; R. whereas the Union’s regulatory framework for AI should also reflect the need to ensure that workers’ rights are respected; whereas regard should be had to the European Social Partners Framework Agreement on Digitalisation of June 2020; S. whereas the scope of the Union’s regulatory framework of AI should be adequate, proportionate and thoroughly assessed; whereas it should cover a wide range of technologies and their components, including algorithms, software and data used or produced by them, a targeted risk-based approach is necessary to avoid hampering future innovation and the creation of unnecessary burdens, especially for SMEs; whereas the diversity of applications driven by artificial intelligence, robotics and related technologies complicates finding a single solution suitable for the entire spectrum of risks; T. whereas data analysis and AI increasingly impact on the information made accessible to citizens; whereas such technologies, if misused, may endanger fundamental rights to PE650.508v02-00 8/130 RR\1215422EN.docx ENfreedom of expression and information as well as media freedom and pluralism; U. whereas the geographical scope of the Union’s regulatory framework for AI should cover all the components of artificial intelligence, robotics and related technologies developed, deployed or used in the Union, including in cases where part of the technologies might be located outside the Union or not have a specific location; V. whereas the Union’s regulatory framework for AI should encompass all relevant stages, namely the development, the deployment and the use of the relevant technologies and their components, requiring due consideration of the relevant legal obligations and ethical principles and should set the conditions to make sure that developers, deployers and users are fully compliant with such obligations and principles; W. whereas a harmonised approach to ethical principles relating to artificial intelligence, robotics and related technologies requires a common understanding in the Union of the concepts that form the basis of the technologies such as algorithms, software, data or biometric recognition; X. whereas action at Union level is justified by the need to avoid regulatory fragmentation or a series of national regulatory provisions with no common denominator and to ensure a homogenous application of common ethical principles enshrined in law when developing, deploying and using high-risk artificial intelligence, robotics and related technologies; whereas clear rules are needed where the risks are significant; Y. whereas common ethical principles are only efficient where they are also enshrined in law, and those responsible for ensuring, assessing and monitoring compliance are identified; Z. whereas ethical guidance, such as the principles adopted by the High-Level Expert Group on Artificial Intelligence, provides a good starting point but cannot ensure that developers, deployers and users act fairly and guarantee the effective protection of individuals; whereas such guidance is all the more relevant with regard to high-risk artificial intelligence, robotics and related technologies; AA. whereas each Member State should designate a national supervisory authority responsible for ensuring, assessing and monitoring the compliance of the development, deployment and use of high-risk artificial intelligence, robotics and related technologies with the Union’s regulatory framework for AI; and for allowing discussions and exchanges of views in close cooperation with relevant stakeholders and civil society; whereas national supervisory authorities should cooperate with each other; AB. whereas in order to ensure a harmonised approach across the Union and the optimal functioning of the Digital Single Market, coordination at Union level by the Commission, and any/or relevant institutions, bodies, offices and agencies of the Union that may be designated in this context, should be assessed as regards the new opportunities and challenges, in particular those of a cross-border nature, arising from ongoing technological developments; whereas, to this end, the Commission should be tasked with finding an appropriate solution to structure such coordination at Union level; RR\1215422EN.docx 9/130 PE650.508v02-00 ENHuman-centric and human-made artificial intelligence 1."
289,"Considers that technologies which can produce automated decisions, thus replacing decisions taken by public authorities, should be treated with the utmost precaution , notably in the area of justice and law enforcement; 68."
289,"(9) The development, deployment and use of artificial intelligence, robotics and related technologies, including the software, algorithms and data used or produced by such technologies, should complement human capabilities, not substitute them and ensure that their execution does not run against the best interests of citizens and that it complies with Union law, fundamental rights as set out in the Charter of Fundamental 1 For automated driving of vehicles, six levels of driving automation have been proposed by SAE International standard J3016, last updated in 2018 to J3016_201806. https://www.sae.org/standards/content/j3016_201806/ RR\1215422EN.docx 39/130 PE650.508v02-00 ENRights of the European Union (the ‘Charter’), settled case-law of the Court of Justice of the European Union, and other European and international instruments which apply in the Union."
289,"Dalunde, Karima Delli, Anna Deparnay-Grunenberg, Tilly Metz 0 0 0 Key to symbols: + : in favour - : against 0 : abstention RR\1215422EN.docx 91/130 PE650.508v02-00 EN22.9.2020 OPINION OF THE COMMITTEE ON CIVIL LIBERTIES, JUSTICE AND HOME AFFAIRS for the Committee on Legal Affairs with recommendations to the Commission on the framework of ethical aspects of artificial intelligence, robotics and related technologies (2020/2012(INL)) Rapporteur for opinion (*): Assita Kanko (*) Associated committee – Rule 57 of the Rules of Procedure (Initiative – Rule 47 of the Rules of Procedure) SUGGESTIONS The Committee on Civil Liberties, Justice and Home Affairs calls on the Committee on Legal Affairs, as the committee responsible, to incorporate the following suggestions into its motion for a resolution: – having regard to Articles 2 and 3 of the Treaty on European Union (TEU), – having regard to Articles 10, 19, 21 and 167 of the Treaty on the Functioning of the European Union (TFEU), – having regard to the right to petition enshrined in Articles 20 and 227 of the TFEU and Article 44 of the Charter of Fundamental Rights of the European Union (EUCFR), – having regard to Articles 21 and 22 of the EUCFR, – having regard to the preamble to the TEU, – having regard to the Council of Europe’s Framework Convention for the Protection of National Minorities, Protocol No 12 to the Convention for the Protection of Human Rights and Fundamental Freedoms, and the European Charter for Regional or Minority Languages, – having regard to Council Directive 2000/43/EC of 29 June 2000 implementing the principle of equal treatment between persons irrespective of racial or ethnic origin1 1 OJ L 180, 19.7.2000, p."
290,"REPORT with recommendations to the Commission on Civil Law Rules on Robotics | A8-0005/2017 | European ParliamentAccess to page content (press ""Enter"")Direct access to language menu (press ""Enter"")EN - English BG - български ES - español CS - čeština DA - dansk DE - Deutsch ET - eesti keel EL - ελληνικά EN - English FR - français GA - Gaeilge HR - hrvatski IT - italiano LV - latviešu valoda LT - lietuvių kalba HU - magyar MT - Malti NL - Nederlands PL - polski PT - português RO - română SK - slovenčina SL - slovenščina FI - suomi SV - svenska NewsTopicsMEPsAbout ParliamentPlenaryCommitteesDelegationsEU budgetOther websitesView other websitesNewsTopicsMEPsAbout ParliamentPlenaryCommitteesDelegationsMultimedia CentrePresidencySecretariat-generalElectionsThink tankEP NewshubAt your serviceVisitsLegislative ObservatoryLegislative trainContracts and GrantsRegisterOpen Data PortalLiaison officesReport - A8-0005/2017ReportA8-0005/2017European ParliamentDownloadA-8-2017-0005_EN (PDF - 573 KB)A-8-2017-0005_EN (DOC - 118 KB) European Parliament REPORT with recommendations to the Commission on Civil Law Rules on Robotics27.1.2017 - (2015/2103(INL))Committee on Legal AffairsRapporteur: Mady Delvaux(Initiative – Rule 46 of the Rules of Procedure)Rapporteurs for the opinions (*):Georg Mayer, Committee on Transport and Tourism Michał Boni, Committee on Civil Liberties, Justice and Home Affairs(*) Associated committees – Rule 54 of the Rules of ProcedureAmendments001-001 (PDF - 10 KB)001-001 (DOC - 48 KB)002-003/REV1 (PDF - 100 KB)002-003/REV1 (DOC - 50 KB)004-008 (PDF - 134 KB)004-008 (DOC - 59 KB)009-010/REV1 (PDF - 102 KB)009-010/REV1 (DOC - 51 KB)009-013 (PDF - 114 KB)009-013 (DOC - 14 KB)012-013/REV1 (PDF - 102 KB)012-013/REV1 (DOC - 50 KB) Procedure : 2015/2103(INL)Document stages in plenaryDocument selected : A8-0005/2017Texts tabled : A8-0005/2017 Debates : PV 15/02/2017 - 14 CRE 15/02/2017 - 14 Votes : PV 16/02/2017 - 6.9 Explanations of votes Texts adopted : P8_TA(2017)0051 MOTION FOR A EUROPEAN PARLIAMENT RESOLUTION ANNEX TO THE MOTION FOR A RESOLUTION:DETAILED RECOMMENDATIONS AS TO THE CONTENT OF THE PROPOSAL REQUESTED EXPLANATORY STATEMENT OPINION of the Committee on Transport and Tourism (*) OPINION of the Committee on Civil Liberties, Justice and Home Affairs (*) OPINION of the Committee on Employment and Social Affairs OPINION of the Committee on the Environment, Public Health and Food Safety OPINION of the Committee on Industry, Research and Energy OPINION of the Committee on the Internal Market and Consumer Protection RESULT OF FINAL VOTE IN COMMITTEE RESPONSIBLEMOTION FOR A EUROPEAN PARLIAMENT RESOLUTION with recommendations to the Commission on Civil Law Rules on Robotics (2015/2103(INL)) The European Parliament, – having regard to Article 225 of the Treaty on the Functioning of the European Union, – having regard to the Product Liability Directive 85/374/EEC, – having regard to Rules 46 and 52 of its Rules of Procedure, – having regard to the report of the Committee on Legal Affairs and the opinions of the Committee on Transport and Tourism, the Committee on Civil Liberties, Justice and Home Affairs, the Committee on Employment and Social Affairs, the Committee on the Environment, Public Health and Food Safety, the Committee on Industry, Research and Energy and the Committee on the Internal Market and Consumer Protection (A8-0005/2017), Introduction A. whereas from Mary Shelley's Frankenstein's Monster to the classical myth of Pygmalion, through the story of Prague's Golem to the robot of Karel Čapek, who coined the word, people have fantasised about the possibility of building intelligent machines, more often than not androids with human features; B. whereas now that humankind stands on the threshold of an era when ever more sophisticated robots, bots, androids and other manifestations of artificial intelligence (""AI"") seem to be poised to unleash a new industrial revolution, which is likely to leave no stratum of society untouched, it is vitally important for the legislature to consider its legal and ethical implications and effects, without stifling innovation; C. whereas there is a need to create a generally accepted definition of robot and AI that is flexible and is not hindering innovation; D. whereas between 2010 and 2014 the average increase in sales of robots stood at 17% per year and in 2014 sales rose by 29%, the highest year-on-year increase ever, with automotive parts suppliers and the electrical/electronics industry being the main drivers of the growth; whereas annual patent filings for robotics technology have tripled over the last decade; E. whereas, over the past 200 years employment figures had persistently increased due to the technological development; whereas the development of robotics and AI may have the potential to transform lives and work practices, raise efficiency, savings, and safety levels, provide enhanced level of services in the short to medium term robotics and AI promise to bring benefits of efficiency and savings, not only in production and commerce, but also in areas such as transport, medical care, rescue, education and farming, while making it possible to avoid exposing humans to dangerous conditions, such as those faced when cleaning up toxically polluted sites; F. whereas ageing is the result of an increased life expectancy due to progress in living conditions and in modern medicine, and is one of the greatest political, social, and economic challenges of the 21st century for European societies; whereas by 2025 more than 20 % of Europeans will be 65 or older, with a particularly rapid increase in numbers of people who are in their 80s or older, which will lead to a fundamentally different balance between generations within our societies, and whereas it is in the interest of society that older people remain healthy and active for as long as possible; G. whereas in the long-term, the current trend leans towards developing smart and autonomous machines, with the capacity to be trained and make decisions independently, holds not only economic advantages but also a variety of concerns regarding their direct and indirect effects on society as a whole; H. whereas machine learning offers enormous economic and innovative benefits for society by vastly improving the ability to analyse data, while also raising challenges to ensure non-discrimination, due process, transparency and understandability in decision-making processes; I. whereas similarly, assessments of economic shifts and the impact on employment as a result of robotics and machine learning need to be assessed; whereas, despite the undeniable advantages afforded by robotics, its implementation may entail a transformation of the labour market and a need to reflect on the future of education, employment, and social policies accordingly; J. whereas the widespread use of robots might not automatically lead to job replacement, but lower skilled jobs in labour-intensive sectors are likely to be more vulnerable to automation; whereas this trend could bring production processes back to the EU; whereas research has demonstrated that employment grows significantly faster in occupations that use computers more; whereas the automation of jobs has the potential to liberate people from manual monotone labour allowing them to shift direction towards more creative and meaningful tasks; whereas automation requires governments to invest in education and other reforms in order to improve reallocation in the types of skills that the workers of tomorrow will need; K. whereas at the same time the development of robotics and AI may result in a large part of the work now done by humans being taken over by robots without fully replenishing the lost jobs, so raising concerns about the future of employment, the viability of social welfare and security systems and the continued lag in pension contributions, if the current basis of taxation is maintained, creating the potential for increased inequality in the distribution of wealth and influence, while, for the preservation of social cohesion and prosperity, the likelihood of levying tax on the work performed by a robot or a fee for using and maintaining a robot should be examined in the context of funding the support and retraining of unemployed workers whose jobs have been reduced or eliminated; L. whereas in the face of increasing divisions in society, with a shrinking middle class, it is important to bear in mind that developing robotics may lead to a high concentration of wealth and influence in the hands of a minority; M. whereas the development of Robotics and AI will definitely influence the landscape of the workplace what may create new liability concerns and eliminate others; whereas the legal responsibility need to be clarified from both business sight model, as well as the workers design pattern, in case emergencies or problems occur; N. whereas the trend towards automation requires that those involved in the development and commercialisation of artificial intelligence applications build in security and ethics at the outset, thereby recognizing that they must be prepared to accept legal liability for the quality of the technology they produce; O. whereas Regulation (EU) 2016/679 of the European Parliament and of the Council[1] (the General Data Protection Regulation) sets out a legal framework to protect personal data; whereas further aspects of data access and the protection of personal data and privacy might still need to be addressed, given that privacy concerns might still arise from applications and appliances communicating with each other and with databases without human intervention; P. whereas the developments in robotics and artificial intelligence can and should be designed in such a way that they preserve the dignity, autonomy and self-determination of the individual, especially in the fields of human care and companionship, and in the context of medical appliances, 'repairing' or enhancing human beings; Q. whereas ultimately there is a possibility that in the long-term, AI could surpass human intellectual capacity; R. whereas further development and increased use of automated and algorithmic decision-making undoubtedly has an impact on the choices that a private person (such as a business or an internet user) and an administrative, judicial or other public authority take in rendering their final decision of a consumer, business or authoritative nature; whereas safeguards and the possibility of human control and verification need to be built into the process of automated and algorithmic decision-making; S. whereas several foreign jurisdictions, such as the US, Japan, China and South Korea, are considering, and to a certain extent have already taken, regulatory action with respect to robotics and AI, and whereas some Member States have also started to reflect on possibly drawing up legal standards or carrying out legislative changes in order to take account of emerging applications of such technologies; T. whereas the European industry could benefit from an efficient, coherent and transparent approach to regulation at Union level, providing predictable and sufficiently clear conditions under which enterprises could develop applications and plan their business models on a European scale while ensuring that the Union and its Member States maintain control over the regulatory standards to be set, so as not to be forced to adopt and live with standards set by others, that is to say the third countries which are also at the forefront of the development of robotics and AI; General principles U. whereas Asimov's Laws[2] must be regarded as being directed at the designers, producers and operators of robots, including robots assigned with built-in autonomy and self-learning, since those laws cannot be converted into machine code; V. whereas a series of rules, governing in particular liability, transparency and accountability, are useful, reflecting the intrinsically European and universal humanistic values that characterise Europe's contribution to society, are necessary; whereas those rules must not affect the process of research, innovation and development in robotics; W. whereas the Union could play an essential role in establishing basic ethical principles to be respected in the development, programming and use of robots and AI and in the incorporation of such principles into Union regulations and codes of conduct, with the aim of shaping the technological revolution so that it serves humanity and so that the benefits of advanced robotics and AI are broadly shared, while as far as possible avoiding potential pitfalls; X. whereas a gradualist, pragmatic and cautious approach of the type advocated by Jean Monnet[3] should be adopted for the Union with regard to future initiatives on robotics and AI so as to ensure that we do not stifle innovation; Y. whereas it is appropriate, in view of the stage reached in the development of robotics and AI, to start with civil liability issues; Liability Z. whereas, thanks to the impressive technological advances of the last decade, not only are today's robots able to perform activities which used to be typically and exclusively human, but the development of certain autonomous and cognitive features – e.g. the ability to learn from experience and take quasi-independent decisions – has made them more and more similar to agents that interact with their environment and are able to alter it significantly; whereas, in such a context, the legal responsibility arising through a robot’s harmful action becomes a crucial issue; AA. whereas a robot's autonomy can be defined as the ability to take decisions and implement them in the outside world, independently of external control or influence; whereas this autonomy is of a purely technological nature and its degree depends on how sophisticated a robot's interaction with its environment has been designed to be; AB. whereas the more autonomous robots are, the less they can be considered to be simple tools in the hands of other actors (such as the manufacturer, the operator, the owner, the user, etc.); whereas this, in turn, questions whether the ordinary rules on liability are sufficient or whether it calls for new principles and rules to provide clarity on the legal liability of various actors concerning responsibility for the acts and omissions of robots where the cause cannot be traced back to a specific human actor and whether the acts or omissions of robots which have caused harm could have been avoided; AC. whereas, ultimately, the autonomy of robots raises the question of their nature in the light of the existing legal categories or whether a new category should be created, with its own specific features and implications; AD. whereas under the current legal framework robots cannot be held liable per se for acts or omissions that cause damage to third parties; whereas the existing rules on liability cover cases where the cause of the robot’s act or omission can be traced back to a specific human agent such as the manufacturer, the operator, the owner or the user and where that agent could have foreseen and avoided the robot’s harmful behaviour; whereas, in addition, manufacturers, operators, owners or users could be held strictly liable for acts or omissions of a robot; AE. whereas according to the current legal framework product liability - where the producer of a product is liable for a malfunction- and rules governing liability for harmful actions -where the user of a product is liable for a behaviour that leads to harm- apply to damages caused by robots or AI; AF. whereas in the scenario where a robot can take autonomous decisions, the traditional rules will not suffice to give rise to legal liability for damage caused by a robot, since they would not make it possible to identify the party responsible for providing compensation and to require that party to make good the damage it has caused; AG. whereas the shortcomings of the current legal framework are also apparent in the area of contractual liability insofar as machines designed to choose their counterparts, negotiate contractual terms, conclude contracts and decide whether and how to implement them make the traditional rules inapplicable, which highlights the need for new, efficient and up-to-date ones, which should comply with the technological development and the innovations recently arisen and used on the market; AH. whereas, as regards non-contractual liability, Council Directive 85/374/EEC[4] can cover only damage caused by a robot's manufacturing defects and on condition that the injured person is able to prove the actual damage, the defect in the product and the causal relationship between damage and defect, therefore strict liability or liability without fault framework may not be sufficient; AI. whereas, notwithstanding the scope of the Directive 85/374/EEC, the current legal framework would not be sufficient to cover the damage caused by the new generation of robots, insofar as they can be equipped with adaptive and learning abilities entailing a certain degree of unpredictability in their behaviour, since those robots would autonomously learn from their own variable experience and interact with their environment in a unique and unforeseeable manner; General principles concerning the development of robotics and artificial intelligence for civil use 1."
290,"Points out that the guiding ethical framework should be based on the principles of beneficence, non-maleficence, autonomy and justice, on the principles and values enshrined in Article 2 of the Treaty on European Union and in the Charter of Fundamental Rights, such as human dignity, equality, justice and equity, non-discrimination, informed consent, private and family life and data protection, as well as on other underlying principles and values of the Union law, such as non-stigmatisation, transparency, autonomy, individual responsibility and social responsibility, and on existing ethical practices and codes; 14."
290,"Researchers in the field of robotics should commit themselves to the highest ethical and professional conduct and abide by the following principles: Beneficence – robots should act in the best interests of humans; Non-maleficence – the doctrine of ‘first, do no harm’, whereby robots should not harm a human; Autonomy – the capacity to make an informed, un-coerced decision about the terms of interaction with robots; Justice – fair distribution of the benefits associated with robotics and affordability of homecare and healthcare robots in particular."
290,"LICENCE FOR DESIGNERS – You should take into account the European values of dignity, autonomy and self-determination, freedom and justice before, during and after the process of design, development and delivery of such technologies including the need not to harm, injure, deceive or exploit (vulnerable) users. – You should introduce trustworthy system design principles across all aspects of a robot’s operation, for both hardware and software design, and for any data processing on or off the platform for security purposes. – You should introduce privacy by design features so as to ensure that private information is kept secure and only used appropriately. – You should integrate obvious opt-out mechanisms (kill switches) that should be consistent with reasonable design objectives. – You should ensure that a robot operates in a way that is in accordance with local, national and international ethical and legal principles. – You should ensure that the robot’s decision-making steps are amenable to reconstruction and traceability. – You should ensure that maximal transparency is required in the programming of robotic systems, as well as predictability of robotic behaviour. – You should analyse the predictability of a human-robot system by considering uncertainty in interpretation and action and possible robotic or human failures. – You should develop tracing tools at the robot’s design stage."
290,"OPINION of the Committee on Civil Liberties, Justice and Home Affairs (*) (23.11.2016)for the Committee on Legal Affairswith recommendations to the Commission on Civil Law Rules on Robotics(2015/2103(INL))Rapporteur: Michał Boni (Initiative – Rule 46 of the Rules of Procedure) (*) Associated committee – Rule 54 of the Rules of Procedure SUGGESTIONS The Committee on Civil Liberties, Justice and Home Affairs calls on the Committee on Legal Affairs, as the committee responsible: – to incorporate the following suggestions into its motion for a resolution: A."
290,"Whereas a number of third countries have adopted guidelines and legislation on robotics and some Member States have launched specific reflections in this area; whereas a regulatory framework that governs at Union level the development and the use of robotics and artificial intelligence and builds on existing rules such as the Union’s General Data Protection Regulation[1] could prevent a fragmentation of rules in the single market and further safeguard the protection of the fundamental rights of all EU citizens to human dignity, privacy and family life, the protection of personal data and intellectual property, freedom of expression and information, equality and non-discrimination, solidarity, and citizens’ rights and justice, as well as security and safety, while being subject to the principle of proportionality; Ethical principles 1."
290,"Believes that robotics and artificial intelligence, especially those with built-in autonomy, including the capability to independently extract, collect and share sensitive information with various stakeholders, and the possibility of self-learning or even evolving to self-modify, should be subject to robust conceptual laws or principles, such as that a robot may not kill or harm a human being and that it must obey and be controlled by a human being; that the process by which robots and artificial intelligence collect, use and process personal data must be transparent and comprehensible; believes that these principles should be technology neutral and based on empirical research; supports the development of an ethics-by-default framework for researchers, academia and engineers which ensures that these technological solutions will not hinder research and technological developments but will be in compliance with existing Union and national ethical practices and codes as well as with the rights and principles enshrined in the CFR, in particular human dignity, the respect for and protection of private and family life, security and safety, the protection of personal data, protection of intellectual property, the freedom of expression and information, equality and non-discrimination, solidarity, and citizens’ rights and justice, and should be subject to proportionality; 3."
290,"RECs and the Commission are encouraged to start a reflection in order to develop a code of conduct for researchers/designers and users of medical CPS, that should be based on the principles enshrined in the Union’s Charter of Fundamental Rights (such as human dignity and human rights, equality, justice and equity, benefit and harm, dignity, non-discrimination and non-stigmatisation, autonomy and individual responsibility, informed consent, privacy and social responsibility as well as the rights of the elderly, the integration of persons with disabilities, the right to healthcare, and the right to consumer protection) and on existing ethical practices and codes."
291,"States that in line with strict liability systems of the Member States, the proposed Regulation should cover violations of the important legally protected rights to life, health, physical integrity and property, and should set out the amounts and extent of compensation, as well as the limitation period; is of the opinion that the proposed Regulation should also incorporate significant immaterial harm that results in a verifiable economic loss above a threshold harmonised in Union liability law, that balances the access to justice of affected persons and the interests of other involved persons; urges the Commission to re-evaluate and to align the thresholds for damages in Union law; is of the opinion that the Commission should analyse in depth the legal traditions in all Member States and their existing national laws that grant compensation for immaterial harm, in order to evaluate if the inclusion of immaterial harm in AIspecific legislative acts is necessary and if it contradicts the existing Union legal framework or undermines the national law of the Member States; 20."
291,"This follows from general and widely accepted liability concepts of justice, according to which the person that creates or maintains a risk for the public is liable if that risk causes harm or damage, and thus should ex-ante minimise or ex-post compensate that risk."
291,"(16) This Regulation should cover harm or damage to life, health, physical integrity, property and significant immaterial harm that results in a verifiable economic loss above a threshold, harmonised in Union liability law, that balances the access to justice of affected persons with the interests of other involved persons."
292,"Texts adopted - Artificial intelligence in criminal law and its use by the police and judicial authorities in criminal matters - Wednesday, 6 October 2021 Choisissez la langue de votre document : bg - български es - español cs - čeština da - dansk de - Deutsch et - eesti keel el - ελληνικά en - English fr - français ga - Gaeilge hr - hrvatski it - italiano lv - latviešu valoda lt - lietuvių kalba hu - magyar mt - Malti nl - Nederlands pl - polski pt - português ro - română sk - slovenčina sl - slovenščina fi - suomi sv - svenska Index Previous Next Full text Procedure : 2020/2016(INI)Document stages in plenaryDocument selected : A9-0232/2021Texts tabled : A9-0232/2021 Debates : PV 04/10/2021 - 13 CRE 04/10/2021 - 13 Votes : PV 05/10/2021 - 9 PV 06/10/2021 - 2 Texts adopted : P9_TA(2021)0405 Texts adopted 168k 65k Wednesday, 6 October 2021 - Strasbourg Artificial intelligence in criminal law and its use by the police and judicial authorities in criminal matters P9_TA(2021)0405A9-0232/2021 European Parliament resolution of 6 October 2021 on artificial intelligence in criminal law and its use by the police and judicial authorities in criminal matters (2020/2016(INI)) The European Parliament, – having regard to the Treaty on European Union, in particular Articles 2 and 6 thereof, and to the Treaty on the Functioning of the European Union, in particular Article 16 thereof, – having regard to the Charter of Fundamental Rights of the European Union (the “Charter”), in particular Articles 6, 7, 8, 11, 12, 13, 20, 21, 24 and 47 thereof, – having regard to the Convention for the Protection of Human Rights and Fundamental Freedoms, – having regard to the Council of Europe Convention for the Protection of Individuals with regard to Automatic Processing of Personal Data (ETS 108), and its amending protocol (Convention 108+), – having regard to the European Ethical Charter on the use of artificial intelligence in judicial systems and their environment of the European Commission for the Efficiency of Justice (CEPEJ) of the Council of Europe, – having regard to the Commission communication of 8 April 2019 entitled ‘Building Trust in Human-Centric Artificial Intelligence’ (COM(2019)0168), – having regard to the Ethics Guidelines for Trustworthy AI published by the Commission’s High-Level Expert Group on Artificial Intelligence on 8 April 2019, – having regard to the Commission white paper of 19 February 2020 entitled ‘Artificial Intelligence – A European approach to excellence and trust’ (COM(2020)0065), – having regard to the Commission communication of 19 February 2020 entitled ‘A European strategy for data’ (COM(2020)0066), – having regard to Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation)(1), – having regard to Directive (EU) 2016/680 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data by competent authorities for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, and on the free movement of such data, and repealing Council Framework Decision 2008/977/JHA(2), – having regard to Regulation (EU) 2018/1725 of the European Parliament and of the Council of 23 October 2018 on the protection of natural persons with regard to the processing of personal data by the Union institutions, bodies, offices and agencies and on the free movement of such data, and repealing Regulation (EC) No 45/2001 and Decision No 1247/2002/EC(3), – having regard to Directive 2002/58/EC of the European Parliament and of the Council of 12 July 2002 concerning the processing of personal data and the protection of privacy in the electronic communications sector (Directive on privacy and electronic communications)(4), – having regard to Regulation (EU) 2016/794 of the European Parliament and of the Council of 11 May 2016 on the European Union Agency for Law Enforcement Cooperation (Europol) and replacing and repealing Council Decisions 2009/371/JHA, 2009/934/JHA, 2009/935/JHA, 2009/936/JHA and 2009/968/JHA(5), – having regard to its resolution of 19 June 2020 on the anti-racism protests following the death of George Floyd(6), – having regard to its resolution of 14 March 2017 on fundamental rights implications of big data: privacy, data protection, non-discrimination, security and law-enforcement(7), – having regard to the hearing in the Committee on Civil Liberties, Justice and Home Affairs (LIBE) on 20 February 2020 on artificial intelligence in criminal law and its use by the police and judicial authorities in criminal matters, – having regard to the report of the LIBE mission to the United States in February 2020, – having regard to Rule 54 of its Rules of Procedure, – having regard to the opinions of the Committee on the Internal Market and Consumer Protection and the Committee on Legal Affairs, – having regard to the report of the Committee on Civil Liberties, Justice and Home Affairs (A9-0232/2021), A. whereas digital technologies in general and the proliferation of data processing and analytics enabled by artificial intelligence (AI) in particular, bring with them extraordinary promises and risks; whereas AI development has made a big leap forward in recent years, making it one of the strategic technologies of the 21st century, with the potential to generate substantial benefits in efficiency, accuracy, and convenience, and thus bringing positive change to the European economy and society, but also great risks for fundamental rights and democracies based on the rule of law; whereas AI should not be seen as an end in itself, but as a tool for serving people, with the ultimate aim of increasing human well-being, human capabilities and safety; B. whereas despite continuing advances in computer processing speed and memory capacity, there are as yet no programs that can match human flexibility over wider domains or in tasks requiring understanding of context or critical analysis; whereas, some AI applications have attained the performance levels of human experts and professionals in performing certain specific tasks (e.g. legal tech), and can provide results at a drastically higher speed and wider scale; C. whereas some countries, including several Member States, make more use of AI applications, or embedded AI systems, in law enforcement and the judiciary than others, which is partly due to a lack of regulation and regulatory differences which enable or prohibit AI use for certain purposes; whereas the increasing use of AI in the criminal law field is based in particular on the promises that it would reduce certain types of crime and lead to more objective decisions; whereas these promises, however, do not always hold true; D. whereas fundamental rights and freedoms enshrined in the Charter should be guaranteed throughout the life cycle of AI and related technologies, notably during their design, development, deployment and use, and should apply to the enforcement of the law in all circumstances; E. whereas AI technology should be developed in such a way as to put people at its centre, be worthy of public trust and always work in the service of humans; whereas AI systems should have the ultimate guarantee of being designed so that they can always be shut down by a human operator; F. whereas AI systems need to be designed for the protection and benefit of all members of society (including consideration of vulnerable, marginalised populations in their design), be non-discriminatory, safe, their decisions be explainable and transparent, and respect human autonomy and fundamental rights, in order to be trustworthy, as described in the Ethics Guidelines of the High-Level Expert Group on Artificial Intelligence; G. whereas the Union together with the Member States bears a critical responsibility for ensuring that decisions surrounding the life cycle and use of AI applications in the field of the judiciary and law enforcement are made in a transparent manner, fully safeguard fundamental rights, and in particular do not perpetuate discrimination, biases or prejudices where they exist; whereas the relevant policy choices should respect the principles of necessity and proportionality in order to guarantee constitutionality and a fair and humane justice system; H. whereas AI applications may offer great opportunities in the field of law enforcement, in particular in improving the working methods of law enforcement agencies and judicial authorities, and combating certain types of crime more efficiently, in particular financial crime, money laundering and terrorist financing, online sexual abuse and exploitation of children as well as certain types of cybercrime, thereby contributing to the safety and security of EU citizens, while at the same time they may entail significant risks for the fundamental rights of people; whereas any blanket application of AI for the purpose of mass surveillance would be disproportionate; I. whereas the development and operation of AI systems for police and judicial authorities involves the contribution of multiple individuals, organisations, machine components, software algorithms, and human users in often complex and challenging environments; whereas the applications of AI in law enforcement and the judiciary are in different stages of development, ranging from conceptualisation through prototyping or evaluation to post-approval use; whereas new possibilities for use may arise in the future as technologies become more mature owing to ongoing scientific research worldwide; J. whereas a clear model for assigning legal responsibility for the potential harmful effects of AI systems in the field of criminal law is imperative; whereas regulatory provisions in this field should always maintain human accountability and must aim, first and foremost, to avoid causing any harmful effects to begin with; K. whereas it is ultimately the responsibility of the Member States to guarantee the full respect of fundamental rights when AI systems are used in the field of law enforcement and the judiciary; L. whereas the relationship between protecting fundamental rights and effective policing must always be an essential element in the discussions on whether and how AI should be used by the law enforcement sector, where decisions may have long-lasting consequences on the life and freedom of individuals; whereas this is particularly important as AI has the potential to be a permanent part of our criminal justice ecosystem providing investigative analysis and assistance; M. whereas AI is in use by law enforcement in applications such as facial recognition technologies, e.g. to search suspect databases and identify victims of human trafficking or child sexual exploitation and abuse, automated number plate recognition, speaker identification, speech identification, lip-reading technologies, aural surveillance (i.e. gunshot detection algorithms), autonomous research and analysis of identified databases, forecasting (predictive policing and crime hotspot analytics), behaviour detection tools, advanced virtual autopsy tools to help determine cause of death, autonomous tools to identify financial fraud and terrorist financing, social media monitoring (scraping and data harvesting for mining connections), and automated surveillance systems incorporating different detection capabilities (such as heartbeat detection and thermal cameras); whereas the aforementioned applications, alongside other potential or future applications of AI technology in law enforcement, can have vastly varying degrees of reliability and accuracy and impact on the protection of fundamental rights and on the dynamics of criminal justice systems; whereas many of these tools are used in non-EU countries but would be illegal under the Union data protection aquis and case law; whereas the routine deployment of algorithms, even with a small false positive rate, can result in false alerts outnumbering correct alerts by far; N. whereas AI tools and applications are also used by the judiciary in several countries worldwide, including to support decisions on pre-trial detention, in sentencing, calculating probabilities for reoffending and in determining probation, online dispute resolution, case law management and the provision of facilitated access to the law; whereas this has led to distorted and diminished chances for people of colour and other minorities; whereas at present in the EU, with the exception of some Member States, their use is limited mainly to civil matters; O. whereas the use of AI in law enforcement entails a number of potentially high, and in some cases unacceptable, risks for the protection of fundamental rights of individuals, such as opaque decision-making, different types of discrimination and errors inherent in the underlying algorithm which can be reinforced by feedback loops, as well as risks to the protection of privacy and personal data, the protection of freedom of expression and information, the presumption of innocence, the right to an effective remedy and a fair trial, as well as risks for the freedom and security of individuals; P. whereas AI systems used by law enforcement and the judiciary are also vulnerable to AI-empowered attacks against information systems or data poisoning, whereby a wrong data set is included on purpose in order to produce biased results; whereas in these situations the resulting damage is potentially even more significant, and can result in exponentially greater levels of harm to both individuals and groups; Q. whereas, the deployment of AI in the field of law enforcement and the judiciary should not be seen as a mere technical feasibility, but rather a political decision concerning the design and the objectives of law enforcement and of criminal justice systems; whereas modern criminal law is based on the idea that authorities react to an offence after it has been committed, without assuming that all people are dangerous and need to be constantly monitored in order to prevent potential wrongdoing; whereas AI-based surveillance techniques deeply challenge this approach and render it urgent that legislators worldwide thoroughly assess the consequences of allowing the deployment of technologies that diminish the role of human beings in law enforcement and adjudication; 1."
292,"Considers it essential, both for the effectiveness of the exercise of defence rights and for the transparency of national criminal justice systems, that a specific, clear and precise legal framework regulates the conditions, modalities and consequences of the use of AI tools in the field of law enforcement and the judiciary, as well as the rights of targeted persons, and effective and easily available complaint and redress procedures, including judicial redress; underlines the right of the parties to a criminal proceeding to have access to the data collection process and the related assessments made by or obtained through the use of AI applications; underlines the need for executing authorities involved in judicial cooperation, when deciding on a request for extradition (or surrender) to another Member State or non-EU country, to assess whether the use of AI tools in the requesting country might manifestly compromise the fundamental right to a fair trial; calls on the Commission to issue guidelines on how to conduct such an assessment in the context of judicial cooperation in criminal matters; insists that Member States, in accordance with applicable laws, should ensure that individuals are informed when they are subject to the use of AI applications by law enforcement authorities or the judiciary; 15."
292,"Points out that if humans only rely on the data, profiles and recommendations generated by machines, they will not be able to conduct an independent assessment; highlights the potentially grave adverse consequences, specifically in the area of law enforcement and justice, when individuals overly trust in the seemingly objective and scientific nature of AI tools and fail to consider the possibility of their results being incorrect, incomplete, irrelevant or discriminatory; emphasises that over-reliance on the results provided by AI systems should be avoided, and stresses the need for authorities to build confidence and knowledge to question or override an algorithmic recommendation; considers it important to have realistic expectations on such technological solutions and not to promise perfect law enforcement solutions and detection of all offences committed; 16."
292,"Stresses that only robust European AI governance with independent evaluation can enable the necessary operationalisation of fundamental rights principles; calls for periodic mandatory auditing of all AI systems used by law enforcement and the judiciary where there is the potential to significantly affect the lives of individuals, by an independent authority, to test and evaluate algorithmic systems, their context, purpose, accuracy, performance and scale, and, once they are in operation, in order to detect, investigate, diagnose and rectify any unwanted and adverse effects and to ensure the AI systems are performing as intended; calls therefore for a clear institutional framework for this purpose, including proper regulatory and supervisory oversight, to ensure full implementation and to guarantee a fully informed democratic debate on the necessity and proportionality of AI in the field of criminal justice; underlines that the results of these audits should be made available in public registers so that citizens know the AI systems being deployed and which measures are taken to remedy any violation of fundamental rights; 22."
292,"Highlights further that adequate accountability, responsibility, and liability require significant specialised training with regard to the ethical provisions, potential dangers, limitations, and proper use of AI technology, especially for police and judiciary personnel; emphasises that suitable professional training and qualifications should ensure that decision-makers are trained about the potential for bias, as the data sets may be based on discriminatory and prejudiced data; supports the establishment of awareness-raising and educational initiatives to ensure that individuals working in law enforcement and the judiciary are aware of and understand the limitations, capabilities and risks that the use of AI systems entails, including the risk of automation bias; recalls that the inclusion in AI training data sets of instances of racism by police forces in fulfilling their duties will inevitably lead to racist bias in AI-generated findings, scores, and recommendations; reiterates its call on Member States, therefore, to promote anti-discrimination policies and to develop national action plans against racism in the field of policing and the justice system; 24."
293,"Texts adopted - Fundamental rights implications of big data - Tuesday, 14 March 2017 Choisissez la langue de votre document : bg - български es - español cs - čeština da - dansk de - Deutsch et - eesti keel el - ελληνικά en - English fr - français ga - Gaeilge hr - hrvatski it - italiano lv - latviešu valoda lt - lietuvių kalba hu - magyar mt - Malti nl - Nederlands pl - polski pt - português ro - română sk - slovenčina sl - slovenščina fi - suomi sv - svenska Index Previous Next Full text Procedure : 2016/2225(INI)Document stages in plenaryDocument selected : A8-0044/2017Texts tabled : A8-0044/2017 Debates : PV 13/03/2017 - 15 CRE 13/03/2017 - 15 Votes : PV 14/03/2017 - 6.12 Explanations of votes Texts adopted : P8_TA(2017)0076 Texts adopted 203k 61k Tuesday, 14 March 2017 - Strasbourg Fundamental rights implications of big data P8_TA(2017)0076A8-0044/2017 European Parliament resolution of 14 March 2017 on fundamental rights implications of big data: privacy, data protection, non-discrimination, security and law-enforcement (2016/2225(INI)) The European Parliament, – having regard to Article 16 of the Treaty on the Functioning of the European Union, – having regard to Articles 1, 7, 8, 11, 14, 21, 47 and 52 of the Charter of Fundamental Rights of the European Union, – having regard to the guidelines for the regulation of computerised personal data files of the United Nations General Assembly in its Resolution 45/95 of 14 December 1990, – having regard to Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation)(1) (GDPR), and to Directive (EU) 2016/680 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data by competent authorities for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, and on the free movement of such data, and repealing Council Framework Decision 2008/977/JHA(2), – having regard to the Communication from the Commission to the European Parliament, the Council, the European Economic and Social Committee and the Committee of the Regions entitled ‘A Digital Single Market Strategy for Europe’ of 6 May 2015 (COM(2015)0192), – having regard to the Council of Europe Convention for the protection of individuals with regard to automatic processing of personal data of 28 January 1981 (ETS No 108) and its Additional Protocol of 8 November 2001 (ETS No 181)(3), – having regard to Recommendation CM/Rec(2010)13 of the Committee of Ministers of the Council of Europe to Member States on the protection of individuals with regard to automatic processing of personal data in the context of profiling of 23 November 2010(4), – having regard to Opinion 7/2015 of the European Data Protection Supervisor of 19 November 2015 entitled ‘Meeting the challenges of big data – A call for transparency, user control, data protection by design and accountability’(5), – having regard to Opinion 8/2016 of the European Data Protection Supervisor of 23 September 2016 entitled ‘EDPS Opinion on coherent enforcement of fundamental rights in the age of big data’(6), – having regard to the statement of the Article 29 Data Protection Working Party on the impact of the development of big data on the protection of individuals with regard to the processing of their personal data in the EU of 16 September 2014(7), – having regard to Rule 52 of its Rules of Procedure, – having regard to the report of the Committee on Civil Liberties, Justice and Home Affairs (A8-0044/2017), A. whereas big data refers to the collection, analysis and the recurring accumulation of large amounts of data, including personal data, from a variety of sources, which are subject to automatic processing by computer algorithms and advanced data-processing techniques using both stored and streamed data in order to generate certain correlations, trends and patterns (big data analytics); B. whereas certain big data use cases involve the training of artificial intelligence appliances, such as neuronal networks, and statistical models in order to predict certain events and behaviours; whereas the training data are often of questionable quality and not neutral; C. whereas the progress of communication technologies and the ubiquitous use of electronic devices, monitoring gadgets, social media, web interactions and networks, including devices which communicate information without human interference, have led to the development of massive, ever-growing data sets which, through advanced processing techniques and analytics, provide unprecedented insight into human behaviour, private life and our societies; D. whereas the intelligence services of third countries and Member States have increasingly been relying on the processing and analytics of such datasets, which are either not covered by any legal framework or, most recently, have been the subject of legislation the compatibility of which with Union primary and secondary law raises concerns and is yet to be ascertained; E. whereas the increase in bullying, violence against women and the vulnerability of children is also taking place on the internet; whereas the Commission and the Member States should adopt all the requisite legal measures to combat these phenomena; F. whereas an increasing number of corporations, businesses, bodies and agencies, governmental and non-governmental organisations (as well as the public and private sectors in general), political leaders, civil society, academia, the scientific community and citizens as a whole have taken advantage of such data sets and big data analytics to bolster competitiveness, innovation, market predictions, political campaigns, targeted advertising, scientific research and policymaking in the field of transport, taxation, financial services, smart cities, law enforcement, transparency, public health and disaster response, and to influence elections and political outcomes through, for instance, targeted communications; G. whereas the big data market is growing as a result of the technology and the process of data-driven decision-making being increasingly accepted as providing solutions; whereas there is not yet the methodology to make an evidence-based assessment of the total impact of big data, but there is evidence to suggest that big data analytics can have a significant horizontal impact across both the public and private sectors; whereas the Commission’s Digital Single Market Strategy for Europe recognises the potential of data-driven technologies, services and big data to act as a catalyst for economic growth, innovation and digitalisation in the EU; H. whereas big data analytics generates added value in a variety of ways, with numerous positive examples, entailing significant opportunities for citizens, e.g. in the areas of healthcare, the fight against climate change, the reduction of energy consumption, improvements to transport safety and the enablement of smart cities, thereby improving business optimisation and efficiency and contributing to improved working conditions and detecting and combating fraud; whereas big data can provide a competitive advantage to the decision-making processes of European companies, while the public sector can benefit from greater efficiency thanks to greater insights into the different levels of socio-economic developments; I. whereas big data has the aforementioned potential for citizens, academia, the scientific community and the public and private sectors, but also entails significant risks, namely with regard to the protection of fundamental rights, such as the right to privacy, data protection and data security, but also freedom of expression and non-discrimination, as guaranteed by the EU Charter of Fundamental Rights and Union law; whereas pseudonymisation and encryption techniques can mitigate risks related to big data analytics and therefore play an important role in safeguarding the privacy of the data subject, while also fostering innovation and economic growth; whereas these elements are to be considered as part of the current revision of the e-privacy Directive; J. whereas the pervasiveness of sensors, extensive routine data production and contemporary data-processing activities are not always sufficiently transparent, posing challenges to the capacity of individuals and authorities to assess the processes and purpose of the collection, compilation, analysis and use of personal data; whereas a blurring between personal and non-personal data can be seen to emerge from the use of big data analytics, which may lead to new personal data being created; K. whereas the big data sector is growing by 40 % per year, seven times faster than the IT market; whereas the concentration of large datasets produced by new technologies offers crucial information for large corporations, triggering unprecedented shifts in the balance of power between citizens, governments and private actors; whereas such concentration of power in the hands of corporations might consolidate monopolies and abusive practices and have a detrimental effect on consumers’ rights and fair market competition; whereas the interests of the individual and the protection of fundamental rights should be further scrutinized in the context of big data mergers; L. whereas big data has huge untapped potential as a driver of productivity and a means of offering better products and services to citizens; underlines, however, that the generalised use of smart devices, networks and web applications by citizens, businesses and organisations does not necessarily indicate satisfaction with the products offered, but rather a broader understanding that these services have become indispensable to live, communicate and work, despite a lack of understanding about the risks that they might pose to our well-being, security and rights; M. whereas a distinction should be made between data quantity and data quality in order to facilitate the effective use of big data (algorithms and other analytical tools); whereas low-quality data and/or low-quality procedures behind decision-making processes and analytical tools could result in biased algorithms, spurious correlations, errors, an underestimation of the legal, social and ethical implications, the risk of data being used for discriminatory or fraudulent purposes and the marginalisation of the role of humans in these processes, leading to flawed decision-making procedures that have a detrimental impact on the lives and opportunities of citizens, in particular marginalised groups, as well as bringing about a negative impact on societies and businesses; N. whereas algorithmic accountability and transparency should mean implementing technical and operational measures that ensure transparency, the non-discrimination of automated decision-making and the calculating of probabilities of individual behaviour; whereas transparency should give individuals meaningful information about the logic involved, the significance and the envisaged consequences; whereas this should include information about the data used for training big data analytics and allow individuals to understand and monitor the decisions affecting them; O. whereas data analysis and algorithms increasingly impact on the information made accessible to citizens; whereas such techniques, if misused, may endanger fundamental rights to information as well as media freedom and pluralism; whereas the system of public broadcasting in Member States is directly related to the democratic, social and cultural needs of each society and to the need to preserve the plurality of the media, as stated in the Protocol on the system of public broadcasting in the Member States to the Amsterdam Treaty (11997D/PRO/09); P. whereas the proliferation of data processing and analytics, the sheer number of actors involved in collecting, retaining, processing, storing and sharing data and the combination of large data sets containing personal and non-personal data from a variety of sources, while entailing significant opportunities, have all created great uncertainty for citizens and the public and private sectors alike over the specific requirements for compliance with current EU data-protection law; Q. whereas there is a plethora of unstructured legacy systems containing vast volumes of data collected by companies over many years, with unclear data governance systems that should be systematically brought into compliance; R. whereas closer cooperation and coherence between different regulators and supervisory competition, consumer protection and data protection authorities at national and EU level should be encouraged, in order to ensure a consistent approach to and understanding of the implications of big data for fundamental rights; whereas the establishment and further development of the Digital Clearing House(8) as a voluntary network of enforcement bodies can contribute to enhancing their work and their respective enforcement activities and can help deepen the synergies and the safeguarding of the rights and interests of individuals; General considerations 1."
293,"Recalls that in accordance with Article 15 of Directive 2000/31/EC, Member States shall neither impose a general obligation on the providers of transmission, storage and hosting services to monitor the information which they transmit or store, nor a general obligation to actively seek facts or circumstances suggesting illegal activity; reiterates in particular that the Court of Justice of the European Union, in the cases C-360/10 and C-70/10, rejected measures for the ‘active monitoring’ of almost all users of the services concerned (internet access providers in one case, a social network in the other) and specified that any injunction requiring a hosting services provider to undertake general monitoring shall be precluded; Non- discrimination 19."
293,"(3) http://www.coe.int/en/web/conventions/full-list/-/conventions/treaty/108 (4) https://search.coe.int/cm/Pages/result_details.aspx?ObjectID=09000016805cdd00 (5) https://secure.edps.europa.eu/EDPSWEB/webdav/site/mySite/shared/Documents/Consultation/Opinions/2015/15-11-19_Big_Data_EN.pdf (6) https://secure.edps.europa.eu/EDPSWEB/webdav/site/mySite/shared/Documents/Consultation/Opinions/2016/16-09-23_BigData_opinion_EN.pdf (7) http://ec.europa.eu/justice/data-protection/article-29/documentation/opinion-recommendation/files/2014/wp221_en.pdf (8) Opinion 8/2016 of the European Data Protection Supervisor of 23 September 2016, p."
294,"Texts adopted - Civil Law Rules on Robotics - Thursday, 16 February 2017 Choisissez la langue de votre document : bg - български es - español cs - čeština da - dansk de - Deutsch et - eesti keel el - ελληνικά en - English fr - français ga - Gaeilge hr - hrvatski it - italiano lv - latviešu valoda lt - lietuvių kalba hu - magyar mt - Malti nl - Nederlands pl - polski pt - português ro - română sk - slovenčina sl - slovenščina fi - suomi sv - svenska Index Previous Next Full text Procedure : 2015/2103(INL)Document stages in plenaryDocument selected : A8-0005/2017Texts tabled : A8-0005/2017 Debates : PV 15/02/2017 - 14 CRE 15/02/2017 - 14 Votes : PV 16/02/2017 - 6.9 Explanations of votes Texts adopted : P8_TA(2017)0051 Texts adopted 253k 74k Thursday, 16 February 2017 - Strasbourg Civil Law Rules on Robotics P8_TA(2017)0051A8-0005/2017 Resolution Annex European Parliament resolution of 16 February 2017 with recommendations to the Commission on Civil Law Rules on Robotics (2015/2103(INL)) The European Parliament, – having regard to Article 225 of the Treaty on the Functioning of the European Union, – having regard to Council Directive 85/374/EEC(1), – having regard to the study on Ethical Aspects of Cyber-Physical Systems carried out on behalf of the Parliament's Science and Technology Options Assessment (STOA) Panel and managed by the Scientific Foresight Unit (STOA), European Parliamentary Research Service; – having regard to Rules 46 and 52 of its Rules of Procedure, – having regard to the report of the Committee on Legal Affairs and the opinions of the Committee on Transport and Tourism, the Committee on Civil Liberties, Justice and Home Affairs, the Committee on Employment and Social Affairs, the Committee on the Environment, Public Health and Food Safety, the Committee on Industry, Research and Energy and the Committee on the Internal Market and Consumer Protection (A8-0005/2017), Introduction A. whereas from Mary Shelley's Frankenstein's Monster to the classical myth of Pygmalion, through the story of Prague's Golem to the robot of Karel Čapek, who coined the word, people have fantasised about the possibility of building intelligent machines, more often than not androids with human features; B. whereas now that humankind stands on the threshold of an era when ever more sophisticated robots, bots, androids and other manifestations of artificial intelligence (""AI"") seem to be poised to unleash a new industrial revolution, which is likely to leave no stratum of society untouched, it is vitally important for the legislature to consider its legal and ethical implications and effects, without stifling innovation; C. whereas there is a need to create a generally accepted definition of robot and AI that is flexible and is not hindering innovation; D. whereas between 2010 and 2014 the average increase in sales of robots stood at 17% per year and in 2014 sales rose by 29%, the highest year-on-year increase ever, with automotive parts suppliers and the electrical/electronics industry being the main drivers of the growth; whereas annual patent filings for robotics technology have tripled over the last decade; E. whereas, over the past 200 years employment figures had persistently increased due to the technological development; whereas the development of robotics and AI may have the potential to transform lives and work practices, raise efficiency, savings, and safety levels, provide enhanced level of services; whereas in the short to medium term robotics and AI promise to bring benefits of efficiency and savings, not only in production and commerce, but also in areas such as transport, medical care, rescue, education and farming, while making it possible to avoid exposing humans to dangerous conditions, such as those faced when cleaning up toxically polluted sites; F. whereas ageing is the result of an increased life expectancy due to progress in living conditions and in modern medicine, and is one of the greatest political, social, and economic challenges of the 21st century for European societies; whereas by 2025 more than 20 % of Europeans will be 65 or older, with a particularly rapid increase in numbers of people who are in their 80s or older, which will lead to a fundamentally different balance between generations within our societies, and whereas it is in the interest of society that older people remain healthy and active for as long as possible; G. whereas in the long-term, the current trend leans towards developing smart and autonomous machines, with the capacity to be trained and make decisions independently, holds not only economic advantages but also a variety of concerns regarding their direct and indirect effects on society as a whole; H. whereas machine learning offers enormous economic and innovative benefits for society by vastly improving the ability to analyse data, while also raising challenges to ensure non-discrimination, due process, transparency and understandability in decision-making processes; I. whereas similarly, assessments of economic shifts and the impact on employment as a result of robotics and machine learning need to be assessed; whereas, despite the undeniable advantages afforded by robotics, its implementation may entail a transformation of the labour market and a need to reflect on the future of education, employment, and social policies accordingly; J. whereas the widespread use of robots might not automatically lead to job replacement, but lower skilled jobs in labour-intensive sectors are likely to be more vulnerable to automation; whereas this trend could bring production processes back to the EU; whereas research has demonstrated that employment grows significantly faster in occupations that use computers more; whereas the automation of jobs has the potential to liberate people from manual monotone labour allowing them to shift direction towards more creative and meaningful tasks; whereas automation requires governments to invest in education and other reforms in order to improve reallocation of the types of skills that the workers of tomorrow will need; K. whereas in the face of increasing divisions in society, with a shrinking middle class, it is important to bear in mind that developing robotics may lead to a high concentration of wealth and influence in the hands of a minority; L. whereas the development of robotics and AI will definitely influence the landscape of the workplace what may create new liability concerns and eliminate others; whereas the legal responsibility need to be clarified from both business sight model, as well as the workers design pattern, in case emergencies or problems occur; M. whereas the trend towards automation requires that those involved in the development and commercialisation of AI applications build in security and ethics at the outset, thereby recognizing that they must be prepared to accept legal liability for the quality of the technology they produce; N. whereas Regulation (EU) 2016/679 of the European Parliament and of the Council(2) (the General Data Protection Regulation) sets out a legal framework to protect personal data; whereas further aspects of data access and the protection of personal data and privacy might still need to be addressed, given that privacy concerns might still arise from applications and appliances communicating with each other and with databases without human intervention; O. whereas the developments in robotics and AI can and should be designed in such a way that they preserve the dignity, autonomy and self-determination of the individual, especially in the fields of human care and companionship, and in the context of medical appliances, 'repairing' or enhancing human beings; P. whereas ultimately there is a possibility that in the long-term, AI could surpass human intellectual capacity; Q. whereas further development and increased use of automated and algorithmic decision-making undoubtedly has an impact on the choices that a private person (such as a business or an internet user) and an administrative, judicial or other public authority take in rendering their final decision of a consumer, business or authoritative nature; whereas safeguards and the possibility of human control and verification need to be built into the process of automated and algorithmic decision-making; R. whereas several foreign jurisdictions, such as the US, Japan, China and South Korea, are considering, and to a certain extent have already taken, regulatory action with respect to robotics and AI, and whereas some Member States have also started to reflect on possibly drawing up legal standards or carrying out legislative changes in order to take account of emerging applications of such technologies; S. whereas the European industry could benefit from an efficient, coherent and transparent approach to regulation at Union level, providing predictable and sufficiently clear conditions under which enterprises could develop applications and plan their business models on a European scale while ensuring that the Union and its Member States maintain control over the regulatory standards to be set, so as not to be forced to adopt and live with standards set by others, that is to say the third countries which are also at the forefront of the development of robotics and AI; General principles T. whereas Asimov's Laws(3) must be regarded as being directed at the designers, producers and operators of robots, including robots assigned with built-in autonomy and self-learning, since those laws cannot be converted into machine code; U. whereas a series of rules, governing in particular liability, transparency and accountability, are useful, reflecting the intrinsically European and universal humanistic values that characterise Europe's contribution to society, are necessary; whereas those rules must not affect the process of research, innovation and development in robotics; V. whereas the Union could play an essential role in establishing basic ethical principles to be respected in the development, programming and use of robots and AI and in the incorporation of such principles into Union regulations and codes of conduct, with the aim of shaping the technological revolution so that it serves humanity and so that the benefits of advanced robotics and AI are broadly shared, while as far as possible avoiding potential pitfalls; W."
294,"Points out that the guiding ethical framework should be based on the principles of beneficence, non-maleficence, autonomy and justice, on the principles and values enshrined in Article 2 of the Treaty on European Union and in the Charter of Fundamental Rights, such as human dignity, equality, justice and equity, non-discrimination, informed consent, private and family life and data protection, as well as on other underlying principles and values of the Union law, such as non-stigmatisation, transparency, autonomy, individual responsibility and social responsibility, and on existing ethical practices and codes; 14."
294,"Researchers in the field of robotics should commit themselves to the highest ethical and professional conduct and abide by the following principles: Beneficence – robots should act in the best interests of humans; Non-maleficence – the doctrine of ‘first, do no harm’, whereby robots should not harm a human; Autonomy – the capacity to make an informed, un-coerced decision about the terms of interaction with robots; Justice – fair distribution of the benefits associated with robotics and affordability of homecare and healthcare robots in particular."
294,"LICENCE FOR DESIGNERS – You should take into account the European values of dignity, autonomy and self-determination, freedom and justice before, during and after the process of design, development and delivery of such technologies including the need not to harm, injure, deceive or exploit (vulnerable) users. – You should introduce trustworthy system design principles across all aspects of a robot’s operation, for both hardware and software design, and for any data processing on or off the platform for security purposes. – You should introduce privacy by design features so as to ensure that private information is kept secure and only used appropriately. – You should integrate obvious opt-out mechanisms (kill switches) that should be consistent with reasonable design objectives. – You should ensure that a robot operates in a way that is in accordance with local, national and international ethical and legal principles. – You should ensure that the robot’s decision-making steps are amenable to reconstruction and traceability. – You should ensure that maximal transparency is required in the programming of robotic systems, as well as predictability of robotic behaviour. – You should analyse the predictability of a human-robot system by considering uncertainty in interpretation and action and possible robotic or human failures. – You should develop tracing tools at the robot’s design stage."
295,"Such tasks concern low -skilled as well as high ly-skilled personnel, for example in sectors such as banking, insurance or justice."
295,"For the deployment of ADS , certification can be on either a voluntary basis (as encouraged by the GDPR) , or mandatory in certain areas such as justice and healthcare."
295,"Decision -making algorithms are increasingly used in areas such as a ccess to information, e-commerce, recommendation systems, employment, health, justice, policing, banking and insurance."
295,Users Objectives Individuals Private sector Public sector Improvement of general Knowledge N/A Drugs discovery Climate Weather forecast Environment Healthcare Digital services Quantified -self Finance Note taking Smart home Recommendations Risk scoring Payment systems Targeting Personali sed services Predictive justice Predictive policing Hazard prediction Infrastructure development planning Physical systems Autonomous Cars Home Robots Security Personal assistants in the home Autonomous robots Autonomous weapons Defence Transport Smart cities Smart grids Understanding algorithmic decision -making: Opportunities and challenges 7 3.
295,"For example, Directive 2000/78/EC9 lays down : 'a general framework for combating discrimination on the grounds of religion or belief, disability, age or sexual orien tation as regards employment and occupation, with a view to putting into effect in the Member States the principle of equal treatment.' In a similar vein , the Convention for the Protection of Human Rights and Fundamental Freedoms10 provides that : 'the enjoyment of the rights and freedoms set forth in this Convention shall be secured without discrimination on any ground such as sex, race, colour, language, religion, political or other opinion, national or social origin, association with a national minority, property, birth or other status. ' The fact that ADS can lead to discrimination has been documented in many areas , such as the justice system, targeted advertisements and employment."
295,Discrimination in justice : Another area that has raised much concern is the increasing reliance on ADS in the criminal justice system.
295,"COMPAS scores can be used at different stages of the criminal justice system , e.g. to decide whether to release or detain a defendant before their trial or whether to grant parole to an offender."
295,"Several occurrences of this process have already been observed, not only in the field of justice with COMPAS, but also in education with the public debate raised by an algorithm called APB32 in Fr ance."
295,"Understanding algorithmic decision -making: Opportunities and challenges 15 authors, 'perhaps even more problematic is the theory of justice impl icitly embedded in the algorithms' .48 The point is that most ADS used in this context are risk -assessment tools: based on a number of factors about the defendants ' criminal history, sociological data or demographic features, they provide an estimation of their risk of recidivism."
295,"ADS are already in use in the medical sector and can potentially contribute to i mprove the decisions taken by practitioners and specialists in many ways: 48 Angèle Christin, Alex Rosenblat, Danah Boyd; Courts and predictive algorithms; Data & Civil Rights: A new era of poli cing and justice; 2015. http://www.law.nyu.edu/sites/default/files/upload_documents/Angele%20Christin.pdf 49 John Monahan; Risk assessment in criminal sentencing; University of Virginia School of Law; Public Law and Legal Theory Research Paper Series; (2015,03); 2015."
295,"Public services ADS are currently being used by government and public agencies to provide new services or improve existing ones in many areas , such as energy, education, healthcare, transportation, justice systems and security ."
295,"These tasks concern low -skilled as well as high lyskilled personnel, for example in sectors like banking, insurance or justice."
295,"ADS Fairness As ADS replace or support human decision -makers in a number of sensitive domains such as justice, health or education, it is important to ensure that they do not result in decisions that are considered unfair or discriminatory."
295,"For example, it is well known that, in certain cities, there is a strong correlation between the reli gion or 141 Richard Berk, Hoda Heidari, Shahin Jabbari, Michael Kearns, Aaron Roth; Fairness in Criminal Justice Risk Assessments: The State of the Art; Sociological Methods & Research; 2018."
295,"186 Richard Berk, Hoda Heidari, Shahin Jabbari, Michael Kearns, Aaron Roth; Fairness in Criminal Justice Risk Assessments: The State of the Art; Sociological Methods & Research; 2018."
295,"187 Richard Berk, Hoda Heidari, Shahin Jabbari, Michael Kearns, Aaron Roth; Fairness in Criminal Justice Risk Assessments: The State of the Art; Sociological Methods & Research; 2018."
295,"Ethical and political debate As illustrated in Chapter 3, ADS raise far reaching issues in many areas such as justice, policing, healthcare, democratic life, etc."
295,"Another example of the systematic analysis of ethical issues that can be useful in this context is the EDPS Ethics Advisory Group Report,204 which proposes a list of ' foundational values to digital ethi cs': dignity, freedom, autonomy, solidarity, equality, democracy, justice and trust."
295,"As seen previously, different approaches can be taken to 212 Rebecca Wexler; Life, liberty, and trade secrets : intellec tual pro perty in the criminal justice system; (70); Standford Law Review; (1343); 2018; https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2920883 ."
295,"[…] The trend towards using risk instruments in all sectors of the criminal justice system, therefore, merits further theoretical d eliberation and empirical study. '221 • In the same vein, Chelsea Barabas and her colleagues argue: 'for a shift away from predictive technologies, towards diagnostic methods that will help us to understand the criminogenic effects of the criminal justice sys tem itself, as well as evaluate the effectiveness of interventions designed to interrupt cycles of crime."
295,"221 Kelly Hannah -Moffat; Actuarial sentencing: an ' unsettled ' proposition; Justice Quarterly; (30,2); 2013."
295,"Dillon Reisman and his colleagues have already advocated AIA as a ' practical framework for public agency accountability' in a recent AINow Institute report .226 Beyond a 'self-assessment of existing and proposed automated d ecision systems, evaluating potential impacts on fairness, justice, bias, or other concerns across affected communities ', they emphasi se the need for ' researcher review processes before the system has been acquired '."
295,"For example, several studies have been conducted about the use of ADS in the area of justice, some of th em focusing on the risks of discrimination ,232 others on the benefits in improv ing judges' decisions.233 In addition, the benefit risk balance applies to both the primary functionalities of the ADS and to its transparency and explainability features."
295,ADS certification can be either on a voluntary basis (as encouraged by the GDPR) or mandatory in certain areas such as justice and healthcare.
295,"Berk R., Heidari H., Jabbari S., Kearns M., Roth A.; Fairness in Criminal Justice Risk Assessments: The State of the Art; Sociological Methods & Research; 2018."
295,"Christin A., Rosenblat A., Boyd D.; Courts and predictive algorithms; Workshop on Data & Civil Rights: A new era of policing and justice; 2015 ."
295,Hannah -Moffat K.; Actuarial sentencing: an 'unsettled ' proposition; Justice Quarterly (30); 2013.
296,"AI tightly developed under human oversight and control), embed the principles of fairness and justice in algorithms, applied in all phases of AI systems’ design, implementation and testing, while following through bias complaints and other undesired effects reporting."
296,"During the 71st session of the United Nations General Assembly, on 29 September 2016, UNICRI (United Nations International Crime and Justice research Institute) announced the opening of the first Centre on A I and Robotics KEY FINDINGS There is not yet robust evidence of AI applications used for addressing significant and wideranging real -life problems or societal challenges."
296,"AI tightly developed under human oversight and control), embed the principles of fairness and justice in algorithms, applied in all phases of AI systems’ design, i mplementation and testing, while following through bias complaints and other undesired effects reporting."
299,"This Declaration notably builds on primary EU law, in particular the Treaty on European Union, the Treaty on the Functioning of the European Union, the Charter of Fundamental Rights of the European Union, as well as on secondary law and the caselaw of the Court of Justice of the European Union."
30,Artificial Intelligence Impact AssessmentAnnex 1 - Artificial Intelligence Code of Conduct 73 •To what extent is there access to the source code of the AI application (openness of algorithms) and is this knowledge usable for outsiders? •To what extent can the operation of the application / the algorithm be explained to end users and those involved? •Is clear to end users (and other relevant actors) what the consequences are of decision making by the AI? •Can the used datasets be made public? •Can the sources of used data be made public? •Can the organisation be transparent in a different way for users and stakeholders? •Does the domain in which the AI application is used demand a higher degree of transparency for users and those involved (e.g. care or justice)? •To what extent does the organisation or AI application take decisions about or for the individual? •Has a balance been found between the benefits of the goal and the freedom or the individual? •Is there a time when the individual can influence decision making by the AI?
30,"23 Note to EGE (2018): AI should contribute to global justice and equal access to the benefits and advantages that AI, robotics and ‘autonomous’ systems can bring."
30,"Erosion of the democratic constitutional state in Europe 26 See: https://www.theguardian.com/news/series/cambridge-analytica-files 27 Note to EGE (2018): Rule of law, access to justice and the right to redress and a fair trial provide the necessary framework for ensuring the observance of human rights standards and potential AI specific regulations."
301,162 5.2 Impact on law enforcement and criminal justice ................................ .........
301,"Christian Archambeau Executive Director EUIPO 8 Acronyms AAAI American Association for the Advancement of Artificial Intelligence ACR Automatic content recognition AGI Artificial general intelligence AI Artificial intelligence A.L.I.C.E Artificial Linguistic Internet Computer Entity ANI Artificial narrow intelligence ASI Artificial superintelligence ASIMO Advanced Step in Innovative M obility APT Advanced Persistent Threat BEC Business email compromise CaaS Cybercrime -as-a-Service CAPTCHA Completely Automated Public Turing test to tell Computers and Humans Apart CoE Council of Europe CJEU Court of Justice of the European Union DARPA Defense Advanced Research Projects Agency DDoS Distributed denial of service EC European Commission EG Impact of Technology Expert Group EIPPN European Intellectual Property Prosecutors Network ETL ENISA Threat Landscape ENISA European Union Agency for Cyber security EU European Union FGCS Fifth-generation computer systems FORTRAN Formula T ranslator HNN Hopfield neural network IoE Internet of Everything IOCTA Internet Organised Crime Threat Assessment IoT Internet of Things IP Intellectual property IPR Intellectual property right IPTV Internet protocol television 9 ISP Internet service provider LEA Law enforcement agenc y LSTM Long Short -Term Memory MANIAC I Mathematical Analyzer, Numerical Integrator, and Computer MASP General Multi -Annual Strategic Plan MITI Ministry of International Trade and Industry of Japan MS Member State (s) (of the European Union) NLP Natural language processing OCR Optical character recognition OAP Operational Action Pla n PSP Payment service provider SIENA Secure Informatio n Exchange Network Application SP2025 EUIPO Strategic Plan 2025 TLD Top-level domain UBA User behavio ur analytics UNICRI United Nations Interregional Crime and Justice Research Institute WIPO World Intellectual Property Organization 10 Definitions The following terminology and definitions will be used in this study."
301,"STUDY ON THE IMPACT O F ARTIFICIAL INTELLIGENCE ON THE INFRINGEMENT AND ENFORCEMENT OF COPYRIGHT AND DESIGN 17 The ‘Intellectual Property Tech Chain ’ In 2021, the EUIPO commissioned the United Nations Interregional Crime and Justice Research Institute (UNICRI) to carry out the first deep -dive research project applying this methodology in cooper ation with the Impact of Technology Expert Group."
301,"In 2021, the EUIPO commissioned the United Nations Interregional Crime and Justice Research Institute (UNICRI) (15) to carry out the first deep -dive research project applying th is methodology in cooperation with the Impact of Technology Expert Group."
301,"(23) Trend Micro, the United Nations Interregional Crime and Justice Research Institute (UNICRI), and Europol."
301,"(24) Trend Micro, the United Nations Interregional Crime and Justice Research Institute (UNICRI), and Europol."
301,"(25) Trend Micro, the United Nations Interregional Crime and Justice Research Institute (UNICRI), and Europol."
301,"The present study will focus on AI technologies ’ impact on crime, law enforcement and criminal justice, taking into account the relevant ethical and fundamental rights -related issues (including data protection and privacy concerns)."
301,"Nevertheless, the experts highlight ed that use of AI in the justice system also presents many opportunities to figure out how to effectively use it without violating individual privacy and affecting fundamental rights."
301,EUR -Lex. https://eur -lex.europa.eu/legal -content/EN/TXT/?uri=COM%3A2018%3A237%3AFIN Euro pean Commission for the Efficiency of Justice (CEPEJ) (2019).
301,Artificial Intelligence in the Context of Crime and Criminal Justice .
301,"Dirty Data, Bad Predictions: How Civil Rights Violations Impact Police Data, Predictive Policing Systems, and Justice."
301,"New York University Law STUDY ON THE IMPACT O F ARTIFICIAL INTELLIGENCE ON THE INFRINGEMENT AND ENFORCEMENT OF COPYRIGHT AND DESIGN 138 Review Online, https://www.nyulawreview.org/online -features/dirty -data-bad-predictions -how-civilrights -violations -impact -police -data-predictive -policing -systems -and-justice/ Russell S. , Norvig P."
301,"USENIX. https://www.usenix.org/conference/usenixsecurity16/technical -sessions/presentation/tramer Trend Micr o, the United Nations Interregional Crime and Justice Research Institute (UNICRI), and Europol."
301,"5 Overview of the main AI-affected a reas relevant for the study For the purpose of this study, three areas in which AI technologies have a significant impact are particularly relevant: crime, law enforcement and criminal justice."
301,"Artificial Intelligence in the Context of Crime and Criminal Justice A Report For The Korean Institute Of Criminology. https://www.cicc iccc.org/public/media/files/prod/publication_files/ArtificialIntelligenceintheCo ntextofCrimeandCriminalJustice_KICICCC_2 019.pdf (286) Caldwell, M., Andrews, J.T.A., Tanay, T. et al."
301,STUDY ON THE IMPACT O F ARTIFICIAL INTELLIGENCE ON THE INFRINGEMENT AND ENFORCEMENT OF COPYRIGHT AND DESIGN 164 5.2 Impact on law enforcement and criminal justice The wide range of existing legitimate AI applications include s systems for crime prevention and detection.
301,"As AI and related technologies are used to make determinations and predictions in high -stakes domains such as criminal justice and law e nforcement, they have the potential to impact basic fundamental rights and liberties in profound ways."
301,"Moreover , as is widely discussed at international level, law enforcement authorities and the criminal justice system should ensure fairness, accountability, transparency and that the use of AI is effectively communicated to the publ ic."
301,Experts highlight that the use of AI in the justice system also presents many opportunities to figure out how to effectively use it without violating an individual’s privacy (293).
301,"With regards to criminal justice, numerous examples can be found of judi cial systems making use of AI tools in criminal proceedings."
301,"Some countries also use automated risk assessment tools in the criminal justice system, though their use may be questioned."
301,"In this context , in December 2018 , the European Commission for the Efficiency of Justice (CEPEJ) of the Council of Europe adopted the ‘Ethical Charter on the Use of Artificial Intelligence in Judicial Systems and their environment ’ (296), which encompasses the following five principles: 1. principle of respect for fundamental rights : ensure that the design and implementation of artificial intelligence tools and services a re compatible with fundamental rights ; 2. principle of non -discrimination : specifically prevent the development or intensification of any discrimination among individuals or groups of individuals ; 3. principle of quality and security : with regard to the proces sing of judicial decisions and data, use certified sources and intangible data with models elaborated in a multi -disciplinary manner, in a secure technological environment ; 4. principle of transparency, impartiality and fairness : make data processing methods accessible and understandable, and authorise external audits ; 5. principle of ‘user control ’: eschew a prescriptive approach and ensure that users are informed actors and in control of the choices made (297)."
301,"Di rty Data, Bad Predictions: How Civil Rights Violations Impact Police Data, Predictive Policing Systems, and Justice."
301,"New York University Law Review Online, https://www.nyulawreview.org/online -features/dirty -data-bad-predictions -how-civil-rights violations -impact -police -data-predictive -policing -systems -and-justice/ (296) European Commis sion for the Efficiency of Justice (CEPEJ) (2019)."
301,(297) European Commission for the Efficiency of Justice (CEPEJ) (2019).
304,"Department of Commerce The following Federal departments and agencies are represented on the Subcommittee on Machine Learning and Artificial Intelligence and thro ugh it, work together to monitor the state of the art in machine learning (ML) and AI (within the Federal Government, in the private sector, and internationally), to watch for the arrival of important technology milestones in the development of AI, to coor dinate the use of and foster the sharing of knowledge and best practices about ML and AI by the Federal Government, and to consult in the development of Federal research and development priorities in AI: Department of Commerce (Co -Chair ) Depa rtment of Defense Department of Education Department of Energy Department of Health and Human Services Department of Homeland Security Department of Justice Department of Labor Department of State Department of Transportation Department of Treasury Department of Veterans Affairs United States Agency for International Development Central Intelligence Agency General Services Administration National Science Foundation National Security Agency National Aeronautics and Space Administration Office of the Director of National Intelligence Social Security Administration The following offices of the Executive Office of the President are also represented on the Subcommittee: Council of Economic Advisers Domestic Policy Council Office of Management and Budget Office of Science and Technology Policy (Co Chair) Office of the Vice President National Economic Council National Security Council PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE Contents Executive Summary ................................ ................................ ................................ ................................ ....................."
304,"30 Justice, Fairness, and Accountability ................................ ................................ ................................ ................."
304,"Public - and private sector investments in basic and applied R&D on AI have already begun reaping major benefits to the public in fields as diverse as health care, transportation, the environment, criminal justice, and economic inclusion ."
304,"Use of AI to make consequential decisions about people, often replacing decisions made by human -driven bureaucra tic processes , leads to concerns about how to ensure justice, fairness, and accountability —the same concerns voiced previously in the Administration’s Big Data: Seizing Opportunities, Preserving Values report of 2014,1 as well as the Report to the President on Big Data and Privacy: A Technological Perspective published by the President’s Council of Advisors on Science and Technology in 2014 .2 Transparency concerns focus not only on the data and algorithms involved, but also on the potential to have some form of explanat ion for any AI -based determination."
304,"Many areas of public policy, from education and the economic safety net, to defense, envi ronmental preservation, and criminal justice, will see new opportunities and new challenges driven by the continued progress of AI."
304,"The promise of AI has been compared to the transformative impacts of advances in mobile computing.21 Public - and private -sector investments in basic and applied R&D on AI have already begun reaping major benefits for the public in fields as diverse as health care, transportation, the environment, criminal justice, and economic inclusion .22 At Walter Reed Medical Center, the Department of Veteran Affairs is using AI to better predict medical complications and improve treatment of severe combat wounds, leading to better patient outcomes, faster healing, and lower costs.23 The same general approac h—predicting complications to enable preventive treatment —has also reduced hospital -acquired infections at Johns Hopkins University .24 Given the current transition to electronic health records, predictive analysis of health data may play a key role across m any health domains like precision medicine and cancer research."
304,"Autonomous watercraft may be much cheaper to operate than manned ships, and may some day be used for enhanced weather prediction, climate monitoring, or policing illegal fishing.27 AI also has the potential to improve aspects of the criminal justice system, including crime reporting, policing, bail, sentencing, and parole decisions."
304,"The Admini stration is exploring how AI can responsibly benefit current initiatives such as Data Driven Justice and the Police Data Initiative that seek to provide law enforcement and the public with data that can better inform decision -making in the criminal justice system, while also taking care to minimize the possibility that AI might introduce bias or inaccuracies due to deficiencies in the available data."
304,Social justice and public policy institutions that do not typically engage with advanced technologies and data science in their work should consider partnerships with AI researchers and practitioners that can help apply AI tactics to the broad social problems these institutions already address in other ways.
304,"The u se of AI to make consequential decisions about people, often replacing decisions made by human actors and institutions , leads to concerns about how to ensure justice, fairness, and accountability —the same concerns voice d previously in the “ Big Data” context.62 The u se of AI to control physical -world equipment leads to concerns about safety, especially as systems are exposed to the full complexity of the human environment."
304,"Justice, Fairness, and Accountability A common theme in the Law and Governance, AI for Social Good, and Social and Economic Impac ts workshops was the need to ensure that AI promotes justice and fairness, and that AI -based processes are accountab le to stakeholders ."
304,"In the criminal justice system, some of the biggest concerns with Big Data are the lack of data and the lack of quality data.65 AI needs good data."
304,It is important that anyone using AI in the criminal justice context is aware of the limitations of current data.
304,"65 Matt Ford, “The Missing Statistics of Criminal Justice,” The Atlantic, May 31, 2015, http://www.theatlantic.com/politics/archive/2015/05/what -we-dont-know -about -mass -incarceration/394520/ 66 Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner, “Machine Bias,” ProPublica, May 23, 2016, https://www.propublica.org/article/machine -bias-risk-assessments -in-criminal -sentencing."
304,"Many areas of public policy, from education and the economic safety net, to defense , environmental prese rvation, and criminal justice, will see new opportunities and new challenges driven by the continued progress of AI."
304,Social justice and public policy institutions that do not typically engage with advanced t echnologies and data science in their work should consider partnerships with AI researchers and practitioners that can help apply AI tactics to the broad social problems these institutions already address in other ways.
304,"Matt Ford, “The Missing Statistics of Criminal Justice,” The Atlantic, May 31, 2015, http://www.theatlantic.com/politics/archive/2015/05/what -we-dont-know-about -mass -incarceration/394520/ Jason Furman, “Is This Time Different?"
309,"Article 29 Data Protection Working Party, Opinion 1/2008 on data protection issues related to search engines, dated 4 April 2008, http://ec.europa.eu/justice/policies/privacy/workinggroup/wpdocs/index_en.htm , S."
32,"This can most clearly be shown by comparing the sets of principles with the set of four core principles commonly used in bioethics: beneficence, non-maleficence, autonomy, and justice."
32,"4.4 Justice: Promoting Prosperity and Preserving Solidarity The last of the four classic bioethics principles is justice, which is typically invoked in relation to the distribution of resources, such as new and experimental treatment options or simply the general availability of conventional healthcare."
32,"The importance of “justice” is explicitly cited in the Montreal Declaration, which argues that “the development of AI should promote justice and seek to eliminate all 699 1 3AI4People—An Ethical Framework for a Good AI Society:… types of discrimination”, while the Asilomar Principles include the need for both “shared benefit” and “shared prosperity” from AI."
32,"Under its principle named “Jus-tice, equity and solidarity”, the EGE argues that AI should “contribute to global justice and equal access to the benefits” of AI technologies."
32,"As with the other principles already discussed, these interpretations of what justice means as an ethical principle in the context of AI are broadly similar, yet con-tain subtle distinctions."
32,"Across the documents, justice variously relates to (a) Using AI to correct past wrongs such as eliminating unfair discrimination; (b) Ensuring that the use of AI creates benefits that are shared (or at least shareable); and (c) Preventing the creation of new harms, such as the undermining of existing social structures."
32,"Notable also are the different ways in which the position of AI, vis-à-vis people, is characterised in relation to justice."
32,"In Asilomar and EGE respectively, it is AI technologies themselves that “should benefit and empower as many people as pos-sible” and “contribute to global justice”, whereas in Montreal, it is “the develop-ment of AI” that “should promote justice” (italics added)."
32,Develop appropriate legal procedures and improve the IT infrastructure of the justice system to permit the scrutiny of algorithmic decisions in court.
321,"And it was in this mindset that the CNIL set a collective approach in motion, for several months overseeing a public debate with the help of partners from various sectorial fields (health, justice...)."
321,"Among them, we could mention the “Ligue de l’Enseignement” (associa tion that focused on education concerns), French Insu rance Federation (FFA), French Ministry of Culture (DG-MIC), Open Law (association that reflects on the justice system) as well as trade unions such as CFE-CFC and FO Cadres (for recruitment and HR), etc.An innovative approach to crafting a collective and pluralist ethical thought process Ethical thinking concerns decisive societal choices."
321,"The views of the diverse stakeholders (trade unions, associations, businesses, researchers, citizens, etc.) across a wide range of sectors (from insurance to education, justice and healthcare) thus informed the writing of this report, which provides an overview of the ethical matters raised by algorithms and artificial intel ligence in their current applications and their potential uses in the relatively short term."
321,"THE ETHICAL MATTERS RAISED BY ALGORITHMS AND ARTIFICIAL INTELLIGENCE ALGORITHMS AND ARTIFICIAL INTELLIGENCE TODAY 22 Education Justice Health Security Work, HR Culture Other Generating knowledgeBetter identify learners’ abilitiesReveal the different ways judgments are handed down between regionsTap into the vast amount of scientific publicationsIdentify unsuspected links for solving gendarmerie-led investigations Understand social phenomena in the workplaceCreate cultural showpieces (painting, music)Fine-tune an insurance company customer’s risk profile MatchingAllocate higher education places to candidates (APB)Allocate patients for participation in a clinical trialMatch a list of applicants to a job vacancyMatch “compatible” profiles on dating apps, etc."
321,"The next step of what some refer to as “predictive justice” would involve entrusting systems with the task of making decisions based on a cross-analysis of the data pertaining to a certain case, with case-law data.Delegating tasks to algorithms: contrasting situations What immediately becomes clear is that concern over the potential ethical and social implications of automated systems varies depending on the tasks being delegated to the latter and the very conditions shaping this delegation."
321,"In the report it submitted to the CNIL, the Conseil National des Barreaux, the national institution that represents all practising lawyers in France, highlighted that “care must be taken to ensure that the obsession for effectiveness and predictability behind the use of algorithms does not lead to us designing legal rules and categories no longer on the grounds of our ideal of justice, but so that they are more readily ‘codable’”."
321,"A question of scale: the massive delegation of non-critical decisions Should ethical thinking on algorithms and artificial intel-ligence be limited to crucial decisions, sectors where the impact on humans is undeniable, such as medicine, justice, educational guidance, and even the automotive sector with its implications in terms of safety?"
321,"Practical examples of algorithms being used by the authorities as well as the example of predictive justice give a clearer idea of this ambivalence, between the optimising and diminishing of processes stripped of their spatial dimension."
321,"Similarly, at the symposium on predictive justice orga nised on 19 May 2017 by the Lille Bar, Law Department of Université catholique de Lille and the Douai Court of Appeal, certain participants stressed that “knowledge of judgments given by the other neighbouring jurisdictions or by the other magistrates would contribute towards a certain consistency and prevent that the outcome of a dispute depends on knowing whether it is heard in a city or another”."
321,The same line of thinking could be applied to the idea of a predictive justice.
321,Predictive justice applications are being subjected to particularly close public scrutiny as regards their Management Profile for Alternative Sanction) tool designed to come up with a recidivism risk score for prisoners or defendants on trial.
321,Medicine and justice are other sectors where this question might be asked.
321,"IIt is crucial to guard against excessive trust by raising awar eness of the ethical dimensions of a decision-making process that must not exclude human intervention and by honing critical thinking in some particularly sensitive sec tors, such as medicine, recruitment, justice and perhaps now marketing above all, where the antisemitic categories recently generated by Facebook’s machine learning algorithms are a stark wakeup call to the sharpness of the risks."
321,"The partners in the public debate • Allistene’s research committee on ethics (CERNA) • Bordeaux’s Cognitique Institute (ENSC) • Bordeaux University • Caisse des dépôts et consignations (CDC) • Club des Juristes (thinktank) • Collège des Bernardins • Complex Systems Institute of Paris Ile-de-France (ISC-PIF) • Confédération française de l’encadrement – Confédération générale des cadres (CFE-CGC, trade union) • Communication Publique • Conseil National des Barreaux (national institution that represents all practising lawyers in France/CNB) • Conseil Supérieur de l’Audiovisuel (independent authority to protect audiovisual communication freedom/CSA) • Conservatoire National des Arts et Métiers (leading higher education and research institution dedicated to adult continuing education/CNAM) • Douai court of appeal • ESCP Europe, IoT Chair • Etalab(body that works in France on data sharing in the public sector) • “Familles rurales” association • Federal University of Toulouse • French Association for Artificial intelligence (AFIA) • French Association for Employment Law (AFDT) • French Development Agency(AFD) • French governmental advisory council on bioethics issues (CCNE) • French Insurance Federation (FFA) • French National Center for Scientific Research (CNRS)’s ethics committee (COMETS) • FO-Cadres (trade union) • Fondation Internet Nouvelle Génération (FING) • Fotonower • Génotoul societal (bioscience and ethics platform) • Groupe VYV (MGEN – ISTYA – Harmonie) • Imagine Institute on genetic diseases • INNOvation Ouverte par Ordinateur (INNOOO)• Institut Mines-Télécom (IMT), Research Chair “Values and Politics of Personal Information” • Laboratory for Collective and Artificial Intelligence (LICA) • Law Department of Université Catholique de Lille, Centre of research on relations between risk and law • Law Department of Université Catholique de Lyon • Ligue des Droits de l’Homme (Human Rights League/LDH) • Ligue de l’Enseignement (Education League) • Lille 2 University • Lille Association of Lawyers • Lyon’s administrative court of appeal • Microsoft • Ministry of Culture, via the General Directorate of Media and Cultural Industries (DGMIC) • Ministry of National Education, via the Directorate of Digital Technology for Education (DNE) and its Numéri’lab • National Academy of Technologies of France • National Institute of Higher Studies on Defence (IHEDN) • National Institute of Higher Studies on Security and Justice (INHESJ) • National Institute of Applied Sciences (INSA) • Necker Hospital • OpenLaw (association) • Paris II University • Randstad • Research Centre of the National Gendarmerie School of Officers (CREOGN) • Rhône Département -level Council of the Medical Association • Renaissance Numérique (thinktank) • School of Advanced Studies in the Social Sciences (EHESS) • Sciences Po Lille • Sciences Po Paris • Société informatique de France (association devoted to computer science/SIF) • The Future Society at Harvard Kennedy School, AI Initiative • Universcience • Visions d’Europe (association) The other contributors • Arbre des connaissances (association) • Autorité de contrôle prudentiel et de résolution (French authority responsible for the supervision of the banking and insurance sectors/ACPR) • Autorité des marchés financiers (authority which regulates participants and products in France’s financial markets/AMF) • Montpellier Méditerranée Métropole and its President, Philippe Saurel • City of MontpellierThe 37 citizens who took part in the public consultation organised in Montpellier on 14 October 2017."
321,"LAUNCH EVENT ROUNDTABLE SESSIONS “Algorithms and humans” and “Fairness, transparency and plurality of algorithms” > CNIL SYMPOSIUM “Towards new forms of humanity?” > Universcience CONFERENCE “Algorithms and law” > Lille II University CONFERENCE “The choice in the age of Big Data” > Sciences Po Lille and Visions d’Europe DEBATE “The governance of emerging technosciences” > German American Conference at Harvard University DEBATE “Transatlantic perspectives on: AI in the age of social media; privacy, security and the future of political campaigning” > The Future Society at Harvard Kennedy School ROUNDTABLE SESSIONS “Big Data, human resources: algorithms on the agenda” > FO-Cadres CONFERENCE “Fairness of algorithmic decision-making” > Toulouse III – Paul Sabatier University DEBATE “Will digital technology spell the end of the rule of law?” > Collège des Bernadins SYMPOSIUM “Predictive justice” > Douai Court of Appeal, Lille Association of Lawyers and Law Department of Université Catholique de Lille WORKSHOPS “Fairness of algorithmic decision-making and processing” > LabEx International Centre for Mathematics and Computer Science in Toulouse23/01/2017 23/03/2017 25/03/2017 31/03/2017 06/04/201708/04/201718/04/2017 18/04/2017 04/05/201716/05/201719/05/201702/06/2017 DEBATE “Algorithms in healthcare: what ethics?” > Groupe VYV (MGEN – ISTYA – Harmonie) ROUNDTABLE SESSION “Artificial intelligence: ethics, at the intersection of HR and Big Data” > Confédération française de l’encadrement – Confédération générale des cadres (CFE-CGC) DEBATE “Algorithms, employment and ethics” > French Association for Employment Law (AFDT) DAY “Ethical algorithms, a moral requirement and competitive advantage” > Allistene’s CERNA and Société Informatique de France (SIF) SYMPOSIUM “Human, non-human in the age of artificial intelligence” > Paris II University SYMPOSIUM “Artificial intelligence: autonomy, delegation and accountability” > Bordeaux’s Cognitique Institute (ENSC) WORKSHOP “Ethics of algorithms: implications for healthcare” > Genotoul (bioscience and ethics platform) CROWDSOURCING WORKSHOP “Artificial intelligence and law” > OpenLaw SYMPOSIUM “ The many dimensions of data ” > Institut Mines-Télécom, Values and Politics of Personal Information Research Chair SYMPOSIUM “Security and justice, the challenge of the algorithm” > National Institute of Higher Studies of Security and Justice (INHESJ) MOCK TRIAL AND ROUNDTABLE SESSION “ Ethique, algorithmes and justice ” > Law Department of Université Catholique de Lyon and Lyon’s Administrative Court of Appeal STUDY DAY “Admission Post-bac, textbook case of public algorithms” > Fondation Internet Nouvelle Génération (FING) and Etalab DAY “Algorithms and digital sovereignty” > Allistene’s CERNA DAY “Ethics and artificial intelligence” > French National Center for Scientific Research (CNRS)’s ethics committee (COMETS) and French Association for AI (AFIA) DEBATES on algorithms in education. > Ligue de l’Enseignement (Education League) DEBATE MORNING “Work in the algorithm era: what ethics for employment?” > Renaissance Numérique and Randstad SYMPOSIUM ““Convergences of law and digital technology” > Bordeaux University DAY “Algorithms and Politics."
322,"In particular, in m edicine, CNOM refers in its report to the applicability to digital technologies of the four principles of medical ethics: beneficence, non-maleficence, auton omy, and justice."
322,Regulation and soft law (self -compliance and volu ntary certification) The ruling on December 7 last by the European Court of Justice notably circumscribed national capacity for regulation on d igital innovation in the healthcare sphere.41 This Community framework therefore opens the door to methods of regulation that do not entail enforceabl e law.
322,"41 The Court of Justice of the European Union (CJEU) was called upon to rule on a prejudicial question regarding whether a software program for p rescription support meets the definition of a medical device, if that program provides at le ast one function that can be used to process data specific to the patient for the purpose of hel ping the doctor to establish a prescription, in particular by detecting contraindications, drug int eractions, and overdoses, although it does not of itself act in or upon the human body (CE, Ju ne 8, 2016, n° 387156)."
323,"1 Statement by the French Presidency of the Committee of Ministers of the Council of Europe at the Conference of Ministers of Justice on “Digital Challenges for Justice in Europe” (15 October 2019) For 70 years, the Council of Europe and its member States have been committed to promoting and protecting human rights, democracy and the rule of law , values that are enshrined in the European Convention on Human Rights."
323,"The development of digital technology is both a n opportunity and a challenge for justice systems in Europe, which are founded on the primacy of law , respect for human rights and the principles of judicial independence, impartiality and efficiency."
323,"In particular, new technologies have important implications for citizens seeking to access law and justice, as well as the suppression of crimes and offenc es they may be victims of."
323,It is essential that the Organisation continue its work to ensure that justice systems can take greater advantage of digital technology while preventing any harmful effects that it may have on our shared values.
323,Encourages ongoing dialogue and coop eration among Council of Europe member States on the use of digital tools in the justice field; 2.
323,Recalls the need to take into account the following principles when developing Council of Europe tools and instruments for justice and digital technology: i.
323,Digital access to law and justice should supplement non -digital access.
323,"The use of digital tools and algorithms in the justice field must not have a ny discriminatory effect on individuals , and must guarantee respect for privacy and the right to data protection. iii."
324,"It points out that a guiding ethical framework should be “based on […] the principles and values enshrined in Article 2 of the Treaty on European Union and in the Charter of Fundamental Rights, such as human dignity, equality, justice and equity, non ­discrimination, informed consent, private and family life and data protection”, among other principles.** * European Parliament (2017a). ** European Parliament (2017b)."
324,"In this regard, consideration could be given to establishing public bodies that have the right and power to investigate the use of predictive systems, which are used to make decisions that affect peo ­ ple’s lives.24 One example of a study on bias in algorithms was carried out by journalists who investigated if there is racial bias in the risk scores used in the US crimi ­ nal justice system."
325,"(2019), ‘Dirty data, bad predictions: How civil rights violations impact police data, predictive policing systems, and justice’, NYU Law Review, Vol."
325,"Beyond that, gender identity is mentioned only in Recital 9 of the Victims’ Rights Directive75 in the context of criminal law.76 According to the Court of Justice of the European Union, gender identity is only partly covered by the principle of equal treatment between men and women.77 Legal protection against discrimination based on religion is currently also limited under EU law.78 Nevertheless, one may argue that many comments referring to people who identify as lesbian, gay, bisexual, transgender and intersex (LGBTI), Jewish or Muslim fall under either the Racial Equality Directive or the Gender Goods and Services Directive, because discrimination based on sexual orientation, gender identity or religion predominantly affects a specific race or gender."
325,"88 The use of algorithms may further increase the opacity of content moderation and further increase challenges linked to fairness and justice.89 Without proper safeguards, such tools can lead to censorship and biased enforcement of laws and platforms’ terms and conditions.90 A potential increase in discrimination is just one of the challenges when using algorithms to support speech detection for content moderation purposes."
325,"Article 29 Working Party (2017a), Opinion on some key issues of the Law Enforcement Directive (EU 2016/680), WP 258, Brussels, European Commission Directorate-General Justice and Consumers."
325,"Article 29 Working Party (2017b), Guidelines on automated individual decisionmaking and profiling for the purposes of Regulation 2016/679, WP251rev.01, Brussels, European Commission Directorate-General Justice, p."
325,"(2019), ‘ CS224n: Natural language processing with deep learning 1 – Lecture notes: Part I ’, course instructor: Manning, C., Winter 2021.CJEU (Court of Justice of the European Union) (1991), C-184/89, Helga Nimz v."
325,"(2021), Automating Injustice – The use of artificial intelligence and automated decision-making systems in criminal justice in Europe, London, Fair Trials.Finck, M."
325,"307–335.FRA (2016), Ensuring justice for hate crime victims: Professional perspectives, Luxembourg, Publications Office.FRA (2017), Second European Union Minorities and Discrimination Survey – Main results, Luxembourg, Publications Office.FRA (2018a), #BigData: Discrimination in data-supported decision making, Luxembourg, Publications Office."
325,"(2019), ‘ Dirty data, bad predictions: How civil rights violations impact police data, predictive policing systems, and justice’, NYU Law Review, Vol."
325,"354–365.The Law Society (2019), Algorithms in the criminal justice system , London, The Law Society, p."
326,"Other rights are also affected; for example, an automated system used in the justice system, which is based on poor quality data, can negatively impact on the right to a fair trial and effective remedy, as well as on the principle of good administration."
326,"7 Committee on Civil Liberties, Justice and Home Affairs (2018)."
326,"If one gender is under-repre sented or if sexist behaviour is represented in the training data28, AI can increase inequality between men and women.29 Access to a fair trial and effective remedies (Article 47 of the Charter) can also be impacted, particularly if algorithms are used in the area of crime preven tion and the criminal justice system."
326,"The use of AI and algorithms in the area of justice needs testing, as highlighted in the CEPEJ European ethical char ter.30 One potential problem might be the use of biased data for automated systems.31 In addition, to enjoy access to a fair trial and effective reme dies, in cases where someone claims to have been mistreated by an AI-system or wants to challenge a decision based on an algorithm, information on how the system or algorithm works is essential."
326,"17.Committee on Civil Liberties, Justice and Home Affairs (2018), Opinion of the Committee on Civil Liberties, Justice and Home Affairs for the Committee on Industry, Research and Energy on a comprehensive European industrial policy on artificial intelligence and robotics , (2018/2088(INI)), 11 December 2018."
326,"(forthcoming), ‘Dirty Data, Bad Predictions: How Civil Rights Violations Impact Police Data, Predictive Policing Systems, and Justice’ , New York University Law Review Online ."
326,"FRA – EUROPEAN UNION AGENCY FOR FUNDAMENTAL RIGHTS Schwarzenbergplatz 11 – 1040 Vienna – Austria Tel: +43 158030-0 – Fax: +43 158030-699 fra.europa.eu facebook.com/fundamentalrights linkedin.com/company/eu-fundamental-rights-agency twitter.com/EURightsAgency© European Union Agency for Fundamental Rights, 2019 Print: ISBN 978-92-9474-605-4, doi:10.2811/615718 PDF: ISBN 978-92-9474-606-1, doi:10.2811/546219 TK-01-19-330-EN-C (print); TK-01-19-330-EN-N (PDF)Further information: The following FRA publications offer further information relevant to the topic of the paper: • #BigData: Discrimination in data-supported decision making (2018) http://fra.europa.eu/en/publication/2018/big-data-discrimination • Under watchful eyes: biometrics, EU IT systems and fundamental rights (2018) http://fra.europa.eu/en/publication/2018/biometrics-rights-protection • Fundamental rights and the interoperability of EU information systems: borders and security (2017) http://fra.europa.eu/en/publication/2017/fundamental-rights-interoperability • Surveillance by intelligence services: fundamental rights safeguards and remedies in the EU - Volume II: field perspectives and legal update (2017) http://fra.europa.eu/en/publication/2017/surveillance-intelligence-socio-lega • Surveillance by intelligence services: fundamental rights safeguards and remedies in the European Union - Mapping Member States’ legal frameworks (2015) http://fra.europa.eu/en/publication/2015/surveillance-intelligence-services • The impact on fundamental rights of the proposed Regulation on the European Travel Information and Authorisation System (ETIAS) (2017) http://fra.europa.eu/en/opinion/2017/etias-impact • Handbook on European data protection law - 2018 edition (2018) https://fra.europa.eu/en/publication/2018/handbook-european-data-protection-law • Handbook on European law relating to access to justice (2016) https://fra.europa.eu/en/publication/2016/handbook-european-law-relating-access-justice • Handbook on European non-discrimination law – 2018 edition (2018) http://fra.europa.eu/en/publication/2018/handbook-european-law-non-discrimination"
327,"20 UK, High Court of Justice (Queens’ Bench Division – Divisional Court Cardiff), The Queen (OTAO) Bridges and Chief Constable of South Wales Police and others , [2019] EWCH 2341 (Admin), 4 September 2019."
327,"The Data Protection Commissioner of Hamburg ( Hamburgische Beauftragte für Datenschutz und Informa tionsfreiheit ) issued a report about the use of facial recognition technologies at the G20 and found that the use of the technology did not comply with data 50 UK, High Court of Justice (Queens’ Bench Division – Divisional Court Cardiff), The Queen (OTAO) Bridges and Chief Constable of South Wales Police and others , [2019] EWCH 2341 (Admin), 4 September 2019, para."
327,"As an additional safeguard, the Agency for the Operational Management of Large-Scale Informa tion Technology Systems (eu-LISA)62 is responsible for quality assurance safeguards and reports regularly 62 For an overview of the role and tasks of eu-LISA, see Chapter II of Regulation (EU) 2018/1726 of the European Parliament and of the Council of 14 November 2018 on the European Union Agency for the Operational Management of LargeScale IT Systems in the Area of Freedom, Security and Justice (eu-LISA), and amending Regulation (EC) No 1987/2006 and Council Decision 2007/533/JHA and repealing Regulation (EU) No 1077/2011, OJ L 295, 21.11.2018, pp."
327,"This research project will examine “how facial recognition is currently being used for the investigation of crime across EU Mem ber States.” It will also give particular consideration to the potential for implementing the exchange of facial images within the Prüm framework.72 The pro ject is implemented by the Forensics Departments of Finland, Latvia, Sweden and the Netherlands, under the leadership of the Estonian Ministry of Justice."
327,"The Court of Justice of the EU (CJEU) has confirmed in its case law that the fundamental right to dignity is part of EU law.78 Biometric data, including facial images, must be pro cessed in a manner that respects human dignity."
327,"150 International Justice and Public Safety Network (2011), Privacy Impact Assessment Report for the Utilization of Facial Recognition Technologies to Identify Subjects in the Field , 30 June 2011, p."
327,"Minister for Justice, Equality and Law Reform, Ireland, Attorney General , 8 May 2014, para."
327,"See also: FRA and CoE (2016), Handbook on European law relating to access to justice , Luxembourg, Publications Office, June 2016, p."
328,"20 UK, High Court of Justice (Queens’ Bench Division – Divisional Court Cardiff), The Queen (OTAO) Bridges and Chief Constable of South Wales Police and others , [2019] EWCH 2341 (Admin), 4 September 2019."
328,"The Data Protection Commissioner of Hamburg ( Hamburgische Beauftragte für Datenschutz und Informa tionsfreiheit ) issued a report about the use of facial recognition technologies at the G20 and found that the use of the technology did not comply with data 50 UK, High Court of Justice (Queens’ Bench Division – Divisional Court Cardiff), The Queen (OTAO) Bridges and Chief Constable of South Wales Police and others , [2019] EWCH 2341 (Admin), 4 September 2019, para."
328,"As an additional safeguard, the Agency for the Operational Management of Large-Scale Informa tion Technology Systems (eu-LISA)62 is responsible for quality assurance safeguards and reports regularly 62 For an overview of the role and tasks of eu-LISA, see Chapter II of Regulation (EU) 2018/1726 of the European Parliament and of the Council of 14 November 2018 on the European Union Agency for the Operational Management of LargeScale IT Systems in the Area of Freedom, Security and Justice (eu-LISA), and amending Regulation (EC) No 1987/2006 and Council Decision 2007/533/JHA and repealing Regulation (EU) No 1077/2011, OJ L 295, 21.11.2018, pp."
328,"This research project will examine “how facial recognition is currently being used for the investigation of crime across EU Mem ber States.” It will also give particular consideration to the potential for implementing the exchange of facial images within the Prüm framework.72 The pro ject is implemented by the Forensics Departments of Finland, Latvia, Sweden and the Netherlands, under the leadership of the Estonian Ministry of Justice."
328,"The Court of Justice of the EU (CJEU) has confirmed in its case law that the fundamental right to dignity is part of EU law.78 Biometric data, including facial images, must be pro cessed in a manner that respects human dignity."
328,"150 International Justice and Public Safety Network (2011), Privacy Impact Assessment Report for the Utilization of Facial Recognition Technologies to Identify Subjects in the Field , 30 June 2011, p."
328,"Minister for Justice, Equality and Law Reform, Ireland, Attorney General , 8 May 2014, para."
328,"See also: FRA and CoE (2016), Handbook on European law relating to access to justice , Luxembourg, Publications Office, June 2016, p."
329,"(2017) “Social justice, epidemiology and health inequalities”, European Journal of Epidemiology, available at https://doi.org/10.1007/ s10654-017-0286-3 134."
329,"Jillian Hastings Ward , Chair of the Participant Panel for the 100,000 Genomes Project Professor Sabine Hauert , Assistant Professor in Robotics at the University of Bristol Eleonora Harwich , Head of Digital and Technological Innovation at Reform Mr Iain Hennessey , Theme Lead for Paediatric Surgical Technologies at the National Institute for Health Research (NIHR), and Clinical Director of Innovation at Alder Hey Children’s Hospital Imogen Heywood , Engagement Manager at the Centre for Information Sharing Matthew Honeyman , Policy Researcher at The King’s Fund Nigel Houlden , Head of Technology Policy at the Information Commissioner’s Ofﬁce Dr Julian Huppert , Director of the Intellectual Forum at Jesus College, Cambridge and Chair of DeepMind Health’s Independent Review Panel Dr Mona Johnson , Senior Clinical Lead, Doman A: Self-care & Prevention at NHS Digital Professor Jeffrey Kahn , Director of the Johns Hopkins Berman Institute of Bioethics Dr Pearse Keane, NIHR Clinician Scientist, Institute of Ophthalmology, UCL and Moorﬁelds Eye Hospital NHS Foundation Trust Dr Dominic King , Clinical Lead at DeepMind Health and Honorary Clinical Lecturer in Surgery at Imperial College London Jacob Lant, Head of Policy and Public Affairs at Healthwatch England Dr Geraint Lewis, Chief Data Ofﬁcer at NHS England and Honorary Clinical Senior Lecturer at University College London Dr Harry Longman , Founder and Chief Executive of GP Access Maxine Mackintosh , PhD candidate at University College London’s Farr Institute of Health Informatics and Co-founder of One HealthTech Professor Eduardo Magrani , Professor of Law and Technology at Fundação Getulio Vargas Law School Christopher Markou , PhD candidate in the Faculty of Law at the University of Cambridge Dr Ben Maruthappu , Co-founder and CEO of Cera Care Dr Debra Mathews , Assistant Director for Science Programs for the Johns Hopkins Berman Institute of Bioethics, and Associate Professor in the Department of Pediatrics, Johns Hopkins University School of Medicine Dr Brent Mittelstadt , Research Fellow and British Academy Postdoctoral Fellow at the Oxford Internet Institute Ben Moody , Head of Health and Social Care at techUK Dr Bertie Müller, Senior Lecturer in Computing at the University of South Wales Michaela Muruianu , Innovation Co-ordinator at Digital Catapult 50ETHICAL, SOCIAL, AND POLITICAL CHALLENGES OF ARTIFICIAL INTELLIGENCE IN HEALTH Dr Luke Oakden-Rayner , Radiologist and PhD candidate with the School of Public Health at the University of Adelaide Dr Claudia Pagliari, Senior Lecturer in Primary Care and Informatics and Director of Global eHealth at the University of Edinburgh Imogen Parker , Head of Justice, Citizens and Digital Society Programmes at The Nufﬁeld Foundation Dr Ali Parsa , Founder and CEO of Babylon Health Bakul Patel , Associate Center Director for Digital Health at the Food and Drug Administration (FDA) Nicola Perrin , Head of Understanding Patient Data Carol Platt , Innovation Associate at Alder Hey Children’s Hospital Professor Nasir Rajpoot , Professor in Computational Pathology at the Department of Computer Science, University of Warwick Professor Daniel Ray, Director of Data at NHS Digital Professor Geraint Rees , Dean of the UCL Faculty of Life Sciences and Professor of Cognitive Neurology at University College London Dr Travis Rieder , Assistant Director for Education Initiatives, Director of the Master of Bioethics degree program and Research Scholar at the Berman Institute of Bioethics Professor Renato Rocha Souza , Professor at the Applied Mathematics School, Fundação Getulio Vargas Professor Ferdinando Rodriguez y Baena , Professor of Medical Robotics in the Department of Mechanical Engineering at Imperial College London Dr Caroline Rubin , Vice-President for Clinical Radiology at the Royal College of Radiologists and Consultant Radiologist at the University Hospital Southampton NHS Foundation Trust Dr Benedict Rumbold , Research Fellow in the Department of Philosophy at University College London Professor Burkhard Schafer , Professor of Computational Legal Theory at the University of Edinburgh’s School of Law Professor Stefan Schulz, Professor of Medical Informatics at Medical University Graz, Austria Allan Tucker , Senior Lecturer of Computer Science at Brunel University Professor Rhema Vaithianathan , Co-Director of the Centre for Social Data Analytics at the University of Auckland Jenny Westaway , Head of the Ofﬁce of the National Data Guardian Hugh Whittall , Director of the Nufﬁeld Council on Bioethics John Wilkinson , Director of Devices at the Medicines and Healthcare products Regulatory Agency (MHRA) Professor Stephen Wilkinson , Professor of Bioethics 51ETHICAL, SOCIAL, AND POLITICAL CHALLENGES OF ARTIFICIAL INTELLIGENCE IN HEALTH D: Patients and members of the public who contributed to this report Alex Brownrigg Mariana Campos Ann Cawley Annabel Dawson Ruth Day Eric Deeson Fran Husson Elaine Manna John Marsh Richard Melville Ballerand Dave McCormick Kath Pollock Bob Ruane Edward Sherley-Price Chris Warner Marney Williams 52ETHICAL, SOCIAL, AND POLITICAL CHALLENGES OF ARTIFICIAL INTELLIGENCE IN HEALTH Professor Richard Ashcroft , Professor of Bioethics at Queen Mary University of London Shirley Cramer CBE , Chief Executive of the Royal Society for Public Health Professor Bobbie Farsides , Professor of Professor of Clinical and Biomedical Ethics at the University of Sussex Professor John Fox , Professor at the Department of Engineering Science at the University of Oxford Professor Nina Hallowell , Associate Professor at the Nuffield Department of Public Health, University of Oxford Dr Hugh Harvey, Clinical Lead for Kheiron Medical and Royal College of Radiologists Informatics Committee Member Eleonora Harwich , Head of Digital and Technological Innovation at Reform Dr Geraint Lewis , Chief Data Officer at NHS England and an Honorary Clinical Senior Lecturer at University College London Maxine Mackintosh , PhD candidate at University College London’s Farr Institute of Health Informatics and co-founder of One HealthTech Dr Benedict Rumbold , Research Fellow in the Department of Philosophy at University College London Professor Ilina Singh , Professor of Neuroscience & Society at the Department of Psychiatry at the University of Oxford and Co-Director of the Wellcome Trust Centre for Ethics Dr Nicola Strickland , President of the Royal College of Radiologists and Consultant Radiologist at the Imperial College Healthcare NHS Trust Professor Stephen Wilkinson , Professor of Bioethics E: List of attendees at expert roundtable 53ETHICAL, SOCIAL, AND POLITICAL CHALLENGES OF ARTIFICIAL INTELLIGENCE IN HEALTH F: Methodology by which patient/public contributors were recruited Patients and members of the public that were interviewed or that participated in our roundtable on the 22nd February 2018 were recruited via one of two methods."
33,"From Principles to Practice An interdisciplinary framework to operationalise AI ethics AI Ethics Impact Group led by From Principles to Practice An interdisciplinary framework to operationalise AI ethics 4 5 EXECUTIVE SUMMARY 6 1 INTRODUCTION 8 1.1 Challenges of practically implementing AI ethics 10 1.2 Multimethod framework as solution 12 1.3 Handling AI ethics in practice 14 2 VALUES, CRITERIA, INDICATORS, OBSERVABLES (VCIO) AND THE AI ETHICS LABEL IN DETAIL 15 2.1 How to apply VCIO to AI ethics: Three illustrated examples 17 2.1.1 Applying the VCIO approach to transparency as a value 20 2.1.2 Applying the VCIO approach to justice as a value 22 2.1.3 Applying the VCIO approach to accountability as a value 24 2.2 Values constituting the AI ethics rating 26 2.2.1 Transparency 26 2.2.2 Accountability 27 2.2.3 Privacy 28 2.2.4 Justice 28 2.2.5 Reliability 29 2.2.6 Environmental sustainability 30 2.3 How VCIO underpins the ratings in the AI Ethics Label 31 3 CLASSIFYING AN AI’S APPLICATION CONTEXT 35 3.1 The risk matrix 35 3.2 Dimensions of the risk matrix 37 3.2.1 Intensity of potential harm (x-axis) 37 3.2.2 Dependence on the decision (y-axis) 38 3.3 Recommendation for classes 38 4 CONCLUSION AND WHERE TO GO FROM HERE 41 4.1 Putting it all together 41 4.2 Next steps 42 5 BIBLIOGRAPHY 45 6 ABOUT THE AUTHORS 48 Imprint 54CONTENTS 6 EXECUTIVE SUMMARY Artificial intelligence (AI) increasingly pervades all areas of life."
33,"In chapter two, we present the VCIO model (values, criteria, indicators, and observables) for the operationalisation and measurement of otherwise abstract principles and demonstrate the functioning of the model for the values of transparency, justice and accountability."
33,"7EXECUTIVE SUMMARY For the proposed AI Ethics Label, we carefully suggest six values, namely justice, environmental sustainability, accountability, transparency, privacy, and reliability, based on contemporary discourse and operability."
33,"2 See the Guidelines of the European High-Level Expert Group.Implementation challenge Solution framework1 INTRODUCTION 9INTRODUCTION • We offer practical examples for applying the VCIO model to selected values such as transparency, accountability and justice."
33,"So how we implement and prioritise values such as justice (here includes fairness or non-discrimination) and transparency in practice, depends to some extent on the field of application and the cultural context an AI system operates in."
33,A system used in the justice sector must necessarily exhibit higher levels of privacy and fairness than a system used in the organisation of industrial production.
33,The implementation of values such as justice and transparency requires multiple measures throughout the complex development and implementation process of AI systems.
33,"We, therefore, introduce a framework that focuses on the three main challenges we have identified: (1) Our answer to the challenge of context-dependency: Combination of a contextindependent ethics rating and a classification approach In a first step, our framework introduces an approach for the rating of ethically relevant characteristics of an AI system (e.g. with regards to justice, accountability, transparency) independent of the system’s application context (see VCIO approach, chapter 2)."
33,"For example, it can become both a template for the work of regulatory bodies commissioned with the enforcement of regulation and provide orientation to AI developers and users and citizens and consumers.Framework addresses all main challenges 13INTRODUCTION Transparency Accountability Privacy Justice Reliability Environmental SustainabilityFIGURE 1 The AI Ethics Label with six selected valuesTaking the energy efficiency label as a guide, a label showing a rating of an AI system’s ethical characteristics could then look as follows: 14INTRODUCTION 1.3 Handling AI ethics in practice Taken together, our approach for the operationalisation of general principles (VCIO), the context-independent rating of ethical characteristics, the proposal of the introduction of an AI ethics label and the classification of different application contexts through a risk matrix provides a framework for bringing AI ethics from principles to practice."
33,"For application fields that are classified in one of the higher risk levels, they may demand that an AI system (1) must carry an ethics label that shows the rating for values such as transparency, robustness, or justice and (2) satisfy minimum levels within the rating. • Consumers use the ethics rating to compare AI products and services and make informed decisions about what is acceptable to them and/or worth investing in."
33,"For example, the demand that algorithms should not discriminate finds consensus; the debate, however, begins with the question of what is understood by discrimination (justice), how to check whether it exists, and how to deal with conflicts between different values."
33,"They are defined at the highest level (as justice or transparency, for example)."
33,"2.1 How to apply VCIO to AI ethics: Three illustrated examples In the following, we illustrate how to apply the VCIO model by focusing on three values, namely transparency, justice, and accountability.7 The findings from the Algo.Rules project, an initiative by the Bertelsmann Stiftung and the iRights.Lab, have been essential for the development of the framework and this chapter in particular."
33,"In practice, where values such as privacy, reliability or justice come into conflict with each other, option and legacy values can act as arbitrator values."
33,2.1.1 Applying the VCIO approach to transparency as a value (page 20/21) Justice The criteria subsumed under the value of justice in this example pertain to classic aspects of algorithmic fairness such as bias prevention and assessment but emphasise a process perspective to include a broader set of ethical considerations.
33,"These aspects are, for example, inclusion, represented by criteria such as participatory procedures, or social justice considerations, and a criterion for the assessment of trade-offs generated by the employment of the AI system in question."
33,"In this sense, justice refers to a broader set of ethical considerations than the often-used term fairness, which mostly focuses on algorithmic outcomes themselves."
33,2.1.2 Applying the VCIO approach to justice as a value (page 22/23) Accountability The value of accountability refers to problems that arise in connection with the complex allocation or clarification of responsibility relationships in the use of AI.
33,"2.1.3 Applying the VCIO approach to accountability as a value (page 24/25)Transparency as explainability and interpretability Justice with aspects of algorithmic fairness and inclusion Accountability refers to questions of assigning responsibility 20VALUES, CRITERIA, INDICATORS, OBSERVABLES (VCIO) AND THE AI ETHICS LABEL IN DETAIL Value TRANSPARENCY TRANSPARENCY Value Criteria Disclosure of origin of data sets Disclosure of properties of algorithm/model used Accessibility Criteria IndicatorsIs the data’s origin documented?Is it plausible for each purpose, which data is being used?Are the training data set’s characteristics documented and disclosed?"
33,"22VALUES, CRITERIA, INDICATORS, OBSERVABLES (VCIO) AND THE AI ETHICS LABEL IN DETAIL ValueJUSTICE JUSTICE ValueCriteriaIdentifying and assessing trade-offsAssessment of different sources of potential biases to ensure fairness1Social justice considerationsDetection and prevention of biases to ensure fairness Participatory procedures CriteriaIndicatorsHave tradeoffs been identified and assessed?Has the training data been analysed for potential biases?Has the input design (sensors, user interface) and input data been reviewed for potential biases?Have the requirements, goals and task definitions been examined for implicit and explicit discriminatory effects?Were possible selfreinforcing processes considered?Has due care been taken with regard to discriminatory effects caused by the design of the data output?Have the applied methods (e.g. categorisation) been evaluated for potential biases and discriminatory effects?Is a special checking procedure for possible proxies of sensitive data in place?"
33,"2.1.2 Applying the VCIO approach to justice as a value 23VALUES, CRITERIA, INDICATORS, OBSERVABLES (VCIO) AND THE AI ETHICS LABEL IN DETAIL ValueJUSTICE JUSTICE ValueCriteriaIdentifying and assessing trade-offsAssessment of different sources of potential biases to ensure fairness1Social justice considerationsDetection and prevention of biases to ensure fairness Participatory procedures CriteriaIndicatorsHave tradeoffs been identified and assessed?Has the training data been analysed for potential biases?Has the input design (sensors, user interface) and input data been reviewed for potential biases?Have the requirements, goals and task definitions been examined for implicit and explicit discriminatory effects?Were possible selfreinforcing processes considered?Has due care been taken with regard to discriminatory effects caused by the design of the data output?Have the applied methods (e.g. categorisation) been evaluated for potential biases and discriminatory effects?Is a special checking procedure for possible proxies of sensitive data in place?"
33,"Building on a meta-analysis of relevant publications, we settled on six values: transparency, accountability, privacy, justice, reliability, and environmental sustainability."
33,2.2.4 Justice Questions of justice include problems of equal treatment and the fair distribution of certain goods.
33,"This includes aspects of social justice, in particular, “hidden” work, which is essential for the operation of AI systems."
33,"9 Rössler 2004, Arendt 2006, Fried 1984, Stahl 2016To ensure privacy AI ethics must consider several methods Informational privacy as data is being used for specific purposes, after explicit consent, and with a right to delete or rectify Differential privacy and privacy by design Justice as algorithmic nondiscrimination and question of fair working conditions 29VALUES, CRITERIA, INDICATORS, OBSERVABLES (VCIO) AND THE AI ETHICS LABEL IN DETAIL Concerning discrimination by AI algorithms, reasons mostly lie in the reproduction of existing discrimination patterns that are introduced via the training data, in the (unintended) bias of software engineers, in the absorption of biases via presuppositions in labels, or the implementation of biases due to particular contexts of use."
33,The aspects of social justice that the VCIO model adds to this debate focus on the said “hidden” work that goes into the operation of AI systems.
33,"While confidentiality means that no unauthorised party has access Algorithmic discrimination through biases Click work as an aspect of social justice Reliability as a precondition for trust Predictability and safety as robustness and resilience Cybersecurity as confidentiality, integrity and availability 30VALUES, CRITERIA, INDICATORS, OBSERVABLES (VCIO) AND THE AI ETHICS LABEL IN DETAIL to the information, integrity covers aspects such as that information cannot be altered, that changes to the information are transparent and traceable, as well as the protection of the authenticity of the information."
33,2.2.6 Environmental sustainability Environmental sustainability is a form of intergenerational justice and describes the obligation towards future generations to ensure and preserve their living conditions.
33,"Those are just a few of many examples that show how various AI tools can be explicitly used to foster sustainability goals when taking the context into account.Resource-saving infrastructures to ensure intergenerational justice A right to repair Positive effects of AI systems on the environment 31VALUES, CRITERIA, INDICATORS, OBSERVABLES (VCIO) AND THE AI ETHICS LABEL IN DETAIL 2.3 How VCIO underpins the ratings in the AI Ethics Label By discussing the VCIO model in more depth, we have set the foundation for a comprehensive approach towards handling AI ethics."
33,"Rating with 5–7 levels, indicated with letters A–GTransparency Accountability Privacy Justice Reliability Environmental SustainabilityFIGURE 3 The AI Ethics Label and the elements of the system rating VALUE 1 Criterion 1.1 Criterion 1.2 Indicator 1.1.1Indicator 1.1.2Indicator 1.2.1Indicator 1.2.2 Observables 1 Observables 2 Observables 3 Observables 4 CA DBA DCBA CBA DFIGURE 4 System rating and operationalisation of a value using minimum requirements and aggregation 33VALUES, CRITERIA, INDICATORS, OBSERVABLES (VCIO) AND THE AI ETHICS LABEL IN DETAIL However, one drawback of a system using minimum requirements may be that it gives few incentives to strive for individual indicator ratings that go beyond the minimum requirements."
33,"We describe the proposed methodology to classify the application context as captured in the risk matrix in the following chapter 3.Ensuring incentives for higher ratings despite aggregation AI system evaluation requires analysis of application context 34VALUES, CRITERIA, INDICATORS, OBSERVABLES (VCIO) AND THE AI ETHICS LABEL IN DETAIL FIGURE 5 Illustration of the composition of the whole system rating using minimum requirements Observables CA DObservables BA D Observables CA D Observables GA Observables CA FObservables BA GC Observables CA D Observables BA CIndicator 1.1.1 Indicator 1.1.2 Indicator 1.2.1 Indicator 1.2.2 Indicator 2.1.1 Indicator 2.1.2 Indicator 2.2.1 Indicator 2.2.2Criterion 1.1 Criterion 1.2 Criterion 2.1 Criterion 2.2 Indicator 3.1.1 Indicator 3.1.2Criterium 3.1 Observables A Observables CA D Transparency Accountability Privacy Justice Reliability Environmental Sustainability 35 The AI Ethics Label provides at a glance information about the ethically relevant characteristics of an AI system."
33,"To assess this, the following issues must be regarded: • Impact on fundamental rights, equality or social justice: Does an AI have a negative impact on a natural, legal persons’ fundamental rights or are social justice mechanisms (e.g. pension, health insurance) at risk for extensive demographics or might the impact even be catastrophic and lead to loss of life (e.g. the treatment of intensive care patients)? • Number of people affected: Is a high number of people affected (e.g. fair assessment for a job application)? • Impact on society: Does the system bear the risk of affecting society as a whole (e.g. personalised selection of political news), independent of directly perceivable damage?"
330,"(2017) “Social justice, epidemiology and health inequalities”, European Journal of Epidemiology, available at https://doi.org/10.1007/ s10654-017-0286-3 134."
330,"Jillian Hastings Ward , Chair of the Participant Panel for the 100,000 Genomes Project Professor Sabine Hauert , Assistant Professor in Robotics at the University of Bristol Eleonora Harwich , Head of Digital and Technological Innovation at Reform Mr Iain Hennessey , Theme Lead for Paediatric Surgical Technologies at the National Institute for Health Research (NIHR), and Clinical Director of Innovation at Alder Hey Children’s Hospital Imogen Heywood , Engagement Manager at the Centre for Information Sharing Matthew Honeyman , Policy Researcher at The King’s Fund Nigel Houlden , Head of Technology Policy at the Information Commissioner’s Ofﬁce Dr Julian Huppert , Director of the Intellectual Forum at Jesus College, Cambridge and Chair of DeepMind Health’s Independent Review Panel Dr Mona Johnson , Senior Clinical Lead, Doman A: Self-care & Prevention at NHS Digital Professor Jeffrey Kahn , Director of the Johns Hopkins Berman Institute of Bioethics Dr Pearse Keane, NIHR Clinician Scientist, Institute of Ophthalmology, UCL and Moorﬁelds Eye Hospital NHS Foundation Trust Dr Dominic King , Clinical Lead at DeepMind Health and Honorary Clinical Lecturer in Surgery at Imperial College London Jacob Lant, Head of Policy and Public Affairs at Healthwatch England Dr Geraint Lewis, Chief Data Ofﬁcer at NHS England and Honorary Clinical Senior Lecturer at University College London Dr Harry Longman , Founder and Chief Executive of GP Access Maxine Mackintosh , PhD candidate at University College London’s Farr Institute of Health Informatics and Co-founder of One HealthTech Professor Eduardo Magrani , Professor of Law and Technology at Fundação Getulio Vargas Law School Christopher Markou , PhD candidate in the Faculty of Law at the University of Cambridge Dr Ben Maruthappu , Co-founder and CEO of Cera Care Dr Debra Mathews , Assistant Director for Science Programs for the Johns Hopkins Berman Institute of Bioethics, and Associate Professor in the Department of Pediatrics, Johns Hopkins University School of Medicine Dr Brent Mittelstadt , Research Fellow and British Academy Postdoctoral Fellow at the Oxford Internet Institute Ben Moody , Head of Health and Social Care at techUK Dr Bertie Müller, Senior Lecturer in Computing at the University of South Wales Michaela Muruianu , Innovation Co-ordinator at Digital Catapult 50ETHICAL, SOCIAL, AND POLITICAL CHALLENGES OF ARTIFICIAL INTELLIGENCE IN HEALTH Dr Luke Oakden-Rayner , Radiologist and PhD candidate with the School of Public Health at the University of Adelaide Dr Claudia Pagliari, Senior Lecturer in Primary Care and Informatics and Director of Global eHealth at the University of Edinburgh Imogen Parker , Head of Justice, Citizens and Digital Society Programmes at The Nufﬁeld Foundation Dr Ali Parsa , Founder and CEO of Babylon Health Bakul Patel , Associate Center Director for Digital Health at the Food and Drug Administration (FDA) Nicola Perrin , Head of Understanding Patient Data Carol Platt , Innovation Associate at Alder Hey Children’s Hospital Professor Nasir Rajpoot , Professor in Computational Pathology at the Department of Computer Science, University of Warwick Professor Daniel Ray, Director of Data at NHS Digital Professor Geraint Rees , Dean of the UCL Faculty of Life Sciences and Professor of Cognitive Neurology at University College London Dr Travis Rieder , Assistant Director for Education Initiatives, Director of the Master of Bioethics degree program and Research Scholar at the Berman Institute of Bioethics Professor Renato Rocha Souza , Professor at the Applied Mathematics School, Fundação Getulio Vargas Professor Ferdinando Rodriguez y Baena , Professor of Medical Robotics in the Department of Mechanical Engineering at Imperial College London Dr Caroline Rubin , Vice-President for Clinical Radiology at the Royal College of Radiologists and Consultant Radiologist at the University Hospital Southampton NHS Foundation Trust Dr Benedict Rumbold , Research Fellow in the Department of Philosophy at University College London Professor Burkhard Schafer , Professor of Computational Legal Theory at the University of Edinburgh’s School of Law Professor Stefan Schulz, Professor of Medical Informatics at Medical University Graz, Austria Allan Tucker , Senior Lecturer of Computer Science at Brunel University Professor Rhema Vaithianathan , Co-Director of the Centre for Social Data Analytics at the University of Auckland Jenny Westaway , Head of the Ofﬁce of the National Data Guardian Hugh Whittall , Director of the Nufﬁeld Council on Bioethics John Wilkinson , Director of Devices at the Medicines and Healthcare products Regulatory Agency (MHRA) Professor Stephen Wilkinson , Professor of Bioethics 51ETHICAL, SOCIAL, AND POLITICAL CHALLENGES OF ARTIFICIAL INTELLIGENCE IN HEALTH D: Patients and members of the public who contributed to this report Alex Brownrigg Mariana Campos Ann Cawley Annabel Dawson Ruth Day Eric Deeson Fran Husson Elaine Manna John Marsh Richard Melville Ballerand Dave McCormick Kath Pollock Bob Ruane Edward Sherley-Price Chris Warner Marney Williams 52ETHICAL, SOCIAL, AND POLITICAL CHALLENGES OF ARTIFICIAL INTELLIGENCE IN HEALTH Professor Richard Ashcroft , Professor of Bioethics at Queen Mary University of London Shirley Cramer CBE , Chief Executive of the Royal Society for Public Health Professor Bobbie Farsides , Professor of Professor of Clinical and Biomedical Ethics at the University of Sussex Professor John Fox , Professor at the Department of Engineering Science at the University of Oxford Professor Nina Hallowell , Associate Professor at the Nuffield Department of Public Health, University of Oxford Dr Hugh Harvey, Clinical Lead for Kheiron Medical and Royal College of Radiologists Informatics Committee Member Eleonora Harwich , Head of Digital and Technological Innovation at Reform Dr Geraint Lewis , Chief Data Officer at NHS England and an Honorary Clinical Senior Lecturer at University College London Maxine Mackintosh , PhD candidate at University College London’s Farr Institute of Health Informatics and co-founder of One HealthTech Dr Benedict Rumbold , Research Fellow in the Department of Philosophy at University College London Professor Ilina Singh , Professor of Neuroscience & Society at the Department of Psychiatry at the University of Oxford and Co-Director of the Wellcome Trust Centre for Ethics Dr Nicola Strickland , President of the Royal College of Radiologists and Consultant Radiologist at the Imperial College Healthcare NHS Trust Professor Stephen Wilkinson , Professor of Bioethics E: List of attendees at expert roundtable 53ETHICAL, SOCIAL, AND POLITICAL CHALLENGES OF ARTIFICIAL INTELLIGENCE IN HEALTH F: Methodology by which patient/public contributors were recruited Patients and members of the public that were interviewed or that participated in our roundtable on the 22nd February 2018 were recruited via one of two methods."
333,"Case 36: Automated credit scoring is not qualifying ADM if a human ultimately decides whether to grant a loan or not In anearly pre-GDPR ruling from 2014, the German Federal Court of Justice (Bundesgerichtsoft ) stated that “credit-scoring only amounts to an automated individual decision where the responsible body takes a decision with a legal consequence for the person concerned or a decision that has a significant impact on the person concerned, solely on the basis of a score result without further examination of the content."
333,Article 2 from the initial version of the law stated that “ Aucune décision de justice impliquant une appréciation sur un comportement humain ne peut avoir pour fondement un traitement automatisé d’informations donnant une définition du profil ou de la personnalité de l’intéressé.
333,"150 CJEU, Order of the President of the Court of Justice “Deletion” in Case C-552/21, January 25, 2022, ECLI:EU:C:2022:105."
335,"We share the view that the digital society must be built on trust among all stakeholders including governments, civil society, international organizations, academics and businesses through sharing common values and principles including equality, justice, transparency and accountability taking into account the global economy and interoperability."
335,"These include freedom, dignity and autonomy, privacy and data protection, non-discrimination and equality, diversity, fairness, social justice, and internationally recognized labor rights. b) To this end, AI actors should implement mechanisms and safeguards, such as capacity for human determination, that are appropriate to the context and consistent with the state of art."
338,"2 On behalf of the German Presidency of the Committee of Ministers of the Council of Europe, the German Fede ral Foreign Office and the Federal Ministry of Justice and Consumer Protection are proud to have hosted a virt ual highlevel Conference on this issue on 20 January 2021, with the support of the Council of Europe."
343,"This issue has particular resonance for policy makers, because algorithmic systems increasingly play a role in determining outcomes in public sector realms like the welfare or criminal justice systems."
345,"39 2022 AI Principles Progress UpdateEnd Notes 1. https://blog.google/technology/ai/join-us-in-the-ai-test-kitchen/ 2. https://blog.google/products/translate/24-new-languages/ 3. https://blog.google/technology/health/advancing-genomics-better-understand-and-treatdisease/ 4. https://blog.google/technology/health/check-up-ai-developments-2022/ 5. https://www.wired.com/story/hurricane-ian-destroyed-homes-google-algorithms-sent-money/ 6. https://www.iso.org/committee/6794475.html 7. https://www.nist.gov/itl/ai-risk-management-framework 8. https://www.pdpc.gov.sg/Help-and-Resources/2020/01/Model-AI-Governance-Framework 9. https://www.mas.gov.sg/schemes-and-initiatives/veritas 10. https://www.niti.gov.in/sites/default/files/2022-11/Ai_for_All_2022_02112022_0.pdf 11. https://www.justice.gc.ca/eng/csj-sjc/pl/charter-charte/c27_1.html#:~:text=In%20 addition%2C%20the%20Artificial%20Intelligence,with%20other%20government%20 entities%20specified 12. https://www.camara.leg.br/proposicoesWeb/prop_ mostrarintegra?codteor=1853928&filename=PL-21-2020 13. https://www.msit.go.kr/bbs/view.do?sCode=eng&mId=10&mPid=9&bbsSeqNo=46&nttSeqNo=9 14. https://www.whitehouse.gov/ostp/news-updates/2021/10/22/icymi-wired-opinion-americansneed-a-bill-of-rights-for-an-ai-powered-world/ 15. https://www.gov.uk/guidance/data-ethics-and-ai-guidance-landscape 16. https://www.gov.il/en/departments/news/most-news20221117 17. https://www.ft.com/content/3467659a-386d-11ea-ac3c-f68c10993b04 18. https://blog.google/technology/ai/crossword-puzzle-big-purpose/ 19. https://blog.google/technology/ai/an-update-on-our-work-in-responsibleinnovation/#:~:text=moral%20imagination%20workshop 20. https://blog.google/inside-google/googlers/meet-3-women-who-test-google-productsfairness/ 21. https://parti.research.google/ 22. https://imagen.research.google/ 2022 AI Principles Progress Update4023. https://translate.google.com/ 24. https://storage.googleapis.com/gresearch/translate-gender-challenge-sets/Readme.html 25. https://ai.google/principles/ 26. https://en.wikipedia.org/wiki/Wikipedia:Biographies_of_living_persons 27. https://storage.googleapis.com/gresearch/translate-gender-challenge-sets/Readme.html 28. https://ai.googleblog.com/2021/06/a-dataset-for-studying-gender-bias-in.html 29. https://storage.googleapis.com/gresearch/translate-gender-challenge-sets/Data%20Card.pdf 30. https://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf 31. http://gendershades.org/ 32. https://openaccess.thecvf.com/content/CVPR2021W/RCV/papers/Hazirbas_Casual_ Conversations_A_Dataset_for_Measuring_Fairness_in_AI_CVPRW_2021_paper.pdf 33. https://www.ncbi.nlm.nih.gov/books/NBK481857/table/chapter6.t1/ 34. https://ieeexplore.ieee.org/abstract/document/9590512 35. https://direct.mit.edu/daed/article/150/2/76/98313/The-Unceasing-Significance-of-ColorismSkin-Tone 36. https://www.journals.uchicago.edu/doi/abs/10.1086/682162 37. https://scholar.harvard.edu/files/monk/files/monk_-_the_consequences_of_race_and_color_in_ brazil_-_sp.pdf 38. https://www.norc.org/Pages/default.aspx 39. https://skintone.google/get-started 40. https://developers.google.com/machine-learning/crash-course/fairness/video-lecture 41. https://google.qualtrics.com/jfe/form/SV_eFJF7qguvcWvdFs 42. https://blog.google/technology/ai/join-us-in-the-ai-test-kitchen/l 43. https://ai.googleblog.com/2022/01/lamda-towards-safe-grounded-and-high.html 44. https://arxiv.org/abs/2201.08239 45. https://dynamicworld.app/explore/ 46. https://io.google/2022/program/385b422e-3a08-4372-8ed3-4e79bafb779a/ 47. https://www.bsr.org/en/ 48. https://arxiv.org/abs/2110.07858 41 2022 AI Principles Progress Update49. https://arxiv.org/pdf/2205.05256.pdf 50. https://arxiv.org/pdf/2202.01034.pdf 51. https://dl.acm.org/doi/abs/10.1145/3491102.3517716 52. https://ai-cultures.github.io/ 53. https://dl.acm.org/doi/abs/10.1145/3491101.3503564 54. https://www.deepmind.com/publications/red-teaming-language-models-with-language-models 55. https://www.tensorflow.org/responsible_ai/model_remediation 56. https://pair-code.github.io/lit/ 57. https://knowyourdata.withgoogle.com/ 58. https://arxiv.org/abs/2204.02311 59. https://sites.research.google/scouts/ 60. https://jigsaw.google.com/ 61. https://perspectiveapi.com/ 62. https://medium.com/jigsaw/scaling-machine-learning-fairness-with-societal-contextbe73d4ad38e2 63. https://arxiv.org/abs/2202.13028 64. https://github.com/google-research/parti/blob/main/data_cards/fit400m_data_card.pdf 65. https://arxiv.org/abs/2204.02311 66. https://pair-code.github.io/datacardsplaybook/ 67. https://arxiv.org/abs/2201.11903 68. https://aclanthology.org/D19-1221.pdf 69. https://arxiv.org/abs/2205.05638 70. https://arxiv.org/abs/2009.06367 71. https://aclanthology.org/2022.acl-long.72.pdf 72. https://blog.google/technology/ai/an-update-on-our-work-in-responsibleinnovation/#:~:text=an%20internal%20tool%20to%20help%20teams%20assess%20how%20 ml%20models%20were%20developed 73. https://blog.youtube/inside-youtube/inside-responsibility-whats-next-on-our-misinfo-efforts/ 74. https://blog.google/outreach-initiatives/accessibility/look-to-speak-launches-in-ukraine/ 2022 AI Principles Progress Update4275. https://globalgoals.withgoogle.com/ 76. https://medium.com/people-ai-research/q-a-courtney-heldreth-and-michal-lahav-onaddressing-inequitable-speech-recognition-it-takes-a-a2d65b1b7744 77. https://blog.google/outreach-initiatives/accessibility/project-relate/ 78. https://sites.research.google/euphonia/about/ 79. https://blog.google/technology/ai/ways-ai-is-scaling-helpful/ 80. https://ai.googleblog.com/2022/05/24-new-languages-google-translate.html 81. https://blog.google/products/chrome/building-a-more-helpful-browser-with-machine-learning/ 82. https://pair.withgoogle.com/guidebook/ 83. https://blog.google/technology/ai/helping-people-understand-ai/ 84. https://blog.google/products/pixel/feature-drop-december-2022/ 85. https://blog.google/products/chrome/building-a-more-helpful-browser-with-machine-learning/ 86. https://blog.google/products/maps/how-ai-and-imagery-build-self-updating-map/ 87. https://blog.google/technology/safety-security/how-we-make-every-day-safer-with-google/ 88. https://www.nature.com/nature-index/institution-outputs/articles/all/global/United%20 States%20of%20America%20%28USA%29/Alphabet%20Inc./corporate 89. https://research.google/pubs/?collection=responsible-ai 90. https://cloud.devsite.corp.google.com/vertex-ai-vision 91. https://www.google.com/search/howsearchworks/ 92. https://www.youtube.com/howyoutubeworks/ 93. http://g.co/DiscoverAI 94. https://applieddigitalskills.withgoogle.com/s/en/home?utm_source=keyword&utm_ medium=blog&utm_campaign=20220211-AI-Blog-2022--all-all-&src=keyword-blog-20220211AI-Blog-2022--all-all95. https://grow.google/ 96. https://blog.google/technology/ai/helping-people-understand-ai/ 97. https://www.cloudskillsboost.google/course_templates/388 98. https://google-research.github.io/proteinfer/ 99. https://aimsammi.org/blog-post/aims-launches-african-masters-in-machine-intelligence-in- 43 2022 AI Principles Progress Updatekigali-rwanda/ 100. https://research.google/outreach/phd-fellowship/ 101. https://blog.google/outreach-initiatives/education/a-look-at-the-responsible-innovationfellowship/ 102. https://blog.google/outreach-initiatives/education/expand-cs-ed-access/ 103. http://g.co/csrmp 104. https://blog.google/technology/research/mentorship-inspires-deyrel-diaz-and-futureresearchers/ 105. https://store.hbr.org/product/responsible-a-i-tackling-tech-s-largest-corporate-governancechallenges/b6021?sku=B6021-PDF-ENG 106. https://insait.ai/ 107. https://blog.google/technology/ai/investing-in-eastern-europes-ai-future/ 108. https://sites.research.google/trc/about/ 109. https://seejane.org/research-informs-empowers/see-it-be-it-what-families-are-watching-ontv/ 110. https://seejane.org/ 111. http://sail.usc.edu/ 112. https://blog.google/around-the-globe/google-europe/united-kingdom/girlguiding-and-googletechnology-is-for-everyone/ 113. https://www.blog.google/around-the-globe/google-asia/digital-skills-japan/ 114. https://blog.google/outreach-initiatives/grow-with-google/michigan-central-ford/ 115. https://michigancentral.com/ 116. https://www.nist.gov/itl/ai-risk-management-framework 117. https://impact.economist.com/perspectives/technology-innovation/pushing-forward-future-aimiddle-east-and-north-africa 118. https://impact.economist.com/perspectives/technology-innovation/seizing-opportunity-futureai-latin-america 119. https://blog.google/technology/ai/update-our-progress-responsible-aiinnovation/#:~:text=equitable%20ai%20research%20roundtables%20(earr)%2C 2022 AI Principles Progress Update44This page is intentionally left blank."
349,"Increasing the availability of open data - Continuing the development open data portal - Project to support both the open data demand and publishing MKM Ongoing activity --- 2 Abbreviations: EAS – Enterprise Estonia, HITSA – Information Technology Foundation for Education, HTM – Ministry of Education and Research, JM – Ministry of Justice, MKM – Ministry of Economic Affairs and Communications, STAT – Statistics Estonia 3 ’---’ marks action item which will not need additional or targeted budget, or it is not possible to distinguish such costs from rest of activity’s budget 4 See https://www.etag.ee/en/funding/programmes/rita/ Estonia’s National AI Strategy – Government of the Republic of Estonia – July 2019 3 Expert group proposals and existing measures Action item Responsible agency2 Deadline Budget3 Additional activities and measures: 1.8."
35,"Such disparities are often sterilized by well-intentioned names (e.g., “disproportionate contact” in criminal justice or the “achievement gap” in education) that hide the social consequence of structural racism: that, as a group, Black, Indigenous, and people of color in America have worse outcomes in many human service system outcome measures regardless of socioeconomic status.6 And yet, many agency solutions and data initiatives are largely disconnected from this root cause, and the “hunt for more data is [often] a barrier for acting on what we already know.”7 3 Racial Equity Tools (n.d.), Core Concepts: Racism 4 We intentionally use the acronym BIPoC (Black, Indigenous, people of color) as a term that seeks to recognize the unique experience of Black and Indigenous People within the United States."
35,"The BDC consists of Broward County Public Schools, Broward County Human Services Department, Broward Behavioral Health Coalition, Florida Departments of Children and Families and Juvenile Justice, Early Learning Coalition of Broward, and the Children’s Services Council of Broward County (which acts as the BDC backbone organization)."
35,"Working with the Kirwan Institute of Race and Social Justice at The Ohio State University, the City of Tacoma created an Equity Index to measure social mobility in the city."
35,"So when racial justice doesn’t have a critique of patriarchy and homophobia, the particular way that racism is experienced and exacerbated by heterosexism, classism, etc., falls outside of our political organizing."
35,"It means that significant numbers of people in our communities aren’t being served by social justice frames because they don’t address the particular ways that they’re experiencing discrimination.” — Kimberlé Williams Crenshaw13 13 Quoted in Guobadia, O."
35,Members of the group were all previously involved in efforts to promote algorithmic justice and had been accumulating knowledge on NYC-specific ADSs since fall of 2018.
35,"Provide a plan to the group that defines harm, and outline processes for repair and restoring justice."
35,"Other useful resources for understanding accountability and repairing harm include: Tools for Addressing Chapter Conflict from Black Lives Matter37 Challenging Neutrality, Examining Privilege and Encouraging Practitioner Self-Reflexivity: A Social Justice Approach to ADR38 Celebrate community and the effort you are putting toward growth and change."
35,"(n.d.) 40 Future of Privacy Forum & AISP (2018) 41 King County Office of Equity and Social Justice (2015) 42 Gorski, P."
35,Community Reconciliation Through Facilitated Dialogue & Restorative Justice .
35,How schools are using restorative justice to remedy racial disparities in discipline .
35,"The Little Book of Race and Restorative Justice: Black Lives, Healing, and US Social Transformation ."
35,The numbers don’t speak for themselves: Racial Disparities and the persistence of inequality in the criminal justice system .
35,"Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency. https://dl.acm.org/doi/abs/10.1145/3351095.3372874 King County Office of Equity and Social Justice."
35,No Small Matters: Reimagining the Use of Research Evidence From A Racial Justice Perspective .
35,How Philanthropy Can Help Lead on Data Justice .
35,"Challenging Neutrality, Examining Privilege, and Encouraging Practitioner Self-Reflexivity: A Social Justice Approach to ADR."
35,Just mercy: A story of justice and redemption .
35,"Racial Equity in Planning: WORK IN ACTION Broward Data Collaborative by Sue Gallagher Who: Broward Data Collaborative, Children’s Services Council of Broward County Where: Broward County, Florida Organization Type: Government Agency, Community-Based Organization Domains: Child welfare, behavioral health, juvenile justice, early learning, school, human services, prevention programs."
35,"The BDC seeks to improve the outcomes of residents in Broward County by integrating child-serving data from child welfare, behavioral health, juvenile justice, schools, early learning systems, county human services, and prevention programs."
35,"One of the BDC’s desired outcomes is for the people whose data are in the IDS (e.g., youth aging out of the child welfare system, youth in the juvenile justice system) to be integrally involved in the use, interpretation, and evaluation of their data."
35,"Recognizing that every child-serving system (e.g., child welfare, juvenile justice, education) produces racially disparate outcomes, the CPAR work is supported by training partners on the history and structures of racism (both nationally and locally) to build a common language and framework for system participants and system professionals."
35,"It centers on themes of equity, opportunity, partnerships, and accountability, and specifically reflects community members’ desire for racial fairness and social justice across all public programs."
35,"Allegheny County Department of Human Services, Office of Analytics, Technology and Planning by AISP with contributions from Samantha Loaney, Brian Bell, & Jamaal Davis Location: Allegheny County, Pennsylvania Organization Types Represented: Government Agency Domains Represented: Child welfare, family support, housing/income support, behavioral health, criminal justice, aging and intellectual disabilities Goal: To provide clients and providers access to the robust data held by the county’s Department of Human Services, allowing clients to understand what data is collected and providers to give more holistic care."
35,"53 The client portal will contain data from local school districts, family support programs, housing, income support programs, child welfare agencies, drug and alcohol treatment, the criminal justice system, mental health providers, and more."
35,"Racial Equity in Algorithms / Use of Statistical Tools: WORK IN ACTION Allegheny County Child Welfare Algorithm by AISP with contributions from Katy Collins Location: Allegheny County, Pennsylvania Organization Types Represented: Government Agency Domains Represented: Criminal justice system, behavioral health, public assistance, child welfare, education Goal: To use predictive analytics to allow caseworkers to engage in data-driven decision making that creates a more equitable, efficient, and successful child welfare system."
35,Members of the group were all previously involved in efforts to promote algorithmic justice and had been accumulating knowledge on NYC-specific ADS since fall of 2018.
35,"In an effort to ensure that an analysis of these indicators felt useful to both participating agencies and to community members that are impacted by these systems, the Educational Services Division of Youth & Family Justice formed a community engagement committee."
35,"One of the co-chairs of the committee, 62 APPENDIX I: WORK IN ACTION THROUGHOUT THE DATA LIFE CYCLESarah Zeller-Berkman, Director of Youth Studies Programs at the City University of New York (CUNY), who is a critical participatory action researcher, proposed that sustained engagement with a group of young people who had been in ACS care (preventive or juvenile justice) or young people who had fallen behind in middle school could generate data from other young people about the lived experience of being enmeshed in these systems."
35,"Most youth team members had either fallen behind in school or had been involved with ACS through foster care or juvenile justice, while others were simply committed to making positive change using research."
35,"See http://racialequitytools.org/glossary#structural-racism Social Justice: The proactive reinforcement of policies, practices, attitudes, and actions that produce equitable power, access, opportunities, treatment, impacts, and outcomes for all."
35,"How Philanthropy Can Help Lead on Data Justice , Stanford Social Innovation Review . https://ssir.org/articles/entry/how_philanthropy_can_help_lead_on_data_justice# Specific to Researchers Andrews, K., Parekh, J., Peckoo, S."
35,"Grant Foundation. http://wtgrantfoundation.org/digest/no-smallmatters-reimagining-the-use-of-research-evidence-from-a-racial-justice-perspective Actionable Intelligence for Social Policy University of Pennsylvania 3701 Locust Walk, Philadelphia, PA 19104 215.573.5827 www.aisp.upenn.edu"
350,"Accept additional cookies Reject additional cookies View cookies Hide cookie message Skip to main content GOV.UK Navigation menu Menu Menu Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments Departments, agencies and public bodies News News stories, speeches, letters and notices Guidance and regulation Detailed guidance, regulations and rules Research and statistics Reports, analysis and official statistics Policy papers and consultations Consultations and strategy Transparency Data, Freedom of Information releases and corporate reports Search GOV.UK × Search GOV.UK Search Search GOV.UK Search Home Business and industry Science and innovation Artificial intelligence Collection A guide to using artificial intelligence in the public sector Guidance on building and using artificial intelligence in the public sector."
350,"How DFID used satellite images to estimate populations 10 June 2019 Case study How the Department for Transport used AI to improve MOT testing 10 June 2019 Case study How GDS used machine learning to make GOV.UK more accessible 10 June 2019 Case study How a signalling company used AI to help trains run on time 10 June 2019 Case study Natural language processing for Land Registry documentation in Sweden 10 June 2019 Case study Using data from electricity meters to predict energy consumption 10 June 2019 Case study Using natural language processing to structure market research 10 June 2019 Case study How the Ministry of Justice used AI to compare prison reports 26 June 2019 Case study How a UK-based bank used AI to increase operational efficiency 18 October 2019 Case study Updates to this page Published 10 June 2019 Last updated 18 October 2019 + show all updates 18 October 2019 We have added a new case study to the ""Examples of artificial intelligence use"" section."
350,"Cancel Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments News Guidance and regulation Research and statistics Policy papers and consultations Transparency How government works Get involved Support links Help Privacy Cookies Accessibility statement Contact Terms and conditions Rhestr o Wasanaethau Cymraeg Government Digital Service All content is available under the Open Government Licence v3.0, except where otherwise stated © Crown copyright"
352,"4.2.6 Ethics and society It is necessary to guarantee that the uses of artificial intelligence are focused on humans’ well -being: artificial intelligenc e must be developed, applied and used with an ethical purpose based on fundamental rights, our social and cultural values, and the ethical principles of beneficence, autonomy of human beings, justice and the necessary explainability of their results ."
352,"Artificial intelligence should be used in a responsible, sensible and secure way and must include ethical reasoning, in terms of following and maintaining tradition and the European differentiating fact for everything that affects people and their development, as well as guarantee ing justice, transparency and lawfulness."
353,"Consider an appropriate mechanism for ensuring a coordinated approach by Irish regulators to Digital, including AI, as part of the forthcoming National Digital Strategy [DOT / DETE / DECC D/ Justice / DTCAGSM / DCEDIY] iii."
353,"For example, the Company Law Review Group submitted a report on AI to the T ánaiste and Minister for Enterprise, Trade and Employment in December 2020, which analysed possible impacts of the increased use of AI in the context of company law and corporate governance matters.20 This work to address regulatory gaps spans a wide range of legal and regulatory regimes including data protection; justice; policing; intellectual property; transport and haulage; finance; health; human rights, export controls; consumer protection; competition law and company law.A Risk-Based Approach to Regulation Prohibited Permitted subject to compliance with AI requirements and ex-ante conformity assessment Permitted but subject to information/ transparency obligations Permitted with no restrictions HIGH RISK e.g. recruitment, medical devices AI WITH SPECIFIC TRANSPARENCY OBLIGATIONS ‘impersonation’ (bots) MINIMAL OR NO RISK UNACCEPTABLE RISK e.g social scoring “NOT MUTUALLY EXCLUSIVE” 19."
353,"31 In 2021, the ADAPT Centre, Science Gallery Dublin and other partners engaged in an innovative multidisciplinary collaboration between artists and technologists on the theme of bias, exploring AI, Ethics, Trust and Justice.32 In a Europe-wide first, a cutting-edge law and technology module has been rolled out for undergraduate students at Maynooth University."
353,"Consider an appropriate mechanism for ensuring a coordinated approach by Irish regulators to Digital, including AI, as part of the forthcoming National Digital Strategy [DOT/ DETE / DECC / D/Justice/ DTCAGSM / DCEDIY] iii."
353,"Funding has been directed at AI solutions across a number of industry sectors, including video production; criminal justice and security; patient empowerment; and decision support systems in medical care."
353,"The EU AI High Level Expert Group (AI HLEG) identifies several areas of opportunity within the public sector where it considers the adoption of AI to be of utmost importance for the well-being of society, as well as for enhancing sustainable growth - these are: the e-Government domain; Justice and law enforcement; and the Healthcare sector.49 The European Commission is prioritising public sector dialogues on AI in healthcare, rural administrations and among public service operators,50 and it has outlined the creation of data spaces in health, agriculture and transport.51 Irish Revenue AI voicebot helps citizens handle tax clearance In early 2018, the Irish Revenue Commissioners initiated a pilot project to examine if AI-based Natural Language Processing (NLP) technologies could be used to deliver an improved customer service, reduce costs and increase efficiencies."
353,JUSTICE SECTOR The EU e-Justice Strategy and Action Plan 2019-2023 identifies the use of AI as a priority area in the justice field.
353,"However, the use of AI within the justice sector also has considerable implications for ethics, human rights and the rule of law."
353,"European Commission for the Efficiency of Justice (CEPEJ), European Ethical Charter on the Use of Artificial Intelligence in Judicial Systems and their environment, December 2018, accessed at: https://rm.coe.int/ethical-charter-en-for-publication-4-december-2018/16808f699c 55."
353,"70 AI – HERE FOR GOOD A National Artificial Intelligence Strategy for IrelandAI Artificial Intelligence ALTAI Assessment List for Trustworthy Artificial Intelligence CAHAI Ad Hoc Committee on Artificial Intelligence CCPC Competition and Consumer Protection Commission CCI Cybersecurity and Cybercrime Investigation CeADAR Ireland’s Centre for Applied Artificial Intelligence CEN European Committee for Standardization CENELEC European Committee for Electrotechnical Standardization CEPEJ European Commission for the Efficiency of Justice CLRG Company Law Review Group CRT Centres for Research Training CSO Central Statistics Office DAFM Department of Agriculture, Food and the Marine DFA Department of Foreign Affairs DCEDIY Department of Children, Equality, Disability, Integration and Youth DCU Dublin City University DETE Department of Enterprise, Trade and Employment DECC Department of the Environment, Climate and Communications DESI Digital Economy and Society Index DFHERIS Department of Further and Higher Education, Research, Innovation and Science DFKI German Research Centre for Artificial Intelligence DIH Digital Innovation Hub DoE Department of Education DoJ Department of Justice DoH Department of Health DPAI Data Protection Impact Assessment DPER Department of Public Expenditure and Reform DTCAGSM Department of T ourism, Culture, Arts, Gaeltacht, Sport and Media DTIF Disruptive T echnologies Innovation Fund EDIHs European Digital Innovation Hubs EGFSN Expert Group on Future Skills Needs EI Enterprise Ireland EPA Environmental Protection Agency ESO European Standards Organizations ETSI European T elecommunications Standards Institute EU European Union FET Further Education and Training GCID Grand Canal Innovation District GDP Gross Domestic Product GDPR General Data Protection RegulationGlossary of Acronyms 71 AI – HERE FOR GOOD A National Artificial Intelligence Strategy for IrelandGGE on LAWS UN Group of Governmental Experts on Lethal Autonomous Weapons Systems GPAI Global Partnership on AI GSI Geological Survey Ireland HE Higher Education HEA Higher Education Authority HEI Higher Education Institutes HLEG EU AI High Level Expert Group HPC High Performance Computing HSE Health Service Executive IA Impact assessments ICHEC Irish Centre for High-end Computing ICT Information and Communications IEC International Electrotechnical Commission IF SFI Industry Fellowship IMR Irish Manufacturing Research IP Intellectual Property IPCEI Important Projects of Common European Interest IRC Irish Research Council ISO International Organization for Standardization ITI InterTrade Ireland MOOC Massive Open Online Course MNE Multinational Enterprise NSAI National Standards Authority of Ireland OECD Organisation for Economic Cooperation and Development OGP Office of Government Procurement ONE-AI OECD on Network of Experts on AI RCSI Royal College of Surgeons Ireland R&I Research and innovation REC Research Ethics Committee RTEF Reference T esting and Experimentation Facilities SEAI Sustainable Energy Authority of Ireland SFI Science Foundation Ireland SME Small and Medium-Sized Enterprises STEM Science, technology, engineering, and mathematics TUD T echnological University Dublin UCC University College Cork UCD University College Dublin UN United Nations UNGP UN Guiding Principles on Business and Human Rights WAI Women in AI WIPO World Intellectual Property Organisation 72 AI – HERE FOR GOOD A National Artificial Intelligence Strategy for IrelandList of Organisations Consulted The list below reflects the organisations that took part in a range of stakeholder engagements throughout the development of this Strategy."
353,"The written submissions to the strategy are available on the Department of Enterprise, Trade and Employment’s website at: https://enterprise.gov.ie/en/Consultations/Public-Consultation-Development-of-a-National-Strategy-on-Artificial-Intelligence.html  30% Club  Accenture  AJH Emerging T echnology Intelligence  Allied Irish Banks  American Chamber of Commerce  Arvoia  Cainthus  CarTrawler  CeADAR Ireland’s Centre for Applied Artificial Intelligence  Central Bank  Chambers Ireland  Concern Worldwide  CONFIRM Centre (AIT)  CONSUS (Crop Optimisation through Sensing, Understanding & viSualisation)  CR Robotics  Data Protection Commission  Department of Agriculture, Food and the Marine  Department of Children, Equality, Disability, Integration and Youth  Department of Defence  Department of Education  Department of Enterprise, Trade and Employment  Department of Environment, Climate and Communication  Department of Finance  Department of Foreign Affairs  Department of Further and Higher Education, Research, Innovation and Science  Department of Health  Department of Housing, Local Government and Heritage  Department of Justice  Department of Public Expenditure and Reform  Department of Rural and Community Development  Department of Social Protection  Department of the T aoiseach  Department of T ourism, Culture, Arts, Gaeltacht, Sport and Media  Department of Transport  Digital Skills Global  Dublin Chamber of Commerce  Dublin City University, Business School  Dublin City University, School of Computing  Dublin City University, School of Electronic Engineering  Edgetier  Enable Ireland  Enterprise Ireland  Fotonation / Xperi  FourThereom  Freedomtech  FTI Consulting  Genesys  Health and Safety Authority  Ibec  IBM  ICT Skillnet  IDA Ireland  I-Form Advanced Manufacturing Research Centre  Industry Research and Development Group  Insight Centre for Data Analytics  Institute of Chartered Accountants Ireland  Insurance Ireland  Intel  InterTrade Ireland  Irish Centre for High-End Computing  Irish Computer Society/ICS Foundation  Irish Congress of Trade Unions  Irish Human Rights and Equality Commission  Irish Institute of Digital Business  Irish Manufacturing Research  Irish Marie Skłodowska-Curie Office  Irish Small and Medium Enterprises Association  Irish Universities Association  Jaguar Land Rover 73 AI – HERE FOR GOOD A National Artificial Intelligence Strategy for Ireland  Kerry Group  Law Society of Ireland  Learnovate  Letterkenny Institute of T echnology, Department of Computing  Lincoln Recruitment  Live tiles  Mason Hayes Curran  Mastercard Labs  Met Éireann  Microsoft  National Archives  National Standards Authority of Ireland  National University of Ireland Galway, School of Computer Science  National University of Ireland Maynooth, Department of Computer Science  National University of Ireland Maynooth, School of Business  Nokia Bell Labs  Office of the Government Chief Information Officer  Office of the Revenue Commissioners  Science Foundation Ireland  Science Foundation Ireland Centre for Research Training in Machine Learning  ServisBot  Skillnet Ireland  Small Firms Association  SOLAS  Swrve  T alent Garden  T ech Ireland  T echnological University Dublin, School of Computer Science  The ADAPT Centre  The Competition and Consumer Protection Commission  Trinity College Dublin, School of Computer Science and Statistics  Trinity College Dublin, School of Creative Arts  Truata  Ubotica  University College Cork, School of Computer Science & IT  University College Dublin, School of Computer Science  University College Dublin, School of Information and Communication Studies  University of Limerick LERO, Science Foundation Ireland Research Centre for Software  Valeo  Version1  Vodafone  Waterford Institute of T echnology, T elecommunications Software & Systems Group  Webio 74 AI – HERE FOR GOOD A National Artificial Intelligence Strategy for Ireland13"
362,"Pah et al., How to Build a More Open Justice System, 369 Sci."
366,Ordered to be printed 21 March 2022 and published 30 March 2022 Published by the Authority of the House of LordsHOUSE OF LORDS Justice and Home Affairs Committee 1st Report of Session 2021–22 HL Paper 180Technology rules?
366,"The advent of new technologies in the justice system Justice and Home Affairs Committee The Justice and Home Affairs Committee was appointed by the House of Lords on 14 April 2021 to consider justice and home affairs, including the domestic criminal justice system, and international cooperation in respect of criminal justice, civil justice, migration and asylum."
366,Membership The Members of the Justice and Home Affairs Committee are: Lord Blunkett Baroness Kennedy of The Shaws Baroness Chakrabarti Baroness Pidding Lord Dholakia Baroness Primarolo Baroness Hallett Lord Ricketts Baroness Hamwee (Chair) Baroness Sanderson of Welton Lord Hunt of Wirral Baroness Shackleton of Belgravia Declaration of interests See Appendix 1.
366,"A full list of Members’ interests can be found in the Register of Lords’ Interests: http://www.parliament.uk/hlregister Publications All publications of the Committee are available at: http://www.parliament.uk/ 519/justice-and-home-affairs-committee / Parliament Live Live coverage of debates and public sessions of the Committee’s meetings are available at: http://www.parliamentlive .tv Further information Further information about the House of Lords and its Committees, including guidance to witnesses, details of current inquiries and forthcoming meetings is available at: http://www.parliament .uk/business/lords Committee staff The staff who worked on this inquiry were Sam Kenny (Clerk), Achille Versaevel (Policy Analyst) and Amanda McGrath (Committee Operations Officer)."
366,"Contact details General correspondence should be addressed to the Clerk of the Justice and Home Affairs Committee, Committee Office, House of Lords, London SW1A 0PW."
366,"3 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM SUMMARY In recent years, and without many of us realising it, Artificial Intelligence has begun to permeate every aspect of our personal and professional lives."
366,Our Committee has limited its investigation to only one area–how these advanced technologies are used in our justice system.
366,"Algorithms are being used to improve crime detection, aid the security categorisation of prisoners, streamline entry clearance processes at our borders and generate new insights that feed into the entire criminal justice pipeline."
366,"When deployed within the justice system, AI technologies have serious implications for a person’s human rights and civil liberties."
366,"Without transparency, there can not only be no scrutiny, but no 4 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM accountability for when things go wrong."
366,Proper trials methodology is fully embedded into medical science but there are no minimum scientific or ethical standards that an AI tool must meet before it can be used in the criminal justice sphere.
366,"5 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM Yet without sufficient safeguards, supervision, and caution, advanced technologies may have a chilling effect on a range of human rights, undermine the fairness of trials, weaken the rule of law, further exacerbate existing inequalities, and fail to produce the promised effectiveness and efficiency gains."
366,The advent of new technologies in the justice system CHAPTER 1: INTRODUCTION 1.
366,"Within the application of the law, we included a broad view of the justice system, examining instances where advanced tools were used to discover, deter, rehabilitate, or punish people who breach the law in England and Wales, as well as border management."
366,8 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM Automated decision making (ADM): ADM is the process of making a decision by automated means without any human involvement.
366,"Written evidence from Dr Miri Zilka, Dr Adrian Weller and Detective Sergeant Laurence Cartwright laid out some categories of tools used in the justice system."
366,9 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM (b) Data analysis: software and tools primarily used to analyse data to create insights.
366,"We heard the most about tools used by the Home Office, the Ministry of Justice, HM Prisons and Probation Service, and individual police forces."
366,"We were told, for example, about the use of polygraphs to monitor sex offenders on parole and manage their level of compliance with parole conditions.14 8 Written evidence from Dr Miri Zilka, Detective Sergeant Laurence Cartwright and Dr Adrian Weller (nTL0040 ) 9 Written evidence from Association of Police and Crime Commissioners, national Police Chiefs’ Council and Police Digital Service ( nTL0049 ) 10 Written evidence from Avon and Somerset Police ( nTL0052 ) 11 Written evidence from the Serious Fraud Office ( nTL0034 ) 12 Written evidence from Public Law Project ( nTL0046 ) 13 Written evidence from Liberty ( nTL0020 ) 14 Written evidence from Dr Kyriakos n Kotsoglou ( nTL0007 ) 10 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM 6."
366,11 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM the end of which it would become costly for the customer to opt out.
366,"Avon and Somerset Constabulary thought their use of data analytics placed “better insights into the hands of those delivering the business to help empower and support more effective decision making.”23 The Rt Hon Kit Malthouse MP, the Minister for Crime and Policing at the Home Office and Ministry of Justice, told us that he was “very excited about the use of artificial intelligence and machine learning in policing.”24 We also acknowledge that, as many submissions pointed out, advanced tools can provide substantial assistance towards enacting the crucial duties of the police to protect and prevent harm."
366,"Matthew Gill, Senior Fellow at the Institute for Government, facilitated a seminar for us to consider the institutional and regulatory frameworks which 22 Q 45 (Professor Elizabeth Joh) 23 Written evidence from Avon and Somerset Police ( nTL0052 ) 24 Q 99 (Kit Malthouse MP) 25 Q 39 (Professor Elizabeth Joh) 26 Written evidence from SAS UK&I ( nTL0041 ) 27 Written evidence from the Information Commissioner’s Office ( nTL0016 ) 12 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM may be put in place."
366,"Box 2: Previous work This inquiry comes in the context of a variety of other national and international work. • In 2017, the House of Lords Artificial Intelligence Committee published its report, AI in the UK: ready, willing and able?28 This report concluded that putting ethics at the centre of the development and use of AI would enhance the UK’s strong position to be a world leader in its development. • In 2019, the Council of Europe Committee of Ministers appointed an Ad Hoc Committee on Artificial Intelligence to consider the feasibility and content of a potential legal framework on AI29. • In 2020, the Scottish Parliament Justice Sub-Committee on Policing published Facial recognition: how policing in Scotland makes use of this technology.30 • In 2021, the European Parliament Committee on Civil Liberties, Justice and Home Affairs published a report on “artificial intelligence in criminal law and its use by the police and judicial authorities in criminal matters”.31 • In 2021, nATO adopted its first Artificial Intelligence Strategy, including principles of the responsible use of AI in Defence and announcing further work to set international AI standards.32 • In 2021, U nESCO adopted a Recommendation on the Ethics of Artificial Intelligence and is working towards establishing the first-ever global normative instrument on the ethics of AI.33 15."
366,"We decided to examine the use of these tools throughout the “criminal justice pipeline”34 and in border management, identifying where change was needed, and identifying some principles for the safe and ethical use of such tools."
366,"(Report of Session 2017–19, HL Paper 100) 29 Council of Europe, CAHAI Ad Hoc Committee on Artificial Intelligence, ‘Terms of Reference’: https://www.coe.int/en/web/artificial-intelligence/cahai [accessed 6 February 2022] 30 The Scottish Parliament, Justice Sub-Committee on Policing, Facial Recognition: How Policing in Scotland Makes Use of This Technology (1st Report, Session 5, SP Paper 678) 31 Committee on Civil Liberties, Justice and Home Affairs, Report on artificial intelligence in criminal law and its use by the police and judicial authorities in criminal matters (13 July 2021): https://www.europarl. europa.eu/doceo/document/A-9-2021–0232 _En.html [accessed 6 February 2022] 32 north Atlantic Treaty Organisation, ‘Summary of the n ATO Artificial Intelligence Strategy’ (22 October 2021): https://www.nato.int/cps/en/natohq/official_texts _187617.htm [accessed 6 February 2022] 33 UnESCO, ‘Recommendation on the Ethics of Artificial Intelligence’ (2021): https://unesdoc .unesco. org/ark:/48223/pf0000380455 [accessed 6 February 2022] 34 Written evidence from Dr Miri Zilka, Detective Sergeant Laurence Cartwright and Dr Adrian Weller (nTL0040 ) 13 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM Chapter 3, we look at transparency: its necessity and proposals to increase it."
366,"The key issues we have identified, however, hold true for a much wider context: their application to all functions of the justice system and to border management."
366,14 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM CHAPTER 2: LEGAL AND INSTITUTIONAL FRAMEWORKS 18.
366,"It was also indicated that “public failures” could “lead to not just operational defects or inefficiencies, but miscarriages of justice”,42 and that where weaknesses were exposed, they “exacerbate the low level and negative trend in public trust for relevant technology”.43 Professor n igel Harvey and Tobias Harvey referred to accountability for errors and misuse, saying that the use of algorithms “may leave people open to dangers for which no person can be identified as responsible”.44 “A chilling effect”45 22."
366,"Various contributors told us that the use of some technologies, notably the use of live facial recognition, created fear or disquiet, and that this risked 35 Written evidence from the Home Office ( nTL0055 ) 36 QQ 103–104 (Kit Malthouse MP) 37 Royal Court of Justice , R v The Chief Constable of South Wales Police , [2020] EWCA Civ 1058 ."
366,"(nTL0022 ) 43 Written evidence from Archie Drake and Perry Keller ( nTL0011 ) 44 Written evidence from Professor n igel Harvey and Tobias Harvey ( nTL0025 ) 45 Written evidence from Dr Joe Purshouse, Dr n essa Lynch, Dr Marcin Betkier and Professor Liz Campbell ( nTL0021 ) 15 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM damaging the democratic process."
366,16 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM The right to a fair trial 23.
366,"We were concerned that, in some instances, the use of advanced tools at certain points of the criminal justice pipeline may impede an individual’s right to a fair trial: whether by a lack of awareness that they were being used, unreliable evidence, or an inability to understand and therefore challenge proceedings."
366,"Kotsoglou ( nTL0006 ) 55 Written evidence from Big Brother Watch ( nTL0037 ) 17 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM discrimination”,56 and Professor n igel Harvey and Tobias Harvey wrote that “learning algorithms based on historical data would preserve bias”.57 28."
366,56 Written evidence from Liberty ( nTL0020 ) 57 Written evidence from Professor n igel Harvey and Tobias Harvey ( nTL0025 ) 58 Q 60 (Professor Karen Yeung) 59 Written evidence from Liberty ( nTL0020 ) 18 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM Figure 1: Predictive policing—a vicious circle?
366,"We have noted over 30 public bodies, initiatives, and programmes playing a role in the governance of new technologies for the application of the law 60 Q 99 (Kit Malthouse MP) 19 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM (see Box 4)."
366,"Its three key areas of work are “to pilot new forms of data stewardship and governance”; to increase assurance practices around AI; and, to assist public sector bodies looking to procure technologies— ”facilitating the delivery of transformative data and AI projects in the public sector”.63 • The AI Council is an independent advisory committee which “works to support the growth of AI in the UK” and aims to increase skills, “work on public perception”, and “[explore] how to develop and deploy safe, fair, legal and ethical data sharing frameworks”.64 61 Office for Artificial Intelligence, ‘About us’: https://www.gov.uk/government/organisations/office-forartificial-intelligence/about [accessed 6 February 2022] 62 Department for Digital, Culture, Media and Sport, National AI Strategy (September 2021): https:// assets.publishing.service. gov.uk/government/uploads/system/uploads/attachment_data/file/1020402 [accessed 24 February 2022] 63 Centre for Data Ethics and Innovation, ‘About us’: https://www.gov.uk/government/organisations/ centre-for -data-ethics-and-innovation/about [accessed 6 February 2022] 64 HM Government, AI Council: https://www.gov.uk/government/ groups/ai-council [accessed 6 February 2022] 20 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM Box 4: List of entities and programmes • Her Majesty’s Inspectorate of Constabulary and Fire and Rescue Services • The AI Council • The Association of Police and Crime Commissioners (APCC), and its various working groups and initiatives, including the APCC Biometrics and Data Ethics Working Group • The Biometrics and Forensics Ethics Group • The Biometrics and Surveillance Camera Commissioner • The Centre for Data Ethics and Innovation • The College of Policing • The Data Analytics Community of Practice • The Equalities and Human Rights Commission • The Forensic Science Regulator • The Home Office Digital, Data and Technology function • The Independent Office for Police Conduct • The Information Commissioner’s Office • The n ational Crime Agency, and its TRACER programme • The n ational Data Analytics Solution • The n ational Digital and Data Ethics Guidance Group • The n ational Digital Exploitation Centre • The national Police Chiefs’ Council, and its eleven co-ordination committees, each responsible for a specific aspect related to new technologies • The n ational Police Ethics Group • The n ational Policing Chief Scientific Adviser • The Office for AI • The Police Digital Service, its Data Office and Chief Data Officer • The Police Rewired initiative • The Police Science, Technology, Analysis and Research (STAR) fund • The Police, Science, and Technology Investment Board • The Royal Statistical Society • The Science Advisory Council to the national Policing Chief Scientific Adviser • The Senior Data Governance Panel within the Ministry of Justice • The specialist and generalist ethics committees of some police forces • The Tackling Organised Exploitation programme 21 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM 33."
366,"65 Q 98 (Professor Paul Taylor) 66 Written evidence from Association of Police and Crime Commissioners, national Police Chiefs’ Council and Police Digital Service ( nTL0049 ) 67 Department for Digital, Culture, Media & Sport, Data: A new direction (10 September 2021), para 409: https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/ file/1022315/Data_Reform_Consultation_Document__Accessible_.pdf [accessed 28 January 2022] 68 Q 99 (Kit Malthouse MP) 69 Q 108 (Kit Malthouse MP) 22 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM Figure 2: “Family tree” of relevant governance arrangements Chief Constable Operational decisionSLT, ethics committee, technical experts, etc.Police and Crime Commissioner Oversight and strategic decision makingPublic Public consultation APCC Support, sharing best practice NPCC Coordination Committees 11 Committees and their members, some of which are national leads for new technologies, bring forces together to coordinate, reform, improve and provide value for money."
366,Dr Christopher Lawless referred to a series of bodies that all play “key roles in oversight” but which “vary in their remit and the extent of their powers”.70 Robin Allen QC and Dee Masters believed that “there has been too much thinking in ‘silos’”.71 There may also be confusion over responsibilities—Dr Lawless gave the example of facial recognition technology 70 Written evidence from Dr Christopher Lawless ( nTL0029 ) 71 Written evidence from Robin Allen QC and Dee Masters ( nTL0019 ) 23 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM to argue that there is a “potentially significant lacuna [in governance] where it is unclear who is statutorily responsible for regulation and oversight”.72 36.
366,"79 Q 99 (Kit Malthouse MP), see also Home Office, New Biometrics and Surveillance Camera Commissioner appointed (15 March 2021): https://www.gov.uk/government/news/new-biometrics-and-surveillancecamera -commissioner-appointed [accessed 28 January 2022] 80 Q 84 (Professor Paul Taylor) 24 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM • In September 2021, the Government published its National Artificial Intelligence Strategy ."
366,"While the Minister said that, as a Minister in both the Home Office and the Ministry of Justice, he was the “living embodiment” of crossdepartmental working, this does not appear to have impacted strategic 81 Department for Business, Energy & Industrial Strategy, ‘Guidance national AI Strategy’ (22 September 2021): https://www.gov.uk/government/publications /national-ai-strategy/national-aistrategy-html-version [accessed 1 February 2022] 82 Department for Digital, Culture, Media & Sport, Data : A new direction , para 409."
366,"83 DCMS Consultation: ‘Data: A new direction’ Response by the Biometrics and Surveillance Camera Commissioner: https://assets.publishing.service.gov.uk/government/uploads/system/uploads/ attachment _data/file/1030248/BSCC_DCMS_Consultation_Response.pdf [accessed 1 February 2022] 84 Written evidence from Association of Police and Crime Commissioners, national Police Chiefs’ Council and Police Digital Service ( nTL0049 ) 85 HL Deb, 3 november 2021, cols 1301–1305 25 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM thinking on the use of new technologies in applying the law, and there is no indication of any collective governmental effort towards a single strategy.86 On the contrary, there are many indications of siloed thinking."
366,"Similarly, BEIS and DCMS are collectively responsible for the implementation of the National AI Strategy , which focuses on businesses and the benefits of innovation and does not appear to have considered the needs of the Ministry of Justice or the Home Office at any length, or AI’s potential in their sectors."
366,"David Tucker, Faculty Lead on Crime and Criminal Justice at the College of Policing, told us: “We have seen that where decisions are challenged or doubted cases go to court and affect the way policing operates."
366,"The Appeal Court said that there was an absence of policy, so we are filling that gap and moving to apply these principles to this piece of technology”.87 86 Q 100 (Kit Malthouse MP) 87 Q 89 (David Tucker) 26 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM Box 5: The Bridges case and the Public Sector Equality Duty 1."
366,"88 Ministry of Justice, Public sector equality duty (6 July 2021): https://www.gov.uk/government/ publications/public-sector-equality-duty [accessed 4 February 2022] 89 Royal Court of Justice, R v The Chief Constable of South Wales Police , [2020] EWCA Civ 1058 90 Q 110 (Kit Malthouse MP) 91 Q 92 (Alun Michael) 27 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM We have also been told that both domestic courts and the European Court of Human Rights had been relied upon in the past.92 49. neither criminal cases nor judicial reviews are systematic processes: they are specific and rely on cases or applications being brought."
366,(nTL0022 ) 93 Written evidence from n CC Group ( nTL0005 ) 94 Written evidence from the Bar Council ( nTL0048 ) 95 Written evidence from n CC Group ( nTL0005 ) 96 Written evidence from Archie Drake and Perry Keller ( nTL0011 ) 97 Written evidence from the Home Office ( nTL0055 ) 98 Q 73 (David Lewis) 99 Written evidence from n CC Group ( nTL0005 ) 100 Q 36 (Dr David Leslie) 28 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM of the EU Commission’s proposed AI regulation” (see Box 6).
366,"Robin Allen QC and Dee Masters argued that “public actors and private companies need clear, pragmatic and effective regulatory frameworks because it provides a safety net within which ‘good’ AI can be developed whilst also protecting the fundamental rights of the public.”104 Archie Drake and Perry Keller had a similar view, stating that “legal uncertainty tends to harm business and innovation as well as public trust in the criminal justice system (and technology).”105 In a joint submission, three police bodies wrote that “Government should seek to clarify public appetite for new technologies and legislate so that policing has a clearer basis on which to make policies and decisions about deployment.”106 55."
366,"Professor Sandra Wachter, Associate Professor at the University of Oxford, thought that “soft regulation would be irresponsible” because the criminal justice system is “one of the most highrisk areas [she] can think of”.107 Dr Joe Purshouse and his co-contributors reflected that while guidance documents may be cited in court, they “do not provide actionable grounds for an individual to make a complaint”, adding that “non-compliance would not impact on the admissibility of any material gleaned.”108 101 Written evidence from Public Law Project ( nTL0046 ) 102 Written evidence from Professor Pete Fussey, Dr Daragh Murray and Dr Amy Stevens ( nTL0017 ) 103 Ibid."
366,"104 Written evidence from Robin Allen QC and Dee Masters ( nTL0019 ) 105 Written evidence from Archie Drake and Perry Keller ( nTL0011 ) 106 Written evidence from the Association of Police and Crime Commissioners (APCC), national Police Chiefs’ Council ( nPCC), and Police Digital Service (PDS) ( nTL0049 ) 107 Q 73 (Dr Liam Owens and Professor Sandra Wachter) 108 Written evidence from Dr Joe Purshouse, Dr n essa Lynch, Dr Marcin Betkier and Professor Liz Campbell ( nTL0021 ) 29 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM Box 6: The EU Artificial Intelligence Regulation Proposal 1."
366,"30 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM of the national Police Chiefs’ Council, who, among others, thought that any new legal framework should be adopted at national level, but that “it would be helpful if it was not too divergent from international regulation”.115 The practicalities 58."
366,"Others favoured a value- and principles-based approach, with Alun Michael saying that “the values and principles need to be established in law”.118 As our witnesses pointed out, “certain things with AI will always be the same … we will always have a data issue, a bias issue and an explainability issue.”119 Professor Raab similarly told us that among the “plethora” of guidance, research and reviews, a consensus had emerged on some principles: “privacy protection, accountability, fairness, non-discrimination, justice, transparency, safety and cybersecurity, serving the common good, explainability, and human oversight”.120 As we highlighted in paragraph 56, the Minister himself said that the Government’s preferred approach was to produce a set of principles—our view is that these should be translated into statute."
366,"We 115 Q 73 (David Lewis) 116 Written evidence from n CC Group ( nTL0005 ) 117 Written evidence from Professor Pete Fussey, Dr Daragh Murray and Dr Amy Stevens ( nTL0017 ) 118 Q 98 (Alun Michael) 119 Q 69 (Professor Sandra Wachter) 120 Written evidence from Professor Charles Raab ( nTL0014 ) 31 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM acknowledge the demands that the development of new legislation would place on parliamentary time and Government capacity, and that legislation is not a ‘quick fix’."
366,32 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM 64.
366,"The Home Office told us about guidance on the CAID programme (the Child Abuse Image Database, a facial recognition tool which helps identify victims and offenders)126, while guidance on facial recognition is currently being developed by the College of Policing, and the Ministry of Justice is working with the Alan Turing Institute to extend existing guidance on the use of data-driven technologies within the justice system.127 There is also various guidance available from the Surveillance Camera and Information Commissioners128, and a host of guidance from non-governmental sources such as the ALGO-care framework (a practical decision-making framework for the policing context).129 The Metropolitan Police Service noted that the application of the “variety of guidance, opinion, codes, directions and proposals for ethical frameworks … risks confusion and inconsistency”.130 126 Written evidence from the Home Office ( nTL0055 ) 127 College of Policing, ‘Police use of live facial recognition technology—have your say’ (17 May 2021): https://www.college.police.uk/article/police-use -live-facial-recognition-technology-have-your-say [accessed 26 January 2022] and written evidence from the Ministry of Justice ( nTL0053 ) 128 Information Commissioner’s Office, ‘Guidance index’: https://ico.org .uk/for-organisations/guidanceindex/ and Biometrics and Surveillance Camera Commissioner, ‘Surveillance camera guidance, tools and templates’ (22 October 2018): https://www.gov. uk/government/collections/surveillance-cameraguidance-tools-and-templates [accessed 7 February 2022] 129 Marion Oswald, ‘Algorithmic risk assessment policing models: lessons from the Durham HART model and ‘Experimental’ proportionality’, Information & Communications Technology Law , vol.27, (3 April 2018): https://www.tandfonline.com/doi/full/ 10.1080/13600834.2018.1458455 [accessed 7 February 2022] 130 Written evidence from the Metropolitan Police Service ( nTL0031 ) 33 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM Box 9: Application of the Equality Act 2010 • To illustrate the confusion in the application of law, several submissions referred to the Equality Act 2010."
366,"As Professor Raab pointed out, comprehensive and practical guidance on 131 Written evidence from Archie Drake and Perry Keller ( nTL0011 ) 132 Cloisters, In the matter of automated data processing in Government decision making (7 September 2019): https://www.cloisters.com/ wp-content/uploads/2019/10/Open-opinion-pdf-version-1.pdf [accessed 25 January 2022] 133 Centre for Data Ethics and Innovation, Review into bias in algorithmic decision-making (november 2020), p 12: https://assets.publishing.service.gov.uk/government/uploads/ system/uploads/attachment_data/ file/957259/Review_into_bias_in_ algorithmic_decision-making.pdf [accessed 2 February 2022] 134 Written evidence from Professor Pete Fussey, Dr Daragh Murray and Dr Amy Stevens ( nTL0017 ) 135 Written evidence from Professor Charles Raab ( nTL0014 ) 136 Written evidence from Robin Allen QC and Dee Masters ( nTL0019 ) 137 College of Policing, ‘APP content’ (4 n ovember 2015): https://www.app.college.police.uk/appcontent/ [accessed 4 February 2022] 138 Written evidence from the Serious Fraud Office ( nTL0034 ) 34 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM the use of types of technologies will require consistent review and ongoing updates as tools are used in operational settings, and practical operational issues identified.139 It could not therefore be expected that such guidance will ever tackle all of the specificities of particular tools."
366,"The Government should require that national guidance for the use of advanced technological tools in policing and criminal justice is drawn up and, as part of their response to this report, should outline concrete plans for this."
366,"142 Written evidence from the Association of Police and Crime Commissioners, n ational Police Chiefs’ Council, and Police Digital Service ( nTL0049 ) 143 Written evidence from the Law Society of England and Wales ( nTL0023 ) 144 Written evidence from Professor Pete Fussey, Dr Daragh Murray and Dr Amy Stevens ( nTL0017 ) 145 Written evidence from BAE Systems ( nTL0056 ) 146 Written evidence from the Information Commissioner’s Office ( nTL0016 ) 35 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM potential influence on individuals, groups and society”147, this trust is critical."
366,"Kit Malthouse MP said that forces must be allowed to fail “before we jump on everything.” It is important to note that the Minister was speaking in this context about technology which proves “not to be terribly useful”152, rather than about a failure to comply with minimum standards or where a miscarriage of justice had occurred."
366,"In particular, they thought that the Home Secretary, the Lord Chancellor and Secretary of State for Justice, and the Minister for Crime and Policing should be answerable for “how the Government’s vision of technological change in the system safeguards its effectiveness and legitimacy.”156 The Minister for Crime and Policing agreed that he, and Government as a whole, are “broadly—whether [they] like it or not—responsible for most things.”157 147 Written evidence from Dr Matthias Wienroth et al."
366,"(nTL0022 ) 148 Committee on Standards in Public Life, ‘The Seven Principles of Public Life’ (31 May 1995): https:// www.gov.uk/government/publications/the-7-principles-of- public-life/the-7-principles-of-publiclife--2 [accessed 27 January 2022] 149 Written evidence from Public Law Project ( nTL0046 ) 150 Q 72 (Dr Liam Owens) 151 Q 76 (Dr Liam Owens) 152 Q 106 (Kit Malthouse MP) 153 Written evidence from Privacy International ( nTL0051 ) 154 Written evidence from Dr Miri Zilka, Detective Sergeant Laurence Cartwright and Dr Adrian Weller (nTL0040 ) and Q 31 (Professor Michael Wooldridge) 155 Written evidence from the Bar Council ( nTL0048 ) 156 Written evidence from Archie Drake and Perry Keller ( nTL0011 ) 157 Q 107 (Kit Malthouse MP) 36 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM • Chief Constables."
366,(nTL0012 ) 167 Written evidence from n CC Group ( nTL0005 ) 168 Written evidence from BAE Systems ( nTL0056 ) 169 Written evidence from Dr Christopher Lawless ( nTL0029 ) 37 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM Lack of recourse 82.
366,174 Written evidence from Robin Allen QC and Dee Masters ( nTL0019 ) 175 Written evidence from Liberty ( nTL0020 ) and Big Brother Watch ( nTL0037 ) 38 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM to ban “clearly harmful or high-risk applications of technology” which lack robust accountability arrangements.176 87.
366,"176 Written evidence from Archie Drake and Perry Keller ( nTL0011 ) 177 Written evidence from the Metropolitan Police Service ( nTL0031 ) 178 Committee on Civil Liberties, Justice and Home Affairs, Report on artificial intelligence in criminal law and its use by the police and judicial authorities in criminal matters (13 July 2021): https://www.europarl. europa.eu/doceo/document/A-9-2021–0232_ En.html [accessed 3 February 2022] 179 United n ations Human Rights Office of the High Commissioner, Artificial intelligence risks to privacy demand urgent action — Bachelet (15 September 2021): https://www.ohchr.org/en/2021/09/artificialintelligence-risks-privacy-demand-urgent-action-bachelet [accessed 3 February 2022] 39 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM CHAPTER 3: TRANSPARENCY 90."
366,"(nTL0022 ) 185 Written evidence from Public Law Project ( nTL0046 ), see also written evidence from Dr Joe Purshouse, Dr n essa Lynch, Dr Marcin Betkier and Professor Liz Campbell ( nTL0021 ) 186 Written evidence from Robin Allen QC and Dee Masters ( nTL0019 ), see also Q 65 (Peter Dawson) 187 Q 78 (Professor Sandra Wachter) 188 Written evidence from The Bar Council ( nTL0048 ) 189 Written evidence from Public Law Project ( nTL0046 ) 190 Q 57 (Professor Karen Yeung) 40 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM of particular technologies but also for ensuring that the decision-making process for the use of technology is open to public scrutiny.”191 94."
366,"The Home Office told us that they were “supporting law enforcement organisations to address … the need for transparency”,192 and that “policing is committed to being transparent.”193 The Ministry of Justice also informed us about an annual review of “analytical algorithms—only a small subset of [which] involve data and decisions about individuals”. nevertheless, we ourselves faced difficulties accessing first-hand information, with repeated reference to confidentiality concerns."
366,"196 Written evidence from Robin Allen QC and Dee Masters ( nTL0019 ) 197 Written evidence from the Metropolitan Police Service ( nTL0031 ) 41 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM the use of technological solutions as they cannot know who is using what, for how long, for what purpose, or with what safeguards."
366,"This risks undermining trust in the police, the justice system, and the rule of law."
366,"42 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM to constantly refine and refresh the model to comply with appropriate ethical and legal oversight and governance.”203 While the full study is expected to be published (at a date yet to be confirmed), there are no commitments as to what information it will contain."
366,"Box 10: Previous support for a register • In 2018, the House of Commons Science and Technology Committee recommended that “the Government should produce, publish, and maintain a list of where algorithms with significant impacts are being used within Central Government, along with projects underway or planned for public service algorithms”.207 • A 2019 report by the Law Society of England and Wales concluded that “a national register of algorithmic systems in the criminal justice system should be created”.208 203 Police Professional, ‘Artificial intelligence ‘marginally better’ at predicting re-offending’ (25 January 2022): https://www.policeprofessional.com/ news/artificial-intelligence-marginally-better-at-predict ing-reoffending/ [accessed 24 February 2022] 204 Q 65 (Silkie Carlo, Peter Dawson, Professor Karen Yeung) and Q 78 (David Lewis, Dr Liam Owens, Professor Sandra Wachter) 205 Written evidence from Robin Allen QC and Dee Masters ( nTL0019 ) 206 Written evidence from Professor Colin Gavaghan ( nTL0047 ), see also written evidence from Archie Drake and Perry Keller ( nTL0011 ) and Professor Lilian Edwards, Professor Derek McAuley, Dr Lachlan Urquhart and Dr Jiahong Chen ( nTL0035 )."
366,"207 Science and Technology Committee, Algorithms in decision-making (Fourth Report, Session 2017– 2019, HC 351) 208 Q 11 (Professor Sylvie Delacroix) see also the Law Society of England and Wales, Algorithm use in the criminal justice system report , p 66: https://www.lawsociety.org .uk/en/topics/research/algorithm-use-inthe-criminal-justice -system-report [accessed 10 January 2022]."
366,"43 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM • A 2020 report by the Royal United Services Institute (RUSI) commissioned by the Centre for Data Ethics and Innovation (CDEI) found that “the nPCC and APCC should … maintain a high-level catalogue for all algorithms used by police forces nationwide”.209 David Lewis told us that the n PCC had recently accepted this recommendation, although caveating that “there is a matter of degree to be debated”.210 There is no indication that such a catalogue would be published. • A 2020 report by the Centre for Data Ethics and Innovation endorsed previous recommendations and suggested a “pilot in a specific part of the public sector”.211 • In 2021, the Commission for Race and Ethnic Disparities called for the introduction of “a mandatory transparency obligation on all public sector organisations applying algorithms that have an impact on significant decisions affecting individuals”.212 This recommendation was later endorsed by the Independent Office for Police Conduct.213 104."
366,One contributor thought that “it is not always feasible or even desirable to make algorithms in criminal justice fully transparent.”214 In the following paragraphs we examine those arguments.
366,"For instance, the information published on a register “could be used to infer how a [Machine Learning] model would make a specific legal decision, and thus what inputs could be crafted to manipulate a desired legal 209 RUSI, Data Analytics and Algorithms in Policing in England and Wales (February 2020), p xi: https:// static.rusi.org/rusi_pub_165_2020_01_ algorithmic_policing_babuta_final_web_copy.pdf [accessed 21 January 2022] 210 Q 78 (David Lewis) 211 Centre for Data Ethics and Innovation, Review into bias in algorithmic decision making ( november 2020): https://assets.publishing.service.gov.uk/government/uploads/ system/uploads/attachment_data/ file/957259/Review_into_bias_in_ algorithmic_decision-making.pdf [accessed 21 January 2022] 212 Commission on Race and Ethnic Disparities, Independent report, Forward, introduction and full recommendations , (28 April 2021): https://www.gov.uk/ government/publications/the-report-of-thecommission-on-race-and- ethnic-disparities/foreword-introduction-and-full-recommendations#fullrecommendations [accessed 10 January 2022] 213 Written evidence from the Independent Office for Police Conduct ( nTL0054 ) 214 Written evidence from Dr Miri Zilka, Detective Sergeant Laurence Cartwright and Dr Adrian Weller (nTL0040 ) 215 Q 78 (Dr Liam Owens) 216 Written evidence from BAE Systems ( nTL0056 ) 217 Q 78 (Professor Sandra Wachter) and Q 73 (Professor Sandra Wachter) 44 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM outcome.”218 Indeed, several witnesses were worried that a technological solution “could be ‘gamed’ by criminals” if algorithms were published.219 This is what BAE Systems calls “data poisoning”220 and the nCC Group calls “adversarial Machine Learning”.221 107."
366,"When some circumscribed their recommendation to “the application of the law”228 or “the criminal justice system”229 only, others advised that it should cover “the public sector”230 or “Government”231 in general."
366,"226 Written evidence from the Information Commissioner’s Office ( nTL0016 ) 227 Written evidence from Professor Colin Gavaghan ( nTL0047 ) 228 Written evidence from Big Brother Watch ( nTL0037 ) 229 Q 11 (Professor Sylvie Delacroix) 230 Q 65 (Professor Karen Yeung) 231 Written evidence from the Public Law Project ( nTL0046 ) 232 Written evidence from Professor Colin Gavaghan ( nTL0047 ) 233 Written evidence from Big Brother Watch ( nTL0037 ) 45 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM • The Public Law Project considered that each entry in the register should be accompanied with “executable versions of listed algorithms” and an explanation of how the technology works.234 • Citing the EU’s proposed AI Regulation currently being discussed within the European Union as a reference (see Box 6), Professor Sandra Wachter suggested that the register could include algorithms themselves, the data on which they are trained, as well as information on tests carried out and on oversight mechanisms.235 • Several witnesses asked for “detailed impact assessments”236 to be included, such as Equality Impact Assessments237 or Human Rights Impact Assessments.238 The Algorithmic Transparency Standard 109."
366,"240 Cabinet Office, UK government publishes pioneering standard for algorithmic transparency 46 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM allow public bodies the time to submit entries without diverting effort away from operational activities."
366,47 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM CHAPTER 4: HUMAN-TECHNOLOGY INTERACTIONS 114.
366,"( nTL0012 ) 248 Article 22 of Regulation (EU) 2016/679 of 23 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation) (Article 22) 4 May 2016 ( OJ L 119/1 ), see written evidence from Professor n igel Harvey and Tobias Harvey ( nTL0025 ) see also written evidence from Professor Lilian Edwards, Professor Derek McAuley, Dr Lachlan Urquhart and Dr Jiahong Chen ( nTL0035 ) 48 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM enforcement body may not take a qualifying significant decision based solely on automated processing unless that decision is required or authorised by law.249 These provisions aim to guarantee that there is a “human in the loop” but only for narrowly specified decisions."
366,"251 Oral evidence taken on 27 October 2021 (Session 2021–22) Q 13 (The Rt Hon Priti Patel MP, Home Secretary) 252 Q 86 (Professor Paul Taylor) 253 See, for example, written evidence from the Law Society of England and Wales ( nTL0023 ), Big Brother Watch ( nTL0037 ) and the Public Law Project ( nTL0046 ) 254 Q 33 (Professor Michael Wooldridge) 255 European Commission, Guidelines on Automated individual decision making and Profiling for the purposes of regulation 2016/679 (wp251rev.01) , 22 August 2018: https://ec.europa.eu/newsroom/article29/ redirection/document/49826 [accessed 24 January 2022] 49 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM • reviewers must ‘weigh-up’ and ‘interpret’ the recommendation, consider all available input data, and also take into account other additional factors.”256 122."
366,"Evidence from the Ministry of Justice stated that “operational decisions are informed by analytical tools rather than being automatic consequences of tool outputs.”257 Similarly, the Home Office stated that they “strongly disagree … that we are allowing sensitive decisions to be delegated to machines in a way that is either contrary to the law or the core principles of the [criminal justice system]”.258 Interactions to date 123."
366,"We were told, for instance, that attendees to an event about facial recognition (many of whom had access to and used facial recognition technology) “had a limited understanding of both face recognition technology and human face recognition.”264 A supplier of some tools had found that “criminal justice professionals are typically also lacking an expert, or even good, understanding.”265 Dee Masters and Robin Allen QC had, similarly, “become increasingly aware of the lack of understanding by regulators and the general public of the way in which AI systems are being used in their field of activity.”266 256 Information Commissioner’s Office, ‘Guidance on AI and data protection’: https://ico.org.uk/for organisations/guide-to-data-protection/key-dp-themes/guidance-on -artificial-intelligence-and-dataprotection/ [accessed 17 January 2022] 257 Written evidence from the Ministry of Justice ( nTL0053 ) 258 Written evidence from the Home Office ( nTL0055 ) 259 Written evidence from BAE systems ( nTL0056 ) 260 Q 8 (Professor Charles Raab) 261 Written evidence from Professor n igel Harvey and Tobias Harvey ( nTL0025 ) 262 Written evidence from n CC Group ( nTL0005 ) 263 Written evidence from Archie Drake and Perry Keller ( nTL0011 ) 264 Written evidence from Dr Eilidh n oyes and Dr Reuben Moreton ( nTL0026 ) 265 Written evidence from SAS UK&I ( nTL0041 ) 266 Written evidence from Robin Allen QC and Dee Masters ( nTL0019 ) 50 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM 125."
366,"Professor Carole McCartney, Professor of Law and Criminal Justice at the University of northumbria, explained this further: “If the humans do not understand the technology and how it is working, how will they spot if it has failed or if they have made a mistake? … The humans have to understand how it is working in order to be able to spot the times when they need to not trust the technology”.267 126."
366,"The Prison Reform Trust were similarly concerned about confidence to challenge outcomes which might appear discriminatory: “managers and policy makers are likely to be less inclined to ‘look under the bonnet’ when the technology they find there is unfamiliar.”268 The lack of understanding does not only apply to the people who are using the tool, but to those who commission it—and those who interact with its outputs later ‘down the justice pipeline’, including judiciary reviewing the conduct and findings of an investigation."
366,"Amy Stevens ( nTL0017 ) 270 Police Professional, Artificial intelligence ‘marginally better’ at predicting re-offending (25 January 2022): https://www.policeprofessional.com/ news/artificial-intelligence-marginally-better-at-predictingreoffending/ [accessed 24 February 2022] 51 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM • An automated triage system used by the Home Office, known as the sham marriage algorithm, is used to help “determine whether a proposed marriage should be investigated as a ‘sham’”."
366,"280 The Human Rights, Big Data and Technology Project, Independent Report on the London Metropolitan Police Service’s Trial of Live Facial Recognition Technology (July 2019), p 10: http://repository.essex.ac. uk /24946/1/ London-Met-Police-Trial-of-Facial-Recognition-Tech- Report-2.pdf [accessed 7 February 2022] 52 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM 128."
366,"The Home Office should, in conjunction with the Ministry of Justice and the College of Policing, undertake or commission appropriate research to determine how the use of predictive algorithms affects decision making, and under what circumstances meaningful human interaction is most likely."
366,"283 Q 87 (David Tucker) 284 Written evidence from the Public Law Project ( nTL0046 ) 285 Written evidence from Dr Eilidh n oyes and Dr Reuben Moreton ( nTL0026 ) 286 Q 70 (David Lewis) 287 Q 58 (Peter Dawson) 53 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM ongoing288, and regularly reviewed.289 It could also address a skills shortage in the workforce: references were made in the evidence to the difficulty in attracting employees highly skilled in technological tools who can command extremely high salaries in the private sector.290 134."
366,"David Tucker, Head of Criminal Justice at the College of Policing, told the Committee that “we have to wait for a moment of maturity, because if we do not we run the risk of trying to give guidance on something that has not settled down and is developing.”291 We are unconvinced by this argument."
366,"There is also ensuring that we have systems and processes in place so that does not occur.”293 The Ministry of Justice also outlined some of its safeguarding systems, which included “clear guidance” for “when the data should and should not be used, and support (and sometimes training) … made available to staff”.294 136."
366,"It would not be reasonable to expect every police officer, or every Ministry of Justice official (to take but two examples), to be trained in data analytics and in the specificities of sophisticated technological solutions."
366,"(nTL0012 ) 290 Written evidence from the Serious Fraud Office ( nTL0034 ) 291 Q 91 (David Tucker) 292 RUSI, ‘Data analytics and algorithms in policing in England and Wales: Towards a new policy framework’ (2020): https://rusi.org/explore-our-research/publications/occasional-papers/data-analyti cs-and-algorithms-policing-england-and-wales-towards-new-policy-framework [accessed 9 March 2022] 293 Q 89 (Professor Paul Taylor) 294 Written evidence from the Ministry of Justice ( nTL0053 ) 54 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM a part,295 and thus also need a thorough understanding of how algorithmic tools work."
366,"As part of continuing professional development, training should also be made available to lawyers, members of the Judiciary, and other professionals involved in the justice system."
366,"The Ministry of Justice referred to their sexual offender predictive tool, which is supported by an “overarching” policy framework to “support consistency of use”.298 Evidence from the Prison Reform Trust acknowledged the need for structures and policies enabling a clear route for challenge, but emphasised that these must work well in practice."
366,"295 See paras 23–26 296 Independent Chief Inspector of Borders and Immigration, An inspection of entry clearance processing operations in Croydon and Istanbul 297 Written evidence from Professor Colin Gavaghan ( nTL0047 ) 298 Written evidence from the Ministry of Justice ( nTL0053 ) 55 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM 144."
366,"Professor Karen Yeung, for instance, warned against tools that produce “a nice colour” such as “a little risk assessment, red, green or yellow” because they are so “easy to interpret” that they do not encourage challenge or critical thinking.304 In a similar vein, the Ministry of Justice told us that when designing “tools which 299 Q 57 (Peter Dawson) 300 Written evidence from the Prison Reform Trust ( nTL0004 ) 301 Independent Chief Inspector of Borders and Immigration, An inspection of entry clearance processing operations in Croydon and Istanbul 302 Q 8 (Professor Delacroix) 303 Written evidence from Gary Pugh ( nTL0036 ) 304 Q 57 (Professor Karen Yeung) 56 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM are used to support decisions about individuals”, they “strive to ensure that the tool is designed to be intuitive.”305 150."
366,"If achieved, algorithmic explainability would therefore provide more compelling explanations of decisions than humans currently provide.314 Certainly, procurement managers need to understand how the tools they are commissioning or purchasing function.315 Importantly, Professor Wachter added that introducing an explainability requirement on technologies used for the application of the law could help with this: “When people do not want to tell you how [a technological solution] is working, it is either because they do not want to or because they do 305 Written evidence from the Ministry of Justice ( nTL0053 ) 306 Written evidence from the Bar Council ( nTL0048 ) 307 Written evidence from BAE Systems ( nTL0056 ) 308 See Marion Oswald, ‘Algorithm-assisted decision-making in the public sector: framing the issues using administrative law rules governing discretionary power’, University of Winchester, (6 August 2018), p 8–9: https://royalsocietypublishing.org/doi/10.1098/rsta."
366,57 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM not know.
366,"I do not think either is acceptable, especially in the criminal justice sector."
366,58 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM CHAPTER 5: EVALUATION AND OVERSIGHT 156.
366,"The Law Society of England and Wales told us that: “Bias, both conscious and unconscious, can be baked into algorithms and undermine consistently reliable results, and that using algorithms without questioning them or explaining them to the public could lead to decisions which threaten human rights and undermine trust in the justice system”.323 158."
366,"(nTL0022 ) 323 Written evidence from the Law Society of England and Wales ( nTL0023 ) 324 Q 33 (Dr David Leslie) 325 Q 57 (Professor Karen Yeung) 326 HM Government, ‘Ethnicity facts and figures: Stop and search’ (February 2021): https://www. ethnicity-facts-figures.service.gov.uk/crime-justice-and-the-law/policing/stop-and-search/ latest#byethnicity [accessed 7 February 2022] 327 Q 71 (Professor Sandra Wachter) 59 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM the application of the categorisation algorithm and on which it depends."
366,"60 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM Assessments are a common approach to complying with the Public Sector Equality Duty,335 while Data Protection Impact Assessments are required for data processing operations which are likely to result in a high risk to individuals.336 163."
366,"61 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM and in demonstrating trustworthiness in ways that are more convincing than slogans and pledges, or compliance with legal requirements.344 Community consultation 166."
366,(nTL0022 ) 350 Written evidence from the Metropolitan Police Service ( nTL0031 ) 351 Written evidence from Big Brother Watch ( nTL0037 ) 62 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM Technical considerations “The system will fail” 170.
366,"63 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM Box 12: Scientific standards In this report, a reference to ‘scientific standards’ is intended to mean a regime of quality standards and processes consistently applied to a person or body developing, maintaining or manufacturing a particular scientific product or technology, providing a scientific service, or incorporating a scientific method into their public service, combined with independent regulatory enforcement."
366,"64 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM issues”.362 For instance, we heard that “the accuracy of face recognition technology depends on … the environment in which the technology is deployed” because “in real settings, images may be of suboptimal quality or environmental conditions may be inhibitory to realising the full accuracy of face recognition technology.”363 176."
366,"371 Q 40 (Professor Colin Gavaghan) 372 Q 66 (Silkie Carlo), Q 46 (Dr Rosamunde van Brakel), and Q 4 (Professor Charles Raab) 373 Written evidence from Archie Drake and Perry Keller, Kings College London ( nTL0011 ) 65 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM confirmed."
366,66 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM was also critical of the Government’s justification for the increased use of polygraph testing—a technological solution with controversial scientific grounds.
366,"David Spreadborough, a forensic analyst, told us that “a technology introduced in the judiciary system should be validated and approved by people technically competent on the matter.”389 BAE Systems agreed that a designated body could “develop a certificate of conformance (or ‘Kitemark’/CE label) for approved AI applications”.390 nCC Group concurred that it is “essential that clear processes are established to vet technologies before they are deployed”391, whereas Dr Liam Owens of technology provider Semantics21 told us about a “review” by “an intermediary”.392 388 Written evidence from the Information Commissioner’s Office ( nTL0016 ) 389 Written evidence from David Spreadborough ( nTL0015 ) 390 Written evidence from BAE Systems ( nTL0056 ) 391 Written evidence from n CC Group ( nTL0005 ) 392 Q 78 (Dr Liam Owens) 67 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM Privacy International agreed with them and detailed mechanisms by which a technological solution should be “approved for use”.393 187."
366,"The Ministry of Justice referred us to a peer-reviewed research study that evaluated the OASys Sexual reoffending Predictor (OSP) before this technological solution was approved by the Sexual Offending Management Board of Her Majesty’s Prison and Probation Service.394 Similarly, the Public Law Project drew our attention to the proposed AI Regulation in the European Union, which foresees central “certification indicating conformity to regulatory standards.”395 188."
366,"Former Deputy Chief Constable David Lewis told us that “there probably should be more centralised procurement”, alluding to the success of “regional procurement hubs” bringing police forces together.398 BAE Systems agreed 393 Written evidence from Privacy International ( nTL0051 ) 394 Written evidence from the Ministry of Justice ( nTL0053 ) 395 Written evidence from Public Law Project ( nTL0046 ) 396 College of Policing, Fundamental review of the College of Policing : https://assets.college.police.uk/s3fspublic/2022–02/Fundamental- review-of-the-College-of-Policing.pdf [accessed 24 February 2022] 397 HMICFRS, Inspectorate with College standards letter (10 February 2022): https://www.justicein spectorates.gov.uk/hmicfrs/publication-html/ inspectorate-relationship-with-college-standards-letter/ [accessed 24 February 2022] 398 Q 77 (David Lewis) 68 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM that they “would support some form of centralised AI procurement within policing and justice.”399 192."
366,"The Ministry of Justice and HM Prison & Probation Service have developed several of them, such as: • the Offender Group Reconviction Score (OGRS), a “predictor of proven reoffending within one and two years of noncustodial sentence or discharge from custody”404 • the Offender Assessment System (OASys), which “aims to assess the risk of harm offenders pose to others and how likely an offender is to reoffend”405 • the Digital Categorisation Service (DCS), an algorithm used to support decisions on security categorisations in prisons."
366,"405 Written evidence from Big Brother Watch ( nTL0037 ) 406 Written evidence from the Prison Reform Trust ( nTL0004 ) 69 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM Police and the University College London.407 The n ational Data Analytics Solution, a nationwide project sponsored by the Home Office and led by West Midlands Police in partnership with the national Crime Agency and Accenture, also falls in this category.408 We were told that, in n ew Zealand, such partnerships were “by far the most common practice” when the government procures technological solutions.409 196."
366,415 Written evidence from the n CC Group ( nTL0005 ) 416 Written evidence from Dr Eilidh n oyes and Dr Reuben Moreton ( nTL0026 ) 417 Q 24 (Professor Charles Raab) 70 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM has been overtaken by marketing” because of salespeople who “will take something they do not understand and shout a number that they do not understand” to make accuracy claims.418 200.
366,"419 West Midlands Police and Crime Commissioner Ethics Committee , ‘Minutes of a meeting held on Wednesday 3rd n ovember 10:00–14:00 hours’: https://www.westmidlands-pcc.gov.uk/ wp-content/ uploads/2022/01/2021–11-03-EC-Minutes-and-Advice.pdf?x41638 [accessed 1 February 2022] 420 Q 94 (Alun Michael) 421 Q 75 (David Lewis 422 Written evidence from Professor Charles Raab ( nTL0014 ) 423 Office for Artificial Intelligence, ‘Guidelines for AI procurement’ (8 June 2020): https://assets. publishing.service.gov.uk/government/uploads/ system/uploads/attachment_data/file/990469/ Guidelines_for_AI_procurement. pdf [accessed 26 January 2022] 424 World Economic Forum, AI Procurement Guidelines (11 June 2020): https://www.weforum.org/reports/ ai-procurement-in-a-box/ai-government-procurement-guidelines [accessed 26 January 2022] 425 Q 73 (David Lewis) 71 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM Chiefs’ Council, and the Police Digital Service confirmed that they “inform contract implementation and management”.426 203."
366,"BAE Systems argued that the guidelines should be “more technical”, more “supplier-focused”, and more specific to “policing and the justice context”.427 Professor Wachter told us that these “vague” guidelines were “not good enough” because they were too soft to induce change in procurement practices.428 Dr Liam Owens agreed that the guidelines are “very broad” and “non-specific” and would need to be better tailored to address the needs of technology providers in the context of the application of the law.429 Furthermore, this document refers to ‘guidance’ as well as ‘guidelines’."
366,"432 World Economic Forum, AI Procurement Guidelines 72 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM used in the application of the law."
366,73 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM The West Midlands Ethics Committee model 211.
366,"These included: • A recruitment based on merit, 443; with independent membership444 with a range of expertise; 445 • A commitment to publish meetings papers, minutes and conclusions;446 • The Committee’s independence from the police force whose use of technology it is scrutinising; and447 • The Committee’s remit to consider technological solutions throughout their lifecycle.448 441 See, for instance, Q 2 (Professor Carole McCartney), Q 110 (Kit Malthouse MP), also written evidence from Archie Drake and Perry Keller ( nTL0011 ), and defenddigitalme ( nTL0044 ) 442 Written evidence from Association of Police and Crime Commissioners, national Police Chiefs’ Council and Police Digital Service ( nTL0049 ), see also Q 11 (Professor McCartney), Q 48 (Dr Rosamunde van Brakel), and written evidence from BAE Systems ( nTL0056 ) 443 Written evidence from Association of Police and Crime Commissioners, national Police Chiefs’ Council and Police Digital Service ( nTL0049 ) 444 Written evidence from Association of Police and Crime Commissioners, national Police Chiefs’ Council and Police Digital Service ( nTL0049 ) and BAE Systems ( nTL0056 ) 445 Q 11 (Professor McCartney), Q 48 (Dr Rosamunde van Brakel) and written evidence from BAE Systems ( nTL0056 ) 446 Q 11 (Professor McCartney), written evidence from Association of Police and Crime Commissioners, national Police Chiefs’ Council and Police Digital Service ( nTL0049 ), and BAE Systems ( nTL0056 ) 447 Written evidence from Association of Police and Crime Commissioners, n ational Police Chiefs’ Council and Police Digital Service ( nTL0049 ), Archie Drake and Perry Keller ( nTL0011 ) and BAE Systems ( nTL0056 ) 448 Written evidence from Association of Police and Crime Commissioners, national Police Chiefs’ Council and Police Digital Service ( nTL0049 ) and BAE Systems ( nTL0056 ) 74 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM Box 14: The West Midlands Police Ethics Committee • The West Midlands Police and Crime Commissioner (PCC) and West Midlands Police (WMP) jointly established a specialist Ethics Committee in early 2019."
366,"He told us that he thought it was “a good idea for local police forces to have ethics committees” but that he viewed Parliament as the national ethics committee, that decides on “the legal and the moral framework within 449 West Midlands Police Ethics Committee, ‘Terms of Reference’, para 47: https://www.westmidlands pcc.gov.uk/wp-content/uploads/2019/07/Ethics-Committee-Terms -of-Reference-as-at-1-April-2019. pdf ?x41638 [accessed 1 February 2022] 450 HL Deb, 3 n ovember 2021, cols 1301–1305 451 Written evidence from the Home Office ( nTL0055 ) 75 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM which everything in society operates”."
366,76 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM SUMMARY OF CONCLUSIONS AND RECOMMENDATIONS Legal and institutional frameworks 1.
366,(Paragraph 66) 77 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM 11.
366,(Paragraph 113) 78 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM Human-technology interactions 21.
366,(Paragraph 183) 79 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM 30.
366,"With the assurance brought by the certification process and the register of algorithms, police forces and other 80 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM public bodies would remain free to procure the technological solutions of their choice, as long as the products have been certified."
366,"(Paragraph 219) 81 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM APPENDI x 1: LIST OF MEMBERS AND DECLARATIONS OF INTEREST Members Lord Blunkett Baroness Chakrabarti Lord Dholakia Baroness Hallett Baroness Hamwee (Chair) Lord Hunt of Wirral Baroness Kennedy of The Shaws Baroness Pidding Baroness Primarolo Lord Ricketts Baroness Sanderson of Welton Baroness of Shackleton of Belgravia Declarations of Interest Lord Blunkett Non- Financial: Non-executive Chairman, Cyber Essentials Direct Limited Directorship: Director and Chairman of the Board, University of Law Limited (subsidiary and affiliated institution of Global University Systems and Interactive Pro Limited) Baroness Chakrabarti No relevant interests to declare Lord Dholakia Trustee of the Police Foundation which produced a report on the Strategic Review of Policing in England and Wales on 8 March 2022 Baroness Hallett Retired judge Baroness Hamwee No relevant interests to declare Lord Hunt of Wirral Partner, DAC Beachcroft LLP (International commercial law firm) Honorary Bencher, Inner Temple Baroness Kennedy of The Shaws Member of Microsoft Technology and Human Rights Advisory Council Baroness Pidding No relevant interests to declare Baroness Primarolo Non-Executive Director on the Board of Thompson’s Solicitors LLP."
366,"Lord Ricketts No relevant interests to declare Baroness Sanderson of Welton No relevant interests to declare Baroness Shackleton of Belgravia No relevant interests to declare other than those on the Register 82 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM Specialist Adviser Dr Marion Oswald Associate Professor, Northumbria Law School Advisory Board member, Centre for Data Ethics and Innovation Senior Research Associate, The Alan Turing Institute Associate Fellow, Royal United Services Institute for Defence and Security Studies; Independent Chair, West Midlands Police & Crime Commissioner and West Midlands Police Data Ethics Committee; Member, New Zealand Police Expert Panel on Emergent Technologies; Advisory board member of the UKRI Trustworthy Autonomous Systems Hub; Member of the Royal Society Working Group on Privacy Enhancing Technologies (2018–19 and reconstituted 2021); Member of National Statistician’s Data Ethics Advisory Committee since its foundation (2016-date); Executive member, British & Irish Law, Education & Technology Association; Member, Arts and Humanities Research Council Peer Review College."
366,83 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM APPENDI x 2: LIST OF WITNESSES Evidence is published online at https://committees .parliament.uk/committee/519/ justice-and-home-affairs-committee/publications / and available for inspection at the Parliamentary Archives (020 7219 3074).
366,"Oral evidence in chronological order * Professor Sylvie Delacroix, Professor in Law and Ethics at University of BirminghamQQ 1–24 * Professor Carole McCartney, Professor of Law and Criminal Justice at n orthumbria UniversityQQ 1–24 ** Professor Charles Raab, Professorial Fellow, Politics and International Relations, School of Social and Political Science at The University of Edinburgh)QQ 1–24 * Dr David Leslie, Ethics Theme Lead at Alan Turing InstituteQQ 25–38 * Professor Michael Wooldridge, Head of Department of Computer Science, Professor of Computer Science at University of OxfordQQ 25–38 ** Professor Colin Gavaghan, Director n ew Zealand Law Foundation Centre for Law and Policy in Emerging Technologies at University of OtagoQQ 39–51 * Professor Elizabeth E Joh, Martin Luther King Jr."
366,"Professor of Law at University of California, DavisQQ 39–51 * Dr Rosamunde Elise van Brakel, Co-Director, Surveillance Studies n etwork, Associate Professor Tilburg University/Vrije Universiteit Brussel (VUB)QQ 39–51 ** Silkie Carlo, Director, Big Brother Watch QQ 52–67 ** Peter Dawson, Director, Prison Reform Trust QQ 52–67 * Professor Karen Yeung, Interdisciplinary Professorial Fellow in Law, Ethics and Informatics, Birmingham Law School at The University of BirminghamQQ 52–67 * David Lewis, Former Deputy Chief Constable and former ethics lead n PCC at Dorset PoliceQQ 68–82 * Dr Liam Owens, Founder and Chief Executive Officer, Semantics 21QQ 68–82 ** Professor Sandra Wachter, Associate Professor and Senior Research Fellow at University of OxfordQQ 68–82 ** Professor Paul Taylor, Chief Scientific Adviser, national Police Chiefs’ CouncilQQ 83–98 84 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM ** Alun Michael, Police and Crime Commissioner for South Wales and Joint Lead for Data and Bioethics, Association of Police and Crime CommissionersQQ 83–98 ** Darryl Preston, Police and Crime Commissioner for Cambridgeshire and Peterborough and Joint Lead for Data and Bioethics, Association of Police and Crime CommissionersQQ 83–98 * David Tucker, Faculty Lead on Crime and Criminal Justice, College of Policing.QQ 83–98 * The Rt Hon Kit Malthouse MP, Minister of State for Crime and Policing at the Home Office and Ministry of JusticeQQ 99–111 * Dr Christophe Prince, Director for Data and Identity, Home OfficeQQ 99–111 Alphabetical list of all witnesses Robin Allen QC, Barristers at A1 Law Consultancy/ Cloisters ChambersnTL0019 Dr Arianna Andreangeli, Senior Lecturer in Competition Law, Edinburgh Law School, University of EdinburghnTL0038 nTL0039 Dr Philip Avenell, Managing Director and Forensic Biologist at Forensic AccessnTL0024 Avon and Somerset Police nTL0052 BAE Systems nTL0056 Professor Melanie Bailey, Professor at University of SurreynTL0024 The Bar Council nTL0048 Dr Marcin Betkier, Lecturer in Law at Victoria University of WellingtonnTL0021 Dr Stephen Bleay, Senior Lecturer in Forensic Science at London South Bank UniversitynTL0024 Katy Bourne OBE, Sussex Police and Crime CommissionernTL0045 Dr Rebecca Brown, Research Fellow at University of OxfordnTL0030 Professor Dame Vicki Bruce DBE, Professor Emerita at newcastle UniversitynTL0012 Professor A Mike Burton, Professor of Psychology at University of YorknTL0012 Professor Liz Campbell, Professor and Francine V Mcniff Chair in Criminal Jurisprudence at Monash UniversitynTL0021 85 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM ** Silkie Carlo, Director, Big Brother Watch (QQ 52–67 )nTL0037 Detective Sergeant Laurence Cartwright, Data Analytics lead at Sussex PolicenTL0040 Dr Jiahong Chen, Lecturer in Law at Sheffield Law School, University of SheffieldnTL0035 The Crown Prosecution Service nTL0018 Dr Benjamin Davies, Wellcome Trust Society & Ethics Research Fellow at University of OxfordnTL0030 ** Peter Dawson, Director, The Prison Reform Trust (QQ 52–67 )nTL0004 defenddigitalme nTL0044 Dr Delphine Defossez (Lecturer in Law), northumbria UniversitynTL0022 * Professor Sylvie Delacroix, Professor in Law and Ethics at University of Birmingham ( QQ 1–24 ) Professor Thomas Douglas, Professor of Applied Philosophy University of OxfordnTL0013 nTL0030 Archie Drake, Research Associate at Kings College, LondonnTL0011 Professor Gary Edmond, Professor of Law at U nSW SydneynTL0012 Professor Lilian Edwards, Professor of Law, Innovation and Society at n ewcastle Law School, newcastle UniversitynTL0035 Professor Seena Fazel, Professor of Forensic Psychiatry & Wellcome Trust Senior Research Fellow in Clinical Science at University of OxfordnTL0030 Dr Lisa Forsberg, British Academy Postdoctoral Fellow at University of OxfordnTL0013 nTL0030 Professor Simona Francese, Professor of Forensic and Bioanalytical Mass Spectrometry at Sheffield Hallam UniversitynTL0024 Professor Pete Fussey, Professor of Sociology, University of EssexnTL0017 Professor Angela Gallop, Professor of Practice/ Director of Forensic Science at University of Strathclyde/Forensic AccessnTL0024 ** Professor Colin Gavaghan, Director n ew Zealand Law Foundation Centre for Law and Policy in Emerging Technologies at University of Otago (QQ 39–51 )nTL0047 86 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM Dr Jamie Grace, Senior Lecturer in Law at Sheffield Hallam UniversitynTL0001 Professor n igel Harvey, Professor of Judgment and Decision Research at UCL LondonnTL0025 Tobias Harvey, Student of Law at Kings College LondonnTL0025 Dr Binesh Hass, Research Fellow at University of OxfordnTL0030 The Home Office nTL0055 Independent Office for Police Conduct nTL0054 The Information Commissioner’s Office (ICO) nTL0016 Istanbul Bar Association nTL0028 * Professor Elizabeth E Joh, Martin Luther King Jr."
366,"Professor of Law at University of California, Davis (QQ 39–51 ) Perry Keller, Reader in Media and Information Law, Director of Doctoral Studies at King’s College LondonnTL0011 Professor Paul Kelly, Professor of Inorganic Chemistry at University of LoughboroughnTL0024 Professor Richard I.Kemp, Professor of Psychology at UnSW SydneynTL0012 Dr Kyriakos n Kotsoglou, Senior Lecturer in Law, northumbria University/Research Fellow, University of LausannenTL0006 nTL0007 The Law Society of England and Wales nTL0023 Dr Christopher Lawless, Associate Professor at Durham UniversitynTL0029 * Dr David Leslie, Ethics Theme Lead at Alan Turing Institute ( QQ 25–38 ) * David Lewis, Former Deputy Chief Constable and former ethics lead n PCC at Dorset Police ( QQ 68– 82) Liberty nTL0020 Sjors Ligthart LLM PhD candidate at Tilburg UniversitynTL0013 Dr n essa Lynch, Associate Professor of Law at Victoria University of WellingtonnTL0021 * The Rt Hon Kit Malthouse MP, Minister of State for Crime and Policing at the Home Office and Ministry of Justice ( QQ 99–111 ) Stephen Mason, Associate Research Fellow, Institute of Advanced Legal StudiesnTL0002 87 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM Dee Masters, Barristers at A1 Law Consultancy/ Cloisters ChambersnTL0019 Professor Derek McAuley, Director of Horizon Digital Economy Research Institute at University of nottinghamnTL0035 ** Professor Carole McCartney, Professor of Law and Criminal Justice at n orthumbria University (QQ 1–24 )nTL0022 medConfidential nTL0050 The Metropolitan Police Service nTL0031 Professor Gerben Meynen, Professor of Forensic Psychiatry and Bioethics at Utrecht University and VU University AmsterdamnTL0013 ** Alun Michael, Police and Crime Commissioner for South Wales and Joint Lead for Data and Bioethics, Association of Police and Crime Commissioners (QQ 83–98 )nTL0049 nTL0057 Migrants’ Rights n etwork nTL0042 The Ministry of Justice nTL0053 Abhishek Mishra, Doctoral Student at University of OxfordnTL0030 Dr Brent Mittelstadt of the Oxford Internet Institute (OII)nTL0058 Dr Reuben Moreton, Reli Ltd nTL0026 Professor Ruth Morgan, Professor of Crime and Forensic Sciences at University College LondonnTL0024 Dr Daragh Murray, Senior Lecturer in Human Rights at University of EssexnTL0017 nCC Group nTL0005 Dr Eilidh n oyes, University of Huddersfield nTL0026 * Dr Liam Owens, Founder and Chief Executive Officer, Semantics 21 ( QQ 68–82 ) Ms Angela Paul (PhD candidate in Law), northumbria UniversitynTL0022 Police Scotland nTL0043 Dr Susan Pope, D nA expert—chair of the Forensic Science Regulator D nA Specialist Group & is an assessor for the n etherlands Register of Court Experts at Principal Forensic ServicesnTL0024 ** Darryl Preston, Police and Crime Commissioner for Cambridgeshire and Peterborough and Joint Lead for Data and Bioethics, Association of Police and Crime Commissioners ( QQ 83–98 )nTL0049 nTL0057 88 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM Dr Christophe Prince, Director for Data and Identity, Home Office ( QQ 99–111 ) Privacy International nTL0051 Public Law Project nTL0046 nTL0059 Gary Pugh, Forensic Science Regulator nTL0036 Dr Jonathan Pugh, Parfit Radcliffe Senior Research Fellow at University of OxfordnTL0030 Dr Joe Purshouse, Senior Lecturer in Criminal Law and Justice at University of SheffieldnTL0021 ** Professor Charles Raab, Professorial Fellow, School of Social and Political Science, University of Edinburgh Fellow, The Alan Turing Institute (QQ 1–24 )nTL0014 Dr Liam Ralph (Lecturer in Criminology and Policing) at the Centre for Crime and Policing & the Science and Justice Research, n orthumbria UniversitynTL0022 Dr Kay L."
366,"Mehera San Roque, U nSW SydneynTL0012 SAS UK&I nTL0041 Professor Julian Savulescu, Professor of Practical Ethics at University of OxfordnTL0030 Serious Fraud Office nTL0034 Professor Ilina Singh, Professor of n euroscience and Society at University of OxfordnTL0030 David Spreadborough, CFVA, Forensic Analyst at Amped SoftwarenTL0015 Dr Amy Stevens, Senior Research Officer, Human Rights, Big Data and Technology Project at University of EssexnTL0017 Dr Clare Sutherland, Senior Lecturer at University of AberdeennTL0012 ** Professor Paul Taylor, Chief Scientific Adviser, national Police Chiefs’ Council ( QQ 83–98 )nTL0049 nTL0057 Dr Alice Towler, Research Fellow at U nSW Sydney nTL0012 ** David Tucker, Faculty Lead on Crime and Criminal Justice, College of Policing ( QQ 83–98 )nTL0057 89 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM Professor Gillian Tully, Professor of Practice for Forensic Science Policy and Regulation at King’s College LondonnTL0024 UCL Centre for the Forensic Sciences nTL0010 Dr Lachlan Urquhart, Lecturer in Technology Law, and Co-Investigator of the UKRI Trustworthy Autonomous Systems n ode in Governance and Regulation at School of Law University of EdinburghnTL0035 * Dr Rosamunde Elise van Brakel, Co-Director, Surveillance Studies n etwork, Associate Professor Tilburg University/Vrije Universiteit Brussel (VUB) (QQ 39–51 ) ** Professor Sandra Wachter, Associate Professor and Senior Research Fellow at Oxford Internet Institute (OII), University of Oxford ( QQ 68–82 )nTL0058 Dr Adrian Weller, Principal Research Fellow in Machine Learning at the University of CambridgenTL0040 Dr David White, Senior Lecturer at U nSW Sydney nTL0012 Dr Matthias Wienroth (Vice-Chancellor’s Senior Fellow in Criminology/Sociology), n orthumbria UniversitynTL0022 Professor Kim Wolff, Director King’s Forensics at King’s College LondonnTL0024 * Professor Michael Woodridge, Head of Department of Computer Science, Professor of Computer Science at University of Oxford ( QQ 25–38 ) * Professor Karen Yeung, Interdisciplinary Professorial Fellow in Law, Ethics and Informatics, Birmingham Law School at The University of Birmingham (QQ 52–67 ) Dr Miri Zilka, Research Associate in Machine Learning at the University of CambridgenTL0040 90 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM APPENDI x 3: CALL FOR EVIDENCE Scope of the inquiry The Committee seeks to explore the use of new technologies in the application of the law and the experience of people currently or previously engaged with them. new technologies include but are not limited to: machine-learning approaches; advanced algorithmic tools; artificial intelligence; and semi-autonomous or autonomous devices or systems."
366,Are safeguards needed to ensure that 91 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM technologies cannot be used to serve purposes incompatible with a democratic society?
366,"92 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM APPENDI x 4: ABBREVIATIONS, ACRONYMS AND TECHNICAL TERMS ADM Automated Decision Making AFR Automated Facial Recognition AI Artificial Intelligence Algorithm A series of instructions for performing a calculation or solving a problem, especially with a computer."
366,93 THE ADVE nT OF n EW TECH nOLOGIES I n THE JUSTICE SYSTEM ML Machine Learning nDAS national Data Analytics Solution (a national analytics capability being developed by West Midlands Police in conjunction with the Home Office). nPCC national Police Chiefs’ Council PCC Police and Crime Commissioner PDS Police Digital Service WMP West Midlands Police
367,"For instance, even if a machine's impact is only ever good, the distribution of that good (concerns for justice) might be in question”."
37,"In the liberal tradition – a key influence on both pub lic debate and the administration of justice in Ger many and the European Union – privacy is generally regarded as a condition for enabling autonomy and as its expression, in the sense of being able to think and act independently."
37,"Collective goods, rather like the terms “common good” and “justice”, cannot be defined in terms of their sub stance."
370,"The third principle, justice, considers who gets chosen to be a research subject and what population segments stand to benefit — or be harmed — by the research results."
370,"JoaAnne Stonier, Chief Data Officer at MasterCard, acknowledged another challenge to data management, which is the urge to “do good” with data when a company is approached by an academic researcher or non-profit with a social justice mission."
38,"In this report, we will focus on systems that affect justice, equality , participation and public welfare, either directly or indirectly."
38,"In case automation as a term was not used, we still scanned for key concepts like discrimination, justice, equity/equality to take a closer look, since automation processes tend to be hiding behind these keywords."
38,"Maze donia EURO pEAN UNION By Kristina Penner The EU is a lot of things: It is a union of 28 Member States that has a commission, a parliament, a council of national ministers, the Court of Justice, and a couple of other institutions."
38,"[…] Whilst AI clearly generates new opportunities, it also poses challenges and risks, for example in the areas of safety and liability, security (criminal use or attacks), bias and discrimination. ” external [eU 2] The Commission announced that it will support (basic and industrial) research and innova-tion in fields built on the guiding principle of “responsible AI” , including investment and encouragement of research and testing in sectors such as health, security, public adminis-tration and justice, with the goal to enable policy makers to gain experience and to devise suitable legal frameworks."
38,"In addition, there was a mention that fundamental rights “would be at risk if unethical practice is facilitated by virtue of algorithms focused on com-mercial gain, for example because humans ‘allow’ or ‘rely’ on robot sorting techniques that are discriminatory and may be unfair and undermine dignity and justice” ."
38,"According to those guidelines, a “legal or similarly significant impact” is manifest in the cancellation of a contract, denial of social benefits, access to education, eligibility for credit, or if it leads to the exclusion or the discrimination of individuals and affects the choices available to the subject. external [eU 43] / Police d irective The EU data protection reform package of 2016, which included the GD pR, also involved a directiv e on data protection in the area of police and justice external [eU 44] as a lex specialis, adopted on May 5, 2016, applicable as of May 6, 2018."
38,"These developments represent the gradual moving away from a “country-centric” approach towards a “person-centric” approach . external [eU 78] Though strongly criticised by civil society and data protection bodies (see below in this paragraph), and accompanied by the request for technological reviews external [eU 79] , the implementation of an overarching interoperable smart border management system is on its way. eu-LISA, the “European Agency for the Operational Management of large-scale IT Systems in the Area of Freedom, Security and Justice” , is now managing the “strengthened” databases and applications VIS, SISII and EURODAC together. external [eU 80] This is leading to T aking Stock of Automated Decision-Making in the EU page 35 the creation of a “biometric core data system” external [eU 81] , with three more systems under construction or currently being discussed: W A new centr alised version of the European Criminal Records Information System which will also include third-country nationals (ECRIS-TCN)."
38,"Reflecting on the interoperability of EU information systems to freedom, security and justice the European Data p rotection Supervisor stresses “that interoperability is not primarily a technical choice, it is first and foremost a political choice to be made, with significant legal and societal implications in the years to come” ."
38,"This is a cooperation between the Ministry of Home Affairs, the Digital Agenda and the Ministry of Justice."
38,"The committee consists of 16 experts from politics, academia and industry and is led by the Federal Ministry for Justice and Consumer Protection and the Federal Ministry of the Interior, Building and Community."
38,"Lastly, the Digital Government Agenda mentions that the Wetenschappelijk onderzoeks- en documentatiecentrum (Research and Documentation Centre of the Ministry of Justice and Security or WODC) will carry out research on the regulation and legality of algorithms taking autonomous decisions."
38,"On March 29, 2018, the Ministry of Justice and Security organised a round table discussion on the use of Artificial Intelli-gence in the legal field. external [nl 9] Among the participants were scientists as well as delegates from civil society organisations and industry."
38,"In January 2018, the Polish Ministry of Justice introduced a system to randomly allocate court cases to judges."
38,"Adm in Ac T ion / m inistry of Justice – s ystem of random Allocation of c ases on 1 January 2018, the Polish Ministry of Justice introduced the “System of Random Allocation of Cases” ( System Losowego Przydziału Spraw), a digital system that, on a onceper-day basis, assigns cases to judges across the country."
38,"The Minister of Justice has de-clared that ""the selection will be made solely by a machine, a computer system that is blind like Themis, and chooses without emotions, without views or biases, and in a manner fully free from possible accusations of corruption“ . external [Pl 13] In mid-2018, the Ministry admitted that the system has faults and, i n the case of some judges, assigns cases unequally."
38,"SAVRY is in general fair, while the machine learning models tend to discriminate against male defendants, foreigners, or people of specific national groups, sa ys Castillo: “Machine learning could be incorporated into SAVRY, but if aspects of algorithmic justice are not taken into account, it could generate an unfair prediction. ” The evaluation external [SP 19] showed that humans were much better than ADM, but that ADM can be more precise with the results. / ris c anvi – an actuarial risk assessment tool RisCanvi is a statistical risk assessment system used in Catalan prisons, similar to LSI-R (Canada), Compass (US) and OaSys (UK)."
38,"The Department of Justice of the Catalan government launched the tool in 2010 and applied it to all inmates in all prisons, and not just for cases involving violent crime."
38,"Anne serves as a chair of the Com-munication and Democracy section of ECREA and is vice-chair of the Activism, Communication and Social Justice Interest Group within ICA."
38,The Data Justice Lab at the University of Cardiff examines the relationship between what it calls ‘data-fication’ and social justice.
38,"In its public consultation document on the role and objectives for the centre, ADM is one of three areas identified by the government as an example of an ethical issue raised by the use of data and AI. external [uK 6] While recognising the potential benefits to society of ADM, it mentions discrimination against job applicants and inequities within the criminal justice system as examples of issues that may arise as a result of ADM."
38,"It organises an international conference on AI. external [uK 15] / Data Justice Lab The Data Justice Lab is a research lab at Cardiff University’s School of Journalism, Media and Culture."
38,It seeks to examine the relationship between what it calls ‘datafication’—the collection and processing of massive amounts of data for decision-making and governance LINKS: You can find a list of all URLs in the report compiled online at: www.algorithmwatch.org/ automating-societyexternal T aking Stock of Automated Decision-Making in the EU page 137 across more and more areas of social life—and social justice.
393,"At a global level, the UNESCO Global Recommendations on the Ethics of AI in November 2021 forefronts the principles of human dignity, inclusive growth and social justice."
394,“Algorithms and Economic Justice: A Taxonomy of Harms and a Path Forward for the Federal Trade Commission. ” Yale Journal of Law & Technology 23 (2020): S1-S1.
396,"An example is given by the US criminal justice system, which is increasingly resorting to the use of artificial agents to ease the burden of managing such a large system."
396,"4 ProPublica (23/05/2016) Machine Bias 5 The Telegraph (24/03/2016) Microsoft deletes 'teen girl' AI after it became a Hitler -loving sex robot within 24 hours 6 The Guardian (03/08/2014) The death of privacy 7 http://ec.europa.eu/justice/data -protection/ 24 Greencoat Place, London SW1P 1BE • t +44 (0) 20 7798 6040 • e info@ibe.org.uk • www.ibe.org.uk • Charity No."
396,"1084014 Page 4 Business Ethics and Artificial Intelligence Issue 58 | January 2018 Fairness Fairness and justice, which are core issues in the stakeholder theory, remain paramount for ethical businesses when dealing with AI."
397,"Veber 18 Big Data in Criminal Justice – Few Chances and Serious Risks 18 Uwe Ewald 18 Big Data, Data Protection and Citizen Empowerment: The Revival of Individual Participation Principle as a Response to New Technological Challenges 19 Wenlong Li 19 Big Data, Psychodiagnostics and Threats to Personal Autonomy 19 Friderik Klampfer, Bojan Musil, Nenad Čuš Babič and Domen Bajde 19 Big health data on social networking platforms: The legal and ethical questions 20 Maria Tzanou 20 Cross-border exchange of big data - innovative technology meets outdated legal framework 21 Stanislaw Tosza 21 Databases and Due Process with regard to European Court of Human Rights’ Case-Law 21 Begüm Bulak Uygun 21 Dispensable humans and indispensable machines in the context of class and social control 22 Zoran Kanduč 22 Economic Cyber Espionage and Regulation of Big Data Theft at the International Level 23 Maša Kovič Dine 23 Finding the right balance between security and privacy: NATO and the big data analyses 23 Mitko Bogdanoski, Metodi Hadji-Janev 23 Five Reasons Not to Personify AI 23 Joanna J."
397,"Current issues and future perspectives 31 Federico Costantini 31 State’s Due Diligence in Cyberspace in the Era of Big Data 31 Vasilka Sancin 31 The alluring promise of objectivity: Big data in criminal justice 32 Mojca Plesničar 32 We don’t know what the Questions are, but we know we're gonna find the Answers 32 Alexander Czadilek, Christof Tschohl and Walter Hötzendorfer 32 About the Venue 34 Map of the Building of the Faculty of Law 35 VENUE: Faculty of Law in Ljubljana 36 HOST CITY: Ljubljana 38 OTHER IMPORTANT INFORMATION 39 Notes 40 4 About the Conference “Big Data” is a phrase that has been used pervasively by the media and the lay public in the last several years."
397,"Criminal justice systems are using technological solution too, for instance, to predict future crimes of those applying for bail or those to be sent on a parole."
397,"The leading questions the conference speaker will tackle are: • how the operations of society, political systems, and, in particular, social control and crime control, is changing due to large data bases and algorithmic data mining and predicting powers? • Will computers decide who to prosecute and who should be sent to jail? • Which programmes and systems of algorithmic predictions are already in place in the criminal justice systems around the globe? • Why this can be dangerous in terms of fundamental human rights and fundamental principles of democratic societies? • Is the new GDPR a suitable framework for »algocracy«, i.e. rule by the algorithm? • How can we propose solutions that may not hinder the development of the technology, but enable more nuanced, ethically and legally sound solutions to be developed in the future?"
397,"Themes of interest include (tentative list): • big data and crime control • predictive policing • automated justice • big data and discrimination • big data and social sorting • ethical dilemmas and predictive analytics • big data and international law • big data and personal data protection law • big data and cyber espionage • big data and citizen empowerment 5 Keynote speakers • Dean Wilson, University of Sussex, Brighton, UK • Nadya Purtova, TILT, Tilburg University, The Netherlands • Joanna J."
397,"Dean’s key research interests are in surveillance and policing, and he has published widely in the areas of histories of urban policing, contemporary policing, surveillance and most recently pre-emption and criminal justice."
397,Together with a preliminary request from Ireland this lead to the abolition of the Data Retention Directive by the European Court of Justice (CJEU) in April 2014.
397,"Maša Galič: Living labs and big data in practice: Stratumseind 2.0 - A discussion of a living lab in the Netherlands 15:30 – 16:00 Coffee break 11 HUMAN RIGHTS, CRIMINAL JUSTICE BIG DATA POLICING AND BIG DATA Session 4 Seminar room 5 Chair: Miha Hafner 1."
397,Plesničar: The alluring promise of objectivity: Big data in criminal justice 3.
397,Uwe Ewald: Big Data in Criminal Justice – Few Chances and Serious Risks Hour 17:30 – WELCOME RECEPTION – FACULTY OF LAW Main Hall 12 TUESDAY 23rd MAY Hour Lecture hall 8:30 – 9:00 REGISTRATION Red Hour Keynote session 3 Chair: Mojca M.
397,"Algorithmic prediction in crime control Aleš Završnik Institute of Criminology at the Faculty of Law The paper will present several existent uses of big data in the criminal justice system, for example, for the prevention of payment card fraud by means of skimming; for the prediction of crime with predictive software; the use of algorithms to predict the recidivism of parolees."
397,It will present the pitfalls of reliance on big data 17 predictions used by law enforcement and criminal justice agencies and the risks big data carries as regards encroachment on fundamental liberties.
397,These are main reasons why Slovenian ministry of justice wants to publish all court decisions on the Internet.
397,Big Data in Criminal Justice – Few Chances and Serious Risks Uwe Ewald Ruhr-Universität Bochum in Germany Starting from the Foucauldian concept of the “regime of truth” in criminal justice this paper will present findings of a case study analyzing a complex organized crime case in Germany were huge amounts of digital data have been introduced into evidence.
397,As findings show Big Data Evidence (BDE) are about to alter the traditional way professionals in law enforcement and criminal justice act in the evidentiary process.
397,"Finally, some suggestions should be offered on how to conceptualize truth-finding and BDE and how to limit the risks for a fundamental human rights and rule of law centered approach in criminal justice."
397,"Big Data, Psychodiagnostics and Threats to Personal Autonomy Friderik Klampfer, Bojan Musil, Nenad Čuš Babič and Domen Bajde University of Maribor Experts and institutions have warned of the threat that big data analysis poses to our right to privacy, the challenge it raises to our traditional notions of criminal responsibility and justice, as well as concerns about the rising levels of invisible and unaccountable social control (EDPS 2015)."
397,Databases are in widespread use in the criminal justice field across the world.
397,"In particular, the privacy challenges associated with surveillance, primarily within the realm of the criminal justice databases will be highlighted."
397,"Examining the necessity and proportionality of the laws in accordance with the United Nations’ (UN) Universal Declaration of Human Rights (UDHR) (UN 1948), this paper sets out to establish how the average social media savvy citizen is likely to be affected by this restrictive and conservative turn in the Australian criminal justice and anti-terrorism landscape."
397,"Judicial oversight of (mass) collecting and processing of personal data Primož Gorkič Faculty of Law, University of Ljubljana The paper explores different approaches to securing judicial oversight of collecting and processing of personal data in a criminal justice system."
397,The alluring promise of objectivity: Big data in criminal justice Mojca Plesničar Institute of Criminology at the Faculty of Law Criminal justice systems have long aimed at preventing judges’ subjectivity from having any impact on in the courtroom.
397,"Big data has so far entered criminal justice at three levels: bail, sentencing, and parole."
397,"Seen as more objective, such algorithms could instil the long-lost trust of the public in the fairness of the criminal justice system."
397,"However, there are some important considerations to be made before embarking on the big-data-saviour-of-justice wagon which we will discuss in detail."
397,"We will then delve into the new legislative acts of EU Data Protection Law, the General Data Protection Regulation (Regulation (EU) 2016/679, GDPR) and the Police and Criminal Justice Authorities Directive (Directive (EU) 2016/680) to analyse their implications on the use of Big Data."
397,"33 Another important issue is profiling and automated decision making for law enforcement, criminal justice and other purposes based on Big Data."
40,(2021)2727 Open letter by 61 organisations calling for legal limits on AI risk assessment systems in the criminal justice context2819 affects the right to the right to a fair trial.
40,THE ADMINISTRATION OF JUSTICE AND DEMOCRATIC PROCESSES 31The use of AI in the administration of justice and democratic processes is particularly sensitive and should be approached with more nuance and scrutiny than it is done now.
40,Administration of justice and democratic processes: (a) AI systems intended to be used for or assist a judicial authority in researching and interpreting facts and the law and in applying the las to a concrete set of facts.
40,"We do see areas for improvement though, in particular where it comes to inclusivity and multi-disciplinarity, complaints and redress, and the exclusion (for now) of the applicability of the AIA to ‘legacy high-risk AI’ and components of large scale European IT systems in the realm of “freedom, security and justice” already put into service before the application of the AIA."
403,"Similarly, traditional values such as dignity, freedom, democracy, equality, autonomy, and justice are part of discussions around digital ethics.10 Privacy and data protection today represent intrinsic and foundational concepts for our modern society, which enable individual freedom of choice and user control."
411,"Quick links Work programme Drafts and new work items Working area Working documents (user account required) ISO Electronic applications IT Tools that help support the standards development process Public material Browse documents made available by this group This committee contributes with 54 standards to the following Sustainable Development Goals: 1 No Poverty 3 Good Health and Well-being 4 Quality Education 5 Gender Equality 6 Clean Water and Sanitation 7 Affordable and Clean Energy 8 Decent Work and Economic Growth 9 Industry, Innovation and Infrastructure 10 Reduced Inequalities 11 Sustainable Cities and Communities 12 Responsible Consumption and Production 13 Climate Action 14 Life Below Water 15 Life on Land 16 Peace, Justice and Strong Institutions 39 Published ISO standards * 45 ISO standards under development * 49 Participating members 26 Observing members * number includes updates Structure Liaisons Meetings Reference Title Type ISO/IEC JTC 1/SC 42/AHG 4 Liaison with SC 27 Working group ISO/IEC JTC 1/SC 42/AHG 8 Best practices for new proposals Working group ISO/IEC JTC 1/SC 42/JAG Joint Advisory Group on AI and sustainability with ISO/IEC JTC1/SC 39 and JTC1/SC 42 Working group ISO/IEC JTC 1/SC 42/JWG 2 Joint Working Group ISO/IEC JTC1/SC 42 - ISO/IEC JTC1/SC 7 Working group ISO/IEC JTC 1/SC 42/JWG 3 Joint Working Group ISO/IEC JTC1/SC42 - ISO/TC 215 WG : AI enabled health informatics Working group ISO/IEC JTC 1/SC 42/JWG 4 Joint Working Group ISO/IEC JTC1/SC42 - IEC TC65/SC65A: Functional safety and AI systems Working group ISO/IEC JTC 1/SC 42/JWG 5 Joint Working Group ISO/IEC JTC1/SC42 - ISO/TC 37 WG: Natural language processing Working group ISO/IEC JTC 1/SC 42/JWG 6 Joint Working Group ISO/IEC JTC1/SC42 - ISO/CASCO: Conformity assessment schemes for AI systems Working group ISO/IEC JTC 1/SC 42/JWG 7 Joint Working Group ISO/IEC JTC1/SC 42 - ISO/TC 68: Artificial intelligence Working group ISO/IEC JTC 1/SC 42/WG 1 Foundational standards Working group ISO/IEC JTC 1/SC 42/WG 2 Data Working group ISO/IEC JTC 1/SC 42/WG 3 Trustworthiness Working group ISO/IEC JTC 1/SC 42/WG 4 Use cases and applications Working group ISO/IEC JTC 1/SC 42/WG 5 Computational approaches and computational characteristics of AI systems Working group Liaison Committees to ISO/IEC JTC 1/SC 42 The committees below can access the documents of ISO/IEC JTC 1/SC 42: Reference Title ISO/IEC IEC/SC 45A Instrumentation, control and electrical power systems of nuclear facilities IEC IEC/SC 62C Equipment for radiotherapy, nuclear medicine and radiation dosimetry IEC IEC/SC 65A System aspects IEC IEC/SyC AAL Active Assisted Living IEC IEC/SyC SM Smart Manufacturing IEC IEC/SyC Smart Cities Electrotechnical aspects of Smart Cities IEC IEC/TC 9 Electrical equipment and systems for railways IEC IEC/TC 56 Dependability IEC IEC/TC 62 Medical equipment, software, and systems IEC IEC/TC 65 Industrial-process measurement, control and automation IEC IEC/TC 100 Audio, video and multimedia systems and equipment IEC ISO/CASCO Committee on conformity assessment ISO ISO/IEC JTC 1 Information technology ISO/IEC ISO/IEC JTC 1/SC 6 Telecommunications and information exchange between systems ISO/IEC ISO/IEC JTC 1/SC 7 Software and systems engineering ISO/IEC ISO/IEC JTC 1/SC 24 Computer graphics, image processing and environmental data representation ISO/IEC ISO/IEC JTC 1/SC 27 Information security, cybersecurity and privacy protection ISO/IEC ISO/IEC JTC 1/SC 29 Coding of audio, picture, multimedia and hypermedia information ISO/IEC ISO/IEC JTC 1/SC 31 Automatic identification and data capture techniques ISO/IEC ISO/IEC JTC 1/SC 32 Data management and interchange ISO/IEC ISO/IEC JTC 1/SC 34 Document description and processing languages ISO/IEC ISO/IEC JTC 1/SC 35 User interfaces ISO/IEC ISO/IEC JTC 1/SC 36 Information technology for learning, education and training ISO/IEC ISO/IEC JTC 1/SC 37 Biometrics ISO/IEC ISO/IEC JTC 1/SC 38 Cloud computing and distributed platforms ISO/IEC ISO/IEC JTC 1/SC 39 Sustainability, IT and data centres ISO/IEC ISO/IEC JTC 1/SC 40 IT service management and IT governance ISO/IEC ISO/IEC JTC 1/SC 41 Internet of things and digital twin ISO/IEC ISO/IEC JTC 1/SC 43 Brain-computer interfaces ISO/IEC ISO/TC 20 Aircraft and space vehicles ISO ISO/TC 20/SC 16 Uncrewed aircraft system ISO ISO/TC 22/SC 32 Electrical and electronic components and general system aspects ISO ISO/TC 24/SC 4 Particle characterization ISO ISO/TC 36 Cinematography ISO ISO/TC 37 Language and terminology ISO ISO/TC 37/SC 3 Management of terminology resources ISO ISO/TC 37/SC 5 Translation, interpreting and related technology ISO ISO/TC 42 Photography ISO ISO/TC 46/SC 11 Archives/records management ISO ISO/TC 68 Financial services ISO ISO/TC 69 Applications of statistical methods ISO ISO/TC 108/SC 5 Condition monitoring and diagnostics of machine systems ISO ISO/TC 172/SC 5 Microscopes and endoscopes ISO ISO/TC 199 Safety of machinery ISO ISO/TC 204 Intelligent transport systems ISO ISO/TC 210 Quality management and corresponding general aspects for products with a health purpose including medical devices ISO ISO/TC 211 Geographic information/Geomatics ISO ISO/TC 215 Health informatics ISO ISO/TC 225 Market, opinion and social research ISO ISO/TC 232 Education and learning services ISO ISO/TC 258 Project, programme and portfolio management ISO ISO/TC 260 Human resource management ISO ISO/TC 261 Additive manufacturing ISO ISO/TC 262 Risk management ISO ISO/TC 267 Facility management ISO ISO/TC 268 Sustainable cities and communities ISO ISO/TC 269 Railway applications ISO ISO/TC 279 Innovation management ISO ISO/TC 299 Robotics ISO ISO/TC 307 Blockchain and distributed ledger technologies ISO ISO/TC 309 Governance of organizations ISO ISO/TC 312 Excellence in service ISO ISO/TC 321 Transaction assurance in E-commerce ISO ISO/TC 322 Sustainable finance ISO ISO/TC 324 Sharing economy ISO ISO/TC 347 Data-driven agrifood systems ISO Liaison Committees from ISO/IEC JTC 1/SC 42 ISO/IEC JTC 1/SC 42 can access the documents of the committees below: Reference Title ISO/IEC IEC/ISO JTC 3 Quantum technologies ISO/IEC IEC/SyC AAL Active Assisted Living IEC IEC/SyC SM Smart Manufacturing IEC IEC/SyC Smart Cities Electrotechnical aspects of Smart Cities IEC IEC/TC 44 Safety of machinery - Electrotechnical aspects IEC IEC/TC 62 Medical equipment, software, and systems IEC IEC/TC 65 Industrial-process measurement, control and automation IEC IEC/TC 100 Audio, video and multimedia systems and equipment IEC ISO/CASCO Committee on conformity assessment ISO ISO/IEC JTC 1 Information technology ISO/IEC ISO/IEC JTC 1/SC 7 Software and systems engineering ISO/IEC ISO/IEC JTC 1/SC 24 Computer graphics, image processing and environmental data representation ISO/IEC ISO/IEC JTC 1/SC 27 Information security, cybersecurity and privacy protection ISO/IEC ISO/IEC JTC 1/SC 29 Coding of audio, picture, multimedia and hypermedia information ISO/IEC ISO/IEC JTC 1/SC 32 Data management and interchange ISO/IEC ISO/IEC JTC 1/SC 34 Document description and processing languages ISO/IEC ISO/IEC JTC 1/SC 35 User interfaces ISO/IEC ISO/IEC JTC 1/SC 36 Information technology for learning, education and training ISO/IEC ISO/IEC JTC 1/SC 37 Biometrics ISO/IEC ISO/IEC JTC 1/SC 38 Cloud computing and distributed platforms ISO/IEC ISO/IEC JTC 1/SC 39 Sustainability, IT and data centres ISO/IEC ISO/IEC JTC 1/SC 40 IT service management and IT governance ISO/IEC ISO/IEC JTC 1/SC 41 Internet of things and digital twin ISO/IEC ISO/IEC JTC 1/SC 43 Brain-computer interfaces ISO/IEC ISO/IEC JTC 1/SC 44 Consumer protection in the field of privacy by design ISO/IEC ISO/TC 20/SC 16 Uncrewed aircraft system ISO ISO/TC 22/SC 32 Electrical and electronic components and general system aspects ISO ISO/TC 24/SC 4 Particle characterization ISO ISO/TC 36 Cinematography ISO ISO/TC 37/SC 3 Management of terminology resources ISO ISO/TC 46 Information and documentation ISO ISO/TC 46/SC 11 Archives/records management ISO ISO/TC 68 Financial services ISO ISO/TC 69 Applications of statistical methods ISO ISO/TC 106 Dentistry ISO ISO/TC 145 Graphical symbols ISO ISO/TC 159 Ergonomics ISO ISO/TC 172/SC 5 Microscopes and endoscopes ISO ISO/TC 199 Safety of machinery ISO ISO/TC 204 Intelligent transport systems ISO ISO/TC 210 Quality management and corresponding general aspects for products with a health purpose including medical devices ISO ISO/TC 215 Health informatics ISO ISO/TC 225 Market, opinion and social research ISO ISO/TC 260 Human resource management ISO ISO/TC 262 Risk management ISO ISO/TC 268 Sustainable cities and communities ISO ISO/TC 299 Robotics ISO ISO/TC 307 Blockchain and distributed ledger technologies ISO ISO/TC 309 Governance of organizations ISO ISO/TC 312 Excellence in service ISO ISO/TC 321 Transaction assurance in E-commerce ISO ISO/TC 324 Sharing economy ISO Organizations in liaison (Category A and B) Acronym Title Category BCI Blockchain & Climate Institute A BDVA Big Data Value AISBL A CI Consumers International A Cloud security alliance Cloud security alliance A EC - European Commission European Commission A ETSI European Telecommunications Standards Institute A ETUC European Trade Union Confederation A euRobotics AISBL euRobotics AISBL A EUROCAE The European Organization for Civil Aviation Equipment A HL7 Health Level Seven International A IEEE Institute of Electrical and Electronics Engineers, Inc A IIOA Independent International Organisation for Assurance A ITU International Telecommunication Union A MedTech Europe Alliance of European medical technology industry associations A ML Commons MLCommons Association A OECD Organisation for Economic Co-operation and Development, OECD A OGC Open Geospatial Consortium, Inc."
412,"Possible source of investments41 41 It could include Public Sectors and society challenges (e.g. for technologies in support to Justice as defined in NRRP), initiatives for Transitions 4.0, co-funded by MUR and by private companies with NRRP incentives, for Space data analysis, for Environment and ecological transitions (e.g. working on satellite and aerospace images), for health (e.g. working con COVID data) and for cultural economy and renewing tourist offers with AI technologies and eventually for new initiatives for climate change.40 Some projects could be highly risky and foundational, e.g. sustainable energy saving machine learning or applicative: e.g. predicting congestion and traffic jams in some interchange mobility nodes near airports and finding automated solutions for minimizing pollution."
423,"Importance of careful management of AI challenges 'How important is it for companies and gove rnments to car efully manage this challenge?'% Low importance %Moderate importance % High importance Cyber Attack 3 9 88 Autonomous Vehicles 4 10 86 Misaligned with Human Values 4 10 86 Data Privacy 3 12 85 Disease Misdiagnosis 3 12 85 Fake Online Content 3 13 84 Critical AI Failur es 4 12 84 Surveillance 4 12 84 Criminal Justice Bias 4 12 84 Autonomous W eapons 5 12 83 HR Bias 5 12 83 Technological Unemployment 4 13 83 Low importance = 'Not at all important' or 'Slightly important' Moderate importance = 'Moderately important' High importance = 'Very important' or 'Extr emely important' ©2021 The University of Queensland ©2021 KPMG, an Australian partnership and a member firm of the KPMG global organisation of independent member firms affiliated with KPMG International Limited, a private English company limited by guarantee."
423,"Likelihood of AI challenges impacting large numbers of citizens 'In the next 10 years, how likely do you think it is that this challenge will impact la rge numbers of the people in your country?'% Unlikely % Equally likely as unlikely % Likely Surveillance 17 22 61 Fake Online Content 17 23 60 Cyber Attack 19 21 60 Data Privacy 19 22 59 Disease Misdiagnosis 25 25 50 HR Bias 26 25 49 Technological Unemployment30 25 45 Critical AI Failur es 29 26 45 Misaligned with Human Values30 25 45 Autonomous Vehicles 31 24 45 Criminal Justice Bias 29 28 43 Autonomous W eapons 42 22 36 Unlikely = 'Very unlikely (<5% chance'), 'Unlikely (5-20% chance)' or 'Somewhat unlikely (20-40% chance)' Equally likely as unlikely = 40-60% chance Likely = 'Somewhat likely (60-80% chance)', 'Likely (80-95% chance)' or 'Very likely (>95% chance)' ©2021 The University of Queensland ©2021 KPMG, an Australian partnership and a member firm of the KPMG global organisation of independent member firms affiliated with KPMG International Limited, a private English company limited by guarantee."
423,"22 Exceptions were autonomous vehicles and criminal justice bias, where Australia was higher than only select countries, not all. ©2021 The University of Queensland ©2021 KPMG, an Australian partnership and a member firm of the KPMG global organisation of independent member firms affiliated with KPMG International Limited, a private English company limited by guarantee."
432,"(2) Leverage graduate students and postdoctoral researchers from diverse student populations for curriculum creation, (3) Engage the undergraduate community in TA opportunities (i.e. , UC Berkeley model) (4) Leverage existing resources currently serving a cross -functional role, e.g., MIT Libraries ’ successful efforts to incorporate diversity, inclusion, and social justice into the Libraries' educational and research mission."
433,"(2) Leverage graduate students and postdoctoral researchers from diverse student populations for curriculum creation, (3) Engage the undergraduate community in TA opportunities (i.e. , UC Berkeley model) (4) Leverage existing resources currently serving a cross -functional role, e.g., MIT Libraries ’ successful efforts to incorporate diversity, inclusion, and social justice into the Libraries' educational and research mission."
461,Equality and justice 6.
461,Equality and justice Artificial intelligence should not reproduce prejudices that marginalise specific population groups.
466,"The resources in the programme will be used in areas where they are expected to be most effective, such as health, justice, consumer protection and publi c administration."
466,"Norway, represented by the Ministry of Justice and Public Security, participates in this work."
466,The Ministry of Justice and Public Security and the Ministry of Defence have overarching responsibility for following up the National Cyber Security Strategy for Norway.
466,"46 Ministries (2019): National Cyber Security Strategy 47 Ministry of Justice and Public Security (2019): National Strategy for Cyber Security Competence 65 Artificial intelligence in law enforcement The Norwegian Police University College and NTNU in Gjøvik are cooperating on a project that examines the use of different forms of artificial intelligence for analysing big data, aimed at detecting, preventing a nd investigating economic crime."
468,"In fact, without being able to explain decisions taken by autonomous systems, it is difficult to justify them: it would seem inconceivable to accept what cannot be The accountability of systems based on machine learning constitutes a real scientifi c challenge 116 justified in areas as crucial to the life of an individual as acce ss to credit, employment, accommodation, justice and health."
468,"Several of the measures that were adopted in recent years have widened and improved group access to litigation; in particular, the French Act for the Modernization of Justice in the Twenty -First Century introduced the ‘personal data’ class action which allows associations of consumer protection to act when infringements to existing legislation occur."
47,Concerns about this are already playing a role in the debates about using AI in areas as diverse as criminal justice and facial recognition technology.
470,"Wecontribut etothisconversationaspeopleconcerned,firstandforemos t,withthelearninganddevelopmen tofananti-racist,intersectionalracecritic alframe workforall.Benjamin(2019)iden tifiestheneedforourcontributionaseduc atorsinthetechnologyspacewhenshesays, “Justice …isnotastaticvaluebutanongoingmethodologythatcanandshouldbeincorpor atedintotechdesign.Forthisreason,too,itisvitalthatpeopleengagedintechdevelopmen tpartnerwiththosewhodoimport antsociocultur alworkhoningnarrativetoolsthroughthearts,humanities,andsocialjusticeorganizing ”(pp.192-193).Ourpersonalpoliticsasauthor sareimport antasourbelie fscomposetheman ysidesofourpersonalabilitiestofunctionlikequbits."
470,(2020).# Hash tagActivism: Ne twork s of rac e and gender justice.
470,“P ods and P od Mapping W orkshee t.” Weblog.BAY ARE A TRANSF ORMA TIVE JUSTICE C OLLE CTIVE Building T ransf ormative Jus ticeResponses t o Child Se xual Abuse (blog).
470,"Katlyn T urner Dr.KatlynTurnerisaResearchScientistwithintheSpaceEnabledresearchgroup.Inthatrole,herprimaryresearchincludesworkoninclusiveinnovationpractices,andonprinciplesofanti-racisttechnologydesign.Sheadditionallymentorsstudents,worksonproposalwritingefforts,andhelpstocommunicatetheteam'swork.Dr.TurnerearnedherPhDinGeologicalSciencesfromStanfordUniversity,wheresheresearchednovelnuclearwasteforms.From2017-2019,KatlynwasapostdoctoralfellowattheProjectonManagingtheAtom&theInternationalSecurityProgramatHarvardKennedySchool'sBelferCenterforScience&InternationalAffairs,wheresheresearchedenvironmentalandsocio-politicalimpactsofnuclearenergy.Dr.TurneradditionallyholdsanM.S.inEarth&EnvironmentalSciencesfromtheUniversityofMichigan,andaB.S.inChemical&BiomolecularEngineeringfromtheUniversityofNotreDame.Dr.Turnerispassionateaboutissuesofdiversity,justice,inclusion,andaccessibilitywithinsociety--particularlyinhigher education and within STEM employment sectors."
471,"I teach gener al concep ts and trends in Digit al Ethics, which covers a wide range of ways technology impacts individuals (such as privacy, accessibility , financial health and opportunity , men tal well-being , personal dignity , and legal status), socie ty (such as health care, educ ation, the econom y, criminal justice, and law enforcemen t), and the environmen t (such as ener gy use, material use, waste, pollution, and impact on biodiv ersity)."
471,"The team used manual coding to iden tify unifying themes and came up with 11 of them: transpar ency (appear ed in 87% of the documen ts), justice and Fairness (81%), non-male ficence (71%), responsibility (71%), Privacy (56%), bene ficence (49%), freedom and autonom y (40%), Trust (33%), sus tainability (17%), dignity (15%), and solidarity (7%)."
471,"In sear ching for unifying themes in AI ethics principles, the author s draw from the four ethical principles commonly used in bioe thics: bene ficence, non-male ficence, autonom y, and justice."
471,"Hagendorf f iden tified eigh t themes: privacy protection (appear ed in 82% of documen ts), fairness, non-discrimina tion, justice (82%), accountability (77%), transpar ency/ openness (73%), safety, cyber -security (73%), common good, sustainability , well-being (73%), human oversight, control, auditing (54%), and solidarity , inclusion, social c ohesion (50%)."
471,"Other moral values like autonom y, justice, and respect for people were also noticeably absent."
471,"Such values are likely to include democr acy, justice, privacy, the protection of human rights, and a commitmen t to environmen tal protection. ” Thus, while they want to avoid adop ting ethical absolutism, the author s also v oice the need t o avoid the tr ap of e thical relativism."
471,"These are by frequency of the number of sour ces in which they appear ed: transpar ency , justice, and fairness, non-male ficence, responsibility , privacy, bene ficence, freedom and autonom y, trust, dignity , sustainability , and solidarity . ● The resear cher s found that no single ethical principle was found common to the entire corpus of documen t, however, an emer ging convergence was found around the following principles: transpar ency , justice and fairness, non-male ficence, responsibility , and priv acy."
471,"It seems that MEDC is shaping this deba te, which raises concerns about “neglecting local knowledg e, cultur al pluralism and global fairness. ” ● Ther e is an emer gence of a cross-s takeholder convergence on promoting the ethical principles of transpar ency , justice, non-male ficence, responsibility , and privacy."
471,"Some of the other values emphasiz ed in the documen t include impr oving human well-being , promoting fairness and justice, protecting priv acy and sa fety, and r aising e thical lit eracy."
471,"Madaio , Jennif er Wortman Vaughan, Luke Stark and Hanna Wallach] [Resear ch Summar y by Anne Boily] Overview : Among the burgeoning literature on AI ethics and the values that would be import ant to respect in the developmen t and use of artificial intelligence systems (AIS), fairness comes up a few times, perhap s as an echo of the very current notion of social justice."
471,"In this sense, there should be a lack of cheap and subversive techniques to avoid complic ated issues like justice, with the social good and social infrastructur e over inno vation and the good of the governmen ts."
471,"In Informania, machine learning systems “optimiz e on outcomes for millions (or billions) of user s, with little regard for individual rights within the c ollectiv e.” Such a futur e is becoming more likely, the author s state, poin ting to China’ s social credit system and the US Justice Departmen t’s COMP AS algorithm."
471,"Getting from Commitmen t to Content in AI and Data Ethics: Justice and Explainability [ Original paper by John Basl, R onald Sandler and St even Tiell] [Resear ch Summar y by Angshuman K aushik] Overview : AI or data ethics principles or frame works mean t to demons trate a commitmen t to addr essing the challeng es posed by AI are ubiquit ous and are an ‘easy first step’."
471,"According to it, much of this comple xity arises fr om thr ee key factors: ● ethical concep ts such as justice and transpar ency that often have man y senses and meaning; ● which senses of e thical concep ts ar e oper ative or appr opria te is oft en contextual; and ● ethical concep ts are multidimensional e.g., in terms of wha t needs to be transpar ent, to whom, and in wha t form."
471,"T h e S t a t e o f A I E t h i c s R e p o r t , V o l u m e 6 ( J a nu a r y 2 0 2 2 ) 1 9 0 Further , the objectiv es of the r eport ar e to: ● demons trate the import ance and comple xity of moving from gener al ethical concep ts and principles t o action-guiding sub stantive content, i.e., norma tive content; ● provide detailed analy sis of two widely discussed and interconnect ed ethical concep ts, justice and tr anspar ency; and ● indic ate strategies for moving from gener al ethical concep ts and principles to more specific norma tive content and ultima tely t o oper ationalizing tha t content."
471,"Meaning of jus tice in AI The report men tions that the concep t of justice is a comple x one, and can mean different things in different contexts."
471,"To determine wha t justice in AI and data use requir es in a particular context, it is imper ative to clarif y the norma tive content and underlying values."
471,"Only then it is possible to specif y wha t is requir ed in specific cases, and in turn how or to wha t extent justice can be oper ationaliz ed in technic al systems."
471,"According to the report, the gener al principle of justice is that all people should be equally respect ed and valued in social, economic and politic al systems and processes."
471,"However, there are man y ways this very gener al principle of justice intersects with social structur es and systems."
471,"As a result, there is a diverse set of more specific justice-orien ted principles such as pr ocedur al, dis tributiv e and r ecognition jus tice."
471,The resear cher s consider context to be critic ally import ant in determining which justice-orien ted principles take precedence.
471,"Ther efore, the first step in specif ying the norma tive content is to iden tify the justice-orien ted principles that are crucial to the work that the AI system does."
471,Only then can a commitmen t to justice be effectiv ely put into practice.
471,"Articula ting the relevant justice-orien ted principles will also requir e considering organizational missions, the types of products and services involved, how those products and services could impact communities and individuals etc."
471,"Further , the report states that the diversity of the justice-orien ted principles and the need to mak e context-specific determina tions about which are relevant and which to prioritiz e expose the limits of a strictly algorithmic manner in incorpor ating justice in AI systems."
471,"The reason being , firstly, there is no singular , gener al justice-orien ted constraint, optimiz ation or utility function and secondly , there will not be a strictly algorithmic way to fully incorpor ate justice into decision-making , even once the relevant justice consider ations have been iden tified."
471,The report then goes on to ask the ques tion as to how and to wha t extent can the salien t aspects of justice be achie ved algorithmic ally.
471,"According to the resear cher s, accomplishing justice in AI will requir e developing justice-in formed, techno-social or human-alg orithm systems."
471,"According to the resear cher s, a commitmen t to justice in AI involves remaining open to the possibility that some times an AI-orien ted appr oach migh t not be a just one."
471,"They stress on the fact that, organizations that are commit ted to justice in AI will requir e signific ant organizational capacity and processes to oper ationaliz e and implemen t their commitmen t, in addition to technic al capacity and expertise."
471,"Transpar ency in AI In the view of the resear cher s, in spite of the role that transpar ency plays in helping to achie ve justice, it can also play an import ant role in realizing other concep ts and values."
471,"T h e S t a t e o f A I E t h i c s R e p o r t , V o l u m e 6 ( J a nu a r y 2 0 2 2 ) 2 0 7 Risk and unaccep table uses The central oper ating mechanism of the Act is to look at high-risk AI uses-c ases which include biome tric iden tification, critic al infrastructur e that can signific antly impact human lives, determining access to educ ation and emplo ymen t, worker manag emen t, access to private and public services (e.g., finance), law enforcemen t, migr ation and immigr ation, and adminis tration of justice and democr atic processes."
471,"Each of the appr oaches come with their own pros and cons, in the case of civil offenses, the burden of proof remains lighter making it perhap s easier to obtain justice but criminal of fenses c arry a higher punitiv e bur den of fering a s tronger de terrent."
471,"Another ethical norm men tioned is “adher e to people-orien ted”, which is e xtremely ar duous t o compr ehend. ● Promot e fairness and justice – It talks about adher ence to inclusiv eness and inclusiv eness, which again does not convey any meaning , wha tsoe ver."
471,"The other ethical norms clubbed under this broad heading effectiv ely protect the legitima te rights and interests of all relevant subjects, promot e social fairness and justice and equal opportunities. ● Protect Privacy and safety – This head includes inter alia, fully respect the rights of personal informa tion to know and consen t, protect personal privacy and data security , informa tion mus t not infring e on personal privacy etc."
471,"Figur es such as Archbishop Desmond Tutu, Professor Gessler Mux e Nkondo and Justice Yvonne Mokg oro have commen ted on Ubun tu."
474,"Human decisions based on automated and predictive 239 technology are often made in settings such as hiring or criminal justice, and can create harmful 240 impacts and amplify and accelerate existing social inequities or, at minimum, perceptions of 241 inequities."
474,"Certainly, there is 248 no shortage of examples where bias in some aspect of AI technology and its use has caused harm 249 and negatively impacted people's lives, such as in hiring [5,12,16,17,36,62,118], health care 250 [46,52,55,59,83,88,103,122,123], and criminal justice [7,20,29,41,44,56,66,74,75,78,87, 251 140,142]."
474,"Such biases may produce unjust outcomes for racial and 315 4 ethnic minorities in areas such as criminal justice [7,41,56,74,75,78,87,140,142], hiring 316 [4,5,12,16,17,36,118,119], and financial decisions [13,65]."
474,"The broad consensus 325 of the literature is that systems meant for decision making or predictive scenarios should 326 demonstrate validity and reliability under the very specific setting in which it is intended to be 327 deployed (hiring purposes, risk assessments in the criminal justice system, etc.)."
474,"Costanza-Chock, Design Justice, A.I., and Escape from the Matrix of Domination, 825 Journal of Design and Science."
474,"851 20 [44] EPIC, Algorithms in the Criminal Justice System: Risk Assessment Tools, Electronic 852 Privacy Information Center, 2020."
476,An inaccurate explanation of how the algorithm 9 ______________________________________________________________________________________________________ This publication is available free of charge from: https://doi.org/10.6028/NIST.IR.8312 arrived at its outcome could result in a miscarriage of justice.
476,"Science and Justice, 57(2):144–154, 2017."
477,"There is no shortage of examples where bias in some aspect of AI technology and its use has caused harm and negatively impacted lives, such as in hiring, [2–7] health care, [8–17] and criminal justice [18–30]."
477,"Department of Justice, and the Office Federal Contract Compliance Programs are responsible for enforcement and interpretation of these laws."
477,"As a result, these algorithmic models have a higher probability of producing and amplifying unjust outcomes (e.g. for racial and ethnic minorities in areas such as criminal justice) [18–30, 214]."
477,These perspectives have led to the deployment of automated and predictive modeling tools within trusted institutions and high-stakes settings such as hiring or criminal justice.
477,"Available: http://www.liebertpub.com/doi/10.1089/big.2016.0047 [23] EPIC, “Algorithms in the Criminal Justice System Risk Assessment Tools,” Electronic Privacy Information Center (EPIC), Tech."
477,Available: https://epic.org/algorithmic-transparency/crim-justice/ [24] K.
477,Available: https://www.nytimes.com/2017/06/13/opinion/how -computers-are-harming-criminal-justice.html [30] “State v.
477,"Crawford, “Dirty Data, Bad Predictions: How Civil Rights Violations Impact Police Data, Predictive Policing Systems, And Justice,” New York University Law Review , vol."
477,"Costanza-Chock, “Design Justice, A.I., and Escape from the Matrix of Domination,” Journal of Design and Science , Jul."
477,"Shadbolt, “’It’s Reducing a Human Being to a Percentage’; Perceptions of Justice in Algorithmic Decisions,” Montreal QC, Canada, Jan."
478,"23In considering the applications of AI in areas such as criminal justice and health care, organizations should design, build and deploy AI systems that leverage human judgment and responsibility where they are needed."
478,"Suggested lead: Department of Commerce, Department of State, Department of Justice. •Track and understand AI standards development strategies and initiatives of foreign governments and entities."
478,"Suggested lead: Department of Commerce, Department of State, Department of Justice."
479,Establish a data protection framework with legal backing : The work being done by Justice Srikrishna Committee on data protection law is very opportune and timely.
48,"The secretariat is provided by Directorate C (Fundamental Rights and Union Citizenship) of the European Commission, Directorate General Justice, B -1049 Brussels, Belgium, Office No MO -59 03/075."
48,"Website: http://ec.europa.eu/justice/data -protection/index_en.htm 17/EN WP 251 Guidelines on Automated individual decision -making and Profiling for the purposes of Regulation 2016/679 Adopted on 3 October 2017 2 THE WORKING PARTY ON THE PROTECTION OF INDIVIDUALS WITH REGARD TO THE PROCESSING OF PERSONAL DATA set up by Directive 95/46/EC of the European Parliament and of the Council of 24 October 1995, having regard to Articles 29 and 30 thereof, having regard to its Rules of Procedure, HAS ADOPTED THE PRESENT GUIDELINES: 3 TABLE OF CONTENT S I."
48,"Opinion 03/2013 on p urpose limitation ,2 April 2013. http://ec.europa.eu/justice/data -protection/article -29/documentation/opinion recommendation/files/2013/wp203_en.pdf ."
48,"In the context of profiling these rights are actionable against the controller creating the profile and the controller making an automat ed decision about a data subject (with or without human intervention) , if these entities ar e not the same. http://ec.europa.eu/justice/data -protection/article -29/documentation/opinion recommendation/files/2014/wp217_en.pdf ."
48,Page 26 http://ec.europa.eu/justice/data -protection/article -29/documentation/opinion recommendation/files/2014/wp217_en.pdf .
482,"Advisory statement on human ethics in artificial intelligence and big data research (2017) - National Research Council Canada Skip to main content Skip to ""About government"" Language selection Language selection Françaisfr / Gouvernement du Canada Search Search Menu Main Menu Home Jobs and the workplace Immigration and citizenship Travel and tourism Business and industry Benefits Health Taxes Environment and natural resources National security and defence Culture, history and sport Policing, justice and emergencies Transport and infrastructure Canada and the world Money and finances Science and innovation You are here Canada.ca National Research Council Canada Corporate Values and ethics Research involving human participants Advisory statement on human ethics in artificial intelligence and big data research (2017) 1."
482,"Related links Research involving human participants From: National Research Council Canada Date modified: 2019-03-26 About this site National Research Council Canada Contact the NRC Order products Directory of science professionals Government of Canada All Contacts Departments and agencies About government Themes and topics Jobs Immigration and citizenship Travel and tourism Business Benefits Health Taxes Environment and natural resources National security and defence Culture, history and sport Policing, justice and emergencies Transport and infrastructure Canada and the world Money and finance Science and innovation Indigenous peoples Veterans and military Youth Government of Canada Corporate Social media Mobile applications About Canada.ca Terms and conditions Privacy Top of Page"
484,"Department of Commerce The following Federal departments and agencies are represented on the Subcommittee on Machine Learning and Artificial Intelligence and thro ugh it, work together to monitor the state of the art in machine learning (ML) and AI (within the Federal Government, in the private sector, and internationally), to watch for the arrival of important technology milestones in the development of AI, to coor dinate the use of and foster the sharing of knowledge and best practices about ML and AI by the Federal Government, and to consult in the development of Federal research and development priorities in AI: Department of Commerce (Co -Chair ) Depa rtment of Defense Department of Education Department of Energy Department of Health and Human Services Department of Homeland Security Department of Justice Department of Labor Department of State Department of Transportation Department of Treasury Department of Veterans Affairs United States Agency for International Development Central Intelligence Agency General Services Administration National Science Foundation National Security Agency National Aeronautics and Space Administration Office of the Director of National Intelligence Social Security Administration The following offices of the Executive Office of the President are also represented on the Subcommittee: Council of Economic Advisers Domestic Policy Council Office of Management and Budget Office of Science and Technology Policy (Co Chair) Office of the Vice President National Economic Council National Security Council PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE Contents Executive Summary ................................ ................................ ................................ ................................ ....................."
484,"30 Justice, Fairness, and Accountability ................................ ................................ ................................ ................."
484,"Public - and private sector investments in basic and applied R&D on AI have already begun reaping major benefits to the public in fields as diverse as health care, transportation, the environment, criminal justice, and economic inclusion ."
484,"Use of AI to make consequential decisions about people, often replacing decisions made by human -driven bureaucra tic processes , leads to concerns about how to ensure justice, fairness, and accountability —the same concerns voiced previously in the Administration’s Big Data: Seizing Opportunities, Preserving Values report of 2014,1 as well as the Report to the President on Big Data and Privacy: A Technological Perspective published by the President’s Council of Advisors on Science and Technology in 2014 .2 Transparency concerns focus not only on the data and algorithms involved, but also on the potential to have some form of explanat ion for any AI -based determination."
484,"Many areas of public policy, from education and the economic safety net, to defense, envi ronmental preservation, and criminal justice, will see new opportunities and new challenges driven by the continued progress of AI."
484,"The promise of AI has been compared to the transformative impacts of advances in mobile computing.21 Public - and private -sector investments in basic and applied R&D on AI have already begun reaping major benefits for the public in fields as diverse as health care, transportation, the environment, criminal justice, and economic inclusion .22 At Walter Reed Medical Center, the Department of Veteran Affairs is using AI to better predict medical complications and improve treatment of severe combat wounds, leading to better patient outcomes, faster healing, and lower costs.23 The same general approac h—predicting complications to enable preventive treatment —has also reduced hospital -acquired infections at Johns Hopkins University .24 Given the current transition to electronic health records, predictive analysis of health data may play a key role across m any health domains like precision medicine and cancer research."
484,"Autonomous watercraft may be much cheaper to operate than manned ships, and may some day be used for enhanced weather prediction, climate monitoring, or policing illegal fishing.27 AI also has the potential to improve aspects of the criminal justice system, including crime reporting, policing, bail, sentencing, and parole decisions."
484,"The Admini stration is exploring how AI can responsibly benefit current initiatives such as Data Driven Justice and the Police Data Initiative that seek to provide law enforcement and the public with data that can better inform decision -making in the criminal justice system, while also taking care to minimize the possibility that AI might introduce bias or inaccuracies due to deficiencies in the available data."
484,Social justice and public policy institutions that do not typically engage with advanced technologies and data science in their work should consider partnerships with AI researchers and practitioners that can help apply AI tactics to the broad social problems these institutions already address in other ways.
484,"The u se of AI to make consequential decisions about people, often replacing decisions made by human actors and institutions , leads to concerns about how to ensure justice, fairness, and accountability —the same concerns voice d previously in the “ Big Data” context.62 The u se of AI to control physical -world equipment leads to concerns about safety, especially as systems are exposed to the full complexity of the human environment."
484,"Justice, Fairness, and Accountability A common theme in the Law and Governance, AI for Social Good, and Social and Economic Impac ts workshops was the need to ensure that AI promotes justice and fairness, and that AI -based processes are accountab le to stakeholders ."
484,"In the criminal justice system, some of the biggest concerns with Big Data are the lack of data and the lack of quality data.65 AI needs good data."
484,It is important that anyone using AI in the criminal justice context is aware of the limitations of current data.
484,"65 Matt Ford, “The Missing Statistics of Criminal Justice,” The Atlantic, May 31, 2015, http://www.theatlantic.com/politics/archive/2015/05/what -we-dont-know -about -mass -incarceration/394520/ 66 Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner, “Machine Bias,” ProPublica, May 23, 2016, https://www.propublica.org/article/machine -bias-risk-assessments -in-criminal -sentencing."
484,"Many areas of public policy, from education and the economic safety net, to defense , environmental prese rvation, and criminal justice, will see new opportunities and new challenges driven by the continued progress of AI."
484,Social justice and public policy institutions that do not typically engage with advanced t echnologies and data science in their work should consider partnerships with AI researchers and practitioners that can help apply AI tactics to the broad social problems these institutions already address in other ways.
484,"Matt Ford, “The Missing Statistics of Criminal Justice,” The Atlantic, May 31, 2015, http://www.theatlantic.com/politics/archive/2015/05/what -we-dont-know-about -mass -incarceration/394520/ Jason Furman, “Is This Time Different?"
485,"Department of Commerce Subcommittee on Networking and Information Technology Research and Development Co-Chair Bryan Biegel Director, National C oordination Office for Networking and Information Technology Research and Development Co-Chair James Kurose Assistant Director, Computer and Information Science and Engineering National Science Foundation Networking and Information Technology Research and Development Task Force on Artificial Intelligence Co-Chair Lynne Parker Division Director Information and Intelligent System s National Science Foundation Co-Chair Jason Matheny Director Intelligence Advanced Research Projects Activity Members Milton Corn National Institutes of Health Nikunj Oza National Aeronautics and Space Administration William Ford National Institute of Justice Robinson Pino Department of Energy Michael Garris National Institute of Standards and Technology Gregory Shannon Office of Science and Technology Policy Steven Knox National Security Agency Scott Tousley Department of Homeland Security viii John Launchbury Defense Advanced Research Projects Agency Faisal D’Souza Technical Coordinator National Coordination Office for Networking and Information Technology Research and Development Richard Linderman Office of the Secretary of Defense NATIONAL ARTIFICIAL INTELLIGENCE RESEARCH AND DEVELOPMENT STRATEGIC PLAN 1 Contents About the National Science and Technology Council ................................ ................................ .......................... iii About the Office of Science and Technology Policy ................................ ................................ ............................ iii About the Subcommittee on Networking and Information Technology Research and Development ................ iii Acknowledgments ................................ ................................ ................................ ................................ ............... iii Copyright Information ................................ ................................ ................................ ................................ .......... iv National Science and Technology Council ................................ ................................ ................................ ........... vii Subcommittee on Machine Learning and Artificial Intelligence ................................ ................................ .......... vii Subcommittee on Networking and Information Technology Research and Development ................................ . vii Task Force on Artificial Intelligence ................................ ................................ ................................ ..................... vii Executive Summary ................................ ................................ ................................ ................................ ..................."
485,"The Federal government should therefore emphasize AI investments in areas of strong societal importance that are not aimed at consumer markets —areas such as AI for public health, urban systems and smart communiti es, social welfare, criminal justice, environmental sustainability, and national security, as well as long -term research that accelerates the production of AI knowledge and technologies ."
485,"Scientists must also study to what extent justice and fairness considerations can be designed into the system, and how to accomplish this within the bounds of current engineering techniques ."
485,NATIONAL ARTIFICIAL INTELLIGENCE RESEARCH AND DEVELOPMENT STRATEGIC PLAN 27 Building e thical AI Beyond fundamental assumptions of justice and fairness are other concerns about whether AI systems can exhibit behavior that a bides by general ethical principles.
486,"Department of Commerce Subcommittee on Networking and Information Technology Research and Development Co-Chair Bryan Biegel Director, National C oordination Office for Networking and Information Technology Research and Development Co-Chair James Kurose Assistant Director, Computer and Information Science and Engineering National Science Foundation Networking and Information Technology Research and Development Task Force on Artificial Intelligence Co-Chair Lynne Parker Division Director Information and Intelligent System s National Science Foundation Co-Chair Jason Matheny Director Intelligence Advanced Research Projects Activity Members Milton Corn National Institutes of Health Nikunj Oza National Aeronautics and Space Administration William Ford National Institute of Justice Robinson Pino Department of Energy Michael Garris National Institute of Standards and Technology Gregory Shannon Office of Science and Technology Policy Steven Knox National Security Agency Scott Tousley Department of Homeland Security viii John Launchbury Defense Advanced Research Projects Agency Faisal D’Souza Technical Coordinator National Coordination Office for Networking and Information Technology Research and Development Richard Linderman Office of the Secretary of Defense NATIONAL ARTIFICIAL INTELLIGENCE RESEARCH AND DEVELOPMENT STRATEGIC PLAN 1 Contents About the National Science and Technology Council ................................ ................................ .......................... iii About the Office of Science and Technology Policy ................................ ................................ ............................ iii About the Subcommittee on Networking and Information Technology Research and Development ................ iii Acknowledgments ................................ ................................ ................................ ................................ ............... iii Copyright Information ................................ ................................ ................................ ................................ .......... iv National Science and Technology Council ................................ ................................ ................................ ........... vii Subcommittee on Machine Learning and Artificial Intelligence ................................ ................................ .......... vii Subcommittee on Networking and Information Technology Research and Development ................................ . vii Task Force on Artificial Intelligence ................................ ................................ ................................ ..................... vii Executive Summary ................................ ................................ ................................ ................................ ..................."
486,"The Federal government should therefore emphasize AI investments in areas of strong societal importance that are not aimed at consumer markets —areas such as AI for public health, urban systems and smart communiti es, social welfare, criminal justice, environmental sustainability, and national security, as well as long -term research that accelerates the production of AI knowledge and technologies ."
486,"Scientists must also study to what extent justice and fairness considerations can be designed into the system, and how to accomplish this within the bounds of current engineering techniques ."
486,NATIONAL ARTIFICIAL INTELLIGENCE RESEARCH AND DEVELOPMENT STRATEGIC PLAN 27 Building e thical AI Beyond fundamental assumptions of justice and fairness are other concerns about whether AI systems can exhibit behavior that a bides by general ethical principles.
489,"40 Privacy Commissioner, Office of the Privacy Commissioner Briefing for the Incoming Minister of Justice: Hon Andrew Little, October 2017, para 2.1 https://privacy.org.nz/assets/Uploads/Briefing-for-Incoming-Min-ister-October-2017.pdf 41 See https://www.eugdpr.org/key-changes.html.1.3 Data Privacy Guidelines and Principles Essential to the right to privacy is the right to protection of personal data."
489,"45 Comprehensive and Progressive Agreement for the Trans-Pacific Partnership Agreement (TPP) 42 Privacy Commissioner, Office of the Privacy Commissioner Briefing for the Incoming Minister of Justice: Hon Andrew Little, October 2017, para 4.14 https://privacy.org.nz/assets/Uploads/Briefing-for-Incom-ing-Minister-October-2017.pdf Ibid para 4.14."
489,"Jurisprudence arising from the judgments of the European Court of Human Rights (ECtHR) and the Court of Justice of the European Union on the application of the right to privacy under the European Convention on Human Rights (ECHR) 52 Hon Christopher Finlayson, Ministerial Policy Statement: Cooperation of New Zealand intelligence and security agencies (GCSB and NZIS) with overseas public authorities, Appendix One, p 15, September 2017 available: https://www.nzic.govt.nz/assets/MPSs/Ministerial-Policy-State-ment-Cooperation-with-overseas-public-authorities.pdf."
489,"56 See para 11 of Winkelmann J’s judgment in TV3 v N (name suppression) (unreported, HC Auckland, 7 July 2006) where she finds at paras 10 and 11 that public interest factors as to reporting of evidence must be balanced with “the State’s particular obligations to young offenders, and in particular Article 8 of the United Nations Standard Minimum Rules for the administration of juvenile justice (“the Beijing Rules”)."
489,"That same month, the Minister of Justice announced that Cabinet had agreed in principle to allow courts to make a declaration of inconsistency and that the Bill of Rights Act will be amended to give the Courts this power."
489,"It is notable that in 2016 the UN Committee on the Rights of the Child recommended that the New Zealand Government ensure “that the Privacy, Human Rights and Ethics framework governing predictive risk modelling takes in to consideration the potentially discriminatory impacts of this practice, is made public and is referenced in all relevant legislation.” 85 The advent of this approach has coincided with extensive reforms to the legislation governing New Zealand’s child protection and youth justice jurisdictions."
489,"The Guidelines set out the following five-part set of questions that officials must apply to proposed legislation: • Is the legislation consistent with the requirements of the Privacy Act 1993 and its 12 Information Privacy Principles? • Have you complied with any relevant Code of Practice issued by the Privacy Commissioner? • Have you consulted the Privacy Commissioner, the Ministry of Justice and the GCPO? • Does the legislation require a complaints process? • Have you considered the consequences of non-compliance with the Privacy Act 1993?"
489,"It should be possible to set out a series of limited powers, safeguards and review mechanisms with a high degree of clarity and . . . without technical jargon: the place for the 149 Privacy Commissioner, Office of the Privacy Commissioner Briefing for the Incoming Minister of Justice: Hon Andrew Little, October 2017, para 4.2 https://privacy.org.nz/assets/Uploads/Briefing-for-Incoming-Min ister-October-2017.pdf 150 Report of Special Rapporteur for freedom of expression, Frank La Rue, (17 April 2013) para 91."
489,174 • Human rights obligations: Agencies must not 172 See https://www.privacy.org.nz/blog/providing-an-adequate-lev-el-of-data-protection/ 173 See http://ec.europa.eu/justice/data-protection/international-trans fers/adequacy/index_en.htm174 Ibid. paras.
489,"235 As discussed earlier in the paper, AI is increasingly used in the criminal justice system."
489,"For example, by the police to target resources or high-risk individuals, by the courts to predict the likelihood of re-offending and prisons in targeting restorative justice."
489,238 Concerns regarding the inherent risk of bias that arises from algorithmic risk assessments in the criminal justice sector were raised by U.S.
489,"Attorney General Eric Holder raised concern about algorithms that produce risk assessments that seek to assign the probability of individual’s likelihood of committing future crimes: “Although these measures were crafted with the best of intentions, I am concerned that they inadvertently undermine our efforts to ensure individualized and equal justice… they may exacerbate unwarranted and unjust disparities that are already far too common in our criminal justice system and in our society."
489,See https://www.justice.gov/opa/speech/attorney-general-eric-holder-speaks-national-association-crimi nal-defense-lawyers-57th.
490,"AI in the Nordic-Baltic region | Nordic cooperation Skip to main content Service menu Press Career Contact EN language dropdown DAFIISSVNO Main navigation Nordic Council of Ministers Nordic Council Mega menu EN language dropdown DAFIISSVNO Nordic Council of Ministers News from the Nordic Council of Ministers Our Vision 2030 Politiske prioriteter 2025-2030 The Presidency of the Nordic Council of Ministers Presidency programme for the Nordic Council of Ministers 2025 Organisation The Secretary General Secretariat Governing documents The Nordic Councils of Ministers Ministers for Co-operation Labour Environment and Climate Sustainable Growth Digitalisation Fisheries, Aquaculture, Agriculture, Food and Forestry Justice Culture Gender Equality and LGBTI Social and Health Affairs Education and Research Economic and Fiscal Policy Meetings and protocols Institutions Nordic Culture Point Nordic House in Reykjavik Nordic House in the Faroe Islands The Nordic Institute in Greenland Nordic Institute on Åland Nordic Welfare Centre NordForsk NordGen Nordic Innovation Nordic Energy Research Nordregio NIVA Education About the Nordic Council of Ministers History of the Nordic Council of Ministers Budget Nordic Council News from the Nordic Council Parliamentary co-operation Nordic Council cases Nordic Council’s international co-operation The Presidency of the Nordic Council Presidency programme for the Nordic Council 2025 Organisation Secretary General Secretariat Governing documents Nordic Council committees and members All members The Presidium Committee for Knowledge and Culture in the Nordic Region Committee for a Sustainable Nordic Region Committee for Growth and Development in the Nordic Region Committee for Welfare in the Nordic Region Control Committee Election Committee Sessions and meetings Protocols and upcoming meetings Session 2025 Theme Session 2025 2024 Session Past sessions About the Nordic Council The history of the Nordic Council Annual report News All news Events Current initiatives 2025 Session of the Nordic Council Arctic Circle 2025 EXPO 2025 Press Nordic image bank Career Knowledge and services Living, working and studying in the Nordic Region Publications Release a publication Facts and statistics Facts about the Nordic Region Nordic statistics Funding opportunities About funding from the Nordic Council of Ministers Public procurements Border database About the Nordic co-operation The history of Nordic co-operation Nordic Council prizes Environment Prize Children and Young People's Literature Prize Literature Prize Film Prize Music Prize Policy areas Environment and climate Culture Legislation and Justice Sustainable development Digitalisation and innovation Children and young people See all policy areas Service menu Press Career Contact Search Search Menu Breadcrumb Home AI in the Nordic-Baltic region 14.05.18 | Declaration Artificial intelligence (AI) can help solve major societal challenges and provide significant benefits in a variety of areas."
493,They don’t connect our ideas about what’s good or just to the practices that create goodness and justice.
497,C’est typiquement le raisonnement utilisé par la justice pour adapter la jurisprudence à une nouvelle situation .
497,"En particulier, ce premier rapport se conclut sur l ’idée que les technologies d’intelligence artificielle font émerg er un potentiel d’amélioration de la vie des citoyens en ouvrant de nouveaux marchés et de nouvelles opportunités permettant de résoudre ce rtains des grands enjeux sociétaux : la santé, les transports, l’éducation, l’énergie , l’environnement, la justice, la sécurité ou encore l’efficacité du gouvernement."
497,5 Article « Le droit à l’épreuve de l’intelligence artificielle » du 28 novembre 2016 paru dans la revue Village de la Justice.
497,"Lors d’un colloque à New York sur les défis posés p ar l’émergence de l’intelligence artificielle, organisé le 14 octo bre 2015 par l’Institut de recherche sur la criminalité et la justice des Nati ons Unies (UNICRI), Max Tegmark était invité avec un autre expert 3 à s’exprimer devant quelques 1 L’Institut a été fondé en mars 2014 par Max Tegmar k cosmologiste au MIT, Jaan Tallinn cofondateur de Skype, Anthony Aguirre physicien à l’U CSC et deux étudiants (Viktoriya Krakovna et Meia Chita-Tegmark), figurent à son conseil consult atif l’informaticien Stuart J."
523,"These i nclude freedom, dignity and autonomy, privacy and data protection, non -discrimination and equality, diversity, fairness, social justice, and internationally recognized labor rights. b) To this end, AI actors should implement mechanisms and safeguards, such as capacity for human determination, that are appropriate to the context and consistent with the state of art."
523,"Some interventions might aim to improve completion and contr ibute to social justice, fairness and non -discri mination, in line with the G20 P rinciples."
532,"Mladenovic, Milos N./McPherson, Tristram : Engineering social justice into traffic control for self-driving vehicles? in Science and engineering ethics Bd."
535,"1 Algorithms in decision-making Contents Summary 3 1 Introduction 7 Our inquiry 10 2 Applications and bias 11 Data sharing 11 In the health sector 11 In the criminal justice system 13 In the web and social media sector 14 Government data sharing and getting value from its data 15 Bias 18 Training data 19 Insufficient data 20 Correlation without causation 21 Lack of representation in the algorithm development community 22 3 Accountability and transparency 24 Accountability 24 Principles and codes 25 Audit and certification 26 Ethics boards 27 Transparency 27 The right to explanation 29 4 The Centre for Data Ethics & Innovation, research and the regulatory environment 32 ‘Automated’ decisions 33 Consent 35 Data protection impact assessments 36 The Information Commissioner’s powers 37 Sector regulation 39 Algorithms in decision-making 2 Conclusions and recommendations 41 Formal minutes 45 Witnesses 46 Published written evidence 47 List of Reports from the Committee during the current Parliament 50 3 Algorithms in decision-making Summary Algorithms have long been used to aid decision-making, but in the last few years the growth of ‘big data’ and ‘machine learning’ has driven an increase in algorithmic decision-making—in finance, the legal sector, the criminal justice system, education, and healthcare, as well as recruitment decisions, giving loans or targeting adverts on social media, and there are plans for autonomous vehicles to be on public roads in the UK."
535,"The range of different industries in which machine learning is already being put to use includes finance (including access to loans and insurance), the legal sector, the criminal justice system, education, and healthcare, as well as recruitment decisions and targeting adverts on social media, 12 and there are plans for driverless vehicles to be on public roads in the UK in the near future."
535,"37 In our current inquiry we examined the way data sharing is affecting three sectors in particular—in healthcare, criminal justice and social media."
535,65 In the criminal justice system 18.
535,"In the criminal justice system, algorithms are being used by some police forces for facial image recognition."
535,"76 64 Qq232, 234, 235 65 Q230 66 Big Brother Watch, Big Brother Watch Briefing for Short Debate on the use of facial recognition technology in security and policing in the House of Lords (March 2018), p8 67 Letter from Baroness Williams of Trafford to the Committee , 28 March 2018 68 Oxford Internet Institute ( ALG0031 ) 69 UCL Jill Dando Institute of Security and Crime Science ( ALG0048 ) para 5 70 Marion Oswald and Sheena Urwin submission; See also, “ Pre-crime software recruited to track gang of thieves “, New Scientist, 11 March 2015 71 RUSI, Big Data and Policing 2017 (September 2017), p20 72 UCL Jill Dando Institute of Security and Crime Science 73 Sheena Urwin, Head of Criminal Justice, Durham Constabulary ( ADM0032 ) 74 Institute of Mathematics and its Applications ( ALG0028 ) para 19 75 Durham Constabulary ( ALG0041 ) 76 HM Inspectorate of Constabulary, PEEL: Police Effectiveness 2016 (March 2017), p33 Algorithms in decision-making 14 Box 2: Durham Constabulary’s use of algorithms The Harm Assessment Risk Tool (HART), designed as a result of a collaboration between Durham Constabulary and Dr Barnes of University of Cambridge, is a decision support system used to assist officers in deciding whether a suspect is eligible for deferred prosecution based on the future risk of offending."
535,"80 Professor Louise Amoore questioned whether there is a “place for inference or correlation in the criminal justice system” 81 since, unlike normal evidence, it cannot be cross-examined or questioned."
535,82 Jamie Grace from Sheffield Hallam University accepted its use but wanted “a single [independent] oversight body and regulator for the use of police databases and algorithmic analysis in criminal justice”.
535,"They are also moving into areas where the benefits to those applying them may not be matched by the benefits to those subject to their ‘decisions’—in some aspects of the criminal justice system, for example, and algorithms using social media datasets."
535,119 Where algorithms are used in the criminal justice system it is imperative that algorithms are not unfairly discriminatory.
535,"144 She also questioned the use of inference and correlation in the criminal justice system, and suggested that its use in the US for sentencing “constitutes a violation of due process or overt discrimination”."
535,"Algorithms in the Criminal Justice System: Assessing the Use of Risk Assessments in Sentencing , accessed 5 April 2018 146 Sheena Urwin, Head of Criminal Justice, Durham Constabulary ( ADM0032 ) 147 Q28 Algorithms in decision-making 22 41."
535,"In some of our evidence, there was a desire for algorithms within the criminal justice system to be restricted to advisory roles."
535,"265 256 Q150 257 Sheena Urwin, Head of Criminal Justice, Durham Constabulary ( ADM0032 ) 258 EU GDPR, ‘ GDPR Key Changes ’, accessed 20 March 2018 259 Information Commissioner’s Office ( ALG0038 ) 260 Science and Technology Committee, Fourth Report of Session 2015–16, The big data dilemma , HC 468 261 Q57 262 Q365 263 Science and Technology Committee, Fourth Report of Session 2015–16, The big data dilemma , HC 468, para 66 264 Q66 265 Q245 [Dr Dominic King] Algorithms in decision-making 36 82."
535,"Q89–148 Sheena Urwin , Head of Criminal Justice, Durham Constabulary; and Professor Kate Bowers , Academic Director, UCL Jill Dando Institute."
54,"The values of equality, tolerance, respect for others, and justice govern this principle."
544,"Forexample, social network maps forservices such asTwitter candetermine credit-worthiness [5],opaque recidivism scores canshape criminal justice decisions inaracially disparate manner [6],and categorization based onzipcodes resulted inlessaccess toAmazon Prime same-day delivery service forAfrican-Americans inUnited States cities [7].These high-profile cases show that apparently neutral data canyield discriminatory outcomes, thereby compounding social inequities."
544,"There areanumber ofgood models forinterdisciplinary ethics research, such asthe trainings offered bytheScience and Justice research center attheUniversity ofCalifornia, Santa Cruz [32] and Values inDesign curricula [33]."
544,Science &Justice Research Center (Collaboratio nsGroup.
545,"Forexample, social network maps forservices such asTwitter candetermine credit-worthiness [5],opaque recidivism scores canshape criminal justice decisions inaracially disparate manner [6],and categorization based onzipcodes resulted inlessaccess toAmazon Prime same-day delivery service forAfrican-Americans inUnited States cities [7].These high-profile cases show that apparently neutral data canyield discriminatory outcomes, thereby compounding social inequities."
545,"There areanumber ofgood models forinterdisciplinary ethics research, such asthe trainings offered bytheScience and Justice research center attheUniversity ofCalifornia, Santa Cruz [32] and Values inDesign curricula [33]."
545,Science &Justice Research Center (Collaboratio nsGroup.
551,"Make it happen with PwC​ Skip to content Skip to footer Industries Services Issues About us Careers More Search Menu Industries Industries See all industries Consumer markets Energy, utilities and resources Financial services Government and public sector Health industries Industrials and services Private equity and principal investors Technology, media and telecommunications Menu Industries See all industries Menu Industries Consumer markets Consumer goods Hospitality and leisure Retail Transportation and logistics Menu Industries Energy, utilities and resources Chemicals Mining and metals Oil and gas Power and utilities Menu Industries Financial services Asset and wealth management Banking and capital markets Insurance Real estate Menu Industries Government and public sector Defence Education and skills Public safety, justice and security Menu Industries Health industries Health services Pharmaceuticals and life sciences Menu Industries Industrials and services Aerospace, defence and security Automotive Business services Engineering and construction Industrial manufacturing Space Menu Industries Private equity and principal investors Capital projects and infrastructure Menu Industries Technology, media and telecommunications Entertainment and media Technology Telecommunications Featured Value in motion Industry edge Engine by Starling: From launching a bank to launching a software business Menu Services Services See all services Alliances Artificial Intelligence Audit and assurance services Business model reinvention Business transformation Consulting Crisis management Deals Entrepreneurial and private business Family business Forensics Legal business solutions Managed Services Risk services Strategy Sustainability and climate change Tax Trust Workforce Menu Services See all services Menu Services Alliances Menu Services Artificial Intelligence Menu Services Audit and assurance services Actuarial services Capital markets Corporate reporting Financial audit IFRS Internal audit Next Generation Audit Risk assurance Sustainability assurance Menu Services Business model reinvention Menu Services Business transformation Menu Services Consulting Cloud transformation Digital operations Deals Finance transformation Forensics Front office transformation HR transformation Risk and regulation Strategy Technology Workforce Menu Services Crisis management Menu Services Deals Acquisitions Capital markets Corporate finance Deals strategy Joint ventures and alliances M&A legal M&A tax Performance and Restructuring​ Sovereign wealth funds Menu Services Entrepreneurial and private business Menu Services Family business Menu Services Forensics Menu Services Legal business solutions Employment Entity governance and compliance International business reorganisations Mergers and acquisitions NewLaw Menu Services Managed Services Menu Services Risk services Menu Services Strategy Menu Services Sustainability and climate change Climate risk, resilience and adaptation Energy solutions Impact management for sustainable business strategy Legal and sustainability Net zero transformation Social sustainability Sustainability assurance Sustainable capital Sustainability reporting Tax and sustainability Menu Services Tax Indirect taxes International tax services Mergers and acquisitions Sightline Tax code of conduct Tax controversy and dispute resolution Tax policy and administration Tax reporting and strategy Transfer pricing Menu Services Trust Menu Services Workforce Culture, leadership and change Inclusion Employment law Employment tax and payroll HR transformation and technology Organisational design People analytics and insights People in deals Retirement and pensions Reward and benefits Workforce risk Workforce strategy Featured Climate risk, resilience and adaptation Business transformation Sustainability assurance Menu Issues Issues See all issues Business model reinvention Business transformation C-suite insights Cybersecurity Climate and sustainability Megatrends Risk and regulation Technology Trust Upskilling Workforce Menu Issues See all issues Menu Issues Business model reinvention Menu Issues Business transformation Menu Issues C-suite insights Accelerating performance Global CEO Survey PwC at Davos strategy+business digital issue Take on Tomorrow: a strategy+business podcast The Leadership Agenda Menu Issues Cybersecurity Menu Issues Climate and sustainability Menu Issues Megatrends Menu Issues Risk and regulation Menu Issues Technology Menu Issues Trust Menu Issues Upskilling Menu Issues Workforce Featured Value in motion PwC’s 28th Annual Global CEO Survey The Fearless Future: 2025 Global AI Jobs Barometer Menu About us About us See more About Us Alumni Analyst relations Client case studies Ethics and compliance Committing to Net Zero Corporate sustainability Inclusion PwC's Global Annual Review Global regulatory affairs Human rights policy Network Leadership, Governance, and Structure New Ventures and Innovation News room Purpose, values and behaviours PwC office locations PwC's Code of Conduct Strategy& Tax Code of Conduct Third party code of conduct Transparency Report Menu About us See more About Us Menu About us Alumni Menu About us Analyst relations Menu About us Client case studies Menu About us Ethics and compliance Menu About us Committing to Net Zero Menu About us Corporate sustainability Menu About us Inclusion Menu About us PwC's Global Annual Review Menu About us Global regulatory affairs Menu About us Human rights policy Menu About us Network Leadership, Governance, and Structure Menu About us New Ventures and Innovation Menu About us News room Menu About us Purpose, values and behaviours Menu About us PwC office locations Menu About us PwC's Code of Conduct Menu About us Strategy& Menu About us Tax Code of Conduct Menu About us Third party code of conduct Menu About us Transparency Report Featured Value in motion Committing to Net Zero Global Transparency Report 2024 Menu Careers Careers Find out more about careers Search for a job Menu Careers Find out more about careers Menu Careers Search for a job Featured PwC’s Global Annual Review Committing to net zero The CEO’s ESG dilemma Loading Results No Match Found View All Results We map the industries of tomorrow so you can start navigating yours today Explore now Your browser does not support the video tag."
552,"How Responsible AI can improve business and preserve value | PwC Skip to content Skip to footer Industries Services Issues About us Careers More Search Menu Industries Industries See all industries Consumer markets Energy, utilities and resources Financial services Government and public sector Health industries Industrials and services Private equity and principal investors Technology, media and telecommunications Menu Industries See all industries Menu Industries Consumer markets Consumer goods Hospitality and leisure Retail Transportation and logistics Menu Industries Energy, utilities and resources Chemicals Mining and metals Oil and gas Power and utilities Menu Industries Financial services Asset and wealth management Banking and capital markets Insurance Real estate Menu Industries Government and public sector Defence Education and skills Public safety, justice and security Menu Industries Health industries Health services Pharmaceuticals and life sciences Menu Industries Industrials and services Aerospace, defence and security Automotive Business services Engineering and construction Industrial manufacturing Space Menu Industries Private equity and principal investors Capital projects and infrastructure Menu Industries Technology, media and telecommunications Entertainment and media Technology Telecommunications Featured Value in motion Industry edge Engine by Starling: From launching a bank to launching a software business Menu Services Services See all services Alliances Artificial Intelligence Audit and assurance services Business model reinvention Business transformation Consulting Crisis management Deals Entrepreneurial and private business Family business Forensics Legal business solutions Managed Services Risk services Strategy Sustainability and climate change Tax Trust Workforce Menu Services See all services Menu Services Alliances Menu Services Artificial Intelligence Menu Services Audit and assurance services Actuarial services Capital markets Corporate reporting Financial audit IFRS Internal audit Next Generation Audit Risk assurance Sustainability assurance Menu Services Business model reinvention Menu Services Business transformation Menu Services Consulting Cloud transformation Digital operations Deals Finance transformation Forensics Front office transformation HR transformation Risk and regulation Strategy Technology Workforce Menu Services Crisis management Menu Services Deals Acquisitions Capital markets Corporate finance Deals strategy Joint ventures and alliances M&A legal M&A tax Performance and Restructuring​ Sovereign wealth funds Menu Services Entrepreneurial and private business Menu Services Family business Menu Services Forensics Menu Services Legal business solutions Employment Entity governance and compliance International business reorganisations Mergers and acquisitions NewLaw Menu Services Managed Services Menu Services Risk services Menu Services Strategy Menu Services Sustainability and climate change Climate risk, resilience and adaptation Energy solutions Impact management for sustainable business strategy Legal and sustainability Net zero transformation Social sustainability Sustainability assurance Sustainable capital Sustainability reporting Tax and sustainability Menu Services Tax Indirect taxes International tax services Mergers and acquisitions Sightline Tax code of conduct Tax controversy and dispute resolution Tax policy and administration Tax reporting and strategy Transfer pricing Menu Services Trust Menu Services Workforce Culture, leadership and change Inclusion Employment law Employment tax and payroll HR transformation and technology Organisational design People analytics and insights People in deals Retirement and pensions Reward and benefits Workforce risk Workforce strategy Featured Climate risk, resilience and adaptation Business transformation Sustainability assurance Menu Issues Issues See all issues Business model reinvention Business transformation C-suite insights Cybersecurity Climate and sustainability Megatrends Risk and regulation Technology Trust Upskilling Workforce Menu Issues See all issues Menu Issues Business model reinvention Menu Issues Business transformation Menu Issues C-suite insights Accelerating performance Global CEO Survey PwC at Davos strategy+business digital issue Take on Tomorrow: a strategy+business podcast The Leadership Agenda Menu Issues Cybersecurity Menu Issues Climate and sustainability Menu Issues Megatrends Menu Issues Risk and regulation Menu Issues Technology Menu Issues Trust Menu Issues Upskilling Menu Issues Workforce Featured Value in motion PwC’s 28th Annual Global CEO Survey The Fearless Future: 2025 Global AI Jobs Barometer Menu About us About us See more About Us Alumni Analyst relations Client case studies Ethics and compliance Committing to Net Zero Corporate sustainability Inclusion PwC's Global Annual Review Global regulatory affairs Human rights policy Network Leadership, Governance, and Structure New Ventures and Innovation News room Purpose, values and behaviours PwC office locations PwC's Code of Conduct Strategy& Tax Code of Conduct Third party code of conduct Transparency Report Menu About us See more About Us Menu About us Alumni Menu About us Analyst relations Menu About us Client case studies Menu About us Ethics and compliance Menu About us Committing to Net Zero Menu About us Corporate sustainability Menu About us Inclusion Menu About us PwC's Global Annual Review Menu About us Global regulatory affairs Menu About us Human rights policy Menu About us Network Leadership, Governance, and Structure Menu About us New Ventures and Innovation Menu About us News room Menu About us Purpose, values and behaviours Menu About us PwC office locations Menu About us PwC's Code of Conduct Menu About us Strategy& Menu About us Tax Code of Conduct Menu About us Third party code of conduct Menu About us Transparency Report Featured Value in motion Committing to Net Zero Global Transparency Report 2024 Menu Careers Careers Find out more about careers Search for a job Menu Careers Find out more about careers Menu Careers Search for a job Featured PwC’s Global Annual Review Committing to net zero The CEO’s ESG dilemma Loading Results No Match Found View All Results Designing, building and operating AI that delivers real-world impact Responsible AI Artificial intelligence is transforming business by streamlining activities, enhancing customer offerings, making workers more effective and speeding up innovation—prompting executives to deploy intelligent applications and agentic systems."
554,"How Responsible AI can improve business and preserve value | PwC Skip to content Skip to footer Industries Services Issues About us Careers More Search Menu Industries Industries See all industries Consumer markets Energy, utilities and resources Financial services Government and public sector Health industries Industrials and services Private equity and principal investors Technology, media and telecommunications Menu Industries See all industries Menu Industries Consumer markets Consumer goods Hospitality and leisure Retail Transportation and logistics Menu Industries Energy, utilities and resources Chemicals Mining and metals Oil and gas Power and utilities Menu Industries Financial services Asset and wealth management Banking and capital markets Insurance Real estate Menu Industries Government and public sector Defence Education and skills Public safety, justice and security Menu Industries Health industries Health services Pharmaceuticals and life sciences Menu Industries Industrials and services Aerospace, defence and security Automotive Business services Engineering and construction Industrial manufacturing Space Menu Industries Private equity and principal investors Capital projects and infrastructure Menu Industries Technology, media and telecommunications Entertainment and media Technology Telecommunications Featured Value in motion Industry edge Engine by Starling: From launching a bank to launching a software business Menu Services Services See all services Alliances Artificial Intelligence Audit and assurance services Business model reinvention Business transformation Consulting Crisis management Deals Entrepreneurial and private business Family business Forensics Legal business solutions Managed Services Risk services Strategy Sustainability and climate change Tax Trust Workforce Menu Services See all services Menu Services Alliances Menu Services Artificial Intelligence Menu Services Audit and assurance services Actuarial services Capital markets Corporate reporting Financial audit IFRS Internal audit Next Generation Audit Risk assurance Sustainability assurance Menu Services Business model reinvention Menu Services Business transformation Menu Services Consulting Cloud transformation Digital operations Deals Finance transformation Forensics Front office transformation HR transformation Risk and regulation Strategy Technology Workforce Menu Services Crisis management Menu Services Deals Acquisitions Capital markets Corporate finance Deals strategy Joint ventures and alliances M&A legal M&A tax Performance and Restructuring​ Sovereign wealth funds Menu Services Entrepreneurial and private business Menu Services Family business Menu Services Forensics Menu Services Legal business solutions Employment Entity governance and compliance International business reorganisations Mergers and acquisitions NewLaw Menu Services Managed Services Menu Services Risk services Menu Services Strategy Menu Services Sustainability and climate change Climate risk, resilience and adaptation Energy solutions Impact management for sustainable business strategy Legal and sustainability Net zero transformation Social sustainability Sustainability assurance Sustainable capital Sustainability reporting Tax and sustainability Menu Services Tax Indirect taxes International tax services Mergers and acquisitions Sightline Tax code of conduct Tax controversy and dispute resolution Tax policy and administration Tax reporting and strategy Transfer pricing Menu Services Trust Menu Services Workforce Culture, leadership and change Inclusion Employment law Employment tax and payroll HR transformation and technology Organisational design People analytics and insights People in deals Retirement and pensions Reward and benefits Workforce risk Workforce strategy Featured Climate risk, resilience and adaptation Business transformation Sustainability assurance Menu Issues Issues See all issues Business model reinvention Business transformation C-suite insights Cybersecurity Climate and sustainability Megatrends Risk and regulation Technology Trust Upskilling Workforce Menu Issues See all issues Menu Issues Business model reinvention Menu Issues Business transformation Menu Issues C-suite insights Accelerating performance Global CEO Survey PwC at Davos strategy+business digital issue Take on Tomorrow: a strategy+business podcast The Leadership Agenda Menu Issues Cybersecurity Menu Issues Climate and sustainability Menu Issues Megatrends Menu Issues Risk and regulation Menu Issues Technology Menu Issues Trust Menu Issues Upskilling Menu Issues Workforce Featured Value in motion PwC’s 28th Annual Global CEO Survey The Fearless Future: 2025 Global AI Jobs Barometer Menu About us About us See more About Us Alumni Analyst relations Client case studies Ethics and compliance Committing to Net Zero Corporate sustainability Inclusion PwC's Global Annual Review Global regulatory affairs Human rights policy Network Leadership, Governance, and Structure New Ventures and Innovation News room Purpose, values and behaviours PwC office locations PwC's Code of Conduct Strategy& Tax Code of Conduct Third party code of conduct Transparency Report Menu About us See more About Us Menu About us Alumni Menu About us Analyst relations Menu About us Client case studies Menu About us Ethics and compliance Menu About us Committing to Net Zero Menu About us Corporate sustainability Menu About us Inclusion Menu About us PwC's Global Annual Review Menu About us Global regulatory affairs Menu About us Human rights policy Menu About us Network Leadership, Governance, and Structure Menu About us New Ventures and Innovation Menu About us News room Menu About us Purpose, values and behaviours Menu About us PwC office locations Menu About us PwC's Code of Conduct Menu About us Strategy& Menu About us Tax Code of Conduct Menu About us Third party code of conduct Menu About us Transparency Report Featured Value in motion Committing to Net Zero Global Transparency Report 2024 Menu Careers Careers Find out more about careers Search for a job Menu Careers Find out more about careers Menu Careers Search for a job Featured PwC’s Global Annual Review Committing to net zero The CEO’s ESG dilemma Loading Results No Match Found View All Results Designing, building and operating AI that delivers real-world impact Responsible AI Artificial intelligence is transforming business by streamlining activities, enhancing customer offerings, making workers more effective and speeding up innovation—prompting executives to deploy intelligent applications and agentic systems."
557,"It has litigated or intervened in cases implicating the right to privacy in the courts of the United States, the UK, and Europe, including the European Court of Human Rights and the European Court of Justice."
559,Department of Justice.
560,"Yet, they pose many threats and concerns, including to our privacy and social justice."
560,"4.4.2 POTs: Protective Optimization Technologies Carmela Troncoso, Bogdan Kulynych, Rebeka Overdorf, and Seda G urses Although the rise of AI has undoubtedly improved our everyday lives in the past decades in many ways, we have also become increasingly aware of the severe risks it poses to our privacy and social justice."
563,"Four of them are core principles commonly used in bioethics: beneficence, non-maleficence, autonomy, and justice."
563,"In the ensuing discussion, we note the limitations and assess the implications of this ethical framework for future efforts to create laws, rules, technical standards, and best practices for ethical AI in a wide range of contexts.Keywords: accountability, autonomy, artificial intelligence, beneficence, ethics, explicability, fairness, intelligibility, justice, non-maleficence.1."
563,"This convergence can most clearly be shown by comparing the sets of principles with the four core principles commonly used in bioethics: beneficence, non-maleficence, autonomy, and justice (Beauchamp & Childress, 2012)."
563,"Justice: Promoting Prosperity, Preserving Solidarity, Avoiding UnfairnessThe decision to make or delegate decisions does not take place in a vacuum."
563,The consequences of this disparity in autonomy are addressed in the principle of justice.
563,"The importance of ‘justice’ is explicitly cited in the Montreal Declaration, which argues that “the development of AI should promote justice and seek to eliminate all types of discrimination,” while the Asilomar Principles include the need for both “shared benefit” and “shared prosperity” from AI."
563,"Under its principle named “Justice, equity and solidarity,” the EGE argues that AI should “contribute to global justice and equal access to the benefits” of AI technologies."
563,"It also warns against the risk of bias in datasets used to train AI systems, and – unique among the documents – argues for the need to defend against threats to “solidarity,” including “systems of mutual assistance such as in social insurance and healthcare.” Elsewhere ‘justice’ has still other meanings (especially in the sense of fairness), variously relating to the use of AI to correct past wrongs such as eliminating unfair discrimination, promoting diversity, and preventing the rise of new threats to justice."
563,"The diverse ways in which justice is characterised hints at a broader lack of clarity over AI as a human-made reservoir of ‘smart agency.’ Put simply, are we (humans) the patient, receiving the ‘treatment’ of AI, the doctor prescribing it?"
563,"This list was designed by consensus of a large diverse interdisciplinary committee to give the public something better than Asimov’s Laws (which covered beneficence & justice), but extended to five in order to bring in transparency and accountability."
57,"But while like goes Artificial Intelligence: Australia’s Ethics Framework (A Discussion Paper) Page 7 with like, justice sometimes demands that different situations be treated differently."
57,"Even when the information is not flawed, if the priorities of the system are not aligned with expectations of fairness, then the system can deliver negative outcomes. - Justice means that like situations should deliver like outcomes, but different situations can deliver different outcomes."
57,"It also highlighted the f act that ethics frameworks on their own are not enough, because concrete actions need to be taken to ensure accountability and justice."
57,"This technology could be especially useful in industries that require decision makers to generate frequent, accurate and replicable predictions and judgements such as the areas of justice, policing and med icine."
57,Miscarriages of justice are frequently attributable to human error or misconduct.
57,"E ven when the information is not flawed, if the priorities of the system are not aligned with expectations of fairness, then the system can deliver negative outcomes. - Justice means that like situations should deliver like outcomes, but different situations can deliver different outcomes."
57,Available from: https://ec .europa.eu/commission/priorities/justice -and-fundamental -rights/data -protection/2018 reform -eu-data -protection -rules_en .
57,Hungry judges dispense rough justice.
58,"But while like goes Artificial Intelligence: Australia’s Ethics Framework (A Discussion Paper) Page 7 with like, justice sometimes demands that different situations be treated differently."
58,"Even when the information is not flawed, if the priorities of the system are not aligned with expectations of fairness, then the system can deliver negative outcomes. - Justice means that like situations should deliver like outcomes, but different situations can deliver different outcomes."
58,"It also highlighted the f act that ethics frameworks on their own are not enough, because concrete actions need to be taken to ensure accountability and justice."
58,"This technology could be especially useful in industries that require decision makers to generate frequent, accurate and replicable predictions and judgements such as the areas of justice, policing and med icine."
58,Miscarriages of justice are frequently attributable to human error or misconduct.
58,"E ven when the information is not flawed, if the priorities of the system are not aligned with expectations of fairness, then the system can deliver negative outcomes. - Justice means that like situations should deliver like outcomes, but different situations can deliver different outcomes."
58,Available from: https://ec .europa.eu/commission/priorities/justice -and-fundamental -rights/data -protection/2018 reform -eu-data -protection -rules_en .
58,Hungry judges dispense rough justice.
582,"AI can find broad applications in such fields as education, medical treatment, eldercare, environmental protection, city operation, and justice services, and it is able to greatly improve the precision level of public services and increase the quality of people’s lives across the board."
584,Court of Appeals for the Second Circuit and Justice David H.
584,"Mariano-Florentino Cuéllar is a Justice on the Supreme Court of California, the Herman Phleger Visiting Professor of Law at Stanford University, and a faculty affiliate at the Stanford Center for AI Safety."
584,"We also appreciate superb editorial assistance and dedicated research support from three members of Justice Cuéllar’s staff: Ryan Azad, Alexandra Havrylyshyn, and Mikayla Hardisty."
584,"A large number of use cases fell under health- and law-enforcement-focused subagencies such as the Food and Drug Administration, the Office of Justice Programs, and the Transportation Safety Administration and Customs and Border Protection."
584,"As a result, the Department of Health and Human Services, the Department of Justice, and the Department of Homeland Security account for a collective 51 use cases."
584,TOP TEN AGENCIES AND SUBAGENCIES BY NUMBER OF USE CASES Agency NameNumber of Use Cases Office of Justice Programs 12 Securities and Exchange Commission 10 National Aeronautics and Space Administration 9 Food and Drug Administration 8 United States Geological Survey 8 United States Postal Service 8 Social Security Administration 7 United States Patent and Trademark Office 6 Bureau of Labor Statistics 5 Customs and Border Protection 4 Table 2: The above list excludes overarching department-level agencies.
584,"For example, the Department of Health and Human Services (19 use cases), the Department of Justice (16 use cases), and the Department of Homeland Security (16 use cases) have been refactored into respective sub-agencies (e.g., the Food and Drug Administration, the Office of Justice Programs, and Customs and Border Protection)."
584,"Others, such as the Federal Bureau of Investigation Terrorist Screening Database and the Department of Justice National Crime Information Center, come from peer agencies."
584,"While the foregoing cannot possibly do justice to ongoing debate about the proper role of technology-enabled surveillance, it is a crucial debate to have. * * * * In sum, AI/ML tools may, as in CBP’s case, significantly expand an agency’s scope and reach and enable it to make agency operations more efficient and accurate."
584,"Loomis, the Wisconsin Supreme Court did not find a due process violation when gender was used in a criminal risk assessment score, finding that the “use of gender promotes accuracy that ultimately inures to the benefit of the justice system.”101 Due to the doctrinal uncertainty, states and localities using criminal risk assessment scores remain split in whether they rely on gender.102 To the extent that the machine learning literature calls for awareness of protected attributes to promote fairness, it is on a collision course with equal protection doctrine."
584,"2013), https://www.governing.com/topics/public-justice-safety/gov-social-media-transforms-chicago-policing.html."
584,"Dep’t of Justice, Exec."
584,"68 Linesight: Advanc ed Targeting Analytics Solution for Border Security, Unisys, https://www.unisys.com/offerings/industry-solutions/public-sector-industry-solutions/justice-law-enforcement-and-border-security-solutions/linesight (last visited Apr 7, 2019)."
584,"Mashaw, Bureaucratic Justice: Managing Social Security Disabilit y Claims (1985); David Ames, Cassandra Handan-Nader, Daniel E."
584,11 Some 390 Immigra tion Judges work for the Executive Office of Immigration Review in the Department of Justice and decide immigration cases.
584,"Immigration Judge, Dep’t of Justice (June 9, 2017), https://www.justice.gov/legal-careers/job/immigration-judge; 4 Executive Off. for Immigration Review & Nat’l Ass’n of Immigration Judges, Labor Agreement Between the National Association of Immigration Judges and U.S."
584,"Dep’t of Justice, Executive Off. for Immigration Review Art."
584,"One of the more interesting arguments for “internal” constraints on algorithmic decision-making is that, while marquee uses of algorithmic decisions systems—e.g., the criminal justice context—will draw certain judicial scrutiny."
584,"Mashaw, Bureaucratic Justice: Managing Social Security (1985)."
584,"101, 109 (2019); Rebecca Wexler, Life, Liberty, and Trade Secrets: Intellectual Property in the Criminal Justice System, 70 Stan."
584,"T yler, What Is Procedural Justice?: Criteria Used by Citizens to Assess the Fairness of Legal Procedures 22 L. & Soc."
584,"Mashaw, Bureaucratic Justice: Managing Social Security Disabilit y Claims (1983)."
584,"124 Eugene V olokh, Chief Justice Robots, 68 Duke L.J."
589,"123 “The Federal government should therefore emphasize AI investments in areas of strong societal impor tance that are not aimed at consumer markets —areas such as AI for public health, urban systems and smart communities, social welfare, criminal justice, environmental sust ainability, and national security, as well as long -term research that accelerates the production of AI knowledge and technologies.” 124 The following subareas are described in the plan: Data analysis; Perception; Theoretical limitations for AI; General AI; Scalable AI; Human -like AI; Robotics; AI Hardware 125 Sub -areas: Human -AI communication; Strengthening of human ability; Natural language processing; Interface and visualisation."
591,"PAGE 5STEP 1: DATA GENERATION AND ACQUISITION JUSTICE The recommendations based on justice are intended to ensure reciprocity, so that when data are collected, subjects are offered benefits that are proportionate to the data you request."
591,"With reference to the basic orientation of justice, the physician can convince Patient U. as follows: – She shows the patient the individual benefit: with the EPD, access to docu ments relevant to treatment is guaranteed at all times, and duplicate or un necessary treatments can be avoided. – She makes it clear to the patient that he or she can determine who has access to which health data."
591,PAGE 11STEP 2: DATA STORAGE AND MANAGEMENT JUSTICE Justice requires enabling customers to use their data for the benefit of third parties and the common good.
591,Source: https:// deepmind.com/blog/article/specifying-ai-safety-problems PAGE 17STEP 3: DATA ANALYSIS AND KNOWLEDGE GENERATION JUSTICE The recommendations on justice address the problem of indirect discrimination as it relates to data-based models and predictions.
591,PAGE 23STEP 4: USE OF DATA-BASED PRODUCTS AND SERVICES JUSTICE Justice requires ensuring that the use of data-based products and services does not lead to undesirable social effects such as indirect discrimination or the stigmatisation or exclusion of groups of people.
591,"If the app were made compulsory, or even linked to significant social advantages (such as the right to use public transportation), not knowing what groups are notified and inequalities in the rate of false positives would imply ignoring important elements about justice in deployment."
591,"Thus, the app as designed protects privacy, but prevents the collection on information relevant to the justice implications of the app’s use and functionality."
591,There is thus a tension between justice and privacy in the deployment of the app.
592,"PAGE 5STEP 1: DATA GENERATION AND ACQUISITION JUSTICE The recommendations based on justice are intended to ensure reciprocity, so that when data are collected, subjects are offered benefits that are proportionate to the data you request."
592,"With reference to the basic orientation of justice, the physician can convince Patient U. as follows: – She shows the patient the individual benefit: with the EPD, access to docu ments relevant to treatment is guaranteed at all times, and duplicate or un necessary treatments can be avoided. – She makes it clear to the patient that he or she can determine who has access to which health data."
592,PAGE 11STEP 2: DATA STORAGE AND MANAGEMENT JUSTICE Justice requires enabling customers to use their data for the benefit of third parties and the common good.
592,Source: https:// deepmind.com/blog/article/specifying-ai-safety-problems PAGE 17STEP 3: DATA ANALYSIS AND KNOWLEDGE GENERATION JUSTICE The recommendations on justice address the problem of indirect discrimination as it relates to data-based models and predictions.
592,PAGE 23STEP 4: USE OF DATA-BASED PRODUCTS AND SERVICES JUSTICE Justice requires ensuring that the use of data-based products and services does not lead to undesirable social effects such as indirect discrimination or the stigmatisation or exclusion of groups of people.
592,"If the app were made compulsory, or even linked to significant social advantages (such as the right to use public transportation), not knowing what groups are notified and inequalities in the rate of false positives would imply ignoring important elements about justice in deployment."
592,"Thus, the app as designed protects privacy, but prevents the collection on information relevant to the justice implications of the app’s use and functionality."
592,There is thus a tension between justice and privacy in the deployment of the app.
593,"Skip to main content Skip to ""About Canada.ca"" Language selection Françaisfr Search CanadaBuys Search Canada.ca Menu Main Menu Home Jobs and the workplace Immigration and citizenship Travel and tourism Business and industry Benefits Health Taxes Environment and natural resources National security and defence Culture, history and sport Policing, justice and emergencies Transport and infrastructure Canada and the world Money and finances Science and innovation Mid Level Menu Account access CanadaBuys Menu Home Getting started Tender opportunities How procurement works Buyer’s Portal Support Account access You are here Canada.ca CanadaBuys home CanadaBuys CanadaBuys Welcome to the home for doing business with the Government of Canada and the broader Canadian public sector."
604,"In addition, special attention needs to be paid to transparency and accessibility of information on the training data used for the development of an AI system. ” 11 ∼ “AI actors should promote social justice, by safeguarding fairness and non -discrimination of any kind in compliance with international law."
604,"11 Council of Europe Commissioner for Human Rights (2019) – “Unboxing AI: 10 steps to protect Human Rights” 27 the least advanced to ensure that the benefits of AI technologies are shared such that access to and participation in the AI system life c ycle for the latter contributes to a fairer world order with regard to information, communication, culture, education, research, and socio -economic and political stability...AI actors should promote social justice and safeguard fairness and non-discriminat ion of any kind in compliance with international law."
604,"This should also include the possibility of receiving insight into and challenging AI- informed decisions in the context of law enforcement or justice, including the right to review of such decisions by a human."
604,"AI can increase the efficiency International Covenant on Civil and Political Rights: -Article 2, International Covenant on Civil and Political Rights – Right to effective remedy -Article 14, International Covenant on Civil and Political Rights – Right to fair tri al Council of Europe Resources: -European Commission for the Efficiency of Justice, ‘European ethical charter on the use of Artificial Intelligence in judicial systems and their environment’ – Council of Europe 22 CAHAI Feasibility Study , Council of Europe CAHAI (2020)23."
604,"Washington, DC: US De partment of Justice, Office of Justice Programs, Office of Juvenile Justice and Delinquency Prevention. ; Sorooshian, S., & Mun, S."
604,"59 Use context (Questions 1 -20) • Sector or domain in which the system is being built • Existing law and regulatory environment of the sector or domain • Impact-level of the system • Prohibited systems and uses • Scope of deployment (breadth and temporality) • Technological maturity • Existing system (human or technological) that the application is replacing • Bias and discrimination in sector or domain context • Environmental context • Cybersecurity context Data Lifecycle Context (Questions 21 -40) • Data quality, integrity, and provenance • Means and methods o f data collection • Data types • Dataset linkage • Data labelling and annotating practices Goal Setting and Problem Formulation Context (Questions 41 -42) • Decision to design • Definition of outcome Model Design & Development Context (Questions 43 -46) • AI model characteristics • Pre-processing and feature engineering • Model selection Model Output & Implementation Context (Questions 47 -52) • Model inference • Model verification and validation • Model accuracy and performance metrics System -User Interface and Human Factors Context (Questions 53 -55) • Implementers or users of the system • Level of automation/level of human involvement and choice Rights & Freedoms Context (Questions 56 -71) • Respect for and protection of human dignity • Protection of human freedom and autonomy • Non-discrimination, fairness, and equality • Data protection and privacy context • Accountability and access to justice • Social and economic rights 60 Depending on the form that the section one questions take, certain responses to each question will trigger one of three classes of risk factors, prohibitive, major, or moderate: Prohibitive risk factor Prohibitive risk factors indicate the presence of determinants of potential harms that trigger the precautionary principle and precipitate preemptive measures to prevent adverse impacts on the human rights and fundamental freedoms of affected persons, democracy, and the rule of law."
604,NOT APPLICABLE : No message Accountability and access to justice 60) Will sufficient and transparently reported processes be implemented throughout the project’s lifecycle to ensure end -toend accountability across the production and use of the AI system?
604,"NOT APPLICABLE : No message 168 62) If the AI system is used in the field of justice and law enforcement, will meaningful information be provided to affected rights -holders about the existence and use of the system, its role within law enforcement and the judicial process, and the right to challenge the decisions informed or made thereby?"
604,"YES, WE HAVE PLANS IN PLACE TO DO THIS WE HAD NOT CONSIDERED IT, BUT MAY DO THIS WE HAD NOT CONSIDERED IT, BUT ARE UNLIKELY TO DO THIS NO, WE ARE NOT PLANNING TO DO THIS UNSURE NOT APPLICABLE Example YES, WE HAVE PLANS IN PLACE TO DO THIS : No message WE HAD NOT CONSIDERED IT, BUT MAY DO THIS / WE HAD NOT CONSIDERED IT, BUT ARE UNLIKELY TO DO THIS / NO, WE ARE NOT PLANNING TO DO THIS: Major modifiable risk factor • Where AI system are being used in the field of justice and law enforcement and meaningful information is not provided to affected rights -holders about the existence and use of the system, its role within law enforcement and the judicial process, and the right to challenge the decisions informed or made thereby, this presents a major modifiable risk factor for adverse impacts on the human rights and fundamental freedom of persons."
604,"NOT APPLICABLE : No message 63) If the AI system is used in the field of justice and law enforcement, will sufficiently and transparently reported processes be implemented throughout the project’s lifecycle to ensure that its deployment is in line with the essential requirements of impac ted individuals' right to a fair trial (equality of arms, right to a natural YES, WE HAVE PLANS IN PLACE TO DO THIS : No message WE HAD NOT CONSIDERED IT, BUT MAY DO THIS / WE HAD NOT CONSIDERED IT, BUT ARE UNLIKELY TO DO THIS / NO, WE ARE NOT PLANNING TO DO THIS: Major modifiable risk factor 170 judge established by law, the right to an independent and impartial tribunal, and respect for the adversarial process)?"
604,"YES, WE HAVE PLANS IN PLACE TO DO THIS WE HAD NOT CONSIDERED IT, BUT MAY DO THIS WE HAD NOT CONSIDERED IT, BUT ARE UNLIKELY TO DO THIS NO, WE ARE NOT PLANNING TO DO THIS UNSURE NOT APPLICABLE Example • Where AI system are being used in the field of justice and law enforcement and sufficiently and transparently reported processes are not implemented throughout the project’s lifecycle to ensure that its deployment is in line with the essential requirements of impacted individuals' right to a fair trial (equality of arms, right to a natural judge established by law, the right to an independent and impartial tribunal, and respect for the adversarial process), this presents a major modifiable risk factor for adverse impacts on the human rights and fundamental freedom of persons."
604,"FAIRNESS is insepara bly connected with sociolegal conceptions of equity and justice , which may emphasize a variety of features such as non-discrimination , equit able outcomes, or procedural fairness through bias mitigation , but also social and economic equality, diversity, and inclusivenes s."
604,"But, beyond this, diligent consideration of the practical, social, or policy issue being addressed by the system will also trigger, inter alia , reflection on the complex intersection of potential algorithmic bias, the cascading effects of sociohistorical patterns of racism and discrimination, wider societal and community impacts, and the potential effects of the use of the model on the actors in the criminal justice systems who will become implementers and subjects of the technology."
604,"In race and social justice discourse, members of society are marginalised by holding an identity or being placed in a demographic category that is not attached to the dominant side of the prevailing structure of power and by which they experience oppression ."
604,"Pre-designated High- Risk or Safety Critical Sector: Annex III of the European Union Proposed Rules on Artificial Intelligence indicates ‘high-risk’ sectors as those concerned with education, emergency services, employment, financial services, public benefits , law enforcement, immigration, border control, and the administration of justice and democratic processes ."
604,(2018). 'It's reducing a human being to a percentage': Perceptions of justice in algorithmic decisions.
604,Algorithmic accountability and digital justice: A critical assessment of technical and sociotechnical approaches.
604,Optimized scoring systems: Toward trust in machine learning for healthcare and criminal justice.
605,"Formulating it as a question : What are each of these values charging you to do? → RESPECT the dignity of individual persons: • Ensure their abilities to make free and informed decisions about their own lives • Safeguard their autonomy, their power to express themselves, and their right to be heard • Secure their capacities to make well-considered and independent contributions to the life of the community • Support their abilities to flourish, to fully develop th emselves , and to pursue their passions and talents according to their o wn freely determined life plans → CONNECT with each other sincerely, openly, and inclusively : • Safeguard the integrit y of interpersonal dialogue, meaningful human connection , and social cohesion • Prioritise diversity, participation, and inclusion at all points in the design, development, and deployment processes of AI innovation . • Encourage all voices to be heard and all opinions to be weighed seriously and sincere ly throughout the production and use lifecycle • Use the advancement and proliferation of AI technologies to strengthen the developmentally essential relationship between interacting human being s. • Utilise AI innovation s pro-socially so as to enable bonds of interpersonal solidarity to form and individuals to be socialised and recognised by each other • Use AI technologies to foster this capacity to connect so as to reinforce the edifice of trust, empathy, reciprocal responsibility, and mutual understanding upon which all ethically well founded social orders rest → CARE for the wellbeing of each and all : • Design and deploy AI systems to foster and to cultivate the welfare of all stakeholders whose interests are affected by their use • Do no harm with these technologies and minimise the risks of their misuse or abuse Understanding Artificial Intelligence Ethics and Safety 11 • Prioritise the safety and the mental and physical integri ty of people when scanning horizon s of technological possibility and when conceiving of and deploying AI applications → PROTECT the priorities of social values, justice, and the public interest : • Treat all individuals equally and protect social equity • Use digital technologies as a n essential support for the protection of fair and equal treatment under the law • Prioritise social welfare, public interest, and the consideration of the social and ethical impacts of innovation in determining the legitimacy and desirability of AI technologies • Use AI to empower and to advance the interests and well -being of as many individuals as possible • Think big -picture about the wider impacts of the AI technologies you are conceiving and developing."
605,Ethical considerations about looking after patient wellbeing and clinical safety are paramount and wider justice c oncerns about improving healthcare for all and health equity factor in as well.
605,I am also incredibly grateful for the impact that our interactions with the Ministry of Justice (MoJ)’s Data Science Hub has had on developing the framing for this guide.
605,(2018). 'It's reducing a human being to a percentage': Perceptions of justice in algorithmic decisions.
605,Optimized scoring systems: Toward trust in machine learning for healthcare and criminal justice.
605,"Criminal Justice and Behavior , 46(2), 185 -209."
605,Data Justice Lab.
605,"Dirty data, bad predictions: How civil rights violations impact police data, predictive policing systems, and justice."
606,"The specific human rights implications for AI systems can be viewed through provisions of the European Convention of Human Rights (ECHR) and the European Social Charter (ESC), including its specific guarantees regarding liberty and justice, privacy, freedom of expression, equality and non-discrimination, and social and economic rights."
606,"Liberty and Justice: AI can adversely affect the liberty and justice of individuals, particularly when implemented in high impact contexts such as criminal justice."
606,"NONDISCRIMINATION, GENDER EQUALITY, FAIRNESS & DIVERSITY-The right to non-discrimination (on the basis of the protected grounds set out in Article 14 of the ECHR and Protocol 12 to the ECHR), including intersectional discrimination. -The right to non-discrimination and the right to equal treatment. -AI systems can also give rise to unjust categorisation based on new types of differentiation that are not traditionally protected. -This right must be ensured in relation to the entire lifecycle of an AI system (design, development, implementation, and use), as well as to the human choices concerning AI design, adoption, and use, whether used in the public or private sector. -Member States are obliged to ensure that the AI systems they deploy do not result in unlawful discrimination, harmful stereotypes (including but not limited to gender stereotypes), and wider social inequality, and should therefore apply the highest level of scrutiny when using or promoting the use of AI systems in sensitive public policy areas, including but not limited to law enforcement, justice, asylum and migration, health, social security, and employment. -Member States should include nondiscrimination and promotion of equality requirements in public procurement processes for AI systems and ensure that the systems are independently audited for discriminatory effects prior to deployment. -Member States should impose requirements to effectively counter the potential discriminatory effects of AI systems deployed by both the public and private sectors and protect individuals from the negative consequences thereof."
606,"This should also include the possibility of receiving insight into and challenging AIinformed decisions in the context of law enforcement or justice, including the right to review of such decision by a human. -The right to judicial independence and impartiality, and the right to legal assistance. -The right to an effective remedy (Art."
606,"13 ECHR), also in case of unlawful harm or breach an individual’s human rights in the context of AI systems.-Member States must ensure that AI systems used in the field of justice and law enforcement are in line with the essential requirements of the right to a fair trial."
606,"Such information must especially be provided when AI systems are used in the field of justice and law enforcement, both as concerns the role of AI systems within the process, and the right to challenge the decisions informed or made thereby. -Member States should ensure that use of AI systems does not interfere with the decisionmaking power of judges or judicial independence and that any judicial decision is subject to meaningful human oversight."
606,"We hope that, taken together, this material can function as a kind of launching pad for meaningful reflection on the prospects for a principles-based legal framework for governing AI research and innovation in accordance with the Council of Europe's stewardship of fundamental rights and freedoms, justice, and democratic values."
606,"Policy makers, scholars, and activists are tasked with proposing and critiquing strategies and actions aimed at promoting general well-being and social justice."
606,"Work in the field of justice 4 3European Committee on Democracy and Governance (CDDG) Currently preparing a study on the impact of digital transformation on democracy and governance Venice Commission: Principles for a fundamental rights-compliant use of digital technologies in electoral processes (2020) Emphasised the need for a human rights-compliant approach to eight principles involving the use of digital technologies in elections The eight principles are described in greater detail in the document, but they are outlined below and have been taken directly from the original document 1."
609,"ArticleSCIENCE + TECHNOLOGYWith great power comes great responsibility – but will tech companies accept it?23 Nov 18 DebateIQ2IQ2 Debate: Humanity is Designing its Own Demise28 Oct 17 ArticleSCIENCE + TECHNOLOGYThe “good enough” ethical setting for self-driving cars19 Jul 16 Say Hello GET IN TOUCH SUBSCRIBE FOLLOW US With respect for the people of our First Nations and the justice of their claims, The Ethics Centre acknowledge their unbroken care for country, since time immemorial."
612,"The relevant concepts include freedom and self-determination, privacy and intimacy, sovereignty and power, beneficence and non-maleficence, as well as justice, solidarity and responsibility."
612,73) The collection and transmission of large volumes of health-relevant data touches on fundamental questions of justice.
612,"As a normalising principle of social relations, justice demands that the arbitrary privi-leging of certain persons or groups be avoided."
612,"25 25 ExEcutIvE Summary 74) As regards big data applications in the healthcare sector, four sets of problems stand out as especially relevant to questions of justice: first, access to datasets for the research sector; second, the insidious con-solidation of monopolistic structures; third, the inclusion of health apps, as well as various devices that facilitate private self-tracking, in determining health insurance premiums; and fourth, aspects of social justice, understood in terms of the capabilities approach, as they concern the responsible handling of health-relevant data."
612,Solidarity is frequently understood as complimentary to – and often subsidiary to – the concept of justice.
612,The shaping of such freedom is responsible when it also orients itself towards the legal and societal demands of solidarity and justice.
612,"These aim to, firstly, realise the potentials of big data; secondly, to ensure individual freedom and privacy; thirdly, to ensure justice and solidarity; and fourthly, to promote responsibility and trust."
612,Ensure justice and solidarity C1.
612,"To do justice to the complexity and significance of this issue, for example, companies and institutions could expand their efforts to establish internal data science departments."
617,"The mission of the Data Science Initiative is to harness the value of data science and artificial intelligence for peace, justice and security."
617,"79 Hackathon for Peace, Justice and Security, The Hague, (2018, 2019) www.hackathonforgood.org."
620,"Technologists should understand the consequences of incorrect predictions, especially when automating critical processes that can have significant impact in human lives (e.g. justice, health, transport, etc)."
627,"This policy brief is based on the Dutch report Big Data in een vrije en veilige samenleving (Big Data in a Free and Secure Society), presented by wrr to Ard van der Steur, the Dutch Minister for Security and Justice, on 28 April 2016."
627,"The gdpr will not be applicable to the police and justice sector, whose work will be regulated by national legislation to be based on the new eu Police and Criminal Justice Data Protection Directive.56 Fundamental rights and security exceptions The regulation of data protection and privacy is founded on fundamental rights that are enshrined in treaties such as the European Convention on Human Rights ( echr ) and the Charter of Fundamental Rights of the European Union."
627,"Table 9.1 Legal frameworks Constitutional framework International Covenant on Civil and Political Rights ( iccpr ) European Convention for the Protection of Human Rights and Fundamental Freedoms ( echr ) Charter of Fundamental Rights of the European Union Constitution of the Netherlands Police and judiciary Code of Criminal Procedure (WvSv) Judicial Data and Criminal RecordsAct (Wjsg)Police Data Act (Wpg)Special Investigative Services Act(Wet bod) Police and Criminal Justice Data ProtectionDirective ( eu) 2016/680Intelligence and security services Intelligence and Security Services Act (Wiv 2002)Government (other agencies) Personal Data Protection Act (Wbp)Data Protection Directive (95/46/ ec) General Data Protection Regulation( eu) 2016/679 Law enforcement and public prosecuting authorities operate under their own legal framework, often with specific laws regulating the collection, exchange and use of data within the police organisation and the wider law enforcement community."
627,27 process to shift to the European Court of Human Rights and the European Court of Justice.
63,"Ideal for small agencies.TASER X26PA single-shot TASER Smart Weapon.CIVILIAN SERIESShop TASER products designed for personal and home use.MoreCamerasAxon Body 4The next-generation body worn cameraAxon Body 3See truth in the momentAxon Body WorkforceSafety in every shift for frontline workers.Axon Fleet 3Drive the future of in-car videoAxon Flex 2Capture point-of-view video evidence in HD with a 120-degree field of view.Axon AirImprove officer safety, provide tactical support, and reconstruct scenes.MoreSoftwareAxon EvidenceStreamline management, storage and sharing of all your digital evidence.Axon RecordsSwitch to one dynamic, integrated report that allows officers to focus on what matters.Axon RespondReal-time situational awareness through your Axon devices.Axon DispatchA faster, more informed CAD experience.MoreView All ProductsTrainingAxon AcademyVirtual learning platform for end-user product trainingVR TrainingTraining for the reality of todayAxon TrainingInnovative training technologies, content and peer networksIndustriesLaw EnforcementMunicipal, county, and state law enforcement agenciesFederalFederal civilian and defense departments and agenciesCorrectionsPrisons, probation and parole, and juvenile justice FireFire response and investigationEMSFirst Responders and emergency medical professionalsCampusCampus law enforcement and school safety teams JusticeLegal teams including DAs and prosecutorsHealthcareHospitals and other healthcare facilities RetailRetail trade, food and beverage, and other shopping establishments Private SecurityGuard services, venues and other on-site businessesPersonal SafetyTASER devices for personal protection and self-defenseView All IndustriesProductsSolutionsTrainingCareersNewsResourcesSupportProductsProduct BundlesSmart WeaponsCamerasSoftwareView All ProductsResourcesResourcesEventsPartnersProducts / Resources /CompanyOverviewLeadershipNewsInvestorCareersContactIndustriesSolutionsLaw EnforcementFederalCorrectionsFireEMSCampusJusticeHealthcareRetailPrivate SecurityPersonal SafetyTrainingAxon AcademyVR TrainingAxon TrainingNews & Resources TechnologyAxon Committed to Listening and Learning So That We can Fulfill our Mission to Protect Life, TogetherJun 05, 2022Rick SmithAxon CEO + FounderJun 05, 2022Axon was founded on our mission to protect life."
633,"Regarding these rights, we focus on issues relating to the right to respect private life, human dignity, ownership, safety and liability, freedom of expression and the prohibition of discrimination as well as acc ess to justice and the right to a fair trial."
633,39 3.8 Access to justice and the right to a fair trial ................................ ................................ ....
633,"The next three sections are dedicated to how automated decisions may affect freedom of expression, the prohibition of discrimination, access to justice and the right to a fair trial (sections 3.6, 3.7 and 3.8)."
633,"Intelligent artefacts may challenge different dimensions of human rights, for example in terms of freedoms (privacy and data protection, ownership, autonomy, personality), equality ( more specifically , non-discrimination) and justice (fair trial, access to justice)."
633,"Thus, the impact of intelligent artefacts is first discussed in the context of seven existing human rights: the right to respect for private and family life (3.2), the right to human dignity (3.3), the right to the peaceful enjoyment of possessions (3.4), tort rights and safety (3.5), the right to freedom of expression as well as the freedom of thought, conscience and religion (3.6), the prohibition of discrimination (3.7) and access to justice as well as the right to a fair trial (3.8)."
633,"18 Court of Justice of the European Union 19 October 2016, C -582/14 (Breyer ) and Court of Justice of the European Union 24 November 2011, C -70/10 (Scarlet/SABAM ), paragraph 51."
633,"For instance, o n an international level, both the European Court of Human Rights and the Court of Justice of the European Union have voiced their concerns on numerous occasions regarding state surveillance activi ties and the impact on privacy rights.25 For 21 The Dutch Data Protection Authority imposed penalty payments on a company that co uld not demonstrate that Wi -Fi tracking in public spaces was necessary for a legitimate purpose."
633,"21 instance when the EU Court of Justice declared the Data Retention Directive to be invalid.26 On a national level, the British Investigatory Powers Tribunal , for instance , ruled that during a time span of more than a decade, the British intelligence agencies illegally collected data about innocent citizens and illegally tracked their phone and web use.27 With regard to surveillance enacted by companies , the European Commission proposed the reform of EU data protect ion regulations , which ultimately led to the G eneral Data Protection Regulation ."
633,"Court of Justice of the European Union 8 April 2014, Joined Cases C -293/12 and C -594/12 ( Digital Rights Ireland and Seitlinger and Others )."
633,"See also: Court of Justice of the European Union 21 December 2016, Joined Cases C -203/15 ( Tele2 Sverige AB v Post -och telestyrelsen ) and C -698/15 ( Secretary of State for the Home Department v Tom Watson and Others )."
633,"28 For an overview of (a selec tion of) Court of Justice of the European Union and European Court of Human Rights cases, see Annex I of Article 29 Data Protection Working Party, Working Document 01/2016 on the justification of interferences with the fundamental rights to priva cy and dat a protection through surveillance measures when transferring personal data (European Essential Guarantees), 13 April 2016."
633,"In addition, wi th regard to decisions of the Court of Justice of the European Union concerning data protection, see: L."
633,These letters are available at: http://ec.europa.e u/justice/data -protection/article -29/documentation/other -document/index_en.htm .
633,42 3.8 Access to justice and the right to a fair trial Access to justice and the right to a fair trial Article 6 (2) ECHR plays an important role with regard to predictive AI .
633,"The increased use of risk -assessing algorithms in the American justice system raises accountability a nd transparency issues.100 It has been reported that software used to set bail , conditions for parole and sentencing decisions is biased against Afr ican Americans (Angwin et al."
633,"To give another example, in response to worries by consumers about Wi -Fi tracking by shop owners, the former Dutch minister of economic affairs and the state secretary of security and justice stated that people should just turn off their smartphone if they do not want to be tracked.102 On the basis of this response , it seems that tracking and tracing people is a right which is deemed more important than peoples’ (privacy) rights."
633,"Besides affecting the right to respect for private lif e in numerous ways, digiti sation, virtuali sation and roboti sation influence human dignity, the right to the peaceful enjoyment of possessions, safety and tort rights, the right to freedom of expression, the prohibition of discrimination, access to justice and the right to a fair trial."
633,Access to justice and the right to a fair trial (see subsection 3.8) The Council of Europe could establish a framework of minimum norms to be taken into account when a court uses AI.
633,"(2007) E-Justice, beginselen van behoorlijke elektronische rechtspraak, The Hague: SDu Uitgevers."
634,"Regarding these rights, we focus on issues relating to the right to respect private life, human dignity, ownership, safety and liability, freedom of expression and the prohibition of discrimination as well as acc ess to justice and the right to a fair trial."
634,39 3.8 Access to justice and the right to a fair trial ................................ ................................ ....
634,"The next three sections are dedicated to how automated decisions may affect freedom of expression, the prohibition of discrimination, access to justice and the right to a fair trial (sections 3.6, 3.7 and 3.8)."
634,"Intelligent artefacts may challenge different dimensions of human rights, for example in terms of freedoms (privacy and data protection, ownership, autonomy, personality), equality ( more specifically , non-discrimination) and justice (fair trial, access to justice)."
634,"Thus, the impact of intelligent artefacts is first discussed in the context of seven existing human rights: the right to respect for private and family life (3.2), the right to human dignity (3.3), the right to the peaceful enjoyment of possessions (3.4), tort rights and safety (3.5), the right to freedom of expression as well as the freedom of thought, conscience and religion (3.6), the prohibition of discrimination (3.7) and access to justice as well as the right to a fair trial (3.8)."
634,"18 Court of Justice of the European Union 19 October 2016, C -582/14 (Breyer ) and Court of Justice of the European Union 24 November 2011, C -70/10 (Scarlet/SABAM ), paragraph 51."
634,"For instance, o n an international level, both the European Court of Human Rights and the Court of Justice of the European Union have voiced their concerns on numerous occasions regarding state surveillance activi ties and the impact on privacy rights.25 For 21 The Dutch Data Protection Authority imposed penalty payments on a company that co uld not demonstrate that Wi -Fi tracking in public spaces was necessary for a legitimate purpose."
634,"21 instance when the EU Court of Justice declared the Data Retention Directive to be invalid.26 On a national level, the British Investigatory Powers Tribunal , for instance , ruled that during a time span of more than a decade, the British intelligence agencies illegally collected data about innocent citizens and illegally tracked their phone and web use.27 With regard to surveillance enacted by companies , the European Commission proposed the reform of EU data protect ion regulations , which ultimately led to the G eneral Data Protection Regulation ."
634,"Court of Justice of the European Union 8 April 2014, Joined Cases C -293/12 and C -594/12 ( Digital Rights Ireland and Seitlinger and Others )."
634,"See also: Court of Justice of the European Union 21 December 2016, Joined Cases C -203/15 ( Tele2 Sverige AB v Post -och telestyrelsen ) and C -698/15 ( Secretary of State for the Home Department v Tom Watson and Others )."
634,"28 For an overview of (a selec tion of) Court of Justice of the European Union and European Court of Human Rights cases, see Annex I of Article 29 Data Protection Working Party, Working Document 01/2016 on the justification of interferences with the fundamental rights to priva cy and dat a protection through surveillance measures when transferring personal data (European Essential Guarantees), 13 April 2016."
634,"In addition, wi th regard to decisions of the Court of Justice of the European Union concerning data protection, see: L."
634,These letters are available at: http://ec.europa.e u/justice/data -protection/article -29/documentation/other -document/index_en.htm .
634,42 3.8 Access to justice and the right to a fair trial Access to justice and the right to a fair trial Article 6 (2) ECHR plays an important role with regard to predictive AI .
634,"The increased use of risk -assessing algorithms in the American justice system raises accountability a nd transparency issues.100 It has been reported that software used to set bail , conditions for parole and sentencing decisions is biased against Afr ican Americans (Angwin et al."
634,"To give another example, in response to worries by consumers about Wi -Fi tracking by shop owners, the former Dutch minister of economic affairs and the state secretary of security and justice stated that people should just turn off their smartphone if they do not want to be tracked.102 On the basis of this response , it seems that tracking and tracing people is a right which is deemed more important than peoples’ (privacy) rights."
634,"Besides affecting the right to respect for private lif e in numerous ways, digiti sation, virtuali sation and roboti sation influence human dignity, the right to the peaceful enjoyment of possessions, safety and tort rights, the right to freedom of expression, the prohibition of discrimination, access to justice and the right to a fair trial."
634,Access to justice and the right to a fair trial (see subsection 3.8) The Council of Europe could establish a framework of minimum norms to be taken into account when a court uses AI.
634,"(2007) E-Justice, beginselen van behoorlijke elektronische rechtspraak, The Hague: SDu Uitgevers."
635,"Targeting interventions for ‘at risk’ groups Some of the most vulnerable individuals in society are often dealing with issues that cut across public services, including housing, health, and justice."
637,"Within a universal system additional resources can and should then be allocated according to specific needs (progressive universalism); 5. support a systemic qualification framework: shared approaches to professional preparation, qualification, • Practice(s) • Values At all levels of a Competent System, actors require a sound body of knowledge (e.g. about the purpose and aims of ECDEC, about children’s rights, democracy, about the importance of addressing diversity, equality, and social justice)."
637,"It is a crucial task to enable systematic encounters and democratic dialogue between all stakeholders in order to raise awareness of own and others’ values, and to work towards a shared orientation towards rights, equality, and social justice for all children and families."
637,"UNESCO, World Bank) Own historiy, culture, values individual and group identity Local knowledge(s) and practices Resistance Creativity ‘Grassroots’ Competent Systems: for social justice, diversity and equalityForward planning Better understanding Evaluation Research and critical inquiryCreative InventionImplementation Interpretation 39 38 The Future of Work and Education for the Digital AgeCentro de Estudios Sociales (CES)."
637,"He works and publishes widely on questions of diversity and equality, social justice, evaluation and professionalism in working with young children, families and communities in diverse socio-cultural contexts."
641,Perceived fairness of web‐ based applicant screening procedures: Weighing the rules of justice and the role of individual differences.
642,"Algorithmic Impact Assessment tool - Canada.ca Skip to main content Skip to ""About government"" Language selection Français fr / Gouvernement du Canada Search Search Canada.ca Search Menu Main Menu Jobs and the workplace Immigration and citizenship Travel and tourism Business and industry Benefits Health Taxes Environment and natural resources National security and defence Culture, history and sport Policing, justice and emergencies Transport and infrastructure Canada and the world Money and finances Science and innovation Manage life events You are here: Canada.ca About government Government in a digital age Digital government innovation Responsible use of artificial intelligence in government Algorithmic Impact Assessment tool On this page 1."
642,"Page details Date modified: 2025-06-24 About this site Government of Canada All contacts Departments and agencies About government Themes and topics Jobs Immigration and citizenship Travel and tourism Business Benefits Health Taxes Environment and natural resources National security and defence Culture, history and sport Policing, justice and emergencies Transport and infrastructure Canada and the world Money and finances Science and innovation Indigenous Peoples Veterans and military Youth Manage life events Government of Canada Corporate Social media Mobile applications About Canada.ca Terms and conditions Privacy"
644,"Government of Canada Strategic Plan for Information Management and Information Technology 2017 to 2021 - Canada.ca Skip to main content Skip to ""About government"" Language selection Français fr / Gouvernement du Canada Search Search Canada.ca Search Menu Main Menu Jobs and the workplace Immigration and citizenship Travel and tourism Business and industry Benefits Health Taxes Environment and natural resources National security and defence Culture, history and sport Policing, justice and emergencies Transport and infrastructure Canada and the world Money and finances Science and innovation Manage life events You are here: Canada.ca About government Government oversight Information, technology and project management Government of Canada Strategic Plan for Information Management and Information Technology 2017 to 2021 From Treasury Board of Canada Secretariat On this page About this document / what’s new Message from the Government of Canada Chief Information Officer Introduction Citizens’ expectations Workplace and workforce evolution Privacy and security The enterprise approach IM-IT sustainability and aging IT The vision Digital services Open and accessible Security Enterprise management Community Workplace Mission statement Guiding principles Principle 1: client and service-centred design Principle 2: open Principle 3: enterprise first Principle 4: secure Principle 5: cloud first approach Principle 6: enable a modern workplace: anywhere, anytime with anyone Strategic goals Strategic goal 1: service Strategic goal 2: value Strategic goal 3: security Strategic goal 4: agility Strategic actions Service Service management Cloud first Technology modernization Information and data sharing Manage Governance Enterprise architecture alignment and practices Agility and innovation Sustainability Secure Defence in depth Trusted solutions and services Awareness and understanding Community IM-IT workforce Modern workplace Digital collaboration The way forward Implementing the Strategic Plan Risks and mitigation strategies Measuring progress Staying evergreen Appendix A: Government of Canada IM/IT modernization priorities Appendix B: implementation roadmap Appendix C: key performance indicators Appendix D: roles and responsibilities Appendix E: definitions Appendix F: draft digital principles About this document / what’s new This is the first update to the Government of Canada Information Technology Strategic Plan, published in June 2016."
644,"Return to footnote 1 referrer © Her Majesty the Queen in Right of Canada, represented by the President of the Treasury Board, 2017,ISBN: 978-0-660-24007-7 Page details Date modified: 2020-07-27 About this site Treasury Board of Canada Secretariat (TBS) Contact us Forms Government of Canada All contacts Departments and agencies About government Themes and topics Jobs Immigration and citizenship Travel and tourism Business Benefits Health Taxes Environment and natural resources National security and defence Culture, history and sport Policing, justice and emergencies Transport and infrastructure Canada and the world Money and finances Science and innovation Indigenous Peoples Veterans and military Youth Manage life events Government of Canada Corporate Social media Mobile applications About Canada.ca Terms and conditions Privacy"
645,"Responsible use of artificial intelligence in government - Canada.ca Skip to main content Skip to ""About government"" Language selection Français fr / Gouvernement du Canada Search Search Canada.ca Search Menu Main Menu Jobs and the workplace Immigration and citizenship Travel and tourism Business and industry Benefits Health Taxes Environment and natural resources National security and defence Culture, history and sport Policing, justice and emergencies Transport and infrastructure Canada and the world Money and finances Science and innovation Manage life events You are here: Canada.ca About government Government in a digital age Digital government innovation Responsible use of artificial intelligence in government Artificial intelligence (AI) technologies offer promise for improving how the Government of Canada provides digital services."
645,"Features (Article) Driving forward: navigating the AI landscape in the Government of Canada LinkedIn article by Stephen Burt, Chief Data Officer, Government of Canada (Video) AI procurement for a digital world Overview of the AI procurement process (Video) Algorithmic Impact Assessment Introduction to the Algorithmic Impact Assessment From: Treasury Board of Canada Secretariat Page details Date modified: 2025-03-04 About this site Government of Canada All contacts Departments and agencies About government Themes and topics Jobs Immigration and citizenship Travel and tourism Business Benefits Health Taxes Environment and natural resources National security and defence Culture, history and sport Policing, justice and emergencies Transport and infrastructure Canada and the world Money and finances Science and innovation Indigenous Peoples Veterans and military Youth Manage life events Government of Canada Corporate Social media Mobile applications About Canada.ca Terms and conditions Privacy"
649,"Accept additional cookies Reject additional cookies View cookies Hide cookie message Skip to main content GOV.UK Navigation menu Menu Menu Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments Departments, agencies and public bodies News News stories, speeches, letters and notices Guidance and regulation Detailed guidance, regulations and rules Research and statistics Reports, analysis and official statistics Policy papers and consultations Consultations and strategy Transparency Data, Freedom of Information releases and corporate reports Search GOV.UK × Search GOV.UK Search Search GOV.UK Search Home Health and social care National Health Service Digital and data-driven health and care technology Departmentof Health &Social Care Guidance A guide to good practice for digital and data-driven health technologies Updated 19 January 2021 Contents Introduction 1."
649,"Cancel Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments News Guidance and regulation Research and statistics Policy papers and consultations Transparency How government works Get involved Support links Help Privacy Cookies Accessibility statement Contact Terms and conditions Rhestr o Wasanaethau Cymraeg Government Digital Service All content is available under the Open Government Licence v3.0, except where otherwise stated © Crown copyright"
650,"Several witnesses highlighted the growing use of AI within the US justice system, in particular the Correctional Offender Management Profiling for Alternative Sanctions (COMPAS) system, developed by Northpointe, and used across several US states to assign risk ratings to defendants, which help to assist judges in sentences and parole decisions."
650,"144 Evidence from Sheena Urwin, Head of Criminal Justice at Durham Constabulary, emphasised the considerable lengths that Durham Constabulary have taken to ensure their use of these tools is open, fair and ethical, in particular the development of their ‘ALGO-CARE’ framework for the ethical use of algorithms in policing."
650,"Konstantinos Karachalios, Managing Director, IEEE-Standards Association QQ 18–28 * Professor Alan Winfield, Professor of Robot Ethics, University of the West of England * Jeremy Barnett, Barrister, St Pauls Chambers, Leeds and Gough Square Chambers QQ 29–37 ** Professor Chris Reed, Professor of Electronic Commerce Law, Queen Mary University of London * Professor Karen Yeung, Professor of Law and Director of the Centre for Technology, Ethics, Law and Society at Dickson Poon School of Law, King’s College London * Dr David Barber, Turing Fellow, The Alan Turing Institute, and Reader in Computational Statistics and Machine Learning, UCL QQ 38–45 ** Dr Marko Balabanovic, Chief Technology Officer, Digital Catapult ** Dr Timothy Lanfear, Director of EMEA Solution Architecture & Engineering Team, NVIDIA * Eileen Burbidge MBE, Partner, Passion Capital QQ 46–54 * David Kelnar, Investment Director and Head of Research, MMC Ventures 142 AI IN THE UK: READY, WILLING AND ABLE? * Libby Kinsey, Co-founder, Project Juno ** Dr Mercedes Bunz, Senior Lecturer, Communications and Media Research Institute, University of WestminsterQQ 55–64 ** Elizabeth Denham, UK Information Commissioner, Information Commissioner’s Office * Dr Sandra Wachter, Postdoctoral Researcher in Data Ethics and Algorithms, Oxford Internet Institute * Olivier Thereaux, Head of Technology, The Open Data Institute QQ 65–75 * Javier Ruiz Diaz, Policy Director, The Open Rights Group ** Frederike Kaltheuner, Policy Officer, Privacy International ** Dr James Luke, Chief Technology Officer for the Public Sector, IBM QQ 76–84 ** Kriti Sharma, Vice President of Artificial Intelligence and Bots, Sage * Andrew de Rozairo, Vice President, Customer Innovation and Enterprise Platform, SAP * Colin Griffiths, Policy Manager, Citizens Advice QQ 85–94 ** Will Hayter, Project Director, Competition and Markets Authority ** Olly Buston, CEO and Founder, Future Advocacy QQ 95–104 * Professor Dame Henrietta Moore, Director, Institute for Global Prosperity, UCL ** Professor Richard Susskind OBE, IT Adviser to the Lord Chief Justice of England and Wales * Dr Mark Taylor, Global Strategy & Research Director, Dyson QQ 105–115 ** Dr Joseph Reger, Chief Technology Officer EMEIA, Fujitsu ** Paul Clarke, Chief Technology Officer, Ocado * Dr Julian Huppert, Chair, Independent Review Panel for DeepMind Health QQ 116–127 ** Dr Sobia Raza, Head of Science, PHG Foundation * Nicola Perrin, Head, Understanding Patient Data, Wellcome Trust ** Dr Hugh Harvey, Clinical Artificial Intelligence Researcher and Consultant Radiologist, Guy’s and St Thomas’ NHS Foundation Trust QQ 128–142 * Dame Fiona Caldicott, National Data Guardian for Health and Care, Office of the National Data Guardian 143 AI IN THE UK: READY, WILLING AND ABLE? * Professor Martin Severs, Medical Director, NHS Digital ** Dr Mark Briers, Strategic Programme Director for Defence and Security, The Alan Turing InstituteQQ 143–152 * Professor Chris Hankin, Co-Director, Institute for Security Science and Technology, Imperial College London * Major Kitty McKendrick, Visiting Fellow, Chatham House QQ 153–162 ** Professor Noel Sharkey, Emeritus Professor of Artificial Intelligence and Robotics and Public Engagement, University of Sheffield * Mike Stone, Former Chief of Digital and Information Officer, Ministry of Defence * Dr Alvin Wilby, Vice President Research, Technical and Innovation, Thales Group * Professor Wolfgang Wahlster, CEO and Scientific Director, German Research Centre for Artificial Intelligence (DFKI) QQ 163–171 ** Dr Alan Bernstein, President and CEO, Canadian Institute for Advanced Research (CIFAR) QQ 172–180 ** Miles Berry, Principal Lecturer, School of Education, University of Roehampton QQ 181–189 * Graham Brown-Martin, Author and entrepreneur ** Professor Rosemary Luckin, Professor of Learner Centred Design, UCL Institute of Education ** The Rt Hon Matt Hancock MP, Minister of State for Digital, Department for Digital, Culture, Media and Sport QQ 190–200 ** The Rt Hon the Lord Henley, Parliamentary Under Secretary of State at the Department for Business, Energy and Industrial Strategy * Dr Jérôme Pesenti, CEO, BenevolentTech at BenevolentAI QQ 201–212 * Professor David Edgerton, Hans Rausing Professor of the History of Science and Technology, and Professor of Modern British History, King’s College London QQ 213–223 * Professor Peter McOwan, Vice Principal, Public Engagement and Student Enterprise, Queen Mary University of London * Professor Sir David Spiegelhalter, President, Royal Statistical Society, Winton Professor of the Public Understanding of Risk, University of Cambridge and Chair, Winton Centre for Risk and Evidence Communication 144 AI IN THE UK: READY, WILLING AND ABLE?"
650,"There were three overarching principles to this: • partnership with, not replacement of, humans; • putting human values at the centre of their applications; and • a strong focus on a wide-ranging set of ethical considerations, including the preservation of human autonomy, beneficence, non-maleficence, and justice."
650,"They emphasised the need for tools to be developed to facilitate transparency and interpretability, which fell into three broad categories: • Tools for developers (e.g. for debugging AI systems); • Tools for users (e.g. for use in the criminal justice system, so defendants and their lawyers can understand and challenge evidence used against them); and • Tools for investigators and auditors for use when things go wrong."
651,"Accept additional cookies Reject additional cookies View cookies Hide cookie message Skip to main content GOV.UK Navigation menu Menu Menu Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments Departments, agencies and public bodies News News stories, speeches, letters and notices Guidance and regulation Detailed guidance, regulations and rules Research and statistics Reports, analysis and official statistics Policy papers and consultations Consultations and strategy Transparency Data, Freedom of Information releases and corporate reports Search GOV.UK × Search GOV.UK Search Search GOV.UK Search Home Defence and armed forces Ambitious, safe, responsible: our approach to the delivery of AI-enabled capability in Defence Ministryof Defence Policy paper Ambitious, safe, responsible: our approach to the delivery of AI-enabled capability in Defence Published 15 June 2022 This was published under the 2019 to 2022 Johnson Conservative government Contents Executive Summary Ambitious delivery of capability Our approach and AI-enabled weapons Key challenges to Defence AI Adoption Using AI Safely Using AI Legally Using AI Ethically Partnerships and Consultation Governance Implementation – building justified trust Annex A: Ethical Principles for AI in Defence Annex B: The Ministry of Defence AI Ethics Advisory Panel ANNEX C: Lethal Autonomous Weapon Systems (LAWS) Print this page © Crown copyright 2022 This publication is licensed under the terms of the Open Government Licence v3.0 except where otherwise stated."
651,"Cancel Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments News Guidance and regulation Research and statistics Policy papers and consultations Transparency How government works Get involved Support links Help Privacy Cookies Accessibility statement Contact Terms and conditions Rhestr o Wasanaethau Cymraeg Government Digital Service All content is available under the Open Government Licence v3.0, except where otherwise stated © Crown copyright"
654,"For example, the use of artificial intelligence tools by law enforcement and the criminal justice system could have an impact on an individual ’s right to be free from arbitrary arrest or to equality before the law; surveillance technologies c ould impact on the right to peaceful assembly; the use of social media platforms could impact the right to mental health; and property rental platforms could alter housing markets, possibly impacting the right to an adequate standard of living."
656,"Human rights: A path for solutions Topics Instruments and mechanisms Publications News UN Human Rights Office Press releases 23 September 2025 Encouraging human rights developments in Egypt Press releases 24 September 2025 Kyrgyzstan: Torture prevention seriously undermined by new law, UN Human Rights Chief warns Press releases 21 September 2025 China China: Second sentencing of Zhang Zhan deeply disturbing View more news View speeches and statements Independent Experts and Committees Special Procedures Press releases 23 September 2025 Israel UN experts call for suspension of Israel from international football amid unfolding genocide in occupied Palestine Press releases 23 September 2025 Belarus: UN experts denounce disappearance of Mikalai Statkevich after his attempted deportation Press releases 22 September 2025 UN Special Rapporteur warns of intensifying repression and widespread torture in Russia aimed at silencing dissent View all Special Procedures News Treaty Bodies Media advisories 19 September 2025 Enforced and involuntary disappearances UN Committee on Enforced Disappearances to review Montenegro, Benin, and Sri Lanka Press releases 17 September 2025 Nigeria: UN committee finds grave and systematic violations persist after Chibok mass abduction of schoolgirls Media advisories 10 September 2025 UN Torture prevention body to visit New Zealand View all Treaty Bodies News Human Rights Council Press releases 24 September 2025 People of African descent UN experts: Systemic racism against Africans and people of African descent in criminal justice systems is pervasive Press releases 24 September 2025 Sudan Sudan: UN Fact-Finding Mission urges immediate action after deadly mosque strike in El Fasher Statements and speeches 23 September 2025 Oral Update by Mr."
660,"Copyright © United Nations Interregional Crime and Justice Research Institute (UNICRI), 2020 Viale Maestri del Lavoro,10, 10127 Torino – Italy Tel: +39 011-6537 111 / Fax: +39 011-6313 368 Website: www.unicri.it E-mail: unicri.publicinfo@un.org © The International Criminal Police Organization (INTERPOL), 2020 200, Quai Charles de Gaulle, 69006 Lyon – France Tel: +33 4 72 44 70 00 / Fax: +33 4 72 44 71 63 Website: www.interpol.int E-mail: edgci-ic@interpol.int 2 FOREWORD Crime is not stagnant."
660,"We have strived to shape this forum, giving it meaning and purpose, and positioning it to grow into a global platform for cooperation and collaboration amongst law enforcement on AI This report on AI for law enforcement is the most recent product of the collaboration on AI between the Innovation Centre of the International Criminal Police Organization (INTERPOL) and the United Nations Interregional Crime and Justice Research Institute’s (UNICRI) Centre for AI and Robotics."
660,The increasing interest and attention these meetings are receiving is both a reward for INTERPOL and UNICRI and reveals the growing relevance of AI for the criminal justice community.
660,"Human rights, civil liberties and even the fundamental principles of law upon which our criminal justice system is based may be unacceptably exposed, or even irreparably compromised, if we do not navigate this route with extreme caution."
660,"The chapter be gins by presenting the general principles that law enforcement should endeavour to adhere to, namely the respect for human rights, democracy, justice and rule of law, as well as the related requirements of fairness, accountability, transparency and explainability that should be adopted in order for law en forcement to meet these principles."
660,"Equally, it is a valuable exercise for policy- and deci sion-makers in the broader criminal justice community to, from a legal and ethical perspective, prepare frameworks for the eventual integration of such technologies into law enforcement."
660,"The seminal 2019 white paper AI and Ethics at the Police by Leiden University and TU Delft16 suggests that, from a legal perspective, to act responsibly means “to accept moral integrity and authenticity as ideals and to deploy reasonable effort toward achieving them.”17 Striving for moral integrity, in turn, implies “adhering to the values of freedom, equality, and solidarity.”18 For the purposes of this report, however, a more straightforward understanding will be adopted and the term ‘responsible’ will be framed in line with the Oxford Dictionary, which defines ‘responsibly’ as acting “in a sensible or trustworthy manner.”19 In this context, the responsible use of AI by law enforcement should be understood as use that enshrines the general principles of respect for human rights, democracy, justice and the rule of law."
660,Justice for Hedgehogs .
660,"It has been heralded for its role in building “an area of freedom, security and justice with a high level of data protection, in accordance with the EU Charter of Fundamental Rights.” Aiming at protecting individuals’ personal data, while guaran teeing a high level of public security, the LED provides rights for data subjects, as well as obligations for “competent authorities” when processing data for “law enforcement purposes”, i.e., prevention, investi gation, detection, prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against and the prevention of threats to public security."
660,"The development of trustworthy AI systems should be based upon established fundamental values, such as the respect for human dignity, democracy, justice and rule of law, while, at the same time, guaranteeing the freedom of the individual and citizens’ rights in order to ensure equality and non-dis crimination."
660,"45 RECOMMENDED ACTIONS Define a statement of principles on the use of AI in law enforcement that will guide law enforcement to ensure respect for human rights, democracy, justice and the rule of law and support it to prioritize the key requirements of fairness, accountability, transparen cy and explainability, as well as safety and robustness; ›Develop guidance for law enforcement on the implementation of new technology to support and encourage law enforcement agencies to explore and invest in new AI opportunities and to develop training in new AI applications and disseminate best practices; ›Create a knowledge-base with the law enforcement community on the requiremen ts for the adoption of AI, such as what kinds of problems AI is capable of tackling, the current or inherent limitations and the resources (tools, data, expertise, com puting power) required to implement AI solutions; ›Develop guidance for law enforcement on the admissibility of AI in court that as sesses the impact and results of the specific use of AI in courts, while ensuring the respect for human rights and rule of law; ›Create an expert advisory committee that can provide guidance to law enforcement in terms of legislation and serve as a forum for discussing appropriate legislative models with legal experts and other key stakeholders; ›Identify an external global body to provide advisory support to law enforcement on ethical issues and to provide support in carrying out audits to check whether a system is responsible and complies with legal requirements; ›Foster a community and organize training courses and workshops to attract and connect different stakeholders from law enforcement, industry, academia, civil society and international bodies with the diverse backgrounds and essential per spectives to gather and synthesize views from cross-sections of society, in order to provide a balanced and facts-based picture of the opportunities and challenges of the use of AI and to highlight the application of AI to law enforcement and provide hands-on support. ›INTERPOL and UNICRI agreed to remain seized of these needs and actions and will seek to build upon them in forthcoming global meetings on AI for law enforcement."
660,"52 ANNEX II LIST OF ABBREVIATIONS ADM Automated Decision-Making AFP Australian Federal Police AI Artificial intelligence AI-HLEG High-Level Expert Group on AI AiLECS Artificial Intelligence for Law Enforcement of Community Safety CCTV Closed-Circuit Television EU European Union FATE Fairness, Accountability, Transparency and Explainability GDPR General Data Protection Regulation GPS Global Positioning Services IC INTERPOL’s Innovation Centre IEDs Improvised Explosive Devices IGCI INTERPOL’s Global Complex for Innovation INTERPOL International Criminal Police Organization LED Law Enforcement Directive 2016/680 MAS Monetary Authority of Singapore NLP Natural Language Processing non-POI non-Person of Interest NPA Japan National Police Agency OECD Organisation for Economic Co-operation and Development R&D Research and Development UAV Unmanned Aerial Vehicles UNICRI United Nations Interregional Crime and Justice Research Institute ZITiS Central Office for Information Technology in the Security Sector 53 ABOUT INTERPOL INTERPOL is the world’s largest international police organiza tion."
660,ABOUT UNICRI The United Nations Interregional Crime and Justice Research Institute was established in 1968.
660,"Within the broad scope of its mandate, the Institute contributes, through research, training, field activities and the collection, exchange and dissemination of information, to the formulation and implementation of improved policies in the field of crime prevention, justice and emerging security threats, due regard being paid to the integration of such policies within broader policies for socio-economic change and development, and to the protection of human rights."
660,"In 2017, UNICRI opened its Centre for Artificial Intelligence and Robotics in The Hague, the Netherlands, with a view towards advancing understanding of artificial intelligence, robotics and related technologies vis-à-vis crime prevention, criminal justice, the rule of law and security."
679,"In a digitally connected world, the question of how to respect, protect and implement human rights and access to environmental justice is becoming paramount."
679,"Human rights and access to environmental justice need to be safeguarded in the development, implementation, legislation, 23and governance of digital technologies."
683,"Artificial intelligence constitutes a major form of scientific and technological progress, which can generate considerable social benefits by improving living conditions and health, facilitating justice, creating wealth, bolstering public safety, and mitigating the impact of human activities on the environment and the climate."
683,"AIS must avoid using acquired data to lock individuals into a user profile, fix their personal identity, or confine them to a filtering bubble, which would restrict and confine their possibilities for personal development — especially in fields such as education, justice, or business."
689,"However, “had he been able to examine and contest the logic of the COMPAS system to prove that its score gave a distorted picture of his life, he might have gone home much earlier” (Wexler 2017b ) Rodríguez’s case is an example of the discriminatory use of AI in criminal justice, which also includes prominent AI applications for the purposes of predictive policing."
689,"In such cases, which include law enforcement and criminal justice applications, the attempt to modify the data to reduce or eliminate underlying biases may inadvertently introduce new challenges."
689,"The desirability of the use of AI solutions is also something that should be duly considered– with regard to the purpose, advantages and burden imposed by them on social values, justice and the public interest."
689,It has links to broader societal structures and the justice of our socio-economic systems and thus relates to the problem of surveillance capitalism.
689,( 2018 ) outline how criminal justice risk assessment tools could beneﬁt low-risk individuals through increased pre-trial releases and shorter sentences.
689,"CV-sorting software for recruitment procedures); in essential private and public services (e.g. when credit scoring denies citizens the opportunity to obtain a loan); in law enforcement that may interfere with people’s fundamental rights (e.g. evaluation of the reliability of evidence); in migration, asylum and border control management (e.g. veriﬁcation of the authenticity of travel documents); and in the administration of justice and democratic processes (e.g. applying the law to a concrete set of facts)."
689,"Directorate-General for Justice and Consumers, European Commission, Brussels. https://data.europa.eu/doi/10.2838/77360 ."
689,"Expert Group on Liability and New Technologies, Directorate-General for Justice and Consumers, European Commission, Brussels. https://data.europa.eu/doi/10.2838/573689 ."
689,"For instance, the opening of the Universal Declaration of Human Rights states that “recognition of the inherent dignity and of the equal and inalienable rights of all members of the human family is the foundation of freedom, justice and peace in the world” (UN 1948 )."
689,"Federal Ministry of Justice and Federal Ofﬁce of Justice, Berlin. https://www.gesetze-im-internet.de/englisch_gg/englisch_gg. pdf."
689,One could perhaps even argue that AI has been linked directly to international justice and sustainability through the SDGs.
690,"Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead Cynthia Rudin Duke University cynthia@cs.duke.edu Abstract Black box machine learning models are currently being used for high stakes decision-making throughout society, causing problems throughout healthcare, criminal justice, and in other domains."
690,"This manuscript clariﬁes the chasm between explaining black boxes and using inherently interpretable models, outlines several key reasons why explainable black boxes should be avoided in high-stakes decisions, identiﬁes challenges to interpretable machine learning, and provides several example applications where interpretable models could potentially replace black box models in criminal justice, healthcare, and computer vision."
690,1 Introduction There has been an increasing trend in healthcare and criminal justice to leverage machine learning (ML) for high-stakes prediction applications that deeply impact human lives.
690,"The lack of transparency and accountability of predictive models can have (and has already had) severe consequences; there have been cases of people incorrectly denied parole [ 1], poor bail decisions leading to the release of dangerous criminals, ML-based pollution models stating that highly polluted air was safe to breathe [ 2], and generally poor use of limited valuable resources in criminal justice, medicine, energy reliability, ﬁnance, and in other domains [3]."
690,"As of yet, I have not encountered such an application, despite having worked on numerous applications in healthcare and criminal justice [e.g., 21], energy reliability [e.g., 20], and ﬁnancial risk assessment [e.g., 22]."
690,Justice system for parole and bail decisions.
690,"Justice System for recidivism risk prediction does not depend on the seriousness of the current crime [ 27,29]."
690,Justice System for predicting the probability that someone will be arrested after their release [29].
690,"This evidence, however, has not changed the momentum of the justice system towards proprietary models."
690,Justice System Table 1: Comparison of COMPAS and CORELS models.
690,Perhaps we could prevent some of the poor decisions in criminal justice and medicine that are caused by problems with using black box models.
690,"This may continue to lead to poor decisions throughout our criminal justice system, incorrect safety guidance for air quality disasters, incomprehensible loan decisions, and other widespread societal problems."
690,When a Computer Program Keeps You in Jail: How Computers are Harming Criminal Justice.
690,Optimized Scoring Systems: Toward Trust in Machine Learning for Healthcare and Criminal Justice.
690,Criminal Justice and Behavior.
691,2020 AI for social good Receiver-contextualized intervention with respect to autonomyNon-maleficence Justice & situational fairnessReceiver-contextualized explanation and transparent purposesPrivacy protection and data subject consent Grote et al.
699,"This list is non-exhaustive, and many important ethical issues -- including justice, economic development, poverty reduction, and inequality, are missing."
699,"There are also a number of AI use cases that could support SDG 16, “Promote peaceful and inclusive societies for sustainable development, provide access to justice for all and build effective, accountable and inclusive institutions at all levels.” The use cases cover domains ranging from helping individuals verify and validate information, providing improved security through detection and prediction of violence, addressing bias to ensure fair and equal access to justice, to optimizing the management of public and social sector institutions."
699,"List of Organizational Documents Document Categorization Official Government/Regulation Official Government/Regulation Official Government/RegulationOfficial Government/Regulation Think Tanks / Policy InstitutesOfficial Government/RegulationOfficial Government/RegulationIndustry & ConsultancyOfficial Government/Regulation Tech Companies Industry & ConsultancyThink Tanks / Policy Institutes Industry & Consultancy Tech CompaniesOfficial Government/Regulation Associations & Consortiums Tech Companies Industry & ConsultancyThink Tanks / Policy Institutes Official Government/RegulationAssociations & ConsortiumsIssuer EUROPEAN COMMISSION FOR THEEFFICIENCY OF JUSTICE (CEPEJ) AI HLEG Australian Government - Department of Industry, Innovation & Science Smart DubaiOECDG20Singapore PDPCDeloitteFinland - Ministry of Economic Affairs and Employment TietoOP Financial GroupFrance - Commission Nationale de l’Informatique et des Libertés Deutsche TelekomSAPAgenzia per l’Italia Digitale Japan - Conference toward AI Network Society SonyTelefonicaInstitute of Business Ethics UK - Department of Health and Social Care The Information Accountability Foundation 273Artificial Intelligence Index Report 2019Technical Appendix 8 - Societal Considerations [Societal_Considerations]_[Appendix_Start] [Access_Data]Return to Societal Considerations - Ethical Challenges Acronym AMA UNTGWGSIIITIWEFICD TPV FAT MAS VOD DNB INDDEKDocument Title Policy Recommendations on Augmented Intelligence in Health Care H-480.940 Introducing Unity’s Guiding Principles for Ethical AI – Unity Blog Position on Robotics and Artificial Intelligence Ethical Principles for Artificial Intelligence and Data AnalyticsITI AI Policy PrinciplesWhite Paper: How to Prevent Discriminatory Outcomes in Machine Learning Declaration on ethics and data protection in Artificial Intelligence Universal Guidelines for Artificial Intelligence Principles for Accountable Algorithms and a Social Impact Statement for Algorithms Principles to Promote Fairness, Ethics, Accountability and Transparency (FEAT) in the Use of Artificial Intelligence and Data Analytics in Singapore’s Financial Sector Artificial Intelligence frameworkGeneral Principles for the use of Artificial Intelligence in the Financial Sector Artificial Intelligence in the Governance Sector in India Opinion of the Data Ethics CommissionTable A8.2."
699,"Osborne China State CouncilSecretary of State for Business, Energy and Industrial Strategy United Nations Interregional Crime and Justice Research Institute Future of Humanity Institute, Oxford University,Centre for the Study of Existential Risk, University of Cambridge FTI Consulting Table A9.1."
702,"Hollywood, “Evaluation of the Shreveport Predictive Policing Experiment,” National Institute of Justice, 2014, https://nij.ojp.gov/topics/articles/evaluation-shreveport- predictive-policing-experiment ."
703,"2018).Accountability, explainability, privacy, justice, but also other values such as robustness or safety are most easily operationalized mathematically and thus tend to be implemented in terms of technical solutions."
703,"With reference to the findings of psychologist Carol Gilligan, one could argue at this point that the way AI ethics is performed and structured constitutes a typical instantiation of a male-dominated justice ethics (Gilligan 1982)."
703,"In the 1980s, Gilligan demonstrated in empirical studies that women do not, as men typically do, address moral problems primarily through a “calculating”, “rational”, “logic-oriented” ethics of justice, but rather interpret them within a wider framework of an “empathic”, “emotion-oriented” ethics of care."
703,What does it mean to implement justice or transparency in AI-systems?
703,"It should not be the objective of ethics to stifle activity, but to do the exact opposite, i.e. broadening the scope of action, uncovering blind spots, promoting autonomy and freedom, and fostering self-responsibility.In view of AI ethics, approaches that focus on virtues aim at cultivating a moral character, expressing technomoral virtues such as honesty, justice, courage, empathy, care, civility, or magnanimity, to name just a few (Vallor 2016)."
703,"This implies that the purposes for which AI systems are developed and applied are not in accordance with societal values or fundamental rights such as beneficence, non-maleficence, justice, and explicability (Taddeo and Floridi 2018; Pekka et al."
704,"117IIHetNederlandsgrondrechtelijkkader –Persoonlijke onafhankelijkheid –ermoeten voldoende waarborgen worden geboden rondom benoeming, ambtsduur enontslag, zodat andere staatsmachten niet alteveel invloed kunnen hebben ophetsoort rechter datwordt benoemd engeen druk kunnen uitoefenen oprechters omopeenbepaalde manier tebeslissen.514 –Zakelijke offunctionele onafhankelijkheid –ermoeten voldoende garanties zijntegen druk vanbuitenaf omzaken opeenbepaalde manier tebeslechten enderechter moet zelfstandig, zonder inmenging vandeandere staatsmachten, totzijnbeslissing kunnen komen.515 –Institutionele onafhankelijkheid –deoverheidsorganisatie waarvan rechters deel uitmaken moet eenonafhankelijke positie kunnen innemen tenaanzien van deandere staatsmachten, bijvoorbeeld alshetgaat omfinanciering, organisatie enwerkwijze.516 –Onpartijdigheid –derechter hoort onpartijdig tezijn, watvooral betekent dathijniet vooringenomen istenopzichte vandezaak oftenopzichte van(een van) departijen.517 Vooral indeEHRM-rechtspraak worden hierbij twee aspecten onderscheiden: –Subjectieve onpartijdigheid –derechter mag geen zodanige verbondenheid hebben met dezaak ofmet (een van) debeide partijen diemaakt dathijniet meer objectief over dezaak kanoordelen; hetgaat hier dusomzijnpersoonlijke instelling enovertuiging.518 –Objectieve onpartijdigheid –deprocedure moet zozijningericht datergeen legitieme twijfel mogelijk isover deobjectiviteit vanderechter (ofeenrechterlijk college) bijde beoordeling vaneenzaak, onder hetmotto ‘justice must notonly bedone, itmust also seen tobedone ’.519 Derechtspraak over deze twee aspecten issterk casuïstisch vanaard, maar hetelement vanontbrekende ‘bias’–hetzij subjectief, hetzij indeogen vandebuitenstaander –komt steeds weer terug. –Toegankelijkheid –onnodige ofdisproportioneel hoge drempels dieeenrechtszoekende afhouden vaneffectieve toegang toteenrechterlijke procedure zijnniet aanvaardbaar: –Altehoge griffierechten ofleges kunnen hetrecht optoegang totderechter disproportioneel aantasten.520 –Hetontbreken vandoor destaat gefinancierde rechtsbijstand kaninbepaalde gevallen indeweg staan aanheteffectief kunnen voeren vaneenprocedure.521 514 Bovend ’Eert 2013, p.18e.v."
704,"Safety and Justice Program 2013, online via;https://www. rand.org/content/dam/rand/pubs/research_reports/RR200/RR233/RAND_RR233.pdf (laatst geraadpleegd 21december 2017)."
713,"Criminal justice, public housing, welfare and health provision are examples of areas where “black box” systems should not be developed or used."
713,"29 In “Fairness in Criminal Justice Risk Assessments: The State of the Art” Berk et al, 2017 provide a through review of the technical pathways towards promoting fairness in machine learning."
713,"Berk et al, 2017, Fairness in Criminal Justice Risk Assessments: The State of the Art https://arxiv.org/ abs/1703.0920730 Ai Now Institute 2017 Report 13 How to Prevent Discriminatory Outcomes in Machine LearningBringing principles of non-discrimination to life: Human rights due diligence for machine learning Companies developing and using ML systems must integrate these principles of non-discrimination into their human rights due diligence – a process by which businesses take ongoing, proactive, and reactive steps to ensure that they uphold people’s dignity and do not cause or contribute to human rights abuses."
72,"In the Judicial Branch digital certification is also widely available , especially in electronic filing, a vailable at the Federal Supreme Court, the Superior Justice Court and at several other courts nationwide."
72,"In other words, it means to apply the transforming p otential of ICT to benefit the society, as in: • Goods and services more adequate to citizens’ needs; • Simple access to services ; 101 • Offering of p ublic service offering which meet the needs for justice, equality, efficiency and effectiveness; • Distributing p ublic benefits efficiently and proportionally; and • Creating value from open government data."
72,"115 MEMBERS OF THE E -DIGITAL WORKGROUP MINISTRY OF SCIENCE, TECHNOLOGY, INNOVATI ON AND COMMUNICATION S Maximiliano Salvadori Martinhão Miriam Wimmer Daniel Brandão Cavalcanti Artur Coimbra de Oliveira MINISTRY OF INDUSTRY , FOREIGN TRADE AND SERVICES Marcos Vinicius De Souza José Henrique Videira Menezes MINISTRY OF PLANNING , DEVELOPMENT AND MA NAGEMENT Wagner Silva de Araújo Elise Sueli Pereira Gonçalves MINISTRY OF FOREIGN AFFAIRS José Antonio Marcondes de Carvalho Benedicto Fonseca Filho MINISTRY OF JUSTICE AND PUBLIC SAFETY Frederico Fernandes Moesch Dim Michelle Ferreira Rodrigues MINISTRY OF CULTURE Rodolfo T."
720,"Decision criteria could include: –Vendor: some vendors could be pre-qualified as accepted data providers, be considered more trustworthy as a result of their previous track record as existing suppliers or have a strong reputation related to their data assets. –Domain: some domains – such as health, justice and immigration – are very sensitive."
720,"These multidisciplinary teams should include expertise in: policy from the domain (e.g. justice) in which the AI solution will be applied, machine learning/data science, data engineering, technology (software and hardware), procurement, ethics and human rights.7 –Ensure that you have a diverse team."
721,"Criminal justice, public housing, welfare and health provision are examples of areas where “black box” systems should not be developed or used."
721,"29 In “Fairness in Criminal Justice Risk Assessments: The State of the Art” Berk et al, 2017 provide a through review of the technical pathways towards promoting fairness in machine learning."
721,"Berk et al, 2017, Fairness in Criminal Justice Risk Assessments: The State of the Art https://arxiv.org/ abs/1703.0920730 Ai Now Institute 2017 Report 13 How to Prevent Discriminatory Outcomes in Machine LearningBringing principles of non-discrimination to life: Human rights due diligence for machine learning Companies developing and using ML systems must integrate these principles of non-discrimination into their human rights due diligence – a process by which businesses take ongoing, proactive, and reactive steps to ensure that they uphold people’s dignity and do not cause or contribute to human rights abuses."
722,"First version of the Principles for Action The first version of these principles has been co-drafted through a multistakeholder process, while paying careful attention to the EU GDPR11 and the police and criminal justice directive,12 and has drawn inspiration from some of their principles."
722,"“EU Data Protection Rules”, EU website, https://ec.europa.eu/commission/priorities/justice-and-fundamental-rights/ data-protection/2018- reform-eu-data-protection-rules/eu-data-protection-rules_en (link as of 28/1/20)."
723,"Thinking about who products are being built for, who they might unintentionally exclude, how product use and product design can protect vulnerable populations, especially now that we’re in the middle of a racial justice crisis and a pandemic, which are disproportionately affecting people of colour and people of lower incomes."
728,ISP DIGITAL FUTURE WHITEPAPER & YJoLT SPECIAL PUBLICATION Algorithms and Economic Justice: A Taxonomy of Harms and a Path Forward for the Federal Trade Commission Rebecca Kelly Slaughter with Janice Kopec and Mohamad Batal August 2021 Contents Algorithms and Economic Justice ....................................................................................
728,"59 Algorithms and Economic Justice | Rebecca Kelly Slaughter 1 Algorithms and Economic Justice: A Taxonomy of Harms and a Path Forward for the Federal Trade Commission The proliferation of artificial intelligence and algorithmic decision-making has helped shape myriad aspects of our society: from facial recognition to deepfake technology to criminal justice and health care, their applications are seemingly endless."
728,"As an FTC Commissioner, I aim to promote economic and social justice through consumer protection and competition law and policy."
728,"The applications of these technologies are innumerable, from facial recognition to deepfake technology, criminal justice, and health care."
728,"Algorithmic decision-making, and the AI that fuels it, could realize its promise of promoting economic justice by distributing opportunities more broadly, resources more efficiently, and benefits more effectively."
728,Algorithms and Economic Justice | Rebecca Kelly Slaughter 3 transformed access to educational opportunities3 and improved health outcomes through improved diagnostic rates and care adjustments.4 But the potentially transformative power of algorithmic decision-making also risks serious harm if misused.
728,"In the criminal justice system, for example, commentators note that algorithms and AI contribute to over-surveillance,5 wrongful detainment and arrest,6 and biased risk assessments used to determine pre-trial status and even sentencing.7 Mounting evidence reveals that algorithmic decisions can produce biased, discriminatory, and unfair outcomes in a variety of high-stakes economic spheres including employment, credit, health care, and housing.8 3 See, e.g., Matt Kasman & Jon Valant, The Opportunities and Risks of K-12 Student Placement Algorithms, BROOKINGS INST."
728,"7 See, e.g., Algorithms in the Criminal Justice System: Pre-Trial Risk Assessment Tools, ELEC."
728,"CTR., https://epic.org/algorithmic-transparency/crim-justice (last visited Jan."
728,"Algorithms and Economic Justice | Rebecca Kelly Slaughter 5 of some of the algorithmic harms that threaten to undermine economic and civil justice.13 I identify three ways in which flaws in algorithm design can produce harmful results: faulty inputs, faulty conclusions, and failure to adequately test."
728,I hope to draw the attention and ingenuity of the interested public to the challenges posed by algorithms so that we can work together on creating an enforcement regime that advances economic justice and equity.
728,"David Edelman, “AI is not magic; it is math and code.”15 As we consider the threats that algorithms pose to justice, we must remember that just as the technology is not magic, neither is any cure to its shortcomings."
728,Algorithms and Economic Justice | Rebecca Kelly Slaughter 7 two subparts.
728,The second subpart describes three ways in which even sophisticated algorithms still systemically undermine civil and economic justice.
728,"Algorithms and Economic Justice | Rebecca Kelly Slaughter 9 thousands of dollars in tuition.19 According to the IB, 60 percent of US public schools that offer IB classes are Title I schools,20 and numerous IB students reportedly saw their college scholarships or admissions offers rescinded because the algorithm assigned them unexpectedly low test scores.21 In a similar case, the United Kingdom used an algorithm to replace its A-Level exams—which play a pivotal role in university admissions there—before ultimately retracting the scores in response to widespread protests."
728,"Algorithms and Economic Justice | Rebecca Kelly Slaughter 11 products can accurately detect an individual’s emotional state by analyzing her facial expressions, eye movements, tone of voice, or even gait.26 The underlying algorithms attempt to find patterns in, and reach conclusions based on, certain types of physical presentations and mannerisms."
728,"Algorithms and Economic Justice | Rebecca Kelly Slaughter 13 suggests that other products in this space can suffer from major structural deficiencies.33 Indeed, Princeton’s Arvind Narayanan, a computer scientist, has criticized AI tools that claim to predict job performance based on body language and speech patterns as “fundamentally dubious.”34 Such algorithmic hiring products merit skepticism in any application, and recent studies suggest they might systematically disadvantage applicants with disabilities because they present differently than the majority of a company’s applicants or employees.35 These reports should trouble any employer using an algorithmic hiring product to screen applicants."
728,"For example, companies can use a five-second clip of a person’s Algorithms and Economic Justice | Rebecca Kelly Slaughter 15 phenomenon with which we are quite familiar at the FTC: new technology, same old lack of substantiation for claims.40 Failure to Test Even if an algorithm is designed with care and good intentions, it can still produce biased or harmful outcomes that are unanticipated."
728,"24, 2019), https://www.sciencenews.org/article/bias-common-health-care-algorithm- Algorithms and Economic Justice | Rebecca Kelly Slaughter 17 of Black patients identified for extra care was reduced by more than half."
728,"Since we weren’t Algorithms and Economic Justice | Rebecca Kelly Slaughter 19 This kind of bias can have meaningful real-world consequences: in this case, that profiles with female-identified names turned up less frequently, potentially resulting in fewer employment opportunities for women."
728,Algorithms and Economic Justice | Rebecca Kelly Slaughter 21 Facebook’s use of Lookalike Audiences that facilitated housing discrimination presents one of the clearest illustrations of proxy discrimination.
728,Algorithms and Economic Justice | Rebecca Kelly Slaughter 23 into both the inputs and the formulae used to make those decisions.
728,"The proliferation of other AI-driven technologies, such as deepfakes and rapidly improving algorithmic text generation, can further exacerbate the Algorithms and Economic Justice | Rebecca Kelly Slaughter 25 radicalization,74 undermines consumers’ mental health,75 and reduces or eliminates consumers’ choices.76 disinformation problem."
728,"Algorithms and Economic Justice | Rebecca Kelly Slaughter 27 platform starting from benign videos.”78 While most of the toddler-oriented content on YouTube is innocuous, the authors highlight an influx of disturbing or inappropriate content that targets young children, as in the infamous “Elsagate” controversy."
728,"Algorithms and Economic Justice | Rebecca Kelly Slaughter 29 Despite this requirement, I voted against the settlement."
728,"Algorithms and Economic Justice | Rebecca Kelly Slaughter 31 The FTC recently announced a timely and important section 6(b) study90 of nine social media and video-streaming services—an industry where the potential for this subtle, data-driven manipulation is clear and obvious."
728,"But the FTC is also responsible for promoting competition, and the threats posed by algorithms profoundly affect that mission as well; moreover, these two missions are not actually distinct, and problems—including those related to algorithms and economic justice—need to be considered with both competition and consumer protection lenses."
728,"Algorithms and Economic Justice | Rebecca Kelly Slaughter 33 algorithms to execute a price-fixing agreement has even given rise to criminal antitrust charges.97 Algorithms may enhance the ability of firms to collude, either tacitly or explicitly.98 While there have been limited cases of enforcement against collusion facilitated by algorithms, it is unclear whether the conduct is in fact not occurring or whether it is simply very difficult for enforcers to detect."
728,"Moving forward, competition enforcers may deploy 97 In 2015, the US Department of Justice brought criminal charges against two e-commerce companies in United States v."
728,"Dep’t of Justice, Former E-Commerce Executive Charged with Price Fixing in the Antitrust Division’s First Online Marketplace Prosecution (Apr."
728,"6, 2015), https://www.justice.gov/opa/pr/former-e-commerce-executive-charged-price-fixing-antitrust-divisions-first-online-marketplace."
728,"Algorithms and Economic Justice | Rebecca Kelly Slaughter 35 $99.103 This practice does not always result in price increase, but it can."
728,Algorithms and Economic Justice | Rebecca Kelly Slaughter 37 rivals.
728,"Using the FTC’s Current Authorities to Better Protect Consumers There is no question that the critical algorithmic problems identified—faulty inputs, faulty conclusions, failure to adequately test, proxy discrimination, surveillance capitalism, and threats to competition—undermine rather than advance economic justice."
728,"The FTC has four types of enforcement authority that provide the agency with some ability to protect consumers and promote economic justice in the face of algorithmic harms: our general authority under the FTC Act; sector-specific rules and statutes, such as FCRA, ECOA, and COPPA; the study authority of section 6(b); and the rulemaking authority of section 18."
728,Algorithms and Economic Justice | Rebecca Kelly Slaughter 39 the agency has been able to apply the statute’s general language to meet new enforcement challenges.
728,"Algorithms and Economic Justice | Rebecca Kelly Slaughter 41 authority cannot be used to combat the fundamentally unfair phenomenon of unlawful discrimination, as well as some of the other algorithmic harms discussed above."
728,"Algorithms and Economic Justice | Rebecca Kelly Slaughter 43 should encourage, non-mortgage creditors to collect demographic data on most borrowers and use it to test algorithmic systems to reduce disparities.128 Vanishingly few creditors take advantage of this exception."
728,"Algorithms and Economic Justice | Rebecca Kelly Slaughter 45 decision-making poses unique challenges in this area.135 Expanding data-reporting requirements under FCRA—for example, broader reporting on the existence and correction of errors, the rates of adverse action notices, and the volume and nature of error complaints—could also help mitigate problems that arise in algorithmic decision-making by providing visibility into the effects of those decisions."
728,"(L 330) (requiring companies meeting certain criteria to publish information on their social and environmental practices Algorithms and Economic Justice | Rebecca Kelly Slaughter 47 about specific businesses, the FTC can also collect information about industry-wide phenomena.144 The study of social media and video-streaming services discussed above is one exciting use of this important tool.145 The FTC should continue to use its 6(b) authority to deepen its expertise on the use and impact of algorithms in our modern economy, focusing on the potential harms to consumers and competition.146 Whether in enforcement or with industry studies, the agency always strives to keep pace with emerging technologies and changing markets.147 But particularly given the scale, opacity, and rapid proliferation of algorithmic decision-making in our economy, there is room for improvement."
728,Algorithms and Economic Justice | Rebecca Kelly Slaughter 49 complicated and facially neutral technology provides a false sense of security in the objectivity of algorithmic decision-making.
728,"Algorithms and Economic Justice | Rebecca Kelly Slaughter 51 the increase of transparency, equity, and accountability in its work—including through Executive Orders.159 Prioritizing transparency and fairness is necessary, but not sufficient; regulation of algorithmic decision-making must also involve real accountability and appropriate remedies."
728,"Algorithms and Economic Justice | Rebecca Kelly Slaughter 53 promulgating rules under section 18, resulting in a variety of rules that protect consumers.166 In recent years, however, the Commission has shied away from extensive section 18 rulemaking.167 The new Democratic majority at the Commission has already taken action to make section 18 rulemaking more viable by bringing Commission procedures in line with statutory requirements and congressional intent."
728,"Algorithms and Economic Justice | Rebecca Kelly Slaughter 55 In the area of algorithmic justice, a section 18 rule might affirmatively impose requirements of transparency, fairness, and accountability."
728,"While privacy legislation may not seem directly applicable to the problems we are discussing today, it can in fact play an important role in addressing algorithmic justice—and it is worth noting that the algorithmic-justice requirements imposed in Europe were done as a part of its privacy law, the GDPR."
728,"The Algorithmic Justice and Online Platform Transparency Act also provides strong civil rights provisions, building upon the transparency requirements of the Algorithmic Accountability Act and adding the civil rights protections Algorithms and Economic Justice | Rebecca Kelly Slaughter 57 of data on the basis of an individual’s actual or perceived protected status for the purpose of marketing in a manner that unlawfully discriminates or otherwise makes the opportunity unavailable to the individual or class of individuals.178 The proposed bill also prohibits the processing or transfer of data in a manner that unlawfully segregates, discriminates against, or otherwise makes unavailable the goods, services, or facilities of any place of public accommodations."
728,See Algorithmic Justice and Online Platform Transparency Act S.
728,"Algorithms could promote economic justice by helping distribute opportunities more broadly, resources more efficiently, and benefits more effectively."
728,Algorithms and Economic Justice | Rebecca Kelly Slaughter 59 Acknowledgements I would like to thank the many colleagues and experts who generously helped this article take shape through their insights and contributions.
73,"China’s strategy, for example, proposes a system of public services underpinned by AI, from education, to healthcare, to justice, as well as AI having a key role in policy-making itself.15 Other countries are creating new institutions and networks to oversee AI research and implementation."
73,"Digitalization, Anticorruption, Rule of Law and Competition PolicyBritish Embassy in Mexico City International Cooperation Carla Vazquez RUCAM Ministry of Economy Government Carlos Gershenson Researcher Metro CDMX/ UNAM Academia CDMX Carlos López Franco Researcher UDG/CUCEI Jal Academia Chris WallHead of Human Rights, Security and Justice at the British Embassy in Mexico CityBritish Embassy in Mexico City International Cooperation Claudia Araujo GálvezCoordinator of Development of Industrial Technological PlatformsMinistry of Innovation, Science and TechnologyJal Govt Claudia Pando Programme Manager, Future Cities British Embassy in Mexico City International Cooperation Cristina Cardenas General Coordinator @prende.mx SEP Government David Bates Social Innovation Programmes CoordinatorMinistry of Innovation, Science and TechnologyJal Govt Edgar Nelson Sánchez CamperosResearcher CINVESTAV Jal Academia Eduardo Barbosa Emerging Technologies Director Ciudad Creativa Digital Jal Govt Eduardo Clark Public Innovation Deputy Director CEDN Government Eduardo Farina BluemessagingCEO Bluemessaging Start-up Eduardo Morales AI Phd INAOE Puebla Academia Elsa Ayala General Director of Normatividad Mercantil Ministry of Economy Government Enrique Jaime Herrera LópezResearcher CIATEJ Jal Academia Enrique Sucar Senior Research Scientist INAOEP Academia Enrique Zapata General Director for Open Data CEDN Government Fernando CotaTechnical Secretary of the Urban Development Commission Senate Government Francisco Búrquez SenatorMember of the Science and Technology CommissionLegislative branch Gabriella Gomez Mont Director Laboratorio de la Ciudad CDMX Govt Gerardo Rodríguez BarbaDirector of Technological Platforms Development and PromotionMinistry of Innovation, Science and TechnologyJal Govt Gustavo Carreon Researcher Metro CDMX/ UNAM Academia CDMX Gustavo Pares Nearshore CEO Nearshore Start-up Isaac Avila Coordinator CANIETI Occidente GDL Industry Ivan Millan General Director Jalisco Talent Land GDL Javier Mata Yalo CEO Yalo Start-up Jessica Paola Avila Open Data Director SEPAF Gobierno Jalisco Jal Govt Appendix 1: List of participants who contributed to this report TOWARDS AN AI STRATEGY IN MEXICO: Harnessing the AI Revolution 40 Name Job Title Organisation Sector Jesus Cepeda CEO One Smart City MTY Civil Society/Consultancy José Cantoral Researcher CIATEQ Jal Academia Jose Franco General CoordinatorForo Consultivo Científico y TecnológicoAcademia / Civil Society Juan Pablo Escobar Director Civica Digital MTY Civil Society/Consultancy Katie Allan Associate Oxford Insights Consultancy Laura Caccia Consultant Oxford Insights Consultancy Lorenzo ValleDirector - Center for Business Development in IT and Big Data InitiativeTEC Academia Lorenzo Valle Garcilazo ITESMBig Data Center Coordinator ITESM Academia Luis Cadena General Administrator of Communications and ICT SAT, SHCP Government Luis Valtierra President IJALTI Cluster Manuel Avalos IBM Storage Cloud and Solutions for IBM WW IBM/ Watson Jal Industry Margarita SolisGeneral Director of Social Innovation and Entrepreneurship Ministry of Innovation, Science and TechnologyJal Govt María de Lourdes Martínez Villaseñor, SMIAVocal SMIA Academia Marian UrizarFuture Cities Programme and Policy Officer– Programme TeamBritish Embassy in Mexico City International Cooperation Mario Angel Siller Gonzalez Researcher CINVESTAV Jal Academia Martha González PérezSandiDirector Cognitive Solutions, IBM Mexico Industry Matt Pasiensky VP of International Operations Wizeline GDL Industry Miguel Gonzalez President & Researcher SMIA, ITESM Academia Miguel González Mendoza President Mexico's AI Society Academia / Civil Society Miguel Salazar Director Ejecutivo Codeando Civil Society GDL Miriam Díaz Rodríguez Researcher/ Professor Tecnológico Mario Molina Jal Academia Morris Schwarzblat y KatzGeneral Director of Science and Technological DevelopmentMinistry of Innovation, Science and TechnologyJal Govt Nancy Guadalupe Arana Daniel Director, Systems Control & AI Center UDG/CUCEI Jal Academia Neil Hernández Gress ITESMResearcher ITESM Academia Olivia Barron AI PhD UDEM MTY Academia Oliver Rice Associate Oxford Insights Consultancy Omar Gonzalez KYSE Agritech UNAM CDMX Startup Raymundo Vazquez SW Engineering Manager INTEL Jal Industry Ricardo Reyes Data Wuki & Quantum LabsCEO Data Wuki and Quantum Labs Start-up Rodrigo FélixHead of Anti-corruption, Competition, Digitalisation and Rule Of Law PolicyBritish Embassy in Mexico City International Cooperation Saiph Savage Coordinator BanFakeNews Bot CDMX Sebastian Sposito Public Policy and Government Affairs Advisor Google Industry Sissi de la Peña Regional Markets CEDN Government Sophie Marment Head of Prosperity Fund FCO Government Tania Cruz Digital Government Services CEDN Government Victor Gutierrez Industry CCE Industry Yamin Ruiz Global Proteus CEO Global Proteus Start-up Yolanda Martinez Coordinator National Digital Strategy Government TOWARDS AN AI STRATEGY IN MEXICO: Harnessing the AI Revolution 41 Appendix 2: Innovation in Mexico’s Regions Jalisco, CDMX, and Nuevo Leon are leading the country’s science and technology scene."
74,"Other common principles include human oversight, explainability or interpretability, legal status of AI systems, and the equitable economic effect of AI.31 A separate analysis of 84 AI ethics documents done in 2019 found that there has been a global convergence around “transparency, justice and fairness, non-maleficence, responsibility and privacy.”32 While much progress has been made aligning on responsible AI, there remain differences—even among FCAI participants."
74,"Rules, Standards, and R&D Projects: Key areas for collaboration | ⮌ contents 62the importance of cross-border data flows as well as challenges to privacy and other values.211 Work to advance data free with trust has continued through the World Economic Forum.212 The “Schrems II” judgment by the Court of Justice of the European Union (CJEU) in 2020, however, has been a seismic event for international transfers of personal information, the aftershocks of which are still reverberating and magnify the impact of the EU regime."
74,"Kerry, ”The oracle at Luxembourg: The EU Court of Justice judges the world on surveillance and privacy,” The Brookings Institution, January 11, 2021, https://www.brookings.edu/ research/the-oracle-at-luxembourg-the-eu-court-of-justice-judges-the-world-on-surveillance-and-privacy/."
74,"Kerry, ”The oracle at Luxembourg: The EU Court of Justice judges the world on surveillance and privacy,” The Brookings Institution, January 11, 2021, https://www.brookings.edu/research/the-oracle-at-luxembourg-the-eu-court-of-justice-judges-the-world-onsurveillance-and-privacy/."
76,"Consumers must have a strong set of rights and access to effective remedies and redress mechanisms in case of harm, including collective redress. • Consumers should have the right to be given a clear explanation about how an AI system affect ing them works, and the right to object to an algorithmic decision that has a significant impact on them. • The proposal must also grant consumers the means to seek justice and redress in case of harm ."
76,"Access to justice and right to redress, including collective redres s .................."
76,57 See also section 7.6 on acces s to justice .
76,"Access to justice and right to redress , including collective redress Greater protection in terms of transparency, safety, non -discrimination, or fairness are vital before consumers can trust AI -powered products and services."
76,"However, it is equally important to ensure that consumers ha ve access to justice if AI -associated risks materialise."
76,Representative a ctions are their only realistic possibility to seek justice .
76,96 An Advocate -General from the Court of Justice of the European Union has already referred to standardisation as “ legislative delegation in favour of a private standardisation bo dy”.
78,"Canada-France Statement on Artificial Intelligence Skip to main content Skip to ""About government"" Language selection Français Government of Canada Search Search website Search Menu Main Menu Jobs and the workplace Immigration and citizenship Travel and tourism Business and industry Benefits Health Taxes Environment and natural resources National security and defence Culture, history and sport Policing, justice and emergencies Transport and infrastructure Canada and the world Money and finances Science and innovation You are here: Canada.ca Canada and the worldForeign policy and international relations Canada's partnerships and priorities by world regionCanada and EuropeCanada-France Statement on Artificial Intelligence Canada-France Statement on Artificial IntelligenceCanada and France affirm that artificial intelligence is a revolution whose impact is being felt more and more each day."
78,"By the end of the year, the task force will submit a report on the implementation of the international study group, whose results will be shared within the G7.For the Government of CanadaNavdeep Singh BAINSMinister of Innovation, Science and Economic DevelopmentFor the Government of the French RepublicFrédérique VIDALMinister of Higher Education, Research and Innovation Date modified: 2018-06-07 About this site Government of Canada All contacts Departments and agencies About government Themes and topics Jobs and the workplace Immigration and citizenship Travel and tourism Business and industry Benefits Health Taxes Environment and natural resources National security and defence Culture, history and sport Policing, justice and emergencies Transport and infrastructure Canada and the world Money and finances Science and innovation Indigenous Peoples Veterans and military Youth About government Social media Mobile applications About Canada.ca Terms and conditions Privacy"
83,"Accept additional cookies Reject additional cookies View cookies Hide cookie message Skip to main content GOV.UK Navigation menu Menu Menu Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments Departments, agencies and public bodies News News stories, speeches, letters and notices Guidance and regulation Detailed guidance, regulations and rules Research and statistics Reports, analysis and official statistics Policy papers and consultations Consultations and strategy Transparency Data, Freedom of Information releases and corporate reports Search GOV.UK × Search GOV.UK Search Search GOV.UK Search Home Government Government efficiency, transparency and accountability Data Ethics Framework GovernmentDigital Service Central Digital & Data Office Guidance Data Ethics Framework Updated 16 September 2020 Contents How to use the Data Ethics Framework Overarching principles Specific actions Next steps Print this page © Crown copyright 2020 This publication is licensed under the terms of the Open Government Licence v3.0 except where otherwise stated."
83,"Cancel Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments News Guidance and regulation Research and statistics Policy papers and consultations Transparency How government works Get involved Support links Help Privacy Cookies Accessibility statement Contact Terms and conditions Rhestr o Wasanaethau Cymraeg Government Digital Service All content is available under the Open Government Licence v3.0, except where otherwise stated © Crown copyright"
84,"Accept additional cookies Reject additional cookies View cookies Hide cookie message Skip to main content GOV.UK Navigation menu Menu Menu Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments Departments, agencies and public bodies News News stories, speeches, letters and notices Guidance and regulation Detailed guidance, regulations and rules Research and statistics Reports, analysis and official statistics Policy papers and consultations Consultations and strategy Transparency Data, Freedom of Information releases and corporate reports Search GOV.UK × Search GOV.UK Search Search GOV.UK Search Home Independent report COVID-19 repository and public attitudes retrospective The CDEI has published new research on the use of AI and data-driven technology in the UK’s COVID-19 response, highlighting insights into public attitudes, as well as trends it has identified."
84,"Cancel Services and information Benefits Births, death, marriages and care Business and self-employed Childcare and parenting Citizenship and living in the UK Crime, justice and the law Disabled people Driving and transport Education and learning Employing people Environment and countryside Housing and local services Money and tax Passports, travel and living abroad Visas and immigration Working, jobs and pensions Government activity Departments News Guidance and regulation Research and statistics Policy papers and consultations Transparency How government works Get involved Support links Help Privacy Cookies Accessibility statement Contact Terms and conditions Rhestr o Wasanaethau Cymraeg Government Digital Service All content is available under the Open Government Licence v3.0, except where otherwise stated © Crown copyright"
85,"Society may reasonably conclude that justice requires decision-making processes to be designed so that human judgment can intervene where needed to achieve fair and reasonable outcomes for each person, informed by individual evidence."
85,"For example, the 2017 Lammy Review81 found that BAME individuals faced bias, including overt discrimination, in parts of the justice system."
85,"Whilst there is no current evidence of police algorithms in the UK being racially biased, one can certainly see the risks of algorithms entrenching and amplifying widely documented human biases and prejudices, in particular against BAME individuals, in the criminal justice system."
85,"94 CDEI have published a research paper on facial recognition technology, which covers police use of live facial recognition technology, along with other uses; https://www.gov.uk/ government/publications/cdei-publishes-briefing-paper-on-facial-recognition-technology/snapshot-paper-facial-recognition-technology 95 See for example: Richardson, Rashida and Schultz, Jason and Crawford, Kate, ‘Dirty Data, Bad Predictions: How Civil Rights Violations Impact Police Data, Predictive Policing Systems, and Justice’, AI Now Institute, https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3333423; Kearns, Ian and Rick Muir, ‘Data Driven Policing and Public Value’, The Police Foundation, 2019; http://www.police-foundation.org.uk/2017/wp-content/uploads/2010/10/data_driven_policing_final.pdf; ‘Policing By Machine’, Liberty, 2019; https://www.libertyhumanrights.org.uk/issue/ policing-by-machine/ 96 RUSI sent Freedom of Information requests to all police forces in England and Wales, interviewed over 60 people from police forces, technology providers, academia, civil society, government, and regulation, and ran roundtables, jointly with CDEI and TechUK."
85,"Review into bias in algorithmic decision-making: Policing Centre for Data Ethics and Innovation675.2 Findings 99 CDEI ‘Call for evidence summary of responses - Review into bias in algorithmic decision-making’, 2019; https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/ file/838426/CDEI-Call-for-Evidence-Bias-Summary-of-responses-October2019.pdf 100 Couchman, Hannah; ‘Policing by machine’, Liberty, 2019; https://www.gov.uk/government/publications/responses-to-cdei-call-for-evidence/cdei-bias-review-call-for-evidence-summary-of-responses 101 Robin Moore, ‘A Compendium of Research and Analysis on the Offender Assessment System (OASys) 2009–2013’, National Offender Management Service, Ministry of Justice Analytical Series, 2015; https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/449357/research-analysis-offender-assessment-system.pdf 102 The Guardian, ‘Met uses software that can be deployed to see if ethnic groups ‘specialise’ in areas of crime’, 2020; https://www.theguardian.com/uk-news/2020/jul/27/met-police-use-software-ethnicgroups-specialise-profileAlgorithms are in develo pment and use across some police forces in England and Wales but the picture i s varied From the responses we received to our call for evidence99 and wider research, we know there are challenges in defining what is meant by an algorithmic tool and consequently understanding the extent and scale of adoption."
85,"In England and Wales, police forces are currently taking a variety of different approaches to their development of algorithmic systems, ethical safeguards, community engagement and data science expertise.Review into bias in algorithmic decision-making: Policing Centre for Data Ethics and Innovation68103 See for example: Richardson, Rashida and Schultz, Jason and Crawford, Kate, ‘Dirty Data, Bad Predictions: How Civil Rights Violations Impact Police Data, Predictive Policing Systems, and Justice’, AI Now Institute, https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3333423 104 Home Office, ‘Police powers and procedures, England and Wales, year ending 31 March 2019’; https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_ data/file/841408/police-powers-procedures-mar19-hosb2519.pdf 105 Nesta, ‘Decision-making in the Age of the Algorithm’, 2019; https://media.nesta.org.uk/documents/Decision-making_in_the_age_of_the_algorithm.pdfMitigating bias and ensuring fairness requires looking at the entire decision-making process As set out earlier in the report, we think it is crucial to take a broad view of the whole decision-making process when considering the different ways bias can enter a system and how this might impact on fairness."
85,It could also influence how high or low risk certain crimes or areas are deemed by a data analytics tool and potentially perpetuate or exacerbate biased criminal justice outcomes for certain groups or individuals.
85,Research by the RSA and DeepMind113 highlights that people feel more strongly against the use of automated decision systems in the criminal justice system (60 percent of people oppose or strongly oppose its use in this domain) than other sectors such as financial services.
85,"Moreover, people are least familiar with the use of automated decision-making systems in the criminal justice system; 83 percent were either not very familiar or not at all familiar with its use."
85,"60 percent of people oppose or strongly oppose the use of automated decision systems in the criminal justice system.113 110 Police Foundation, ‘Data-Driven Policing and Public Value’, 2019; http://www.police-foundation.org.uk/2017/wp-content/uploads/2010/10/data_driven_policing_final.pdf 111 Quote from Rick Muir, Director of Police Foundation, in, Strategic View of Policing, ‘Sir Michael Barber to head major review of the police service’, 2019; https://policingreview.org.uk/ hello-world/ 112 https://www.gov.uk/government/publications/policing-by-consent/definition-of-policing-by-consent 113 Royal Society for the encouragement of Arts, Manufactures and Commerce, ‘Artificial Intelligence: Real Public Engagement’, 2018; https://www.thersa.org/globalassets/pdfs/reports/ rsa_artificial-intelligence---real-public-engagement.pdf 114 ‘Ipsos MORI Veracity Index 2019’; 76% survey respondents trust the police to tell the truth - an increase of 15ppt since 1983."
85,"Policing and public safety Source: Data Science in Local Government, Oxford Internet Institute, Bright et al 2019Review into bias in algorithmic decision-making: Local government Centre for Data Ethics and Innovation75 6.2 Findings 120 The Guardian, ‘One in three councils using algorithms to make welfare decisions’, 2019; https://www.theguardian.com/society/2019/oct/15/councils-using-algorithms-make-welfare-decisionsbenefits; and, Dencik, L. et al., ‘Data Scores as Governance: Investigating uses of citizen scoring in public services’, Data Justice Lab, Cardiff University, 2018; https://datajustice.files.wordpress. com/2018/12/data-scores-as-governance-project-report2.pdf 121 The Guardian, ‘One in three councils using algorithms to make welfare decisions’, 2019; https://www.theguardian.com/society/2019/oct/15/councils-using-algorithms-make-welfare-decisionsbenefits 122 Ibid.Our work on local government as a sector began with desk based research facilitated through our call for evidence and the landscape summary we commissioned."
85,"It is difficult to map how widespread algorithmic decision-making is in local government There have been multiple attempts to map the usage of algorithmic decision-making tools across local authorities but many researchers have found this challenging.120 An investigation by The Guardian found that, at a minimum, 140 councils out of 408 have invested in software contracts that cover identifying benefit fraud, identifying children at risk and allocating school places.121 However this did not include additional use cases found in a report by the Data Justice Lab, a research group based in Cardiff University."
85,The Data Justice Lab used Freedom of Information requests to learn which tools are being used and how frequently.
85,"123 House of Commons Library, ‘The Troubled Families programme (England), 2020; https://researchbriefings.parliament.uk/ResearchBriefing/Summary/CBP-7585 124 Dencik, L. et al., ‘Data Scores as Governance: Investigating uses of citizen scoring in public services’, Data Justice Lab, Cardiff University, 2018; https://datajustice.files.wordpress. com/2018/12/data-scores-as-governance-project-report2.pdf 125 The Guardian, ‘One in three councils using algorithms to make welfare decisions’, 2019; https://www.theguardian.com/society/2019/oct/15/councils-using-algorithms-make-welfaredecisions-benefits; and, Dencik, L. et al., ‘Data Scores as Governance: Investigating uses of citizen scoring in public services’, Data Justice Lab, Cardiff University, 2018; https://datajustice.files.wordpress.com/2018/12/data-scores-as-governance-project-report2.pdfReview into bias in algorithmic decision-making: Local government Centre for Data Ethics and Innovation 77Third-party providers offer specialist data science expertise that is likely not available to most local authorities and are likely to have valuable experience from previous work with other local authorities."
85,"126 Dencik, L. et al., ‘Data Scores as Governance: Investigating uses of citizen scoring in public services’, Data Justice Lab, Cardiff University, 2018, p34; https://datajustice.files.wordpress. com/2018/12/data-scores-as-governance-project-report2.pdf 127 CDEI, ‘Addressing trust in public sector data use’, 2020; https://datajustice.files.wordpress.com/2018/12/data-scores-as-governance-project-report2.pdfReview into bias in algorithmic decision-making: Local government Centre for Data Ethics and Innovation78128 What Works for Children’s Social Care, ‘Ethics Review of Machine Learning in Children’s Social Care’, 2020; https://whatworks-csc.org.uk/wp-content/uploads/WWCSC_Ethics_of_Machine_ Learning_in_CSC_Jan2020.pdfGovernment departments such as the Department for Education, who oversee children’s social care and the Ministry of Housing, Communities, and Local Government (MHCLG) are well placed to support and coordinate the development of national guidance.National guidance is needed to govern the use of algorithms in the delivery of public services There is currently little guidance for local authorities wanting to use algorithms to assist decision-making."
85,"P.; and Weller, A.; ‘Blind Justice: Fairness with Encrypted Sensitive Attributes’."
85,"P., and Weller, A., ‘Blind Justice: Fairness with Encrypted Sensitive Attributes’."
85,"Review into bias in algorithmic decision-making: Enabling fair innovation Centre for Data Ethics and Innovation96 Centre for Data Ethics and Innovation 96160 House of Commons Justice Committee, ‘Court and Tribunal reforms, Second Report of Session 2019’; https://publications.parliament.uk/pa/cm201919/cmselect/cmjust/190/190.pdf 161 Lord Chancellor; Lord Chief Justice; Senior President of Tribunals, ‘Transforming Our Justice System’, 2016; https://assets.publishing.service.gov.uk/government/uploads/system/uploads/ attachment_data/file/553261/joint-vision-statement.pdf 162 Administrative Data Research UK, ‘Data First, Harnessing the Potential of linked administrative data for the justice system’, ongoing; https://www.adruk.org/our-work/browse-all-projects/ data-first-harnessing-the-potential-of-linked-administrative-data-for-the-justice-system-169/ 163 Ibid.Case study: Monitoring for bias in digital transformation of the courts Accessing protected characteristic data to monitor outcomes is not only necessary when introducing algorithmic decisionmaking, but also when making other major changes to significant decision-making processes."
85,"They have worked with the Government Statistical Service’s Harmonisation Team and academic researchers to rebuild their data architecture to support this.163 The resulting information is intended to both be valuable to the Ministry of Justice for designing fair interventions in the functioning of the courts, but also eventually to be made available for independent academic research (via Administrative Data Research UK and the Office for National Statistics)."
85,"Ultimately, humans must choose which notions of fairness an algorithm will work to, taking wider notions and considerations into account, and recognising that there will always be aspects of fairness outside of any statistical definition.Review into bias in algorithmic decision-making: Enabling fair innovation Centre for Data Ethics and Innovation99An example of how these different definitions play out in practice can be seen in the US criminal justice system, as per the following case study.Group Individual • Demographic parity - outcomes for different protected groups are equally distributed, and statistically independent."
85,"Review into bias in algorithmic decision-making: The regulatory environment Centre for Data Ethics and Innovation113186 Lord Sales, Justice of the UK Supreme Court; ‘Algorithms, Artificial Intelligence and the Law’, The Sir Henry Brooke Lecture for BAILI, 2019; https://www.supremecourt.uk/ docsspeech-191112.pdf In support of this legislation, there are two primary cross-cutting regulators: the Equality and Human Rights Commission (EHRC, for the Equality Act and Human Rights Act) and the Information Commissioner’s Office (ICO, for the Data Protection Act and the GDPR)."
85,"For example, the ruling by the European Court of Justice in the Test-Achats case made it unlawful for insurers to charge different rates based on sex or gender.200 UK car insurance providers had routinely charged higher premiums for men, based on their higher expected claims profile."
85,"Instead the implications of new technologies for the justice system, transport provision and decisionmaking in the workplace are captured within those specific programmes."
85,"It also recently completed an inquiry into the experiences of people with disabilities in the criminal justice system, including the challenges arising from a move towards digital justice, and has undertaken research into the potential for discrimination in using AI in recruitment."
85,"For example, an investigation by The Guardian last year (https://www.theguardian.com/society/2019/oct/15/councils-using-algorithms-make-welfaredecisions-benefits) showed some 140 of 408 councils in the UK are using privately-developed algorithmic ‘risk assessment’ tools, particularly to determine eligibility for benefits and to calculate entitlements; the New Statesman (https://www.newstatesman.com/science-tech/technology/2019/07/revealed-how-citizen-scoring-algorithms-are-being-used-local) revealed that Experian secured £2m from British councils in 2018; and Data Justice Lab research in late 2018 (https://datajustice.files.wordpress.com/2018/12/data-scores-as-governance-project-report2.pdf) showed 53 out of 96 local authorities and about a quarter of police authorities are now using algorithms for prediction, risk assessment and assistance in decision-making."
85,"These could include social care, criminal justice or benefits allocation."
85,"By making publication of information a truly proactive process it can help government: • Build in expectations of what will eventually have to be published at the early stages of projects. • Structure releases in a consistent way which hopefully helps external groups (e.g. journalists, academia and civil society) engage with the data being published in an effective way, i.e. over time fewer genuine misunderstandings in the communication. • Manage the overhead of responding to large numbers of similar reactive requests.Review into bias in algorithmic decision-making: Transparency in the public sector Centre for Data Ethics and Innovation139253 House of Commons Science and Technology Committee, ‘Algorithms in decision-making, Fourth Report of Session 2017-19’; https://publications.parliament.uk/pa/cm201719/cmselect/ cmsctech/351/351.pdf 254 The Law Society, ‘Algorithms in the criminal justice system’, 2019; https://www.lawsociety.org.uk/support-services/research-trends/algorithm-use-in-the-criminal-justice-system-report/ 255 Guidance: Gender pay gap reporting: overview; https://www.gov.uk/guidance/gender-pay-gap-reporting-overviewManaging the process of transparency The House of Lords Science and Technology Select Committee and the Law Society have both recently recommended that parts of the public sector should maintain a register of algorithms in development or use."
85,"Quote “... the Government should produce, publish, and maintain a list of where algorithms with significant impacts are being used within Central Government, along with projects underway or planned for public service algorithms, to aid not just private sector involvement but also transparency.” - House of Lords Science and Technology Select Committee253 Quote “A National Register of Algorithmic Systems should be created as a crucial initial scaffold for further openness, cross-sector learning and scrutiny.” - The Law Society ‘Algorithms in the Criminal Justice System’254 CDEI agrees that there are some significant advantages both to government and citizens in some central coordination around this transparency."
87,"AnnexIII: ·Remote biometric identification and categorisation of natural persons (e.g. a system classifying the number of people of different skin tones walking down a street) ·Management and operation of critical infrastructure (road traffic and the supply of water , gas, heating, and electricity) ·Education and vocational training, where systems are used for e.g. admission and grading ·Employment, worker management, and access to self-employment opportunities, including systems that make or inform decisions about hiring, firing, and task allocation ·Access to and enjoyment of essential private services and public services and benefits ·Specific uses of law enforcement ·Specific uses in migration, asylum, and border control management ·Administration of justice and democratic processes, in particular when used to research and establish facts or applying the law to some factsProviders of high-risk systems must perform a conformity assessment to make sure that they are compliant with requirements including: ·Risk management system ·Data requirements ·T echnical documentation ·Record-keeping ·T ransparency on the system’s functioning ·Human oversight ·Accuracy, robustness, and cybersecurity ·Post-market monitoringFines up to 4% of global revenue or 20mn euros, whichever is higher, for everything except the data requirements, where the same fines apply as for the prohibited systems LimitedRisk: Transparency Obligations (TitleIV)·AI systems interacting with natural persons ·Emotion recognition systems or biometric categorisation systems ·AI system that generates or manipulates image, audio, or video content that appears realNotify the user that they are engaging with an AI systemFines up to 4% of global revenue or 20mn euros, whichever is higher MinimalRisk: Voluntary Codesof Conduct (TitleIX)All AI systems that are not either prohibited or high- riskProviders can choose to comply with voluntary codes of conduct."
87,"276European Commission and Directorate-General for Justice and Consumers, Liability for Artificial Intelligence and Other Emerging Digital Technologies (Publications Office of the European Union, 2019); European Commission, “InceptionImpactAssessment:ProposalforaDirectiveAdaptingLiability RulestotheDigitalAgeandArtificialIntelligence.” 277“The EU Product Liability Directive (PLD), that governs the responsibility for such defects, should be applied ‘without prejudice’ to the product safety regime” European Parliament, “Directive2001/95/ECoftheEuropeanParliamentandoftheCouncilof3December2001onGeneralProductSafety (TextwithEEARelevance),” CELEX number: 32001L0095, Official Journal of the European Union L 11, January 15, 2002, 4–17, art."
87,"Schwartz, “Global Data Privacy: The EU Way.” 406Court of Justice of the European Union, “Judgment in Case C-362/14 Maximillian Schrems v Data Protection Commissioner: The Court of Justice DeclaresThattheCommission’sUSSafeHarbourDecisionIsInvalid,” Press Release 117/15 (Court of Justice of the European Union , October 6, 2015); European Commission, “EU-US Data Transfers: How Personal Data Transferred between the EU and US Is Protected,” European Commission, accessed July 14, 2022."
87,"Both agreements were adopted even though the US data privacy standards were not equivalent to the EU, which is a requirement for data transmission agreements in both the DPD and GDPR.405Consequently, both data transmission agreements were declared invalid by the European Court of Justice (ECJ) in 2015 and 2020, respectively.406Since 2020, the US and the Commission have stated their intention to negotiate a new agreement."
87,Court of Justice of the European Union.
87,“ Judgment in Case C-362/14 Maximillian Schrems v Data Protection Commissioner: The Court of Justice Declares That the Commission’s US Safe Harbour Decision Is Invalid. ” Press Release 117/15.
87,"Court of Justice of the European Union , October 6, 2015. https://curia.europa.eu/jcms/upload/docs/application/pdf/2015-10/cp150117en.pdf ."
87,"“The EU Code of Conduct on Countering Illegal Hate Speech Online: The Robust Response Provided by the European Union. ” Accessed July 11, 2022. https://ec.europa.eu/info/policies/justice-and-funda- THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•87 mental-rights/combatting-discrimination/racism-and-xenophobia/eu-code-conduct-countering-illegalhate-speech-online_en . ———."
87,"European Commission, and Directorate-General for Justice and Consumers."
88,"AnnexIII: ·Remote biometric identification and categorisation of natural persons (e.g. a system classifying the number of people of different skin tones walking down a street) ·Management and operation of critical infrastructure (road traffic and the supply of water , gas, heating, and electricity) ·Education and vocational training, where systems are used for e.g. admission and grading ·Employment, worker management, and access to self-employment opportunities, including systems that make or inform decisions about hiring, firing, and task allocation ·Access to and enjoyment of essential private services and public services and benefits ·Specific uses of law enforcement ·Specific uses in migration, asylum, and border control management ·Administration of justice and democratic processes, in particular when used to research and establish facts or applying the law to some factsProviders of high-risk systems must perform a conformity assessment to make sure that they are compliant with requirements including: ·Risk management system ·Data requirements ·T echnical documentation ·Record-keeping ·T ransparency on the system’s functioning ·Human oversight ·Accuracy, robustness, and cybersecurity ·Post-market monitoringFines up to 4% of global revenue or 20mn euros, whichever is higher, for everything except the data requirements, where the same fines apply as for the prohibited systems LimitedRisk: Transparency Obligations (TitleIV)·AI systems interacting with natural persons ·Emotion recognition systems or biometric categorisation systems ·AI system that generates or manipulates image, audio, or video content that appears realNotify the user that they are engaging with an AI systemFines up to 4% of global revenue or 20mn euros, whichever is higher MinimalRisk: Voluntary Codesof Conduct (TitleIX)All AI systems that are not either prohibited or high- riskProviders can choose to comply with voluntary codes of conduct."
88,"276European Commission and Directorate-General for Justice and Consumers, Liability for Artificial Intelligence and Other Emerging Digital Technologies (Publications Office of the European Union, 2019); European Commission, “InceptionImpactAssessment:ProposalforaDirectiveAdaptingLiability RulestotheDigitalAgeandArtificialIntelligence.” 277“The EU Product Liability Directive (PLD), that governs the responsibility for such defects, should be applied ‘without prejudice’ to the product safety regime” European Parliament, “Directive2001/95/ECoftheEuropeanParliamentandoftheCouncilof3December2001onGeneralProductSafety (TextwithEEARelevance),” CELEX number: 32001L0095, Official Journal of the European Union L 11, January 15, 2002, 4–17, art."
88,"Schwartz, “Global Data Privacy: The EU Way.” 406Court of Justice of the European Union, “Judgment in Case C-362/14 Maximillian Schrems v Data Protection Commissioner: The Court of Justice DeclaresThattheCommission’sUSSafeHarbourDecisionIsInvalid,” Press Release 117/15 (Court of Justice of the European Union , October 6, 2015); European Commission, “EU-US Data Transfers: How Personal Data Transferred between the EU and US Is Protected,” European Commission, accessed July 14, 2022."
88,"Both agreements were adopted even though the US data privacy standards were not equivalent to the EU, which is a requirement for data transmission agreements in both the DPD and GDPR.405Consequently, both data transmission agreements were declared invalid by the European Court of Justice (ECJ) in 2015 and 2020, respectively.406Since 2020, the US and the Commission have stated their intention to negotiate a new agreement."
88,Court of Justice of the European Union.
88,“ Judgment in Case C-362/14 Maximillian Schrems v Data Protection Commissioner: The Court of Justice Declares That the Commission’s US Safe Harbour Decision Is Invalid. ” Press Release 117/15.
88,"Court of Justice of the European Union , October 6, 2015. https://curia.europa.eu/jcms/upload/docs/application/pdf/2015-10/cp150117en.pdf ."
88,"“The EU Code of Conduct on Countering Illegal Hate Speech Online: The Robust Response Provided by the European Union. ” Accessed July 11, 2022. https://ec.europa.eu/info/policies/justice-and-funda- THEBRUSSELSEFFECTANDARTIFICIALINTELLIGENCE•87 mental-rights/combatting-discrimination/racism-and-xenophobia/eu-code-conduct-countering-illegalhate-speech-online_en . ———."
88,"European Commission, and Directorate-General for Justice and Consumers."
89,"Such systems can therefore be ex pected to act in line with the norms and values of a humane society, including fairness, justice, ethics, responsibility and trustworthinessControl: HCAI preserves human agency and sense of re sponsibility by designing AI systems to give users a high level of understanding of, and control over, their specific and unique processes and outputsThis manifesto emerges from the frustrations and concerns shared among researchers at AiTH: about the state of discourse on AI ethics and trustworthiness, about the unquestioned dominance of Big Tech, and about the deficiencies of techno-solutionist and machine-centred approaches to AI."
9,"If the data is not representative for minority populations then it could be potentially harmful.’ Berk Ustun, Postdoctoral Fellow, Center for Research in Computation and Society, Harvard University ‘There should be a notion amongst patients, society and the general population that there is a societal good in sharing their data to make sure that health related algorithms are as fair and beneficial as possible.’ Finale Doshi-Velez, Assistant Professor in Computer Science at the Harvard Paulson School of Engineering and Applied ScienceRacial bias in criminal justice algorithms The Correctional Offender Management Profiling for Alternative Sanctions (COMPAS) is an algorithmic risk score used to help judges in certain US states decide sentencing, by predicting a defendant’s risk of reoffending."
91,"Khoo said that racial justice activists, whom she and her colleagues talked to in the context of the research conducted for the Citizen Lab report, consider the use of algorithmic technologies by police t o be 21st -century state violence: before it was done with pen and paper, now it is done with computers and algorithms.20 Ms."
91,"The RCMP also confirmed that no ethics review was done before using Clearview AI’s FRT.26 Roch Séguin , director of the Strategic Services Branch, Technical Operations, said that the RCMP had approached the Department of Justice regarding the use of FRTs in its investigations only once, but it was internal to the RCMP ."
91,17 (Justice La Forest).
91,"In April 2022, the Scottish Commissioner published a draft code of practice on the acquisition, retention, use and destruction of biometric data for criminal justice and police purposes in Scotland."
93,"The development of artificial intelligence should ensure fairness and justice, avoid bias or discrimination against specific groups or individuals, and avoid placing disadvantaged people in an even more unfavorable position.Article 4: Avoid harm."
96,"“When a Computer Program Keeps You in Jail.” New York Times , June 13. www.nytimes.com/2017/06/13/opinion/howcomputers-are-harming-criminal-justice.html."
97,"Seven values underpin these ethical guidelines: well -being, autonomy, justice, privacy, knowledge, democracy and responsibility."
